{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "920c2a79-4646-4f09-8fc0-9c6f9197250e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import this"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab6322f2-2326-4e12-ad4d-d93c5e4195dc",
   "metadata": {
    "tags": []
   },
   "source": [
    "# What is this code doing?\n",
    "\n",
    "* Divides dataset to 10 category in simulation.\n",
    "\n",
    "* Trains GM.\n",
    "\n",
    "* Prunes GM & Show Results.\n",
    "\n",
    "* Shows participation & global sparsity results.\n",
    "\n",
    "* Use standart Federated Learning as baseline.\n",
    "\n",
    "***\n",
    "### Core contributions:\n",
    "\n",
    "* Pruning increase model sparsification significantly while still preserve a good performance. \n",
    "\n",
    "* Thus, to use in Federated Learning system, a group of talented devices in terms of hardware can train a dense model and then gradually rise sparsification threshold of model to assign them as proper initial global model for model contrainted devices. \n",
    "\n",
    "* As a result, those assigned proper models own tuned parameters from previous training, which act as transfer learning and increase model generality (1). Moreover, number of devices participate to Federated Learning system is increased by using a trainable model (2).\n",
    "\n",
    "* Beside, our model works with quantisation method as well, by representing 32 float bits with smaller integer bits. Thus, reduce training time and communication overhead.\n",
    "\n",
    "* Furthermore, since each device trains their proper model, syncronisation during training is also rises."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55c824a3-b11b-4535-aece-048e9db387ad",
   "metadata": {},
   "source": [
    "***\n",
    "# Install Necessary Libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4f531e7f-81e1-4fa7-a9f0-6f17ee2b096d",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: flwr[simulation] in /usr/local/lib/python3.10/dist-packages (0.19.0)\n",
      "Collecting flwr[simulation]\n",
      "  Using cached flwr-1.3.0-py3-none-any.whl (139 kB)\n",
      "Requirement already satisfied: iterators<0.0.3,>=0.0.2 in /usr/local/lib/python3.10/dist-packages (from flwr[simulation]) (0.0.2)\n",
      "Requirement already satisfied: protobuf<4.0.0,>=3.19.0 in /usr/local/lib/python3.10/dist-packages (from flwr[simulation]) (3.20.3)\n",
      "Requirement already satisfied: grpcio!=1.52.0,<2.0.0,>=1.43.0 in /usr/local/lib/python3.10/dist-packages (from flwr[simulation]) (1.51.1)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from flwr[simulation]) (1.24.1)\n",
      "Requirement already satisfied: ray[default]<2.3.0,>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from flwr[simulation]) (2.2.0)\n",
      "Requirement already satisfied: jsonschema in /usr/local/lib/python3.10/dist-packages (from ray[default]<2.3.0,>=2.2.0->flwr[simulation]) (4.17.3)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from ray[default]<2.3.0,>=2.2.0->flwr[simulation]) (3.9.0)\n",
      "Requirement already satisfied: virtualenv>=20.0.24 in /usr/local/lib/python3.10/dist-packages (from ray[default]<2.3.0,>=2.2.0->flwr[simulation]) (20.17.1)\n",
      "Requirement already satisfied: frozenlist in /usr/local/lib/python3.10/dist-packages (from ray[default]<2.3.0,>=2.2.0->flwr[simulation]) (1.3.3)\n",
      "Requirement already satisfied: aiosignal in /usr/local/lib/python3.10/dist-packages (from ray[default]<2.3.0,>=2.2.0->flwr[simulation]) (1.3.1)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from ray[default]<2.3.0,>=2.2.0->flwr[simulation]) (23.0)\n",
      "Requirement already satisfied: msgpack<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from ray[default]<2.3.0,>=2.2.0->flwr[simulation]) (1.0.4)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from ray[default]<2.3.0,>=2.2.0->flwr[simulation]) (6.0)\n",
      "Requirement already satisfied: attrs in /usr/local/lib/python3.10/dist-packages (from ray[default]<2.3.0,>=2.2.0->flwr[simulation]) (22.2.0)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from ray[default]<2.3.0,>=2.2.0->flwr[simulation]) (2.28.2)\n",
      "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.10/dist-packages (from ray[default]<2.3.0,>=2.2.0->flwr[simulation]) (8.1.3)\n",
      "Requirement already satisfied: smart-open in /usr/local/lib/python3.10/dist-packages (from ray[default]<2.3.0,>=2.2.0->flwr[simulation]) (6.3.0)\n",
      "Requirement already satisfied: prometheus-client<0.14.0,>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from ray[default]<2.3.0,>=2.2.0->flwr[simulation]) (0.13.1)\n",
      "Requirement already satisfied: gpustat>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from ray[default]<2.3.0,>=2.2.0->flwr[simulation]) (1.0.0)\n",
      "Requirement already satisfied: pydantic in /usr/local/lib/python3.10/dist-packages (from ray[default]<2.3.0,>=2.2.0->flwr[simulation]) (1.10.4)\n",
      "Requirement already satisfied: aiohttp>=3.7 in /usr/local/lib/python3.10/dist-packages (from ray[default]<2.3.0,>=2.2.0->flwr[simulation]) (3.8.3)\n",
      "Requirement already satisfied: aiohttp-cors in /usr/local/lib/python3.10/dist-packages (from ray[default]<2.3.0,>=2.2.0->flwr[simulation]) (0.7.0)\n",
      "Requirement already satisfied: py-spy>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from ray[default]<2.3.0,>=2.2.0->flwr[simulation]) (0.3.14)\n",
      "Requirement already satisfied: opencensus in /usr/local/lib/python3.10/dist-packages (from ray[default]<2.3.0,>=2.2.0->flwr[simulation]) (0.11.1)\n",
      "Requirement already satisfied: colorful in /usr/local/lib/python3.10/dist-packages (from ray[default]<2.3.0,>=2.2.0->flwr[simulation]) (0.5.5)\n",
      "Collecting charset-normalizer<3.0,>=2.0\n",
      "  Downloading charset_normalizer-2.1.1-py3-none-any.whl (39 kB)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp>=3.7->ray[default]<2.3.0,>=2.2.0->flwr[simulation]) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp>=3.7->ray[default]<2.3.0,>=2.2.0->flwr[simulation]) (1.8.2)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp>=3.7->ray[default]<2.3.0,>=2.2.0->flwr[simulation]) (4.0.2)\n",
      "Requirement already satisfied: blessed>=1.17.1 in /usr/local/lib/python3.10/dist-packages (from gpustat>=1.0.0->ray[default]<2.3.0,>=2.2.0->flwr[simulation]) (1.19.1)\n",
      "Requirement already satisfied: psutil>=5.6.0 in /usr/local/lib/python3.10/dist-packages (from gpustat>=1.0.0->ray[default]<2.3.0,>=2.2.0->flwr[simulation]) (5.9.4)\n",
      "Requirement already satisfied: nvidia-ml-py<=11.495.46,>=11.450.129 in /usr/local/lib/python3.10/dist-packages (from gpustat>=1.0.0->ray[default]<2.3.0,>=2.2.0->flwr[simulation]) (11.495.46)\n",
      "Requirement already satisfied: six>=1.7 in /usr/local/lib/python3.10/dist-packages (from gpustat>=1.0.0->ray[default]<2.3.0,>=2.2.0->flwr[simulation]) (1.16.0)\n",
      "Requirement already satisfied: platformdirs<3,>=2.4 in /usr/local/lib/python3.10/dist-packages (from virtualenv>=20.0.24->ray[default]<2.3.0,>=2.2.0->flwr[simulation]) (2.6.2)\n",
      "Requirement already satisfied: distlib<1,>=0.3.6 in /usr/local/lib/python3.10/dist-packages (from virtualenv>=20.0.24->ray[default]<2.3.0,>=2.2.0->flwr[simulation]) (0.3.6)\n",
      "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema->ray[default]<2.3.0,>=2.2.0->flwr[simulation]) (0.19.3)\n",
      "Requirement already satisfied: google-api-core<3.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from opencensus->ray[default]<2.3.0,>=2.2.0->flwr[simulation]) (2.11.0)\n",
      "Requirement already satisfied: opencensus-context>=0.1.3 in /usr/local/lib/python3.10/dist-packages (from opencensus->ray[default]<2.3.0,>=2.2.0->flwr[simulation]) (0.1.3)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic->ray[default]<2.3.0,>=2.2.0->flwr[simulation]) (4.4.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->ray[default]<2.3.0,>=2.2.0->flwr[simulation]) (1.26.14)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->ray[default]<2.3.0,>=2.2.0->flwr[simulation]) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->ray[default]<2.3.0,>=2.2.0->flwr[simulation]) (2022.12.7)\n",
      "Requirement already satisfied: wcwidth>=0.1.4 in /usr/local/lib/python3.10/dist-packages (from blessed>=1.17.1->gpustat>=1.0.0->ray[default]<2.3.0,>=2.2.0->flwr[simulation]) (0.2.6)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.56.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core<3.0.0,>=1.0.0->opencensus->ray[default]<2.3.0,>=2.2.0->flwr[simulation]) (1.58.0)\n",
      "Requirement already satisfied: google-auth<3.0dev,>=2.14.1 in /usr/local/lib/python3.10/dist-packages (from google-api-core<3.0.0,>=1.0.0->opencensus->ray[default]<2.3.0,>=2.2.0->flwr[simulation]) (2.16.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0dev,>=2.14.1->google-api-core<3.0.0,>=1.0.0->opencensus->ray[default]<2.3.0,>=2.2.0->flwr[simulation]) (4.9)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0dev,>=2.14.1->google-api-core<3.0.0,>=1.0.0->opencensus->ray[default]<2.3.0,>=2.2.0->flwr[simulation]) (5.3.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0dev,>=2.14.1->google-api-core<3.0.0,>=1.0.0->opencensus->ray[default]<2.3.0,>=2.2.0->flwr[simulation]) (0.2.8)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3.0dev,>=2.14.1->google-api-core<3.0.0,>=1.0.0->opencensus->ray[default]<2.3.0,>=2.2.0->flwr[simulation]) (0.4.8)\n",
      "Installing collected packages: flwr, charset-normalizer\n",
      "Successfully installed charset-normalizer-2.1.1 flwr-1.3.0\n"
     ]
    }
   ],
   "source": [
    "!pip install -U flwr[\"simulation\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9ac6ae98-9cc7-409d-ab9f-ac9eb442030a",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting flwr==0.19.0\n",
      "  Downloading flwr-0.19.0-py3-none-any.whl (106 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m106.5/106.5 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: iterators<0.0.3,>=0.0.2 in /usr/local/lib/python3.10/dist-packages (from flwr==0.19.0) (0.0.2)\n",
      "Requirement already satisfied: protobuf<4.0.0,>=3.19.0 in /usr/local/lib/python3.10/dist-packages (from flwr==0.19.0) (3.20.3)\n",
      "Requirement already satisfied: numpy<2.0,>=1.21 in /usr/local/lib/python3.10/dist-packages (from flwr==0.19.0) (1.24.1)\n",
      "Requirement already satisfied: grpcio<2.0.0,>=1.41.0 in /usr/local/lib/python3.10/dist-packages (from flwr==0.19.0) (1.51.1)\n",
      "Installing collected packages: flwr\n",
      "  Attempting uninstall: flwr\n",
      "    Found existing installation: flwr 1.3.0\n",
      "    Uninstalling flwr-1.3.0:\n",
      "      Successfully uninstalled flwr-1.3.0\n",
      "Successfully installed flwr-0.19.0\n"
     ]
    }
   ],
   "source": [
    "!pip install -U flwr==0.19.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "edb30e5a-f315-4091-b645-4e9390685b2f",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: torch==1.13.1 in /usr/local/lib/python3.10/dist-packages (1.13.1)\n",
      "Requirement already satisfied: torchvision==0.14.1 in /usr/local/lib/python3.10/dist-packages (0.14.1)\n",
      "Requirement already satisfied: numpy==1.24.1 in /usr/local/lib/python3.10/dist-packages (1.24.1)\n",
      "Requirement already satisfied: pandas==1.5.3 in /usr/local/lib/python3.10/dist-packages (1.5.3)\n",
      "Requirement already satisfied: matplotlib==3.6.3 in /usr/local/lib/python3.10/dist-packages (3.6.3)\n",
      "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /usr/local/lib/python3.10/dist-packages (from torch==1.13.1) (8.5.0.96)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /usr/local/lib/python3.10/dist-packages (from torch==1.13.1) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /usr/local/lib/python3.10/dist-packages (from torch==1.13.1) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /usr/local/lib/python3.10/dist-packages (from torch==1.13.1) (11.10.3.66)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch==1.13.1) (4.4.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/lib/python3/dist-packages (from torchvision==0.14.1) (9.0.1)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchvision==0.14.1) (2.28.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas==1.5.3) (2022.7.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas==1.5.3) (2.8.2)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib==3.6.3) (4.38.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib==3.6.3) (0.11.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib==3.6.3) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib==3.6.3) (23.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib==3.6.3) (1.0.7)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /usr/lib/python3/dist-packages (from matplotlib==3.6.3) (2.4.7)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch==1.13.1) (67.1.0)\n",
      "Requirement already satisfied: wheel in /usr/lib/python3/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch==1.13.1) (0.37.1)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas==1.5.3) (1.16.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision==0.14.1) (2022.12.7)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision==0.14.1) (1.26.14)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision==0.14.1) (3.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/zeyn-i/.local/lib/python3.10/site-packages (from requests->torchvision==0.14.1) (2.1.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install torch==1.13.1 torchvision==0.14.1 numpy==1.24.1 pandas==1.5.3 matplotlib==3.6.3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51703fc2-8ae8-4a24-b6c6-fba7121e65e3",
   "metadata": {},
   "source": [
    "***\n",
    "## 1- Importing Libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "59fcc7f0-1a62-4dbb-8e76-929e67be4236",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on cpu\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torchvision.datasets import CIFAR10\n",
    "import torchvision.models as models\n",
    "import torchvision\n",
    "\n",
    "import torch.nn.utils.prune as prune\n",
    "\n",
    "\n",
    "import flwr as fl\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from collections import OrderedDict\n",
    "from typing import Dict, List, Optional, Tuple\n",
    "import json\n",
    "import os\n",
    "\n",
    "DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Training on {DEVICE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "40197165-b7be-4702-ae74-79312022098e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.19.0 1.13.1+cu117 0.14.1+cu117 1.24.1 1.5.3 2.0.9 3.6.3\n"
     ]
    }
   ],
   "source": [
    "print(fl.__version__, torch.__version__, torchvision.__version__, np.__version__, pd.__version__,\n",
    "json.__version__, matplotlib.__version__)\n",
    "\n",
    "library_versions = {\"flwr\": fl.__version__, \"torch\": torch.__version__, \n",
    "                    \"torchvision\": torchvision.__version__, \"numpy\": np.__version__, \n",
    "                    \"pandas\": pd.__version__, \"json\": json.__version__, \n",
    "                    \"matplotlib\": matplotlib.__version__}\n",
    "\n",
    "with open('library_versions.txt', 'w') as f:\n",
    "    f.write(json.dumps(library_versions))\n",
    "\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4c8301b-fe3c-41e1-8128-7e8058dc47f4",
   "metadata": {},
   "source": [
    "***\n",
    "## 2- Initilisation/Hyperparameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "589ffaf0-468a-4b82-a827-03013b9fdd85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total number of devices (For D1 devices):\n",
    "NUM_DEVICES = 100\n",
    "\n",
    "# Model aggregation (Training round):\n",
    "NUM_ROUNDS = 100\n",
    "\n",
    "# On device local updates:\n",
    "LOCAL_EPOCH = 3\n",
    "\n",
    "# You may need to decrease it since total image per device is 60.\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "# D1, D2, D3, ... , D10:\n",
    "NUM_DEVICE_TYPE = 10\n",
    "\n",
    "hyperparameters = {'NUM_DEVICES': NUM_DEVICES,\n",
    "                   'NUM_ROUNDS': NUM_ROUNDS,\n",
    "                   'NUM_DEVICE_TYPE': NUM_DEVICE_TYPE,\n",
    "                   'BATCH_SIZE': BATCH_SIZE,\n",
    "                   'LOCAL_EPOCH': LOCAL_EPOCH}\n",
    "\n",
    "with open('hyperparameters.txt', 'w') as f:\n",
    "    f.write(json.dumps(hyperparameters))\n",
    "\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "181048bd-67d0-417b-87a2-10bd8517bb60",
   "metadata": {},
   "source": [
    "***\n",
    "## 3- Load Datasets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c85638ba-9a0c-4df3-a874-77fbc5607a79",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_datasets(num_clients: int):\n",
    "    \n",
    "    \n",
    "    # ######################## Test Dataset Preparetion #########################\n",
    "    testset = torchvision.datasets.MNIST(\"./data\", \n",
    "                                         train = False, \n",
    "                                         transform = transforms.Compose([transforms.Resize((32,32)),\n",
    "                                                                         transforms.ToTensor(),\n",
    "                                                                         transforms.Normalize(mean = (0.1325,), \n",
    "                                                                                              std = (0.3105,))]),\n",
    "                                         download=True)\n",
    "    \n",
    "    testloader = DataLoader(testset, batch_size=BATCH_SIZE)\n",
    "    \n",
    "    \n",
    "    # #################### Train and Val Datasets Preparetion ####################\n",
    "    trainset = torchvision.datasets.MNIST(\"./data\", \n",
    "                                          train = True, \n",
    "                                          transform = transforms.Compose([transforms.Resize((32,32)),\n",
    "                                                                          transforms.ToTensor(),\n",
    "                                                                          transforms.Normalize(mean = (0.1307,), \n",
    "                                                                                               std = (0.3081,))]),\n",
    "                                          download=True)\n",
    "    \n",
    "    plan = num_clients * NUM_DEVICE_TYPE\n",
    "    partition_size = len(trainset) // plan\n",
    "    lengths = [partition_size] * plan\n",
    "    # plan = num_clients * 2\n",
    "    # partition_size = len(trainset) // plan\n",
    "    # lengths = [partition_size] * plan\n",
    "    # partition_size = len(trainset) // num_clients\n",
    "    # lengths = [partition_size] * num_clients\n",
    "    \n",
    "    datasets = random_split(trainset, lengths, torch.Generator().manual_seed(42))\n",
    "\n",
    "    \n",
    "    trainloaders_1, valloaders_1 = [], []\n",
    "    trainloaders_2, valloaders_2 = [], []\n",
    "    trainloaders_3, valloaders_3 = [], []\n",
    "    trainloaders_4, valloaders_4 = [], []\n",
    "    trainloaders_5, valloaders_5 = [], []\n",
    "    trainloaders_6, valloaders_6 = [], []\n",
    "    trainloaders_7, valloaders_7 = [], []\n",
    "    trainloaders_8, valloaders_8 = [], []\n",
    "    trainloaders_9, valloaders_9 = [], []\n",
    "    trainloaders_10, valloaders_10 = [], []\n",
    "\n",
    "    \n",
    "    # The amount of data should be shared per device class (D1, D2, ... , D10):\n",
    "    amount = (len(datasets) // NUM_DEVICE_TYPE)\n",
    "    \n",
    "    # Sharing dataset to devices:\n",
    "    for i, ds in enumerate(datasets):\n",
    "        len_val = len(ds) // 10  \n",
    "        len_train = len(ds) - len_val\n",
    "        lengths = [len_train, len_val]\n",
    "\n",
    "        ds_train, ds_val = random_split(ds, lengths, torch.Generator().manual_seed(42))\n",
    "\n",
    "        # D1 devices:\n",
    "        if (amount*0 <= i) and (i < amount*1):\n",
    "            trainloaders_1.append(DataLoader(ds_train, batch_size=BATCH_SIZE, shuffle=True))\n",
    "            valloaders_1.append(DataLoader(ds_val, batch_size=BATCH_SIZE))\n",
    "\n",
    "        # D2 devices:\n",
    "        elif (amount*1 <= i) and (i < amount*2):\n",
    "            trainloaders_2.append(DataLoader(ds_train, batch_size=BATCH_SIZE, shuffle=True))\n",
    "            valloaders_2.append(DataLoader(ds_val, batch_size=BATCH_SIZE))\n",
    "\n",
    "        # D3 devices:\n",
    "        elif (amount*2 <= i) and (i < amount*3):\n",
    "            trainloaders_3.append(DataLoader(ds_train, batch_size=BATCH_SIZE, shuffle=True))\n",
    "            valloaders_3.append(DataLoader(ds_val, batch_size=BATCH_SIZE))\n",
    "\n",
    "        # D4 devices:    \n",
    "        elif (amount*3 <= i) and (i < amount*4):\n",
    "            trainloaders_4.append(DataLoader(ds_train, batch_size=BATCH_SIZE, shuffle=True))\n",
    "            valloaders_4.append(DataLoader(ds_val, batch_size=BATCH_SIZE))\n",
    "\n",
    "        # D5 devices:\n",
    "        elif (amount*4 <= i) and (i < amount*5):\n",
    "            trainloaders_5.append(DataLoader(ds_train, batch_size=BATCH_SIZE, shuffle=True))\n",
    "            valloaders_5.append(DataLoader(ds_val, batch_size=BATCH_SIZE))\n",
    "\n",
    "        # D6 devices:\n",
    "        elif (amount*5 <= i) and (i < amount*6):\n",
    "            trainloaders_6.append(DataLoader(ds_train, batch_size=BATCH_SIZE, shuffle=True))\n",
    "            valloaders_6.append(DataLoader(ds_val, batch_size=BATCH_SIZE))\n",
    "\n",
    "        # D7 devices:\n",
    "        elif (amount*6 <= i) and (i < amount*7):\n",
    "            trainloaders_7.append(DataLoader(ds_train, batch_size=BATCH_SIZE, shuffle=True))\n",
    "            valloaders_7.append(DataLoader(ds_val, batch_size=BATCH_SIZE))\n",
    "\n",
    "        # D8 devices:    \n",
    "        elif (amount*7 <= i) and (i < amount*8):\n",
    "            trainloaders_8.append(DataLoader(ds_train, batch_size=BATCH_SIZE, shuffle=True))\n",
    "            valloaders_8.append(DataLoader(ds_val, batch_size=BATCH_SIZE))\n",
    "\n",
    "        # D9 devices:   \n",
    "        elif (amount*8 <= i) and (i < amount*9):\n",
    "            trainloaders_9.append(DataLoader(ds_train, batch_size=BATCH_SIZE, shuffle=True))\n",
    "            valloaders_9.append(DataLoader(ds_val, batch_size=BATCH_SIZE))\n",
    "\n",
    "        # D10 devices:\n",
    "        elif (amount*9 <= i) and (i < amount*10):\n",
    "            trainloaders_10.append(DataLoader(ds_train, batch_size=BATCH_SIZE, shuffle=True))\n",
    "            valloaders_10.append(DataLoader(ds_val, batch_size=BATCH_SIZE))\n",
    "\n",
    "            \n",
    "    return (trainloaders_1, valloaders_1, trainloaders_2, valloaders_2, \n",
    "            trainloaders_3, valloaders_3, trainloaders_4, valloaders_4, \n",
    "            trainloaders_5, valloaders_5, trainloaders_6, valloaders_6, \n",
    "            trainloaders_7, valloaders_7, trainloaders_8, valloaders_8, \n",
    "            trainloaders_9, valloaders_9, trainloaders_10, valloaders_10,\n",
    "            testloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "85a63e33-6ee5-46c1-851e-5568847f92e5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "trainloaders_1, valloaders_1, trainloaders_2, valloaders_2, trainloaders_3, valloaders_3, trainloaders_4, valloaders_4, trainloaders_5, valloaders_5, trainloaders_6, valloaders_6, trainloaders_7, valloaders_7, trainloaders_8, valloaders_8, trainloaders_9, valloaders_9, trainloaders_10, valloaders_10, testloader = load_datasets(NUM_DEVICES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b381314b-4065-4097-8d30-f9836c030f06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# D1 devices are choosed to train:\n",
    "trainloaders = trainloaders_1\n",
    "valloaders = valloaders_1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcd3093f-d3ed-4c5b-b0dc-70aae2a00d71",
   "metadata": {},
   "source": [
    "***\n",
    "## 4- Flower Client to Simulate Devices:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "709858c8-73f7-4496-9735-fcd194b5b979",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FlowerClient(fl.client.NumPyClient):\n",
    "    def __init__(self, cid, net, trainloader, valloader):\n",
    "        self.cid = cid\n",
    "        self.net = net\n",
    "        self.trainloader = trainloader\n",
    "        self.valloader = valloader\n",
    "\n",
    "    def get_parameters(self):\n",
    "        print(f\"[Client {self.cid}] get_parameters\")\n",
    "        \n",
    "        return get_parameters(self.net)\n",
    "    \n",
    "    # Fit Function A:\n",
    "    # Configuration from client-side\n",
    "    # To make client-side execution (trainig, evaluation).\n",
    "    def fit(self, parameters, config):\n",
    "        print(f\"[Client {self.cid}] fit, config: {config}\")\n",
    "        set_parameters(self.net, parameters)\n",
    "        train(self.net, self.trainloader, epochs=1)\n",
    "        \n",
    "        return get_parameters(self.net), len(self.trainloader), {}\n",
    "    \n",
    "    \"\"\"\n",
    "    # Fit Function B:\n",
    "    # To make configuration values from the server to the clients using a dictionary.\n",
    "    def fit(self, parameters, config):\n",
    "        # Read values from config\n",
    "        current_round = config[\"current_round\"]\n",
    "        local_epochs = config[\"local_epochs\"]\n",
    "\n",
    "        # Use values provided by the config\n",
    "        print(f\"[Client {self.cid}, round {current_round}] fit, config: {config}\")\n",
    "        set_parameters(self.net, parameters)\n",
    "        train(self.net, self.trainloader, epochs=local_epochs)\n",
    "        return get_parameters(self.net), len(self.trainloader), {}\n",
    "    \"\"\"\n",
    "\n",
    "    # This function is included for case of client side (federated) evaluation is required to use.\n",
    "    def evaluate(self, parameters, config):\n",
    "        print(f\"[Client {self.cid}] evaluate, config: {config}\")\n",
    "        set_parameters(self.net, parameters)\n",
    "        loss, accuracy = test(self.net, self.valloader)\n",
    "        \n",
    "        return float(loss), len(self.valloader), {\"accuracy\": float(accuracy)}\n",
    "    \n",
    "\n",
    "def client_fn(cid) -> FlowerClient:\n",
    "    net = Net().to(DEVICE)\n",
    "    trainloader = trainloaders[int(cid)]\n",
    "    valloader = valloaders[int(cid)]\n",
    "    \n",
    "    return FlowerClient(cid, net, trainloader, valloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37d808e4-ddcc-4a5f-b9be-67e33c651527",
   "metadata": {},
   "source": [
    "***\n",
    "## 5- Model Preparetion:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "72628d2a-eeff-469a-b265-d701b6f71c42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LeNet:\n",
    "class Net(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        # 1 input image channel, 6 output channels, 5x5 square convolution\n",
    "        # kernel\n",
    "        self.conv1 = nn.Conv2d(1, 6, 5)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        # an affine operation: y = Wx + b\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)  # 5*5 from image dimension\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Max pooling over a (2, 2) window\n",
    "        x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2))\n",
    "        # If the size is a square, you can specify with a single number\n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)), 2)\n",
    "        x = torch.flatten(x, 1) # flatten all dimensions except the batch dimension\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d1124124-3d73-45a4-a0fb-7352579d6f4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_parameters(net) -> List[np.ndarray]:\n",
    "    return [val.cpu().numpy() for _, val in net.state_dict().items()]\n",
    "\n",
    "def set_parameters(net, parameters: List[np.ndarray]):\n",
    "    params_dict = zip(net.state_dict().keys(), parameters)\n",
    "    state_dict = OrderedDict({k: torch.tensor(v) for k, v in params_dict})\n",
    "    net.load_state_dict(state_dict, strict=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfab70d1-c956-4154-b902-17c0946bf0d5",
   "metadata": {},
   "source": [
    "***\n",
    "## 6- Train & Test Functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "94d1355a-e5b8-4943-9bdc-246b1ab3d8f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(net, trainloader, epochs: int):\n",
    "    \"\"\"Train the network on the training set.\"\"\"\n",
    "    \n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(net.parameters())\n",
    "    net.train()\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        correct, total, epoch_loss = 0, 0, 0.0\n",
    "        \n",
    "        for images, labels in trainloader:\n",
    "            images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = net(images)\n",
    "            loss = criterion(net(images), labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            # Metrics\n",
    "            epoch_loss += loss\n",
    "            total += labels.size(0)\n",
    "            correct += (torch.max(outputs.data, 1)[1] == labels).sum().item()\n",
    "        \n",
    "        epoch_loss /= len(testloader.dataset)\n",
    "        epoch_acc = correct / total\n",
    "        print(f\"Epoch {epoch+1}: train loss {epoch_loss}, accuracy {epoch_acc}\")\n",
    "\n",
    "\n",
    "        \n",
    "def test_model(net, testloader):\n",
    "    \"\"\"Evaluate the network on the entire test set.\"\"\"\n",
    "    \n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    correct, total, loss = 0, 0, 0.0\n",
    "    net.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, labels in testloader:\n",
    "            images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
    "            outputs = net(images)\n",
    "            loss += criterion(outputs, labels).item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    \n",
    "    loss /= len(testloader.dataset)\n",
    "    accuracy = correct / total\n",
    "    \n",
    "    \n",
    "    return [loss, accuracy]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b961cbad-4370-4e79-b714-c03965d3123f",
   "metadata": {},
   "source": [
    "***\n",
    "## 7- System Running (Training):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b20d4303-6db1-493f-8a99-31fc1169ea5c",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-01 12:18:41,545\tINFO worker.py:1529 -- Started a local Ray instance. View the dashboard at \u001b[1m\u001b[32m127.0.0.1:8265 \u001b[39m\u001b[22m\n",
      "INFO flower 2023-02-01 12:18:42,387 | app.py:155 | Ray initialized with resources: {'object_store_memory': 8652102451.0, 'CPU': 8.0, 'memory': 17304204903.0, 'node:137.43.23.126': 1.0}\n",
      "INFO flower 2023-02-01 12:18:42,390 | app.py:171 | Starting Flower simulation running: Config(num_rounds=100, round_timeout=None)\n",
      "INFO flower 2023-02-01 12:18:42,391 | server.py:84 | Initializing global parameters\n",
      "INFO flower 2023-02-01 12:18:42,392 | server.py:252 | Using initial parameters provided by strategy\n",
      "INFO flower 2023-02-01 12:18:42,392 | server.py:86 | Evaluating initial parameters\n",
      "INFO flower 2023-02-01 12:18:42,393 | server.py:99 | FL starting\n",
      "DEBUG flower 2023-02-01 12:18:42,393 | server.py:203 | fit_round: strategy sampled 30 clients (out of 100)\n",
      "2023-02-01 12:18:42,907\tWARNING __init__.py:182 -- DeprecationWarning: `ray.worker.get` is a private attribute and access will be removed in a future Ray version.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m [Client 60] fit, config: {'current_round': 1, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m Epoch 1: train loss 0.00022995176550466567, accuracy 0.1111111111111111\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m [Client 99] fit, config: {'current_round': 1, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m [Client 57] fit, config: {'current_round': 1, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m Epoch 1: train loss 0.000231607147725299, accuracy 0.14814814814814814\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m [Client 49] fit, config: {'current_round': 1, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m Epoch 1: train loss 0.00023130733461584896, accuracy 0.037037037037037035\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m [Client 22] fit, config: {'current_round': 1, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m Epoch 1: train loss 0.000230749326874502, accuracy 0.09259259259259259\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m [Client 11] fit, config: {'current_round': 1, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m Epoch 1: train loss 0.00022969550627749413, accuracy 0.14814814814814814\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m [Client 7] fit, config: {'current_round': 1, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m Epoch 1: train loss 0.0002290959528181702, accuracy 0.14814814814814814\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m [Client 78] fit, config: {'current_round': 1, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m Epoch 1: train loss 0.0002304170629940927, accuracy 0.12962962962962962\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m Epoch 1: train loss 0.00023055383644532412, accuracy 0.1111111111111111\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m [Client 28] fit, config: {'current_round': 1, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m Epoch 1: train loss 0.00022995953622739762, accuracy 0.16666666666666666\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m [Client 18] fit, config: {'current_round': 1, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m Epoch 1: train loss 0.0002312571305083111, accuracy 0.07407407407407407\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m [Client 85] fit, config: {'current_round': 1, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m Epoch 1: train loss 0.0002308292459929362, accuracy 0.07407407407407407\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m [Client 64] fit, config: {'current_round': 1, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m Epoch 1: train loss 0.00022953057487029582, accuracy 0.1111111111111111\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m [Client 67] fit, config: {'current_round': 1, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m Epoch 1: train loss 0.00023084782878868282, accuracy 0.07407407407407407\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m [Client 43] fit, config: {'current_round': 1, 'local_epochs': 3}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 12:18:45,103 | server.py:216 | fit_round received 30 results and 0 failures\n",
      "WARNING flower 2023-02-01 12:18:45,138 | fedavg.py:237 | No fit_metrics_aggregation_fn provided\n",
      "DEBUG flower 2023-02-01 12:18:45,142 | server.py:157 | evaluate_round: strategy sampled 30 clients (out of 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m [Client 91] fit, config: {'current_round': 1, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m Epoch 1: train loss 0.0002293566649314016, accuracy 0.18518518518518517\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m [Client 10] fit, config: {'current_round': 1, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m Epoch 1: train loss 0.00023183862504083663, accuracy 0.037037037037037035\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m [Client 69] fit, config: {'current_round': 1, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m [Client 82] fit, config: {'current_round': 1, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m Epoch 1: train loss 0.0002285161317558959, accuracy 0.18518518518518517\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m [Client 6] fit, config: {'current_round': 1, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m Epoch 1: train loss 0.0002304982190253213, accuracy 0.1111111111111111\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m [Client 54] fit, config: {'current_round': 1, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m Epoch 1: train loss 0.0002297911123605445, accuracy 0.14814814814814814\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m [Client 58] fit, config: {'current_round': 1, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m Epoch 1: train loss 0.0002289963304065168, accuracy 0.14814814814814814\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m Epoch 1: train loss 0.00023151464120019227, accuracy 0.09259259259259259\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m [Client 74] fit, config: {'current_round': 1, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m [Client 29] fit, config: {'current_round': 1, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m Epoch 1: train loss 0.00023000974033493549, accuracy 0.09259259259259259\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m Epoch 1: train loss 0.00023156206589192152, accuracy 0.07407407407407407\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m [Client 80] fit, config: {'current_round': 1, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m Epoch 1: train loss 0.00022935494780540466, accuracy 0.1111111111111111\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m [Client 8] fit, config: {'current_round': 1, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m Epoch 1: train loss 0.00023080168466549367, accuracy 0.1111111111111111\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m Epoch 1: train loss 0.00022954847372602671, accuracy 0.16666666666666666\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m [Client 50] fit, config: {'current_round': 1, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m Epoch 1: train loss 0.00022965669631958008, accuracy 0.18518518518518517\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m [Client 55] fit, config: {'current_round': 1, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m Epoch 1: train loss 0.00023194239474833012, accuracy 0.12962962962962962\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m [Client 35] fit, config: {'current_round': 1, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m Epoch 1: train loss 0.00022964448726270348, accuracy 0.16666666666666666\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m [Client 21] fit, config: {'current_round': 1, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m Epoch 1: train loss 0.00023089503520168364, accuracy 0.1111111111111111\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m [Client 41] fit, config: {'current_round': 1, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m Epoch 1: train loss 0.00023230629449244589, accuracy 0.07407407407407407\n",
      "Saving round 1 aggregated_parameters...\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38337)\u001b[0m [Client 45] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38339)\u001b[0m [Client 33] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38337)\u001b[0m [Client 87] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38337)\u001b[0m [Client 41] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38337)\u001b[0m [Client 60] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38339)\u001b[0m [Client 3] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38337)\u001b[0m [Client 62] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38339)\u001b[0m [Client 32] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38337)\u001b[0m [Client 92] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38337)\u001b[0m [Client 47] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38334)\u001b[0m [Client 4] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38336)\u001b[0m [Client 98] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38339)\u001b[0m [Client 94] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38340)\u001b[0m [Client 49] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38337)\u001b[0m [Client 83] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38334)\u001b[0m [Client 81] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38336)\u001b[0m [Client 97] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38337)\u001b[0m [Client 43] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38334)\u001b[0m [Client 72] evaluate, config: {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 12:18:46,574 | server.py:170 | evaluate_round received 0 results and 30 failures\n",
      "DEBUG flower 2023-02-01 12:18:46,574 | server.py:203 | fit_round: strategy sampled 30 clients (out of 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38334)\u001b[0m [Client 8] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38339)\u001b[0m [Client 28] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38340)\u001b[0m [Client 85] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38337)\u001b[0m [Client 27] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38334)\u001b[0m [Client 69] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38341)\u001b[0m [Client 2] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38338)\u001b[0m [Client 57] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38336)\u001b[0m [Client 66] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38339)\u001b[0m [Client 48] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38340)\u001b[0m [Client 95] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38335)\u001b[0m [Client 40] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m [Client 45] fit, config: {'current_round': 2, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m Epoch 1: train loss 0.0002295351296197623, accuracy 0.1111111111111111\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m [Client 72] fit, config: {'current_round': 2, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m [Client 81] fit, config: {'current_round': 2, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m [Client 49] fit, config: {'current_round': 2, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m Epoch 1: train loss 0.00023049733135849237, accuracy 0.05555555555555555\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m Epoch 1: train loss 0.0002290069096488878, accuracy 0.16666666666666666\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m [Client 90] fit, config: {'current_round': 2, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m Epoch 1: train loss 0.00022868938685860485, accuracy 0.18518518518518517\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m Epoch 1: train loss 0.000228920005611144, accuracy 0.12962962962962962\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m [Client 29] fit, config: {'current_round': 2, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m Epoch 1: train loss 0.00022922796779312193, accuracy 0.12962962962962962\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m [Client 16] fit, config: {'current_round': 2, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m Epoch 1: train loss 0.00022781202278565615, accuracy 0.12962962962962962\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m [Client 77] fit, config: {'current_round': 2, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m Epoch 1: train loss 0.00022894887661095709, accuracy 0.2037037037037037\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m [Client 15] fit, config: {'current_round': 2, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m Epoch 1: train loss 0.00022966587857808918, accuracy 0.14814814814814814\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m [Client 55] fit, config: {'current_round': 2, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m Epoch 1: train loss 0.0002303864894201979, accuracy 0.12962962962962962\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m [Client 14] fit, config: {'current_round': 2, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m Epoch 1: train loss 0.00022909075778443366, accuracy 0.12962962962962962\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m [Client 11] fit, config: {'current_round': 2, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m Epoch 1: train loss 0.00022848932712804526, accuracy 0.16666666666666666\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m [Client 82] fit, config: {'current_round': 2, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m Epoch 1: train loss 0.00022779744176659733, accuracy 0.18518518518518517\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m [Client 85] fit, config: {'current_round': 2, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m Epoch 1: train loss 0.00022965202515479177, accuracy 0.14814814814814814\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m [Client 96] fit, config: {'current_round': 2, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m Epoch 1: train loss 0.00022819178411737084, accuracy 0.2222222222222222\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m [Client 47] fit, config: {'current_round': 2, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m Epoch 1: train loss 0.00023013920872472227, accuracy 0.16666666666666666\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m [Client 13] fit, config: {'current_round': 2, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m Epoch 1: train loss 0.00022853331756778061, accuracy 0.18518518518518517\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m [Client 94] fit, config: {'current_round': 2, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m Epoch 1: train loss 0.00022966062533669174, accuracy 0.09259259259259259\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m [Client 88] fit, config: {'current_round': 2, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m Epoch 1: train loss 0.00022954397718422115, accuracy 0.16666666666666666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 12:18:48,175 | server.py:216 | fit_round received 30 results and 0 failures\n",
      "DEBUG flower 2023-02-01 12:18:48,211 | server.py:157 | evaluate_round: strategy sampled 30 clients (out of 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m [Client 86] fit, config: {'current_round': 2, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m [Client 32] fit, config: {'current_round': 2, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m Epoch 1: train loss 0.00023085944121703506, accuracy 0.05555555555555555\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m [Client 31] fit, config: {'current_round': 2, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m Epoch 1: train loss 0.000226618314627558, accuracy 0.2962962962962963\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m [Client 6] fit, config: {'current_round': 2, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m [Client 21] fit, config: {'current_round': 2, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m Epoch 1: train loss 0.00022985314717516303, accuracy 0.14814814814814814\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m Epoch 1: train loss 0.00022945378441363573, accuracy 0.1111111111111111\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m [Client 89] fit, config: {'current_round': 2, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m Epoch 1: train loss 0.00022803564206697047, accuracy 0.25925925925925924\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m [Client 73] fit, config: {'current_round': 2, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m Epoch 1: train loss 0.00023070933821145445, accuracy 0.12962962962962962\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m Epoch 1: train loss 0.0002305182279087603, accuracy 0.09259259259259259\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m [Client 1] fit, config: {'current_round': 2, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m Epoch 1: train loss 0.00022968970006331801, accuracy 0.14814814814814814\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m [Client 93] fit, config: {'current_round': 2, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m Epoch 1: train loss 0.00022817531134933233, accuracy 0.14814814814814814\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m [Client 99] fit, config: {'current_round': 2, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m Epoch 1: train loss 0.00022945909586269408, accuracy 0.12962962962962962\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m [Client 42] fit, config: {'current_round': 2, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m Epoch 1: train loss 0.0002295010635862127, accuracy 0.16666666666666666\n",
      "Saving round 2 aggregated_parameters...\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38341)\u001b[0m [Client 42] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38338)\u001b[0m [Client 30] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38338)\u001b[0m [Client 41] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38338)\u001b[0m [Client 38] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38338)\u001b[0m [Client 20] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38338)\u001b[0m [Client 23] evaluate, config: {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 12:18:49,685 | server.py:170 | evaluate_round received 0 results and 30 failures\n",
      "DEBUG flower 2023-02-01 12:18:49,687 | server.py:203 | fit_round: strategy sampled 30 clients (out of 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38341)\u001b[0m [Client 11] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38338)\u001b[0m [Client 8] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38340)\u001b[0m [Client 29] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38337)\u001b[0m [Client 25] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38335)\u001b[0m [Client 83] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38334)\u001b[0m [Client 91] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38341)\u001b[0m [Client 6] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38338)\u001b[0m [Client 52] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38336)\u001b[0m [Client 65] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38339)\u001b[0m [Client 74] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38341)\u001b[0m [Client 69] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38341)\u001b[0m [Client 53] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38336)\u001b[0m [Client 43] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38334)\u001b[0m [Client 28] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38334)\u001b[0m [Client 51] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38341)\u001b[0m [Client 18] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38341)\u001b[0m [Client 80] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38338)\u001b[0m [Client 60] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38338)\u001b[0m [Client 16] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38336)\u001b[0m [Client 22] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38339)\u001b[0m [Client 61] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38340)\u001b[0m [Client 0] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38337)\u001b[0m [Client 10] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38335)\u001b[0m [Client 31] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m [Client 62] fit, config: {'current_round': 3, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m Epoch 1: train loss 0.00022797436395194381, accuracy 0.25925925925925924\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m [Client 70] fit, config: {'current_round': 3, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m Epoch 1: train loss 0.00022708506730850786, accuracy 0.2777777777777778\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m [Client 58] fit, config: {'current_round': 3, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m Epoch 1: train loss 0.00022763812739867717, accuracy 0.16666666666666666\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m [Client 66] fit, config: {'current_round': 3, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m Epoch 1: train loss 0.0002293658908456564, accuracy 0.12962962962962962\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m [Client 59] fit, config: {'current_round': 3, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m Epoch 1: train loss 0.00022869117674417794, accuracy 0.2222222222222222\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m [Client 2] fit, config: {'current_round': 3, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m Epoch 1: train loss 0.00022978846391197294, accuracy 0.09259259259259259\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 12:18:51,170 | server.py:216 | fit_round received 30 results and 0 failures\n",
      "DEBUG flower 2023-02-01 12:18:51,204 | server.py:157 | evaluate_round: strategy sampled 30 clients (out of 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m [Client 81] fit, config: {'current_round': 3, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m Epoch 1: train loss 0.00022794077813159674, accuracy 0.2037037037037037\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m [Client 48] fit, config: {'current_round': 3, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m Epoch 1: train loss 0.0002295177400810644, accuracy 0.1111111111111111\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m [Client 46] fit, config: {'current_round': 3, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m Epoch 1: train loss 0.00022738054394721985, accuracy 0.18518518518518517\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m [Client 64] fit, config: {'current_round': 3, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m Epoch 1: train loss 0.00022801787417847663, accuracy 0.16666666666666666\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m [Client 49] fit, config: {'current_round': 3, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m Epoch 1: train loss 0.0002297241153428331, accuracy 0.1111111111111111\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m [Client 97] fit, config: {'current_round': 3, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m [Client 90] fit, config: {'current_round': 3, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m Epoch 1: train loss 0.00022750819334760308, accuracy 0.18518518518518517\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m Epoch 1: train loss 0.00022846669889986515, accuracy 0.16666666666666666\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m [Client 36] fit, config: {'current_round': 3, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m [Client 93] fit, config: {'current_round': 3, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m Epoch 1: train loss 0.0002269906981382519, accuracy 0.14814814814814814\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m [Client 16] fit, config: {'current_round': 3, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m Epoch 1: train loss 0.0002265813818667084, accuracy 0.14814814814814814\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m Epoch 1: train loss 0.00022950182028580457, accuracy 0.12962962962962962\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m [Client 14] fit, config: {'current_round': 3, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m Epoch 1: train loss 0.00022804393665865064, accuracy 0.1111111111111111\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m [Client 47] fit, config: {'current_round': 3, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m Epoch 1: train loss 0.00022911408450454473, accuracy 0.12962962962962962\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m [Client 67] fit, config: {'current_round': 3, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m Epoch 1: train loss 0.0002283977810293436, accuracy 0.16666666666666666\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m [Client 40] fit, config: {'current_round': 3, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m Epoch 1: train loss 0.00022788645583204925, accuracy 0.2037037037037037\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m [Client 22] fit, config: {'current_round': 3, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m Epoch 1: train loss 0.00022831647947896272, accuracy 0.2037037037037037\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m [Client 94] fit, config: {'current_round': 3, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m Epoch 1: train loss 0.00022858576267026365, accuracy 0.14814814814814814\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m [Client 88] fit, config: {'current_round': 3, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m Epoch 1: train loss 0.0002282049390487373, accuracy 0.14814814814814814\n",
      "Saving round 3 aggregated_parameters...\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m [Client 34] fit, config: {'current_round': 3, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m Epoch 1: train loss 0.00022727411123923957, accuracy 0.25925925925925924\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m [Client 30] fit, config: {'current_round': 3, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m Epoch 1: train loss 0.0002296363381901756, accuracy 0.14814814814814814\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m [Client 17] fit, config: {'current_round': 3, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m Epoch 1: train loss 0.00022918407921679318, accuracy 0.2222222222222222\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m [Client 9] fit, config: {'current_round': 3, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m Epoch 1: train loss 0.0002284689253428951, accuracy 0.2037037037037037\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m [Client 8] fit, config: {'current_round': 3, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m Epoch 1: train loss 0.0002289542171638459, accuracy 0.14814814814814814\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m [Client 57] fit, config: {'current_round': 3, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m Epoch 1: train loss 0.00022833295224700123, accuracy 0.2222222222222222\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m [Client 87] fit, config: {'current_round': 3, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m Epoch 1: train loss 0.0002282542991451919, accuracy 0.24074074074074073\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38334)\u001b[0m [Client 45] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38334)\u001b[0m [Client 35] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38336)\u001b[0m [Client 81] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38334)\u001b[0m [Client 60] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38341)\u001b[0m [Client 82] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38338)\u001b[0m [Client 80] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38336)\u001b[0m [Client 67] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38335)\u001b[0m [Client 5] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38336)\u001b[0m [Client 40] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38334)\u001b[0m [Client 1] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38334)\u001b[0m [Client 72] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38336)\u001b[0m [Client 33] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38336)\u001b[0m [Client 90] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38335)\u001b[0m [Client 98] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38335)\u001b[0m [Client 48] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38334)\u001b[0m [Client 92] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38341)\u001b[0m [Client 29] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38338)\u001b[0m [Client 49] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38336)\u001b[0m [Client 38] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38335)\u001b[0m [Client 28] evaluate, config: {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 12:18:52,934 | server.py:170 | evaluate_round received 0 results and 30 failures\n",
      "DEBUG flower 2023-02-01 12:18:52,935 | server.py:203 | fit_round: strategy sampled 30 clients (out of 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38338)\u001b[0m [Client 7] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38334)\u001b[0m [Client 9] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38341)\u001b[0m [Client 10] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38338)\u001b[0m [Client 93] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38336)\u001b[0m [Client 51] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38339)\u001b[0m [Client 73] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38340)\u001b[0m [Client 63] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38337)\u001b[0m [Client 99] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38337)\u001b[0m [Client 25] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38335)\u001b[0m [Client 58] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m [Client 23] fit, config: {'current_round': 4, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m Epoch 1: train loss 0.00022779946448281407, accuracy 0.12962962962962962\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m [Client 87] fit, config: {'current_round': 4, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m Epoch 1: train loss 0.00022692691709380597, accuracy 0.25925925925925924\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m [Client 45] fit, config: {'current_round': 4, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m Epoch 1: train loss 0.00022667227312922478, accuracy 0.12962962962962962\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m [Client 71] fit, config: {'current_round': 4, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m [Client 99] fit, config: {'current_round': 4, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m Epoch 1: train loss 0.00022728969634044915, accuracy 0.12962962962962962\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m Epoch 1: train loss 0.00022739030828233808, accuracy 0.2222222222222222\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m [Client 79] fit, config: {'current_round': 4, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m Epoch 1: train loss 0.00022785489272791892, accuracy 0.18518518518518517\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m [Client 76] fit, config: {'current_round': 4, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m Epoch 1: train loss 0.00022675316722597927, accuracy 0.18518518518518517\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m [Client 65] fit, config: {'current_round': 4, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m Epoch 1: train loss 0.00022559596982318908, accuracy 0.2777777777777778\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m [Client 82] fit, config: {'current_round': 4, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m Epoch 1: train loss 0.00022611480380874127, accuracy 0.24074074074074073\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m [Client 15] fit, config: {'current_round': 4, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m Epoch 1: train loss 0.00022801391605753452, accuracy 0.16666666666666666\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m [Client 50] fit, config: {'current_round': 4, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m Epoch 1: train loss 0.00022731094213668257, accuracy 0.25925925925925924\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m [Client 34] fit, config: {'current_round': 4, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m Epoch 1: train loss 0.0002259748725919053, accuracy 0.2777777777777778\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m [Client 29] fit, config: {'current_round': 4, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m [Client 86] fit, config: {'current_round': 4, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m Epoch 1: train loss 0.00022702016576658934, accuracy 0.16666666666666666\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m Epoch 1: train loss 0.00022746861213818192, accuracy 0.16666666666666666\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m [Client 20] fit, config: {'current_round': 4, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m Epoch 1: train loss 0.00022719586559105664, accuracy 0.2222222222222222\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m [Client 58] fit, config: {'current_round': 4, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m [Client 97] fit, config: {'current_round': 4, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m Epoch 1: train loss 0.00022728006297256798, accuracy 0.16666666666666666\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m [Client 92] fit, config: {'current_round': 4, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m [Client 22] fit, config: {'current_round': 4, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m [Client 30] fit, config: {'current_round': 4, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m [Client 63] fit, config: {'current_round': 4, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m Epoch 1: train loss 0.00022759231796953827, accuracy 0.2037037037037037\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m Epoch 1: train loss 0.00022689612524118274, accuracy 0.2037037037037037\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m Epoch 1: train loss 0.00022666600125376135, accuracy 0.16666666666666666\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m [Client 68] fit, config: {'current_round': 4, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m Epoch 1: train loss 0.00022836757125332952, accuracy 0.14814814814814814\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m [Client 27] fit, config: {'current_round': 4, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m Epoch 1: train loss 0.00022680085385218263, accuracy 0.14814814814814814\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m Epoch 1: train loss 0.00022821867605671287, accuracy 0.14814814814814814\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m [Client 66] fit, config: {'current_round': 4, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m Epoch 1: train loss 0.00022822835308033973, accuracy 0.12962962962962962\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m Epoch 1: train loss 0.0002284616493852809, accuracy 0.12962962962962962\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 12:18:54,564 | server.py:216 | fit_round received 30 results and 0 failures\n",
      "DEBUG flower 2023-02-01 12:18:54,598 | server.py:157 | evaluate_round: strategy sampled 30 clients (out of 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m [Client 83] fit, config: {'current_round': 4, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m Epoch 1: train loss 0.00022644696582574397, accuracy 0.2222222222222222\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m [Client 13] fit, config: {'current_round': 4, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m Epoch 1: train loss 0.0002267309173475951, accuracy 0.2222222222222222\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m [Client 56] fit, config: {'current_round': 4, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m Epoch 1: train loss 0.0002278617612319067, accuracy 0.18518518518518517\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m [Client 10] fit, config: {'current_round': 4, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m Epoch 1: train loss 0.00022818410070613027, accuracy 0.07407407407407407\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m [Client 36] fit, config: {'current_round': 4, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m Epoch 1: train loss 0.00022809607617091388, accuracy 0.12962962962962962\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m [Client 54] fit, config: {'current_round': 4, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m Epoch 1: train loss 0.00022729742340743542, accuracy 0.2222222222222222\n",
      "Saving round 4 aggregated_parameters...\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38340)\u001b[0m [Client 56] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38340)\u001b[0m [Client 94] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38335)\u001b[0m [Client 58] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38340)\u001b[0m [Client 3] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38340)\u001b[0m [Client 85] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38335)\u001b[0m [Client 33] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38339)\u001b[0m [Client 37] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38340)\u001b[0m [Client 69] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38335)\u001b[0m [Client 2] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38335)\u001b[0m [Client 16] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38341)\u001b[0m [Client 53] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38339)\u001b[0m [Client 13] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38335)\u001b[0m [Client 95] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38340)\u001b[0m [Client 78] evaluate, config: {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 12:18:56,625 | server.py:170 | evaluate_round received 0 results and 30 failures\n",
      "DEBUG flower 2023-02-01 12:18:56,627 | server.py:203 | fit_round: strategy sampled 30 clients (out of 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38341)\u001b[0m [Client 46] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38340)\u001b[0m [Client 81] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38339)\u001b[0m [Client 96] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38340)\u001b[0m [Client 60] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38334)\u001b[0m [Client 51] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38338)\u001b[0m [Client 4] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38336)\u001b[0m [Client 83] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38335)\u001b[0m [Client 9] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38338)\u001b[0m [Client 59] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38334)\u001b[0m [Client 98] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38338)\u001b[0m [Client 70] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38336)\u001b[0m [Client 23] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38336)\u001b[0m [Client 0] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38339)\u001b[0m [Client 93] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38340)\u001b[0m [Client 27] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38335)\u001b[0m [Client 8] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m [Client 42] fit, config: {'current_round': 5, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m Epoch 1: train loss 0.0002263259666506201, accuracy 0.25925925925925924\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m [Client 86] fit, config: {'current_round': 5, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m Epoch 1: train loss 0.00022536535107064992, accuracy 0.25925925925925924\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m [Client 72] fit, config: {'current_round': 5, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m Epoch 1: train loss 0.00022617800277657807, accuracy 0.25925925925925924\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m [Client 50] fit, config: {'current_round': 5, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m Epoch 1: train loss 0.0002259775355923921, accuracy 0.25925925925925924\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m [Client 75] fit, config: {'current_round': 5, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m [Client 66] fit, config: {'current_round': 5, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m Epoch 1: train loss 0.00022588013962376863, accuracy 0.25925925925925924\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m [Client 9] fit, config: {'current_round': 5, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m Epoch 1: train loss 0.00022610965243075043, accuracy 0.2777777777777778\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m [Client 57] fit, config: {'current_round': 5, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m Epoch 1: train loss 0.0002242656919406727, accuracy 0.3333333333333333\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m [Client 22] fit, config: {'current_round': 5, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m Epoch 1: train loss 0.0002253882703371346, accuracy 0.2777777777777778\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m Epoch 1: train loss 0.00022685797011945397, accuracy 0.14814814814814814\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m [Client 37] fit, config: {'current_round': 5, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m Epoch 1: train loss 0.00022569803695660084, accuracy 0.2222222222222222\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m [Client 81] fit, config: {'current_round': 5, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m Epoch 1: train loss 0.00022556721523869783, accuracy 0.24074074074074073\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m [Client 41] fit, config: {'current_round': 5, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m Epoch 1: train loss 0.0002278612373629585, accuracy 0.14814814814814814\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m [Client 62] fit, config: {'current_round': 5, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m Epoch 1: train loss 0.0002248650271212682, accuracy 0.35185185185185186\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m [Client 6] fit, config: {'current_round': 5, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m Epoch 1: train loss 0.00022718992840964347, accuracy 0.16666666666666666\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m [Client 64] fit, config: {'current_round': 5, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m Epoch 1: train loss 0.0002259168104501441, accuracy 0.2777777777777778\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m [Client 80] fit, config: {'current_round': 5, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m [Client 48] fit, config: {'current_round': 5, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m Epoch 1: train loss 0.00022687511227559298, accuracy 0.18518518518518517\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m [Client 74] fit, config: {'current_round': 5, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m Epoch 1: train loss 0.00022568681742995977, accuracy 0.2222222222222222\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m [Client 16] fit, config: {'current_round': 5, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m Epoch 1: train loss 0.00022351962979882956, accuracy 0.3148148148148148\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m [Client 28] fit, config: {'current_round': 5, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m Epoch 1: train loss 0.0002237194566987455, accuracy 0.2962962962962963\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m [Client 53] fit, config: {'current_round': 5, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m Epoch 1: train loss 0.00022484772489406168, accuracy 0.25925925925925924\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m [Client 17] fit, config: {'current_round': 5, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m Epoch 1: train loss 0.0002260150940855965, accuracy 0.2037037037037037\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m [Client 71] fit, config: {'current_round': 5, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m Epoch 1: train loss 0.00022572281886823475, accuracy 0.3333333333333333\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m [Client 2] fit, config: {'current_round': 5, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m [Client 32] fit, config: {'current_round': 5, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m Epoch 1: train loss 0.00022809389338362962, accuracy 0.09259259259259259\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m Epoch 1: train loss 0.00022680210531689227, accuracy 0.24074074074074073\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m Epoch 1: train loss 0.00022719576372765005, accuracy 0.2037037037037037\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m [Client 99] fit, config: {'current_round': 5, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m Epoch 1: train loss 0.00022599758813157678, accuracy 0.2222222222222222\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m [Client 46] fit, config: {'current_round': 5, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m [Client 54] fit, config: {'current_round': 5, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m Epoch 1: train loss 0.00022576293849851936, accuracy 0.2777777777777778\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 12:18:58,627 | server.py:216 | fit_round received 30 results and 0 failures\n",
      "DEBUG flower 2023-02-01 12:18:58,685 | server.py:157 | evaluate_round: strategy sampled 30 clients (out of 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving round 5 aggregated_parameters...\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m [Client 21] fit, config: {'current_round': 5, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m Epoch 1: train loss 0.00022648413141723722, accuracy 0.2037037037037037\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m [Client 45] fit, config: {'current_round': 5, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m Epoch 1: train loss 0.00022478341998066753, accuracy 0.24074074074074073\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m Epoch 1: train loss 0.00022506296227220446, accuracy 0.25925925925925924\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38336)\u001b[0m [Client 54] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38339)\u001b[0m [Client 90] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38336)\u001b[0m [Client 39] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38336)\u001b[0m [Client 58] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38336)\u001b[0m [Client 53] evaluate, config: {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(raylet)\u001b[0m Spilled 2709 MiB, 88 objects, write throughput 914 MiB/s. Set RAY_verbose_spill_logs=0 to disable this message.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38336)\u001b[0m [Client 31] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38339)\u001b[0m [Client 88] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38341)\u001b[0m [Client 14] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38336)\u001b[0m [Client 48] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38337)\u001b[0m [Client 64] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38334)\u001b[0m [Client 74] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38338)\u001b[0m [Client 4] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38336)\u001b[0m [Client 66] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38337)\u001b[0m [Client 62] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38335)\u001b[0m [Client 28] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38337)\u001b[0m [Client 75] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38337)\u001b[0m [Client 5] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38336)\u001b[0m [Client 93] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38337)\u001b[0m [Client 32] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38336)\u001b[0m [Client 98] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38337)\u001b[0m [Client 60] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38335)\u001b[0m [Client 37] evaluate, config: {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 12:19:00,636 | server.py:170 | evaluate_round received 0 results and 30 failures\n",
      "DEBUG flower 2023-02-01 12:19:00,637 | server.py:203 | fit_round: strategy sampled 30 clients (out of 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38334)\u001b[0m [Client 80] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38341)\u001b[0m [Client 59] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38338)\u001b[0m [Client 76] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38336)\u001b[0m [Client 77] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38339)\u001b[0m [Client 70] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38340)\u001b[0m [Client 23] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38337)\u001b[0m [Client 49] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38335)\u001b[0m [Client 71] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m [Client 27] fit, config: {'current_round': 6, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m Epoch 1: train loss 0.00022377858113031834, accuracy 0.3333333333333333\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m [Client 13] fit, config: {'current_round': 6, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m Epoch 1: train loss 0.00022353949316311628, accuracy 0.3888888888888889\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m [Client 46] fit, config: {'current_round': 6, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m Epoch 1: train loss 0.00022338794951792806, accuracy 0.3148148148148148\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m [Client 52] fit, config: {'current_round': 6, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m Epoch 1: train loss 0.00022306933533400297, accuracy 0.35185185185185186\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m [Client 80] fit, config: {'current_round': 6, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m Epoch 1: train loss 0.00022418158187065274, accuracy 0.25925925925925924\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(raylet)\u001b[0m Spilled 4512 MiB, 132 objects, write throughput 1011 MiB/s.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m [Client 34] fit, config: {'current_round': 6, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m [Client 25] fit, config: {'current_round': 6, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m [Client 67] fit, config: {'current_round': 6, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m Epoch 1: train loss 0.0002235826977994293, accuracy 0.37037037037037035\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m Epoch 1: train loss 0.00022225362772587687, accuracy 0.4444444444444444\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m [Client 74] fit, config: {'current_round': 6, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m Epoch 1: train loss 0.00022519972117152065, accuracy 0.24074074074074073\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m Epoch 1: train loss 0.00022458865714725107, accuracy 0.2962962962962963\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m [Client 10] fit, config: {'current_round': 6, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m [Client 48] fit, config: {'current_round': 6, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m Epoch 1: train loss 0.00022511498536914587, accuracy 0.25925925925925924\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m [Client 57] fit, config: {'current_round': 6, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m Epoch 1: train loss 0.00022482113854493946, accuracy 0.25925925925925924\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m [Client 33] fit, config: {'current_round': 6, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m Epoch 1: train loss 0.0002215966524090618, accuracy 0.42592592592592593\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m [Client 18] fit, config: {'current_round': 6, 'local_epochs': 3}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 12:19:02,638 | server.py:216 | fit_round received 30 results and 0 failures\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m [Client 61] fit, config: {'current_round': 6, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m [Client 29] fit, config: {'current_round': 6, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m Epoch 1: train loss 0.0002249616663902998, accuracy 0.2777777777777778\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m [Client 24] fit, config: {'current_round': 6, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m Epoch 1: train loss 0.00022249353060033172, accuracy 0.42592592592592593\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m Epoch 1: train loss 0.0002270999684697017, accuracy 0.18518518518518517\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m Epoch 1: train loss 0.00022734668164048344, accuracy 0.18518518518518517\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m [Client 22] fit, config: {'current_round': 6, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m Epoch 1: train loss 0.00022336850815918297, accuracy 0.37037037037037035\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m Epoch 1: train loss 0.0002249319077236578, accuracy 0.25925925925925924\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m [Client 95] fit, config: {'current_round': 6, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m Epoch 1: train loss 0.00022348119819071144, accuracy 0.3888888888888889\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m [Client 20] fit, config: {'current_round': 6, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m Epoch 1: train loss 0.00022441503824666142, accuracy 0.35185185185185186\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m [Client 44] fit, config: {'current_round': 6, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m Epoch 1: train loss 0.0002221295580966398, accuracy 0.4074074074074074\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m [Client 55] fit, config: {'current_round': 6, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m [Client 79] fit, config: {'current_round': 6, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m Epoch 1: train loss 0.00022379877918865532, accuracy 0.3148148148148148\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m [Client 45] fit, config: {'current_round': 6, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m Epoch 1: train loss 0.000224670598981902, accuracy 0.2962962962962963\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m [Client 86] fit, config: {'current_round': 6, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m [Client 43] fit, config: {'current_round': 6, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m Epoch 1: train loss 0.00022404699120670557, accuracy 0.35185185185185186\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m [Client 2] fit, config: {'current_round': 6, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m Epoch 1: train loss 0.000225419455091469, accuracy 0.25925925925925924\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m Epoch 1: train loss 0.00022240243561100215, accuracy 0.3333333333333333\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m [Client 0] fit, config: {'current_round': 6, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m Epoch 1: train loss 0.00022344313038047403, accuracy 0.37037037037037035\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m [Client 81] fit, config: {'current_round': 6, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m [Client 39] fit, config: {'current_round': 6, 'local_epochs': 3}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 12:19:02,677 | server.py:157 | evaluate_round: strategy sampled 30 clients (out of 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving round 6 aggregated_parameters...\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m Epoch 1: train loss 0.00022473027638625354, accuracy 0.2777777777777778\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m Epoch 1: train loss 0.00022388980141840875, accuracy 0.2962962962962963\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m Epoch 1: train loss 0.0002246551011921838, accuracy 0.35185185185185186\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38339)\u001b[0m [Client 23] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38337)\u001b[0m [Client 61] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38335)\u001b[0m [Client 92] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38337)\u001b[0m [Client 97] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38337)\u001b[0m [Client 19] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38335)\u001b[0m [Client 8] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38335)\u001b[0m [Client 57] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38335)\u001b[0m [Client 50] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38335)\u001b[0m [Client 7] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38337)\u001b[0m [Client 44] evaluate, config: {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(raylet)\u001b[0m Spilled 12544 MiB, 437 objects, write throughput 2075 MiB/s.\n",
      "DEBUG flower 2023-02-01 12:19:04,472 | server.py:170 | evaluate_round received 0 results and 30 failures\n",
      "DEBUG flower 2023-02-01 12:19:04,474 | server.py:203 | fit_round: strategy sampled 30 clients (out of 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38335)\u001b[0m [Client 16] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38334)\u001b[0m [Client 73] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38338)\u001b[0m [Client 22] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38336)\u001b[0m [Client 43] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38339)\u001b[0m [Client 1] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38338)\u001b[0m [Client 86] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38336)\u001b[0m [Client 54] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38334)\u001b[0m [Client 49] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38338)\u001b[0m [Client 41] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38336)\u001b[0m [Client 11] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38339)\u001b[0m [Client 46] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38338)\u001b[0m [Client 18] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38334)\u001b[0m [Client 47] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38338)\u001b[0m [Client 52] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38336)\u001b[0m [Client 84] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38339)\u001b[0m [Client 98] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38340)\u001b[0m [Client 53] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38337)\u001b[0m [Client 62] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38341)\u001b[0m [Client 33] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38335)\u001b[0m [Client 95] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m [Client 35] fit, config: {'current_round': 7, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m Epoch 1: train loss 0.00021971089881844819, accuracy 0.46296296296296297\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m [Client 69] fit, config: {'current_round': 7, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m Epoch 1: train loss 0.00022280530538409948, accuracy 0.3333333333333333\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m [Client 67] fit, config: {'current_round': 7, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m [Client 58] fit, config: {'current_round': 7, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m Epoch 1: train loss 0.00022215506760403514, accuracy 0.3888888888888889\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m [Client 43] fit, config: {'current_round': 7, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m [Client 88] fit, config: {'current_round': 7, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m Epoch 1: train loss 0.000221239824895747, accuracy 0.46296296296296297\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m [Client 4] fit, config: {'current_round': 7, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m Epoch 1: train loss 0.00022129427816253155, accuracy 0.3888888888888889\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m [Client 89] fit, config: {'current_round': 7, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m Epoch 1: train loss 0.0002217150031356141, accuracy 0.35185185185185186\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m [Client 90] fit, config: {'current_round': 7, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m [Client 64] fit, config: {'current_round': 7, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m Epoch 1: train loss 0.0002228587691206485, accuracy 0.4074074074074074\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m Epoch 1: train loss 0.00022182257089298218, accuracy 0.4074074074074074\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m [Client 26] fit, config: {'current_round': 7, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m [Client 2] fit, config: {'current_round': 7, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m Epoch 1: train loss 0.00022315433307085186, accuracy 0.2777777777777778\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m [Client 1] fit, config: {'current_round': 7, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m Epoch 1: train loss 0.0002197571302531287, accuracy 0.3888888888888889\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m Epoch 1: train loss 0.00022134114988148212, accuracy 0.4074074074074074\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m Epoch 1: train loss 0.00022145108960103244, accuracy 0.3888888888888889\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m Epoch 1: train loss 0.00022005762730259448, accuracy 0.4444444444444444\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m [Client 7] fit, config: {'current_round': 7, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m [Client 82] fit, config: {'current_round': 7, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m [Client 52] fit, config: {'current_round': 7, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m Epoch 1: train loss 0.00022075865126680583, accuracy 0.3888888888888889\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 12:19:06,322 | server.py:216 | fit_round received 30 results and 0 failures\n",
      "DEBUG flower 2023-02-01 12:19:06,360 | server.py:157 | evaluate_round: strategy sampled 30 clients (out of 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m [Client 55] fit, config: {'current_round': 7, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m Epoch 1: train loss 0.0002213354891864583, accuracy 0.2962962962962963\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m [Client 32] fit, config: {'current_round': 7, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m Epoch 1: train loss 0.00022494579025078565, accuracy 0.24074074074074073\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m Epoch 1: train loss 0.00022179250663612038, accuracy 0.35185185185185186\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m [Client 19] fit, config: {'current_round': 7, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m [Client 0] fit, config: {'current_round': 7, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m Epoch 1: train loss 0.00022091739811003208, accuracy 0.3888888888888889\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m [Client 80] fit, config: {'current_round': 7, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m Epoch 1: train loss 0.00022253207862377167, accuracy 0.3148148148148148\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m [Client 40] fit, config: {'current_round': 7, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m Epoch 1: train loss 0.00022031019034329802, accuracy 0.4074074074074074\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m [Client 54] fit, config: {'current_round': 7, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m Epoch 1: train loss 0.00022230049944482744, accuracy 0.2962962962962963\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m [Client 85] fit, config: {'current_round': 7, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m Epoch 1: train loss 0.0002227515506092459, accuracy 0.35185185185185186\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m Epoch 1: train loss 0.00022068357793614268, accuracy 0.3333333333333333\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m [Client 61] fit, config: {'current_round': 7, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m Epoch 1: train loss 0.00022570810688193887, accuracy 0.2222222222222222\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m Epoch 1: train loss 0.00022297000396065414, accuracy 0.3148148148148148\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m [Client 65] fit, config: {'current_round': 7, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m Epoch 1: train loss 0.00021987974469084293, accuracy 0.42592592592592593\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m [Client 22] fit, config: {'current_round': 7, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m [Client 17] fit, config: {'current_round': 7, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m Epoch 1: train loss 0.00022316293325275183, accuracy 0.3148148148148148\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m [Client 36] fit, config: {'current_round': 7, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m Epoch 1: train loss 0.00022254462237469852, accuracy 0.3148148148148148\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m [Client 34] fit, config: {'current_round': 7, 'local_epochs': 3}\n",
      "Saving round 7 aggregated_parameters...\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m Epoch 1: train loss 0.0002207960351370275, accuracy 0.4074074074074074\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m Epoch 1: train loss 0.00021979992743581533, accuracy 0.5\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38338)\u001b[0m [Client 83] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38338)\u001b[0m [Client 47] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38336)\u001b[0m [Client 35] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38337)\u001b[0m [Client 72] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38341)\u001b[0m [Client 22] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38341)\u001b[0m [Client 87] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38341)\u001b[0m [Client 26] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38341)\u001b[0m [Client 93] evaluate, config: {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 12:19:08,125 | server.py:170 | evaluate_round received 0 results and 30 failures\n",
      "DEBUG flower 2023-02-01 12:19:08,125 | server.py:203 | fit_round: strategy sampled 30 clients (out of 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38341)\u001b[0m [Client 92] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38338)\u001b[0m [Client 89] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38341)\u001b[0m [Client 29] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38338)\u001b[0m [Client 86] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38336)\u001b[0m [Client 17] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38337)\u001b[0m [Client 9] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38338)\u001b[0m [Client 96] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38338)\u001b[0m [Client 60] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38341)\u001b[0m [Client 63] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38338)\u001b[0m [Client 65] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38336)\u001b[0m [Client 61] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38337)\u001b[0m [Client 98] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38341)\u001b[0m [Client 75] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38336)\u001b[0m [Client 24] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38334)\u001b[0m [Client 0] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38341)\u001b[0m [Client 71] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38338)\u001b[0m [Client 53] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38336)\u001b[0m [Client 1] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38339)\u001b[0m [Client 5] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38340)\u001b[0m [Client 52] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38337)\u001b[0m [Client 41] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38335)\u001b[0m [Client 64] evaluate, config: {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(raylet)\u001b[0m Spilled 17113 MiB, 585 objects, write throughput 1804 MiB/s.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m [Client 34] fit, config: {'current_round': 8, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m Epoch 1: train loss 0.0002171403175452724, accuracy 0.48148148148148145\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m [Client 36] fit, config: {'current_round': 8, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m Epoch 1: train loss 0.00022018504387233406, accuracy 0.35185185185185186\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m [Client 87] fit, config: {'current_round': 8, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m Epoch 1: train loss 0.00021860559354536235, accuracy 0.48148148148148145\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m [Client 12] fit, config: {'current_round': 8, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m Epoch 1: train loss 0.00022156861086841673, accuracy 0.2777777777777778\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m [Client 88] fit, config: {'current_round': 8, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m Epoch 1: train loss 0.00021838059183210135, accuracy 0.46296296296296297\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m [Client 17] fit, config: {'current_round': 8, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m Epoch 1: train loss 0.00022066572273615748, accuracy 0.4444444444444444\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m [Client 11] fit, config: {'current_round': 8, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m Epoch 1: train loss 0.00021694776660297066, accuracy 0.5370370370370371\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m [Client 44] fit, config: {'current_round': 8, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m Epoch 1: train loss 0.00021688621200155467, accuracy 0.5\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m [Client 45] fit, config: {'current_round': 8, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m [Client 28] fit, config: {'current_round': 8, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m Epoch 1: train loss 0.00021484363242052495, accuracy 0.6111111111111112\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m [Client 57] fit, config: {'current_round': 8, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m Epoch 1: train loss 0.00021518334688153118, accuracy 0.5185185185185185\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m [Client 33] fit, config: {'current_round': 8, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m Epoch 1: train loss 0.0002170466468669474, accuracy 0.37037037037037035\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m Epoch 1: train loss 0.00022370307124219835, accuracy 0.25925925925925924\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 12:19:09,893 | server.py:216 | fit_round received 30 results and 0 failures\n",
      "DEBUG flower 2023-02-01 12:19:09,931 | server.py:157 | evaluate_round: strategy sampled 30 clients (out of 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m [Client 9] fit, config: {'current_round': 8, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m Epoch 1: train loss 0.00022063472715672106, accuracy 0.37037037037037035\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m [Client 30] fit, config: {'current_round': 8, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m Epoch 1: train loss 0.00022223859559744596, accuracy 0.18518518518518517\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m [Client 59] fit, config: {'current_round': 8, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m Epoch 1: train loss 0.00022198446094989777, accuracy 0.2777777777777778\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m [Client 40] fit, config: {'current_round': 8, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m Epoch 1: train loss 0.0002172352105844766, accuracy 0.48148148148148145\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m [Client 91] fit, config: {'current_round': 8, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m Epoch 1: train loss 0.00021746540733147413, accuracy 0.48148148148148145\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m [Client 10] fit, config: {'current_round': 8, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m Epoch 1: train loss 0.00021983070473652333, accuracy 0.3888888888888889\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m [Client 49] fit, config: {'current_round': 8, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m Epoch 1: train loss 0.00022388833167497069, accuracy 0.2222222222222222\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m [Client 60] fit, config: {'current_round': 8, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m Epoch 1: train loss 0.00021915786783210933, accuracy 0.4074074074074074\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m [Client 37] fit, config: {'current_round': 8, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m Epoch 1: train loss 0.00021911329531576484, accuracy 0.37037037037037035\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m [Client 4] fit, config: {'current_round': 8, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m Epoch 1: train loss 0.00021852288045920432, accuracy 0.46296296296296297\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m [Client 50] fit, config: {'current_round': 8, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m Epoch 1: train loss 0.00022056596935726702, accuracy 0.4074074074074074\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m [Client 6] fit, config: {'current_round': 8, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m [Client 21] fit, config: {'current_round': 8, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m Epoch 1: train loss 0.00022054428700357676, accuracy 0.35185185185185186\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m [Client 82] fit, config: {'current_round': 8, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m Epoch 1: train loss 0.0002197225549025461, accuracy 0.37037037037037035\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m Epoch 1: train loss 0.0002220575261162594, accuracy 0.2777777777777778\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m [Client 95] fit, config: {'current_round': 8, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m Epoch 1: train loss 0.00021856433886568993, accuracy 0.46296296296296297\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m [Client 16] fit, config: {'current_round': 8, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m Epoch 1: train loss 0.00021605433721560985, accuracy 0.46296296296296297\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m [Client 85] fit, config: {'current_round': 8, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m Epoch 1: train loss 0.00022044322395231575, accuracy 0.3333333333333333\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m [Client 86] fit, config: {'current_round': 8, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m Epoch 1: train loss 0.00021856155944988132, accuracy 0.4074074074074074\n",
      "Saving round 8 aggregated_parameters...\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38341)\u001b[0m [Client 42] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38340)\u001b[0m [Client 86] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38335)\u001b[0m [Client 30] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38340)\u001b[0m [Client 46] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38340)\u001b[0m [Client 14] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38335)\u001b[0m [Client 69] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38335)\u001b[0m [Client 43] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38341)\u001b[0m [Client 77] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38334)\u001b[0m [Client 81] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38341)\u001b[0m [Client 78] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38336)\u001b[0m [Client 45] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38339)\u001b[0m [Client 56] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38335)\u001b[0m [Client 18] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38340)\u001b[0m [Client 5] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38340)\u001b[0m [Client 38] evaluate, config: {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 12:19:11,685 | server.py:170 | evaluate_round received 0 results and 30 failures\n",
      "DEBUG flower 2023-02-01 12:19:11,686 | server.py:203 | fit_round: strategy sampled 30 clients (out of 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38340)\u001b[0m [Client 8] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38335)\u001b[0m [Client 57] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38334)\u001b[0m [Client 87] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38341)\u001b[0m [Client 27] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38341)\u001b[0m [Client 29] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38338)\u001b[0m [Client 12] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38336)\u001b[0m [Client 90] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38339)\u001b[0m [Client 63] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38340)\u001b[0m [Client 25] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38337)\u001b[0m [Client 3] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38335)\u001b[0m [Client 74] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38334)\u001b[0m [Client 82] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38341)\u001b[0m [Client 94] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38340)\u001b[0m [Client 84] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38337)\u001b[0m [Client 0] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m [Client 66] fit, config: {'current_round': 9, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m Epoch 1: train loss 0.00021808147721458226, accuracy 0.3148148148148148\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m [Client 48] fit, config: {'current_round': 9, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m Epoch 1: train loss 0.00021816120715811849, accuracy 0.2962962962962963\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m [Client 22] fit, config: {'current_round': 9, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m Epoch 1: train loss 0.0002151588851120323, accuracy 0.48148148148148145\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m [Client 18] fit, config: {'current_round': 9, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m Epoch 1: train loss 0.000217514592804946, accuracy 0.42592592592592593\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m [Client 10] fit, config: {'current_round': 9, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m Epoch 1: train loss 0.0002171129744965583, accuracy 0.4074074074074074\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m [Client 82] fit, config: {'current_round': 9, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m Epoch 1: train loss 0.00021754925546701998, accuracy 0.35185185185185186\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m [Client 44] fit, config: {'current_round': 9, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m [Client 72] fit, config: {'current_round': 9, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m Epoch 1: train loss 0.0002199013251811266, accuracy 0.2962962962962963\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m [Client 70] fit, config: {'current_round': 9, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m Epoch 1: train loss 0.00021544394257944077, accuracy 0.42592592592592593\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m [Client 86] fit, config: {'current_round': 9, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m [Client 63] fit, config: {'current_round': 9, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m Epoch 1: train loss 0.00021693482995033264, accuracy 0.37037037037037035\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m Epoch 1: train loss 0.00021519996516872197, accuracy 0.4444444444444444\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m Epoch 1: train loss 0.0002128313499270007, accuracy 0.5\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m [Client 85] fit, config: {'current_round': 9, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m Epoch 1: train loss 0.00021767344151157886, accuracy 0.3888888888888889\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m [Client 51] fit, config: {'current_round': 9, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m Epoch 1: train loss 0.00021586770890280604, accuracy 0.4074074074074074\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m [Client 52] fit, config: {'current_round': 9, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m Epoch 1: train loss 0.00021520261361729354, accuracy 0.35185185185185186\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m [Client 53] fit, config: {'current_round': 9, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m Epoch 1: train loss 0.0002134975220542401, accuracy 0.5\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m [Client 54] fit, config: {'current_round': 9, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m Epoch 1: train loss 0.00021842394198756665, accuracy 0.24074074074074073\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m [Client 14] fit, config: {'current_round': 9, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m Epoch 1: train loss 0.00021552001999225467, accuracy 0.3148148148148148\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m [Client 7] fit, config: {'current_round': 9, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m Epoch 1: train loss 0.00021668599219992757, accuracy 0.4074074074074074\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m [Client 26] fit, config: {'current_round': 9, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m Epoch 1: train loss 0.00021694821771234274, accuracy 0.4444444444444444\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m [Client 34] fit, config: {'current_round': 9, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m Epoch 1: train loss 0.00021394086070358753, accuracy 0.42592592592592593\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m [Client 78] fit, config: {'current_round': 9, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m Epoch 1: train loss 0.00021557341096922755, accuracy 0.42592592592592593\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m [Client 6] fit, config: {'current_round': 9, 'local_epochs': 3}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 12:19:13,497 | server.py:216 | fit_round received 30 results and 0 failures\n",
      "DEBUG flower 2023-02-01 12:19:13,537 | server.py:157 | evaluate_round: strategy sampled 30 clients (out of 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m [Client 27] fit, config: {'current_round': 9, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m Epoch 1: train loss 0.00021661631762981415, accuracy 0.46296296296296297\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m [Client 23] fit, config: {'current_round': 9, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m [Client 4] fit, config: {'current_round': 9, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m Epoch 1: train loss 0.00021605227084364742, accuracy 0.46296296296296297\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m [Client 62] fit, config: {'current_round': 9, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m Epoch 1: train loss 0.00021428735635709018, accuracy 0.46296296296296297\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m Epoch 1: train loss 0.00021902132721152157, accuracy 0.2962962962962963\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m [Client 56] fit, config: {'current_round': 9, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m [Client 73] fit, config: {'current_round': 9, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m Epoch 1: train loss 0.00021909964561928064, accuracy 0.3148148148148148\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m [Client 20] fit, config: {'current_round': 9, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m Epoch 1: train loss 0.00021800231479573995, accuracy 0.46296296296296297\n",
      "Saving round 9 aggregated_parameters...\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m [Client 25] fit, config: {'current_round': 9, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m Epoch 1: train loss 0.0002189563529100269, accuracy 0.35185185185185186\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m Epoch 1: train loss 0.00021919584833085537, accuracy 0.35185185185185186\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m Epoch 1: train loss 0.0002202328178100288, accuracy 0.35185185185185186\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38341)\u001b[0m [Client 85] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38338)\u001b[0m [Client 13] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38341)\u001b[0m [Client 81] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38338)\u001b[0m [Client 45] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38341)\u001b[0m [Client 57] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38338)\u001b[0m [Client 9] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38338)\u001b[0m [Client 86] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38340)\u001b[0m [Client 77] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38341)\u001b[0m [Client 58] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38340)\u001b[0m [Client 59] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38341)\u001b[0m [Client 97] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38340)\u001b[0m [Client 24] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38341)\u001b[0m [Client 27] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38341)\u001b[0m [Client 19] evaluate, config: {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 12:19:15,193 | server.py:170 | evaluate_round received 0 results and 30 failures\n",
      "DEBUG flower 2023-02-01 12:19:15,194 | server.py:203 | fit_round: strategy sampled 30 clients (out of 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38338)\u001b[0m [Client 11] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38338)\u001b[0m [Client 91] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38340)\u001b[0m [Client 40] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38335)\u001b[0m [Client 46] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38334)\u001b[0m [Client 6] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38341)\u001b[0m [Client 49] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38336)\u001b[0m [Client 50] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38339)\u001b[0m [Client 67] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38340)\u001b[0m [Client 44] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38337)\u001b[0m [Client 3] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38335)\u001b[0m [Client 31] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38334)\u001b[0m [Client 96] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38341)\u001b[0m [Client 52] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38336)\u001b[0m [Client 23] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38339)\u001b[0m [Client 47] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38340)\u001b[0m [Client 90] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m [Client 58] fit, config: {'current_round': 10, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m Epoch 1: train loss 0.00021352875046432018, accuracy 0.5185185185185185\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m [Client 37] fit, config: {'current_round': 10, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m [Client 80] fit, config: {'current_round': 10, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m Epoch 1: train loss 0.00021549589291680604, accuracy 0.4444444444444444\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m [Client 85] fit, config: {'current_round': 10, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m Epoch 1: train loss 0.00021444191224873066, accuracy 0.4444444444444444\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m [Client 74] fit, config: {'current_round': 10, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m Epoch 1: train loss 0.00021293657482601702, accuracy 0.4444444444444444\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m [Client 27] fit, config: {'current_round': 10, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m Epoch 1: train loss 0.0002129371860064566, accuracy 0.5185185185185185\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m Epoch 1: train loss 0.0002155107504222542, accuracy 0.48148148148148145\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m [Client 45] fit, config: {'current_round': 10, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m Epoch 1: train loss 0.00020965051953680813, accuracy 0.46296296296296297\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m [Client 77] fit, config: {'current_round': 10, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m Epoch 1: train loss 0.00021495205874089152, accuracy 0.4444444444444444\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m [Client 48] fit, config: {'current_round': 10, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m Epoch 1: train loss 0.0002146126498701051, accuracy 0.3333333333333333\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m [Client 6] fit, config: {'current_round': 10, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m Epoch 1: train loss 0.00021704415848944336, accuracy 0.35185185185185186\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m [Client 14] fit, config: {'current_round': 10, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m Epoch 1: train loss 0.00021164570352993906, accuracy 0.46296296296296297\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m [Client 44] fit, config: {'current_round': 10, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m Epoch 1: train loss 0.00020961000700481236, accuracy 0.5\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m [Client 67] fit, config: {'current_round': 10, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m [Client 47] fit, config: {'current_round': 10, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m Epoch 1: train loss 0.00021607449161820114, accuracy 0.46296296296296297\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m [Client 0] fit, config: {'current_round': 10, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m Epoch 1: train loss 0.00021543109323829412, accuracy 0.3333333333333333\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m [Client 79] fit, config: {'current_round': 10, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m Epoch 1: train loss 0.00021217289031483233, accuracy 0.5\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m [Client 90] fit, config: {'current_round': 10, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m Epoch 1: train loss 0.00020881732052657753, accuracy 0.5925925925925926\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m [Client 73] fit, config: {'current_round': 10, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m Epoch 1: train loss 0.00021478622511494905, accuracy 0.4074074074074074\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m [Client 99] fit, config: {'current_round': 10, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m [Client 32] fit, config: {'current_round': 10, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m Epoch 1: train loss 0.00021866319002583623, accuracy 0.35185185185185186\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m [Client 12] fit, config: {'current_round': 10, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m Epoch 1: train loss 0.0002163927856599912, accuracy 0.2962962962962963\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m Epoch 1: train loss 0.00021423840371426195, accuracy 0.48148148148148145\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m Epoch 1: train loss 0.00021657154138665646, accuracy 0.4074074074074074\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m [Client 11] fit, config: {'current_round': 10, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m Epoch 1: train loss 0.00020982710702810436, accuracy 0.5740740740740741\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 12:19:16,949 | server.py:216 | fit_round received 30 results and 0 failures\n",
      "DEBUG flower 2023-02-01 12:19:16,991 | server.py:157 | evaluate_round: strategy sampled 30 clients (out of 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m [Client 84] fit, config: {'current_round': 10, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m Epoch 1: train loss 0.00021674389427062124, accuracy 0.4074074074074074\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m [Client 83] fit, config: {'current_round': 10, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m [Client 57] fit, config: {'current_round': 10, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m Epoch 1: train loss 0.00020631046209018677, accuracy 0.5555555555555556\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m [Client 70] fit, config: {'current_round': 10, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m Epoch 1: train loss 0.0002117822878062725, accuracy 0.5185185185185185\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m [Client 3] fit, config: {'current_round': 10, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m [Client 87] fit, config: {'current_round': 10, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m Epoch 1: train loss 0.00021218891197349876, accuracy 0.5\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m [Client 16] fit, config: {'current_round': 10, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m [Client 42] fit, config: {'current_round': 10, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m Epoch 1: train loss 0.00021518098947126418, accuracy 0.4074074074074074\n",
      "Saving round 10 aggregated_parameters...\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m Epoch 1: train loss 0.0002149208594346419, accuracy 0.46296296296296297\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m Epoch 1: train loss 0.00021538761211559176, accuracy 0.48148148148148145\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m Epoch 1: train loss 0.00020921819668728858, accuracy 0.48148148148148145\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38334)\u001b[0m [Client 46] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38334)\u001b[0m [Client 31] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38334)\u001b[0m [Client 37] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38336)\u001b[0m [Client 84] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38337)\u001b[0m [Client 88] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38337)\u001b[0m [Client 43] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38336)\u001b[0m [Client 69] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38337)\u001b[0m [Client 65] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38337)\u001b[0m [Client 24] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38337)\u001b[0m [Client 59] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38337)\u001b[0m [Client 91] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38337)\u001b[0m [Client 33] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38337)\u001b[0m [Client 10] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38334)\u001b[0m [Client 49] evaluate, config: {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 12:19:18,613 | server.py:170 | evaluate_round received 0 results and 30 failures\n",
      "DEBUG flower 2023-02-01 12:19:18,614 | server.py:203 | fit_round: strategy sampled 30 clients (out of 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38341)\u001b[0m [Client 86] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38338)\u001b[0m [Client 23] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38336)\u001b[0m [Client 44] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38339)\u001b[0m [Client 45] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38337)\u001b[0m [Client 32] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38335)\u001b[0m [Client 27] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38340)\u001b[0m [Client 67] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38341)\u001b[0m [Client 99] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38340)\u001b[0m [Client 82] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38335)\u001b[0m [Client 64] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38335)\u001b[0m [Client 52] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38334)\u001b[0m [Client 93] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38341)\u001b[0m [Client 1] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38339)\u001b[0m [Client 25] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38340)\u001b[0m [Client 12] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38337)\u001b[0m [Client 48] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m [Client 88] fit, config: {'current_round': 11, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m Epoch 1: train loss 0.00020611858053598553, accuracy 0.5185185185185185\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m [Client 22] fit, config: {'current_round': 11, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m Epoch 1: train loss 0.00020753280841745436, accuracy 0.46296296296296297\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m [Client 38] fit, config: {'current_round': 11, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m Epoch 1: train loss 0.00020972623315174133, accuracy 0.4444444444444444\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m [Client 86] fit, config: {'current_round': 11, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m Epoch 1: train loss 0.00020769223920069635, accuracy 0.5\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m [Client 5] fit, config: {'current_round': 11, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m Epoch 1: train loss 0.00020809606940019876, accuracy 0.5185185185185185\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m [Client 37] fit, config: {'current_round': 11, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m Epoch 1: train loss 0.00020875208429060876, accuracy 0.4444444444444444\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m [Client 74] fit, config: {'current_round': 11, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m [Client 42] fit, config: {'current_round': 11, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m Epoch 1: train loss 0.00021141460456419736, accuracy 0.42592592592592593\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m [Client 62] fit, config: {'current_round': 11, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m Epoch 1: train loss 0.00020671596575994045, accuracy 0.4444444444444444\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m Epoch 1: train loss 0.00021260585344862193, accuracy 0.46296296296296297\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m [Client 87] fit, config: {'current_round': 11, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m Epoch 1: train loss 0.0002080346894217655, accuracy 0.5\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m [Client 9] fit, config: {'current_round': 11, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m [Client 75] fit, config: {'current_round': 11, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m [Client 41] fit, config: {'current_round': 11, 'local_epochs': 3}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 12:19:20,496 | server.py:216 | fit_round received 30 results and 0 failures\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m Epoch 1: train loss 0.0002119500859407708, accuracy 0.4444444444444444\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m [Client 32] fit, config: {'current_round': 11, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m Epoch 1: train loss 0.00021392342750914395, accuracy 0.42592592592592593\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m [Client 99] fit, config: {'current_round': 11, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m Epoch 1: train loss 0.00020975487132091075, accuracy 0.4444444444444444\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m [Client 33] fit, config: {'current_round': 11, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m Epoch 1: train loss 0.0002167202765122056, accuracy 0.37037037037037035\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m [Client 97] fit, config: {'current_round': 11, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m Epoch 1: train loss 0.00021093784016557038, accuracy 0.42592592592592593\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m Epoch 1: train loss 0.00021375455253291875, accuracy 0.3333333333333333\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m [Client 71] fit, config: {'current_round': 11, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m [Client 31] fit, config: {'current_round': 11, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m Epoch 1: train loss 0.00020661394228227437, accuracy 0.5185185185185185\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m [Client 11] fit, config: {'current_round': 11, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m Epoch 1: train loss 0.00020468051661737263, accuracy 0.5370370370370371\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m [Client 54] fit, config: {'current_round': 11, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m Epoch 1: train loss 0.00021249668498057872, accuracy 0.35185185185185186\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m Epoch 1: train loss 0.0002148230269085616, accuracy 0.3333333333333333\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m [Client 84] fit, config: {'current_round': 11, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m Epoch 1: train loss 0.0002142100129276514, accuracy 0.37037037037037035\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m Epoch 1: train loss 0.0002090806665364653, accuracy 0.46296296296296297\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m [Client 43] fit, config: {'current_round': 11, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m Epoch 1: train loss 0.0002096649695886299, accuracy 0.5185185185185185\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m [Client 49] fit, config: {'current_round': 11, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m Epoch 1: train loss 0.00021764871780760586, accuracy 0.2962962962962963\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m [Client 70] fit, config: {'current_round': 11, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m Epoch 1: train loss 0.0002087121974909678, accuracy 0.46296296296296297\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m [Client 29] fit, config: {'current_round': 11, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m Epoch 1: train loss 0.00021275851759128273, accuracy 0.4074074074074074\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m [Client 68] fit, config: {'current_round': 11, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m Epoch 1: train loss 0.000214376428630203, accuracy 0.35185185185185186\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m [Client 85] fit, config: {'current_round': 11, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m Epoch 1: train loss 0.00021130123059265316, accuracy 0.42592592592592593\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m [Client 57] fit, config: {'current_round': 11, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m Epoch 1: train loss 0.00020018361101392657, accuracy 0.5925925925925926\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m [Client 39] fit, config: {'current_round': 11, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m Epoch 1: train loss 0.0002123546291841194, accuracy 0.48148148148148145\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 12:19:20,535 | server.py:157 | evaluate_round: strategy sampled 30 clients (out of 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving round 11 aggregated_parameters...\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38341)\u001b[0m [Client 48] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38337)\u001b[0m [Client 86] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38335)\u001b[0m [Client 97] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38337)\u001b[0m [Client 61] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38341)\u001b[0m [Client 46] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38338)\u001b[0m [Client 99] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38337)\u001b[0m [Client 82] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38335)\u001b[0m [Client 52] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38341)\u001b[0m [Client 83] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38335)\u001b[0m [Client 73] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38338)\u001b[0m [Client 53] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38335)\u001b[0m [Client 70] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38341)\u001b[0m [Client 54] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38337)\u001b[0m [Client 57] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38335)\u001b[0m [Client 93] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38335)\u001b[0m [Client 38] evaluate, config: {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 12:19:22,311 | server.py:170 | evaluate_round received 0 results and 30 failures\n",
      "DEBUG flower 2023-02-01 12:19:22,311 | server.py:203 | fit_round: strategy sampled 30 clients (out of 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38341)\u001b[0m [Client 88] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38338)\u001b[0m [Client 32] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38337)\u001b[0m [Client 26] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38335)\u001b[0m [Client 16] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38336)\u001b[0m [Client 8] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38339)\u001b[0m [Client 23] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38339)\u001b[0m [Client 96] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38338)\u001b[0m [Client 55] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38336)\u001b[0m [Client 18] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38339)\u001b[0m [Client 58] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38341)\u001b[0m [Client 45] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38340)\u001b[0m [Client 84] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38337)\u001b[0m [Client 67] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38335)\u001b[0m [Client 36] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m [Client 90] fit, config: {'current_round': 12, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m Epoch 1: train loss 0.0001998104271478951, accuracy 0.5370370370370371\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m [Client 58] fit, config: {'current_round': 12, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m Epoch 1: train loss 0.0002072497154586017, accuracy 0.5740740740740741\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m [Client 16] fit, config: {'current_round': 12, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m Epoch 1: train loss 0.00019983138190582395, accuracy 0.5925925925925926\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m [Client 1] fit, config: {'current_round': 12, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m Epoch 1: train loss 0.00019879575120285153, accuracy 0.6296296296296297\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m [Client 17] fit, config: {'current_round': 12, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m Epoch 1: train loss 0.00020898158254567534, accuracy 0.4074074074074074\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m [Client 28] fit, config: {'current_round': 12, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m Epoch 1: train loss 0.00019649956084322184, accuracy 0.6481481481481481\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m [Client 68] fit, config: {'current_round': 12, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m Epoch 1: train loss 0.000210362792131491, accuracy 0.3888888888888889\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m [Client 42] fit, config: {'current_round': 12, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m Epoch 1: train loss 0.0002072750503430143, accuracy 0.46296296296296297\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m [Client 91] fit, config: {'current_round': 12, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m Epoch 1: train loss 0.00020211853552609682, accuracy 0.6481481481481481\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m [Client 93] fit, config: {'current_round': 12, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m [Client 67] fit, config: {'current_round': 12, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m Epoch 1: train loss 0.00020131054043304175, accuracy 0.5925925925925926\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m [Client 6] fit, config: {'current_round': 12, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m Epoch 1: train loss 0.00020951693295501173, accuracy 0.4074074074074074\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m Epoch 1: train loss 0.00020410168508533388, accuracy 0.6481481481481481\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m [Client 59] fit, config: {'current_round': 12, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m Epoch 1: train loss 0.00021031673531979322, accuracy 0.5\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m [Client 49] fit, config: {'current_round': 12, 'local_epochs': 3}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 12:19:24,327 | server.py:216 | fit_round received 30 results and 0 failures\n",
      "DEBUG flower 2023-02-01 12:19:24,369 | server.py:157 | evaluate_round: strategy sampled 30 clients (out of 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m [Client 81] fit, config: {'current_round': 12, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m Epoch 1: train loss 0.00020730774849653244, accuracy 0.5185185185185185\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m [Client 76] fit, config: {'current_round': 12, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m [Client 18] fit, config: {'current_round': 12, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m [Client 3] fit, config: {'current_round': 12, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m Epoch 1: train loss 0.00020770574337802827, accuracy 0.5740740740740741\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m Epoch 1: train loss 0.00021376529184635729, accuracy 0.3888888888888889\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m [Client 60] fit, config: {'current_round': 12, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m Epoch 1: train loss 0.0002045332221314311, accuracy 0.48148148148148145\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m Epoch 1: train loss 0.00020560195844154805, accuracy 0.48148148148148145\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m [Client 89] fit, config: {'current_round': 12, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m Epoch 1: train loss 0.00020665080228354782, accuracy 0.5555555555555556\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m [Client 36] fit, config: {'current_round': 12, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m Epoch 1: train loss 0.00020642674644477665, accuracy 0.48148148148148145\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m [Client 53] fit, config: {'current_round': 12, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m Epoch 1: train loss 0.00020035762281622738, accuracy 0.5740740740740741\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m [Client 15] fit, config: {'current_round': 12, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m Epoch 1: train loss 0.00021015545644331723, accuracy 0.48148148148148145\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m Epoch 1: train loss 0.00020582981233019382, accuracy 0.48148148148148145\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m [Client 10] fit, config: {'current_round': 12, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m [Client 97] fit, config: {'current_round': 12, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m Epoch 1: train loss 0.0002063947031274438, accuracy 0.48148148148148145\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m [Client 14] fit, config: {'current_round': 12, 'local_epochs': 3}\n",
      "Saving round 12 aggregated_parameters...\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m Epoch 1: train loss 0.0002055871009360999, accuracy 0.42592592592592593\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m [Client 46] fit, config: {'current_round': 12, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m Epoch 1: train loss 0.00020702795882243663, accuracy 0.35185185185185186\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m [Client 57] fit, config: {'current_round': 12, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m Epoch 1: train loss 0.0001942600792972371, accuracy 0.6481481481481481\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m [Client 24] fit, config: {'current_round': 12, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m Epoch 1: train loss 0.0002055927470792085, accuracy 0.5740740740740741\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m Epoch 1: train loss 0.00020368005789350718, accuracy 0.5\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m [Client 23] fit, config: {'current_round': 12, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m Epoch 1: train loss 0.0002091422356897965, accuracy 0.46296296296296297\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38340)\u001b[0m [Client 62] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38340)\u001b[0m [Client 53] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38336)\u001b[0m [Client 93] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38340)\u001b[0m [Client 69] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38336)\u001b[0m [Client 90] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38336)\u001b[0m [Client 68] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38340)\u001b[0m [Client 8] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38336)\u001b[0m [Client 7] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38336)\u001b[0m [Client 40] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38336)\u001b[0m [Client 72] evaluate, config: {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 12:19:25,947 | server.py:170 | evaluate_round received 0 results and 30 failures\n",
      "DEBUG flower 2023-02-01 12:19:25,948 | server.py:203 | fit_round: strategy sampled 30 clients (out of 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38336)\u001b[0m [Client 94] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38339)\u001b[0m [Client 86] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38340)\u001b[0m [Client 43] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38337)\u001b[0m [Client 46] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38335)\u001b[0m [Client 31] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38341)\u001b[0m [Client 75] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38338)\u001b[0m [Client 95] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38340)\u001b[0m [Client 48] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38338)\u001b[0m [Client 28] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38341)\u001b[0m [Client 10] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38338)\u001b[0m [Client 59] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38340)\u001b[0m [Client 70] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38337)\u001b[0m [Client 29] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38334)\u001b[0m [Client 36] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38338)\u001b[0m [Client 4] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38336)\u001b[0m [Client 49] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38339)\u001b[0m [Client 2] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38340)\u001b[0m [Client 71] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38337)\u001b[0m [Client 39] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38335)\u001b[0m [Client 18] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m [Client 33] fit, config: {'current_round': 13, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m Epoch 1: train loss 0.0002087917528115213, accuracy 0.3888888888888889\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m [Client 22] fit, config: {'current_round': 13, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m [Client 92] fit, config: {'current_round': 13, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m Epoch 1: train loss 0.00020430183212738484, accuracy 0.48148148148148145\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m [Client 43] fit, config: {'current_round': 13, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m [Client 46] fit, config: {'current_round': 13, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m Epoch 1: train loss 0.00020242255413904786, accuracy 0.4074074074074074\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m Epoch 1: train loss 0.0001983501570066437, accuracy 0.5185185185185185\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m Epoch 1: train loss 0.00020058009249623865, accuracy 0.5555555555555556\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m [Client 64] fit, config: {'current_round': 13, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m Epoch 1: train loss 0.00020501484686974436, accuracy 0.5185185185185185\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m [Client 12] fit, config: {'current_round': 13, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m Epoch 1: train loss 0.00020425043476279825, accuracy 0.5185185185185185\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m [Client 23] fit, config: {'current_round': 13, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m Epoch 1: train loss 0.00020395843603182584, accuracy 0.5555555555555556\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m [Client 71] fit, config: {'current_round': 13, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m Epoch 1: train loss 0.0002002973051276058, accuracy 0.5185185185185185\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m [Client 30] fit, config: {'current_round': 13, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m [Client 27] fit, config: {'current_round': 13, 'local_epochs': 3}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 12:19:27,651 | server.py:216 | fit_round received 30 results and 0 failures\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m [Client 55] fit, config: {'current_round': 13, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m [Client 17] fit, config: {'current_round': 13, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m Epoch 1: train loss 0.00020475458586588502, accuracy 0.4444444444444444\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m [Client 7] fit, config: {'current_round': 13, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m Epoch 1: train loss 0.00020657034474425018, accuracy 0.3888888888888889\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m [Client 94] fit, config: {'current_round': 13, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m Epoch 1: train loss 0.00019992454326711595, accuracy 0.6111111111111112\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m Epoch 1: train loss 0.00020059652160853148, accuracy 0.48148148148148145\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m [Client 21] fit, config: {'current_round': 13, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m Epoch 1: train loss 0.00020320116891525686, accuracy 0.5370370370370371\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m Epoch 1: train loss 0.0001943303650477901, accuracy 0.5740740740740741\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m [Client 96] fit, config: {'current_round': 13, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m [Client 59] fit, config: {'current_round': 13, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m Epoch 1: train loss 0.00020694373233709484, accuracy 0.5\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m Epoch 1: train loss 0.00020326483354438096, accuracy 0.5185185185185185\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m [Client 83] fit, config: {'current_round': 13, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m Epoch 1: train loss 0.00020363859948702157, accuracy 0.5185185185185185\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m [Client 25] fit, config: {'current_round': 13, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m Epoch 1: train loss 0.0002051130577456206, accuracy 0.5185185185185185\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m Epoch 1: train loss 0.00020260500605218112, accuracy 0.5\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m [Client 48] fit, config: {'current_round': 13, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m Epoch 1: train loss 0.00020230286463629454, accuracy 0.5925925925925926\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m [Client 26] fit, config: {'current_round': 13, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m Epoch 1: train loss 0.00020203005988150835, accuracy 0.5740740740740741\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m [Client 14] fit, config: {'current_round': 13, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m [Client 90] fit, config: {'current_round': 13, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m Epoch 1: train loss 0.00019353684911038727, accuracy 0.5925925925925926\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m [Client 93] fit, config: {'current_round': 13, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m Epoch 1: train loss 0.00019546887779142708, accuracy 0.6481481481481481\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m Epoch 1: train loss 0.000198565045138821, accuracy 0.5740740740740741\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m [Client 81] fit, config: {'current_round': 13, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m Epoch 1: train loss 0.00020322688214946538, accuracy 0.5555555555555556\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m [Client 49] fit, config: {'current_round': 13, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m Epoch 1: train loss 0.00021134431881364435, accuracy 0.4444444444444444\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m [Client 85] fit, config: {'current_round': 13, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m Epoch 1: train loss 0.00020231340022291988, accuracy 0.48148148148148145\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m [Client 67] fit, config: {'current_round': 13, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m [Client 62] fit, config: {'current_round': 13, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m Epoch 1: train loss 0.00019710791821125895, accuracy 0.5370370370370371\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 12:19:27,688 | server.py:157 | evaluate_round: strategy sampled 30 clients (out of 100)\n",
      "\u001b[2m\u001b[36m(raylet)\u001b[0m Spilled 33211 MiB, 1113 objects, write throughput 1552 MiB/s.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving round 13 aggregated_parameters...\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m Epoch 1: train loss 0.00019831284589599818, accuracy 0.6296296296296297\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38340)\u001b[0m [Client 74] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38337)\u001b[0m [Client 90] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38340)\u001b[0m [Client 5] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38334)\u001b[0m [Client 14] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38341)\u001b[0m [Client 28] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38336)\u001b[0m [Client 82] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38340)\u001b[0m [Client 45] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38337)\u001b[0m [Client 93] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38334)\u001b[0m [Client 22] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38336)\u001b[0m [Client 64] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38337)\u001b[0m [Client 72] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38337)\u001b[0m [Client 46] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38334)\u001b[0m [Client 35] evaluate, config: {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 12:19:29,394 | server.py:170 | evaluate_round received 0 results and 30 failures\n",
      "DEBUG flower 2023-02-01 12:19:29,395 | server.py:203 | fit_round: strategy sampled 30 clients (out of 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38336)\u001b[0m [Client 62] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38337)\u001b[0m [Client 66] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38334)\u001b[0m [Client 17] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38341)\u001b[0m [Client 68] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38336)\u001b[0m [Client 56] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38340)\u001b[0m [Client 71] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38337)\u001b[0m [Client 34] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38336)\u001b[0m [Client 73] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38334)\u001b[0m [Client 59] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38341)\u001b[0m [Client 86] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38338)\u001b[0m [Client 32] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38336)\u001b[0m [Client 87] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38339)\u001b[0m [Client 3] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38340)\u001b[0m [Client 49] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38337)\u001b[0m [Client 0] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38336)\u001b[0m [Client 8] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38335)\u001b[0m [Client 92] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m [Client 90] fit, config: {'current_round': 14, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m Epoch 1: train loss 0.0001884165103547275, accuracy 0.6111111111111112\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m [Client 18] fit, config: {'current_round': 14, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m Epoch 1: train loss 0.00019643883570097387, accuracy 0.5185185185185185\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m [Client 8] fit, config: {'current_round': 14, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m Epoch 1: train loss 0.00020064816635567695, accuracy 0.5\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m [Client 41] fit, config: {'current_round': 14, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m Epoch 1: train loss 0.00020070276514161378, accuracy 0.46296296296296297\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m [Client 64] fit, config: {'current_round': 14, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m [Client 20] fit, config: {'current_round': 14, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m Epoch 1: train loss 0.00019872505799867213, accuracy 0.6296296296296297\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m Epoch 1: train loss 0.00020104782015550882, accuracy 0.5370370370370371\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m [Client 62] fit, config: {'current_round': 14, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m Epoch 1: train loss 0.00019085188978351653, accuracy 0.5555555555555556\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m [Client 91] fit, config: {'current_round': 14, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m Epoch 1: train loss 0.00019081546633969992, accuracy 0.7407407407407407\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m [Client 38] fit, config: {'current_round': 14, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m Epoch 1: train loss 0.0001955915504368022, accuracy 0.5740740740740741\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m [Client 81] fit, config: {'current_round': 14, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m Epoch 1: train loss 0.00019831025565508753, accuracy 0.7037037037037037\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m [Client 60] fit, config: {'current_round': 14, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m Epoch 1: train loss 0.00019527404219843447, accuracy 0.5555555555555556\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m [Client 6] fit, config: {'current_round': 14, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m Epoch 1: train loss 0.0002013047196669504, accuracy 0.48148148148148145\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m [Client 13] fit, config: {'current_round': 14, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m Epoch 1: train loss 0.00019755591347347945, accuracy 0.6296296296296297\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m [Client 79] fit, config: {'current_round': 14, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m Epoch 1: train loss 0.0002007127768592909, accuracy 0.48148148148148145\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m [Client 28] fit, config: {'current_round': 14, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m [Client 42] fit, config: {'current_round': 14, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m Epoch 1: train loss 0.0001846878876676783, accuracy 0.7037037037037037\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m [Client 59] fit, config: {'current_round': 14, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m Epoch 1: train loss 0.00020172534277662635, accuracy 0.5555555555555556\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m Epoch 1: train loss 0.00019872111442964524, accuracy 0.5555555555555556\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m [Client 44] fit, config: {'current_round': 14, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m Epoch 1: train loss 0.00018723707762546837, accuracy 0.6111111111111112\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m [Client 61] fit, config: {'current_round': 14, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m Epoch 1: train loss 0.00020728594972752035, accuracy 0.5185185185185185\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m [Client 58] fit, config: {'current_round': 14, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m Epoch 1: train loss 0.00019753225205931813, accuracy 0.5925925925925926\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m [Client 9] fit, config: {'current_round': 14, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m Epoch 1: train loss 0.0001991387252928689, accuracy 0.46296296296296297\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m [Client 31] fit, config: {'current_round': 14, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m [Client 49] fit, config: {'current_round': 14, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m Epoch 1: train loss 0.00020643360039684922, accuracy 0.5185185185185185\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m [Client 34] fit, config: {'current_round': 14, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m [Client 40] fit, config: {'current_round': 14, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m Epoch 1: train loss 0.00018900221039075404, accuracy 0.7037037037037037\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m [Client 3] fit, config: {'current_round': 14, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m Epoch 1: train loss 0.0001984433038160205, accuracy 0.6481481481481481\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m [Client 77] fit, config: {'current_round': 14, 'local_epochs': 3}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 12:19:31,174 | server.py:216 | fit_round received 30 results and 0 failures\n",
      "DEBUG flower 2023-02-01 12:19:31,210 | server.py:157 | evaluate_round: strategy sampled 30 clients (out of 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving round 14 aggregated_parameters...\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m Epoch 1: train loss 0.00019918241014238447, accuracy 0.5\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m Epoch 1: train loss 0.00019302892906125635, accuracy 0.6851851851851852\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m Epoch 1: train loss 0.0001915951434057206, accuracy 0.5740740740740741\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m [Client 25] fit, config: {'current_round': 14, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m Epoch 1: train loss 0.00019912920834030956, accuracy 0.6111111111111112\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m [Client 14] fit, config: {'current_round': 14, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m Epoch 1: train loss 0.00019367170170880854, accuracy 0.5925925925925926\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m [Client 53] fit, config: {'current_round': 14, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m Epoch 1: train loss 0.0001894898305181414, accuracy 0.5925925925925926\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38338)\u001b[0m [Client 54] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38340)\u001b[0m [Client 55] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38337)\u001b[0m [Client 41] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38335)\u001b[0m [Client 71] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38341)\u001b[0m [Client 72] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38339)\u001b[0m [Client 33] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38337)\u001b[0m [Client 37] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38337)\u001b[0m [Client 74] evaluate, config: {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 12:19:32,983 | server.py:170 | evaluate_round received 0 results and 30 failures\n",
      "DEBUG flower 2023-02-01 12:19:32,984 | server.py:203 | fit_round: strategy sampled 30 clients (out of 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38341)\u001b[0m [Client 21] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38339)\u001b[0m [Client 75] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38337)\u001b[0m [Client 18] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38341)\u001b[0m [Client 83] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38339)\u001b[0m [Client 70] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38340)\u001b[0m [Client 1] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38337)\u001b[0m [Client 73] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38340)\u001b[0m [Client 14] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38337)\u001b[0m [Client 53] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38337)\u001b[0m [Client 15] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38337)\u001b[0m [Client 10] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38334)\u001b[0m [Client 64] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38341)\u001b[0m [Client 45] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38338)\u001b[0m [Client 66] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38336)\u001b[0m [Client 86] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38339)\u001b[0m [Client 12] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38339)\u001b[0m [Client 97] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38340)\u001b[0m [Client 51] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38340)\u001b[0m [Client 32] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38337)\u001b[0m [Client 59] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38335)\u001b[0m [Client 9] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38337)\u001b[0m [Client 95] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m [Client 69] fit, config: {'current_round': 15, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m Epoch 1: train loss 0.00019132734450977296, accuracy 0.48148148148148145\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m [Client 53] fit, config: {'current_round': 15, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m Epoch 1: train loss 0.00018255763279739767, accuracy 0.5555555555555556\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m [Client 93] fit, config: {'current_round': 15, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m Epoch 1: train loss 0.00018434262892697006, accuracy 0.6296296296296297\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m [Client 45] fit, config: {'current_round': 15, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m Epoch 1: train loss 0.0001829882530728355, accuracy 0.7037037037037037\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m [Client 24] fit, config: {'current_round': 15, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m [Client 88] fit, config: {'current_round': 15, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m Epoch 1: train loss 0.00018398916290607303, accuracy 0.6111111111111112\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m Epoch 1: train loss 0.00019101426005363464, accuracy 0.6481481481481481\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m [Client 72] fit, config: {'current_round': 15, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m Epoch 1: train loss 0.00019815862469840795, accuracy 0.42592592592592593\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m [Client 3] fit, config: {'current_round': 15, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m Epoch 1: train loss 0.00019262208661530167, accuracy 0.5740740740740741\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m [Client 6] fit, config: {'current_round': 15, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m Epoch 1: train loss 0.00019554796745069325, accuracy 0.5370370370370371\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m [Client 94] fit, config: {'current_round': 15, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m Epoch 1: train loss 0.000188623191206716, accuracy 0.6666666666666666\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m [Client 32] fit, config: {'current_round': 15, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m Epoch 1: train loss 0.00019767943012993783, accuracy 0.48148148148148145\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m [Client 51] fit, config: {'current_round': 15, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m [Client 33] fit, config: {'current_round': 15, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m Epoch 1: train loss 0.00019971247820649296, accuracy 0.42592592592592593\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m [Client 9] fit, config: {'current_round': 15, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m Epoch 1: train loss 0.00019439152674749494, accuracy 0.48148148148148145\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m [Client 63] fit, config: {'current_round': 15, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m Epoch 1: train loss 0.00019103607337456197, accuracy 0.5740740740740741\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m Epoch 1: train loss 0.0001929589343490079, accuracy 0.6111111111111112\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m [Client 66] fit, config: {'current_round': 15, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m Epoch 1: train loss 0.0001917915215017274, accuracy 0.5740740740740741\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m [Client 86] fit, config: {'current_round': 15, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m Epoch 1: train loss 0.00018864325829781592, accuracy 0.5740740740740741\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m [Client 81] fit, config: {'current_round': 15, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m Epoch 1: train loss 0.00019365492335055023, accuracy 0.5555555555555556\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m [Client 64] fit, config: {'current_round': 15, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m Epoch 1: train loss 0.00019547506235539913, accuracy 0.5185185185185185\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m [Client 82] fit, config: {'current_round': 15, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m Epoch 1: train loss 0.00019569315190892667, accuracy 0.5555555555555556\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m [Client 90] fit, config: {'current_round': 15, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m Epoch 1: train loss 0.0001835617731558159, accuracy 0.5925925925925926\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m [Client 26] fit, config: {'current_round': 15, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m Epoch 1: train loss 0.00019259469991084188, accuracy 0.6481481481481481\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m [Client 85] fit, config: {'current_round': 15, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m Epoch 1: train loss 0.00019157964561600238, accuracy 0.48148148148148145\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m [Client 8] fit, config: {'current_round': 15, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m [Client 62] fit, config: {'current_round': 15, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m [Client 37] fit, config: {'current_round': 15, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m Epoch 1: train loss 0.00018806994194164872, accuracy 0.5555555555555556\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 12:19:34,787 | server.py:216 | fit_round received 30 results and 0 failures\n",
      "DEBUG flower 2023-02-01 12:19:34,838 | server.py:157 | evaluate_round: strategy sampled 30 clients (out of 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m [Client 42] fit, config: {'current_round': 15, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m Epoch 1: train loss 0.00019284134032204747, accuracy 0.48148148148148145\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m [Client 0] fit, config: {'current_round': 15, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m Epoch 1: train loss 0.00019338750280439854, accuracy 0.5185185185185185\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m Epoch 1: train loss 0.00019657168013509363, accuracy 0.46296296296296297\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m Epoch 1: train loss 0.00018572001135908067, accuracy 0.5740740740740741\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m [Client 71] fit, config: {'current_round': 15, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m Epoch 1: train loss 0.0001884107041405514, accuracy 0.5370370370370371\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m [Client 61] fit, config: {'current_round': 15, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m Epoch 1: train loss 0.00020245435007382184, accuracy 0.42592592592592593\n",
      "Saving round 15 aggregated_parameters...\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38337)\u001b[0m [Client 62] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38335)\u001b[0m [Client 80] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38335)\u001b[0m [Client 60] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38335)\u001b[0m [Client 84] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38335)\u001b[0m [Client 2] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38335)\u001b[0m [Client 24] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38334)\u001b[0m [Client 96] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38341)\u001b[0m [Client 25] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38337)\u001b[0m [Client 16] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38335)\u001b[0m [Client 94] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38334)\u001b[0m [Client 45] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38341)\u001b[0m [Client 11] evaluate, config: {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 12:19:36,549 | server.py:170 | evaluate_round received 0 results and 30 failures\n",
      "DEBUG flower 2023-02-01 12:19:36,549 | server.py:203 | fit_round: strategy sampled 30 clients (out of 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38334)\u001b[0m [Client 59] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38341)\u001b[0m [Client 85] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38336)\u001b[0m [Client 34] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38335)\u001b[0m [Client 6] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38338)\u001b[0m [Client 56] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38339)\u001b[0m [Client 61] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38340)\u001b[0m [Client 39] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38340)\u001b[0m [Client 54] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38335)\u001b[0m [Client 1] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38334)\u001b[0m [Client 65] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38336)\u001b[0m [Client 53] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38337)\u001b[0m [Client 66] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38334)\u001b[0m [Client 50] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38338)\u001b[0m [Client 23] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38336)\u001b[0m [Client 31] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38339)\u001b[0m [Client 93] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38340)\u001b[0m [Client 81] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38337)\u001b[0m [Client 52] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m [Client 77] fit, config: {'current_round': 16, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m Epoch 1: train loss 0.0001894501765491441, accuracy 0.5185185185185185\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m [Client 19] fit, config: {'current_round': 16, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m Epoch 1: train loss 0.00017915024363901466, accuracy 0.6296296296296297\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m [Client 61] fit, config: {'current_round': 16, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m Epoch 1: train loss 0.00019762477313634008, accuracy 0.5370370370370371\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m [Client 42] fit, config: {'current_round': 16, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m Epoch 1: train loss 0.00018771033501252532, accuracy 0.5555555555555556\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m [Client 66] fit, config: {'current_round': 16, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m Epoch 1: train loss 0.00018576611182652414, accuracy 0.6111111111111112\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m [Client 96] fit, config: {'current_round': 16, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m Epoch 1: train loss 0.000186394972843118, accuracy 0.5740740740740741\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m [Client 36] fit, config: {'current_round': 16, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m Epoch 1: train loss 0.00018501187150832266, accuracy 0.6111111111111112\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m [Client 60] fit, config: {'current_round': 16, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m Epoch 1: train loss 0.00018272367015015334, accuracy 0.5925925925925926\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m [Client 14] fit, config: {'current_round': 16, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m Epoch 1: train loss 0.00018253893358632922, accuracy 0.5925925925925926\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m [Client 99] fit, config: {'current_round': 16, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m Epoch 1: train loss 0.0001852457644417882, accuracy 0.6111111111111112\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m [Client 51] fit, config: {'current_round': 16, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m Epoch 1: train loss 0.00018702071974985301, accuracy 0.6481481481481481\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m [Client 43] fit, config: {'current_round': 16, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m Epoch 1: train loss 0.00018422285211272538, accuracy 0.6296296296296297\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m [Client 50] fit, config: {'current_round': 16, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m Epoch 1: train loss 0.00019189363229088485, accuracy 0.6111111111111112\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m [Client 67] fit, config: {'current_round': 16, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m Epoch 1: train loss 0.00018231004651170224, accuracy 0.6666666666666666\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m [Client 33] fit, config: {'current_round': 16, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m Epoch 1: train loss 0.00019358712597750127, accuracy 0.5555555555555556\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m [Client 82] fit, config: {'current_round': 16, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m Epoch 1: train loss 0.00019086159591097385, accuracy 0.5925925925925926\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m [Client 94] fit, config: {'current_round': 16, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m Epoch 1: train loss 0.00018261228979099542, accuracy 0.6851851851851852\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m [Client 95] fit, config: {'current_round': 16, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m Epoch 1: train loss 0.00018144401838071644, accuracy 0.6481481481481481\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m [Client 38] fit, config: {'current_round': 16, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m Epoch 1: train loss 0.00018417791579850018, accuracy 0.6481481481481481\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m [Client 44] fit, config: {'current_round': 16, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m Epoch 1: train loss 0.00017356361786369234, accuracy 0.6666666666666666\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m [Client 8] fit, config: {'current_round': 16, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m [Client 37] fit, config: {'current_round': 16, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m [Client 27] fit, config: {'current_round': 16, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m Epoch 1: train loss 0.0001915281463880092, accuracy 0.5185185185185185\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m [Client 85] fit, config: {'current_round': 16, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m Epoch 1: train loss 0.0001840000186348334, accuracy 0.6111111111111112\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m [Client 74] fit, config: {'current_round': 16, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m Epoch 1: train loss 0.00019065428932663053, accuracy 0.6111111111111112\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m [Client 55] fit, config: {'current_round': 16, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m Epoch 1: train loss 0.00017641724843997508, accuracy 0.6481481481481481\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m [Client 90] fit, config: {'current_round': 16, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m [Client 21] fit, config: {'current_round': 16, 'local_epochs': 3}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 12:19:38,350 | server.py:216 | fit_round received 30 results and 0 failures\n",
      "DEBUG flower 2023-02-01 12:19:38,387 | server.py:157 | evaluate_round: strategy sampled 30 clients (out of 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving round 16 aggregated_parameters...\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m Epoch 1: train loss 0.00018220979836769402, accuracy 0.5555555555555556\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m Epoch 1: train loss 0.00018614326836541295, accuracy 0.6111111111111112\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m [Client 76] fit, config: {'current_round': 16, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m Epoch 1: train loss 0.00018502068996895105, accuracy 0.5555555555555556\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m [Client 58] fit, config: {'current_round': 16, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m Epoch 1: train loss 0.00018707058916334063, accuracy 0.6296296296296297\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m Epoch 1: train loss 0.00017636494885664433, accuracy 0.6851851851851852\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m Epoch 1: train loss 0.00018716644262894988, accuracy 0.5740740740740741\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38339)\u001b[0m [Client 86] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38338)\u001b[0m [Client 71] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38339)\u001b[0m [Client 81] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38341)\u001b[0m [Client 43] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38335)\u001b[0m [Client 52] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38341)\u001b[0m [Client 39] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38341)\u001b[0m [Client 10] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38341)\u001b[0m [Client 51] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38335)\u001b[0m [Client 21] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38338)\u001b[0m [Client 61] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38335)\u001b[0m [Client 27] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38338)\u001b[0m [Client 55] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38341)\u001b[0m [Client 69] evaluate, config: {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 12:19:40,144 | server.py:170 | evaluate_round received 0 results and 30 failures\n",
      "DEBUG flower 2023-02-01 12:19:40,145 | server.py:203 | fit_round: strategy sampled 30 clients (out of 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38338)\u001b[0m [Client 94] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38339)\u001b[0m [Client 8] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38339)\u001b[0m [Client 90] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38335)\u001b[0m [Client 72] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38335)\u001b[0m [Client 11] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38335)\u001b[0m [Client 78] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38341)\u001b[0m [Client 63] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38338)\u001b[0m [Client 6] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38339)\u001b[0m [Client 12] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38339)\u001b[0m [Client 74] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38335)\u001b[0m [Client 37] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38341)\u001b[0m [Client 0] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38339)\u001b[0m [Client 20] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38334)\u001b[0m [Client 2] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38338)\u001b[0m [Client 96] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38337)\u001b[0m [Client 46] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38335)\u001b[0m [Client 33] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m [Client 97] fit, config: {'current_round': 17, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m Epoch 1: train loss 0.00018003305012825876, accuracy 0.6481481481481481\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m [Client 63] fit, config: {'current_round': 17, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m [Client 92] fit, config: {'current_round': 17, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m [Client 47] fit, config: {'current_round': 17, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m Epoch 1: train loss 0.00018349623132962734, accuracy 0.5740740740740741\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m Epoch 1: train loss 0.0001799322635633871, accuracy 0.6111111111111112\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m [Client 18] fit, config: {'current_round': 17, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m Epoch 1: train loss 0.00017977521929424256, accuracy 0.5370370370370371\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m Epoch 1: train loss 0.00018186791567131877, accuracy 0.6296296296296297\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m [Client 90] fit, config: {'current_round': 17, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m Epoch 1: train loss 0.00016977806808426976, accuracy 0.6481481481481481\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m [Client 17] fit, config: {'current_round': 17, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m Epoch 1: train loss 0.00018375007493887097, accuracy 0.5185185185185185\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m [Client 30] fit, config: {'current_round': 17, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m Epoch 1: train loss 0.0001871227432275191, accuracy 0.46296296296296297\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m [Client 33] fit, config: {'current_round': 17, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m [Client 3] fit, config: {'current_round': 17, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m Epoch 1: train loss 0.0001797108125174418, accuracy 0.6481481481481481\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m [Client 80] fit, config: {'current_round': 17, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m Epoch 1: train loss 0.00018392065248917788, accuracy 0.6666666666666666\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m [Client 56] fit, config: {'current_round': 17, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m Epoch 1: train loss 0.00018994543643202633, accuracy 0.48148148148148145\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m Epoch 1: train loss 0.00018768773588817567, accuracy 0.48148148148148145\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m [Client 9] fit, config: {'current_round': 17, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m Epoch 1: train loss 0.00018405908485874534, accuracy 0.5740740740740741\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m [Client 89] fit, config: {'current_round': 17, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m Epoch 1: train loss 0.0001826496300054714, accuracy 0.5370370370370371\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m [Client 19] fit, config: {'current_round': 17, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m Epoch 1: train loss 0.00017223517352249473, accuracy 0.6296296296296297\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m [Client 66] fit, config: {'current_round': 17, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m Epoch 1: train loss 0.00017982760618906468, accuracy 0.6481481481481481\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m [Client 54] fit, config: {'current_round': 17, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m Epoch 1: train loss 0.00018357043154537678, accuracy 0.6481481481481481\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m [Client 7] fit, config: {'current_round': 17, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m Epoch 1: train loss 0.00018354506755713373, accuracy 0.6296296296296297\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m [Client 48] fit, config: {'current_round': 17, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m Epoch 1: train loss 0.0001795064308680594, accuracy 0.6851851851851852\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m [Client 87] fit, config: {'current_round': 17, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m Epoch 1: train loss 0.00017630800721235573, accuracy 0.6296296296296297\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m [Client 84] fit, config: {'current_round': 17, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m [Client 91] fit, config: {'current_round': 17, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m Epoch 1: train loss 0.00017173780361190438, accuracy 0.7962962962962963\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m [Client 69] fit, config: {'current_round': 17, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m [Client 44] fit, config: {'current_round': 17, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m Epoch 1: train loss 0.0001675696694292128, accuracy 0.6666666666666666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 12:19:41,954 | server.py:216 | fit_round received 30 results and 0 failures\n",
      "DEBUG flower 2023-02-01 12:19:41,991 | server.py:157 | evaluate_round: strategy sampled 30 clients (out of 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m [Client 74] fit, config: {'current_round': 17, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m Epoch 1: train loss 0.0001841513585532084, accuracy 0.6481481481481481\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m [Client 49] fit, config: {'current_round': 17, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m Epoch 1: train loss 0.0001927898993017152, accuracy 0.5925925925925926\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m Epoch 1: train loss 0.00018681153596844524, accuracy 0.5\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m [Client 14] fit, config: {'current_round': 17, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m Epoch 1: train loss 0.0001760991581249982, accuracy 0.6296296296296297\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m [Client 38] fit, config: {'current_round': 17, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m Epoch 1: train loss 0.0001765097549650818, accuracy 0.6666666666666666\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m [Client 59] fit, config: {'current_round': 17, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m Epoch 1: train loss 0.00018623718642629683, accuracy 0.6481481481481481\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m Epoch 1: train loss 0.00017911940813064575, accuracy 0.6481481481481481\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m [Client 16] fit, config: {'current_round': 17, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m Epoch 1: train loss 0.0001705177128314972, accuracy 0.6666666666666666\n",
      "Saving round 17 aggregated_parameters...\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38336)\u001b[0m [Client 30] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38335)\u001b[0m [Client 40] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38336)\u001b[0m [Client 24] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38336)\u001b[0m [Client 99] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38336)\u001b[0m [Client 67] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38341)\u001b[0m [Client 71] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38336)\u001b[0m [Client 70] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38340)\u001b[0m [Client 21] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38335)\u001b[0m [Client 86] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38334)\u001b[0m [Client 41] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38338)\u001b[0m [Client 63] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38339)\u001b[0m [Client 77] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38340)\u001b[0m [Client 4] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38335)\u001b[0m [Client 44] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38338)\u001b[0m [Client 58] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38338)\u001b[0m [Client 83] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38339)\u001b[0m [Client 25] evaluate, config: {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 12:19:43,663 | server.py:170 | evaluate_round received 0 results and 30 failures\n",
      "DEBUG flower 2023-02-01 12:19:43,664 | server.py:203 | fit_round: strategy sampled 30 clients (out of 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38338)\u001b[0m [Client 32] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38339)\u001b[0m [Client 55] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38339)\u001b[0m [Client 52] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38339)\u001b[0m [Client 54] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38334)\u001b[0m [Client 3] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38341)\u001b[0m [Client 5] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38338)\u001b[0m [Client 84] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38338)\u001b[0m [Client 10] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38336)\u001b[0m [Client 56] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38339)\u001b[0m [Client 91] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38340)\u001b[0m [Client 68] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38337)\u001b[0m [Client 6] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38335)\u001b[0m [Client 16] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m [Client 99] fit, config: {'current_round': 18, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m [Client 56] fit, config: {'current_round': 18, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m Epoch 1: train loss 0.00018303441174793988, accuracy 0.6111111111111112\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m [Client 25] fit, config: {'current_round': 18, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m Epoch 1: train loss 0.00017615416436456144, accuracy 0.6666666666666666\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m Epoch 1: train loss 0.00017461039533372968, accuracy 0.6666666666666666\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m [Client 16] fit, config: {'current_round': 18, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m Epoch 1: train loss 0.00016393580881413072, accuracy 0.7777777777777778\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m [Client 60] fit, config: {'current_round': 18, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m Epoch 1: train loss 0.00017062516417354345, accuracy 0.6666666666666666\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m [Client 41] fit, config: {'current_round': 18, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m [Client 96] fit, config: {'current_round': 18, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m Epoch 1: train loss 0.00017402280354872346, accuracy 0.6296296296296297\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m Epoch 1: train loss 0.00017971510533243418, accuracy 0.5740740740740741\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m [Client 70] fit, config: {'current_round': 18, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m Epoch 1: train loss 0.0001705027825664729, accuracy 0.6666666666666666\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m [Client 39] fit, config: {'current_round': 18, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m Epoch 1: train loss 0.0001821861951611936, accuracy 0.5925925925925926\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m [Client 15] fit, config: {'current_round': 18, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m Epoch 1: train loss 0.00018051316146738827, accuracy 0.6481481481481481\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m [Client 14] fit, config: {'current_round': 18, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m Epoch 1: train loss 0.0001713313249638304, accuracy 0.6666666666666666\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m [Client 90] fit, config: {'current_round': 18, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m Epoch 1: train loss 0.00016364743351005018, accuracy 0.7037037037037037\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m [Client 78] fit, config: {'current_round': 18, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m Epoch 1: train loss 0.00016974686877802014, accuracy 0.6111111111111112\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m [Client 9] fit, config: {'current_round': 18, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m Epoch 1: train loss 0.00017674006812740117, accuracy 0.6111111111111112\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m [Client 0] fit, config: {'current_round': 18, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m Epoch 1: train loss 0.0001763523177942261, accuracy 0.6111111111111112\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m [Client 43] fit, config: {'current_round': 18, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m [Client 20] fit, config: {'current_round': 18, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m Epoch 1: train loss 0.00017761510389391333, accuracy 0.7592592592592593\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 12:19:45,366 | server.py:216 | fit_round received 30 results and 0 failures\n",
      "DEBUG flower 2023-02-01 12:19:45,421 | server.py:157 | evaluate_round: strategy sampled 30 clients (out of 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m Epoch 1: train loss 0.00017275093705393374, accuracy 0.6666666666666666\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m [Client 28] fit, config: {'current_round': 18, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m Epoch 1: train loss 0.0001584311103215441, accuracy 0.7777777777777778\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m [Client 80] fit, config: {'current_round': 18, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m Epoch 1: train loss 0.00017952773487195373, accuracy 0.7037037037037037\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m [Client 84] fit, config: {'current_round': 18, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m Epoch 1: train loss 0.00018136078142561018, accuracy 0.5370370370370371\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m [Client 5] fit, config: {'current_round': 18, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m Epoch 1: train loss 0.00016891268023755401, accuracy 0.6851851851851852\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m [Client 11] fit, config: {'current_round': 18, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m Epoch 1: train loss 0.00016535424219910055, accuracy 0.6851851851851852\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m [Client 61] fit, config: {'current_round': 18, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m Epoch 1: train loss 0.00018747945432551205, accuracy 0.5555555555555556\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m [Client 73] fit, config: {'current_round': 18, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m Epoch 1: train loss 0.0001768215443007648, accuracy 0.6111111111111112\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m [Client 46] fit, config: {'current_round': 18, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m Epoch 1: train loss 0.00017770272097550333, accuracy 0.5555555555555556\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m [Client 71] fit, config: {'current_round': 18, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m Epoch 1: train loss 0.0001701765286270529, accuracy 0.6851851851851852\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m [Client 77] fit, config: {'current_round': 18, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m [Client 54] fit, config: {'current_round': 18, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m [Client 79] fit, config: {'current_round': 18, 'local_epochs': 3}\n",
      "Saving round 18 aggregated_parameters...\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m Epoch 1: train loss 0.00017877938807941973, accuracy 0.5740740740740741\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m Epoch 1: train loss 0.0001781844039214775, accuracy 0.7037037037037037\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m Epoch 1: train loss 0.00017892889445647597, accuracy 0.6111111111111112\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m [Client 94] fit, config: {'current_round': 18, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m Epoch 1: train loss 0.00017220573499798775, accuracy 0.6851851851851852\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38335)\u001b[0m [Client 63] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38338)\u001b[0m [Client 92] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38335)\u001b[0m [Client 89] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38335)\u001b[0m [Client 85] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38338)\u001b[0m [Client 21] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38338)\u001b[0m [Client 73] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38335)\u001b[0m [Client 42] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38338)\u001b[0m [Client 93] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38339)\u001b[0m [Client 65] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38336)\u001b[0m [Client 45] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38334)\u001b[0m [Client 1] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38341)\u001b[0m [Client 77] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38338)\u001b[0m [Client 76] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38336)\u001b[0m [Client 81] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38340)\u001b[0m [Client 59] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38337)\u001b[0m [Client 39] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38335)\u001b[0m [Client 26] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38336)\u001b[0m [Client 8] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38336)\u001b[0m [Client 62] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38340)\u001b[0m [Client 9] evaluate, config: {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 12:19:47,171 | server.py:170 | evaluate_round received 0 results and 30 failures\n",
      "DEBUG flower 2023-02-01 12:19:47,172 | server.py:203 | fit_round: strategy sampled 30 clients (out of 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38334)\u001b[0m [Client 54] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38341)\u001b[0m [Client 43] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38338)\u001b[0m [Client 53] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38339)\u001b[0m [Client 27] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38339)\u001b[0m [Client 90] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38340)\u001b[0m [Client 22] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38337)\u001b[0m [Client 82] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38335)\u001b[0m [Client 15] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38335)\u001b[0m [Client 14] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38336)\u001b[0m [Client 6] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m [Client 16] fit, config: {'current_round': 19, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m Epoch 1: train loss 0.00015674886526539922, accuracy 0.6851851851851852\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m [Client 21] fit, config: {'current_round': 19, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m Epoch 1: train loss 0.00016775303811300546, accuracy 0.7037037037037037\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m [Client 72] fit, config: {'current_round': 19, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m Epoch 1: train loss 0.00017625144391786307, accuracy 0.5185185185185185\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m [Client 28] fit, config: {'current_round': 19, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m Epoch 1: train loss 0.00014747869863640517, accuracy 0.7407407407407407\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m [Client 70] fit, config: {'current_round': 19, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m Epoch 1: train loss 0.00016549012798350304, accuracy 0.6111111111111112\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m [Client 63] fit, config: {'current_round': 19, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m Epoch 1: train loss 0.00016748833877500147, accuracy 0.6111111111111112\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m [Client 48] fit, config: {'current_round': 19, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m Epoch 1: train loss 0.00016675563529133797, accuracy 0.6666666666666666\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m [Client 85] fit, config: {'current_round': 19, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m Epoch 1: train loss 0.00016535029863007367, accuracy 0.5740740740740741\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m [Client 40] fit, config: {'current_round': 19, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m Epoch 1: train loss 0.00015259253268595785, accuracy 0.7037037037037037\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m [Client 64] fit, config: {'current_round': 19, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m Epoch 1: train loss 0.0001714142708806321, accuracy 0.5925925925925926\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 12:19:48,936 | server.py:216 | fit_round received 30 results and 0 failures\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m [Client 43] fit, config: {'current_round': 19, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m Epoch 1: train loss 0.0001659491827012971, accuracy 0.6296296296296297\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m [Client 35] fit, config: {'current_round': 19, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m Epoch 1: train loss 0.00015986085054464638, accuracy 0.7222222222222222\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m [Client 78] fit, config: {'current_round': 19, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m [Client 23] fit, config: {'current_round': 19, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m Epoch 1: train loss 0.00016426782531198114, accuracy 0.6666666666666666\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m [Client 87] fit, config: {'current_round': 19, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m Epoch 1: train loss 0.00016387739742640406, accuracy 0.6111111111111112\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m [Client 57] fit, config: {'current_round': 19, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m [Client 39] fit, config: {'current_round': 19, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m Epoch 1: train loss 0.00017516985826659948, accuracy 0.48148148148148145\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m [Client 68] fit, config: {'current_round': 19, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m Epoch 1: train loss 0.00017357198521494865, accuracy 0.5555555555555556\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m Epoch 1: train loss 0.00017276252037845552, accuracy 0.5925925925925926\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m Epoch 1: train loss 0.00014598187408410013, accuracy 0.6296296296296297\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m [Client 82] fit, config: {'current_round': 19, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m Epoch 1: train loss 0.00017449546430725604, accuracy 0.6296296296296297\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m [Client 22] fit, config: {'current_round': 19, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m Epoch 1: train loss 0.0001627486344659701, accuracy 0.5555555555555556\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m [Client 45] fit, config: {'current_round': 19, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m Epoch 1: train loss 0.00015719083603471518, accuracy 0.7037037037037037\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m [Client 96] fit, config: {'current_round': 19, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m Epoch 1: train loss 0.0001690530334599316, accuracy 0.6111111111111112\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m [Client 44] fit, config: {'current_round': 19, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m Epoch 1: train loss 0.000153059940203093, accuracy 0.6666666666666666\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m [Client 31] fit, config: {'current_round': 19, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m Epoch 1: train loss 0.00016399580636061728, accuracy 0.6481481481481481\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m [Client 86] fit, config: {'current_round': 19, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m Epoch 1: train loss 0.00016440935723949224, accuracy 0.6296296296296297\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m [Client 12] fit, config: {'current_round': 19, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m Epoch 1: train loss 0.00016960302309598774, accuracy 0.6851851851851852\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m [Client 11] fit, config: {'current_round': 19, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m Epoch 1: train loss 0.00015931730740703642, accuracy 0.6296296296296297\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m [Client 18] fit, config: {'current_round': 19, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m Epoch 1: train loss 0.0001684678136371076, accuracy 0.5185185185185185\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m [Client 10] fit, config: {'current_round': 19, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m Epoch 1: train loss 0.00016470917034894228, accuracy 0.6296296296296297\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 12:19:48,973 | server.py:157 | evaluate_round: strategy sampled 30 clients (out of 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving round 19 aggregated_parameters...\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m [Client 55] fit, config: {'current_round': 19, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m Epoch 1: train loss 0.0001553716283524409, accuracy 0.7037037037037037\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38336)\u001b[0m [Client 78] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38335)\u001b[0m [Client 45] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38335)\u001b[0m [Client 23] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38336)\u001b[0m [Client 7] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38337)\u001b[0m [Client 93] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38335)\u001b[0m [Client 34] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38335)\u001b[0m [Client 58] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38335)\u001b[0m [Client 0] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38335)\u001b[0m [Client 77] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38334)\u001b[0m [Client 44] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38341)\u001b[0m [Client 97] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38338)\u001b[0m [Client 70] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38336)\u001b[0m [Client 33] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38339)\u001b[0m [Client 67] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38337)\u001b[0m [Client 18] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38335)\u001b[0m [Client 89] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38334)\u001b[0m [Client 8] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38336)\u001b[0m [Client 84] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38340)\u001b[0m [Client 71] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38337)\u001b[0m [Client 81] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38336)\u001b[0m [Client 26] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38335)\u001b[0m [Client 21] evaluate, config: {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 12:19:50,798 | server.py:170 | evaluate_round received 0 results and 30 failures\n",
      "DEBUG flower 2023-02-01 12:19:50,799 | server.py:203 | fit_round: strategy sampled 30 clients (out of 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38334)\u001b[0m [Client 22] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38341)\u001b[0m [Client 38] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38338)\u001b[0m [Client 51] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38336)\u001b[0m [Client 63] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38339)\u001b[0m [Client 9] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38340)\u001b[0m [Client 15] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38337)\u001b[0m [Client 39] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38335)\u001b[0m [Client 64] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m [Client 84] fit, config: {'current_round': 20, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m Epoch 1: train loss 0.0001707010087557137, accuracy 0.5185185185185185\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m [Client 9] fit, config: {'current_round': 20, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m Epoch 1: train loss 0.0001648219331400469, accuracy 0.5740740740740741\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m [Client 76] fit, config: {'current_round': 20, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m Epoch 1: train loss 0.0001611371844774112, accuracy 0.6111111111111112\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m [Client 68] fit, config: {'current_round': 20, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m [Client 69] fit, config: {'current_round': 20, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m Epoch 1: train loss 0.0001603450218681246, accuracy 0.7037037037037037\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m Epoch 1: train loss 0.0001690488716121763, accuracy 0.5370370370370371\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m [Client 14] fit, config: {'current_round': 20, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m Epoch 1: train loss 0.00015891499060671777, accuracy 0.6296296296296297\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m [Client 85] fit, config: {'current_round': 20, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m Epoch 1: train loss 0.00015688835992477834, accuracy 0.6666666666666666\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m [Client 65] fit, config: {'current_round': 20, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m Epoch 1: train loss 0.00015578862803522497, accuracy 0.7407407407407407\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m [Client 27] fit, config: {'current_round': 20, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m Epoch 1: train loss 0.00016484198567923158, accuracy 0.7037037037037037\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m [Client 35] fit, config: {'current_round': 20, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m Epoch 1: train loss 0.00015141455514822155, accuracy 0.7777777777777778\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m [Client 95] fit, config: {'current_round': 20, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m Epoch 1: train loss 0.0001542578829685226, accuracy 0.7037037037037037\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m [Client 4] fit, config: {'current_round': 20, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m Epoch 1: train loss 0.0001573140179971233, accuracy 0.7407407407407407\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m [Client 52] fit, config: {'current_round': 20, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m [Client 19] fit, config: {'current_round': 20, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m Epoch 1: train loss 0.0001563989499118179, accuracy 0.7407407407407407\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m [Client 40] fit, config: {'current_round': 20, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m [Client 11] fit, config: {'current_round': 20, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m Epoch 1: train loss 0.0001512662711320445, accuracy 0.6851851851851852\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m [Client 30] fit, config: {'current_round': 20, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m Epoch 1: train loss 0.00016873114509508014, accuracy 0.5\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m [Client 46] fit, config: {'current_round': 20, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m Epoch 1: train loss 0.0001657451648497954, accuracy 0.6111111111111112\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m Epoch 1: train loss 0.00015219763736240566, accuracy 0.6481481481481481\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m [Client 60] fit, config: {'current_round': 20, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m Epoch 1: train loss 0.00015716830966994166, accuracy 0.5740740740740741\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m Epoch 1: train loss 0.00014720715989824384, accuracy 0.7407407407407407\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m [Client 78] fit, config: {'current_round': 20, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m Epoch 1: train loss 0.0001567258732393384, accuracy 0.6296296296296297\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m [Client 22] fit, config: {'current_round': 20, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m Epoch 1: train loss 0.00015637963952030987, accuracy 0.6481481481481481\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m [Client 64] fit, config: {'current_round': 20, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m Epoch 1: train loss 0.000167298290762119, accuracy 0.6666666666666666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 12:19:52,880 | server.py:216 | fit_round received 30 results and 0 failures\n",
      "DEBUG flower 2023-02-01 12:19:52,918 | server.py:157 | evaluate_round: strategy sampled 30 clients (out of 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m [Client 2] fit, config: {'current_round': 20, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m Epoch 1: train loss 0.00016035433509387076, accuracy 0.6666666666666666\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m [Client 8] fit, config: {'current_round': 20, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m Epoch 1: train loss 0.00017185213800985366, accuracy 0.5925925925925926\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m [Client 92] fit, config: {'current_round': 20, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m [Client 59] fit, config: {'current_round': 20, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m Epoch 1: train loss 0.00016907430835999548, accuracy 0.6851851851851852\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m [Client 96] fit, config: {'current_round': 20, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m Epoch 1: train loss 0.0001605579600436613, accuracy 0.6111111111111112\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m [Client 73] fit, config: {'current_round': 20, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m Epoch 1: train loss 0.00016742380103096366, accuracy 0.6481481481481481\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m [Client 36] fit, config: {'current_round': 20, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m Epoch 1: train loss 0.00016005881479941308, accuracy 0.6481481481481481\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m [Client 12] fit, config: {'current_round': 20, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m Epoch 1: train loss 0.00016822073666844517, accuracy 0.6481481481481481\n",
      "Saving round 20 aggregated_parameters...\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m Epoch 1: train loss 0.0001617519446881488, accuracy 0.6851851851851852\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38338)\u001b[0m [Client 42] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38340)\u001b[0m [Client 25] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38338)\u001b[0m [Client 51] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38340)\u001b[0m [Client 18] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38340)\u001b[0m [Client 71] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38338)\u001b[0m [Client 2] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38340)\u001b[0m [Client 21] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38339)\u001b[0m [Client 58] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38338)\u001b[0m [Client 26] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38336)\u001b[0m [Client 16] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38339)\u001b[0m [Client 90] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38337)\u001b[0m [Client 24] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38334)\u001b[0m [Client 8] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38341)\u001b[0m [Client 35] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38338)\u001b[0m [Client 50] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38339)\u001b[0m [Client 85] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38340)\u001b[0m [Client 96] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38337)\u001b[0m [Client 83] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38335)\u001b[0m [Client 65] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38336)\u001b[0m [Client 55] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38341)\u001b[0m [Client 54] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38336)\u001b[0m [Client 56] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38337)\u001b[0m [Client 66] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38335)\u001b[0m [Client 14] evaluate, config: {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 12:19:54,753 | server.py:170 | evaluate_round received 0 results and 30 failures\n",
      "DEBUG flower 2023-02-01 12:19:54,754 | server.py:203 | fit_round: strategy sampled 30 clients (out of 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38334)\u001b[0m [Client 11] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38338)\u001b[0m [Client 89] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38336)\u001b[0m [Client 44] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38339)\u001b[0m [Client 37] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38340)\u001b[0m [Client 32] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38337)\u001b[0m [Client 38] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m [Client 62] fit, config: {'current_round': 21, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m Epoch 1: train loss 0.00014835641195531934, accuracy 0.6666666666666666\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m [Client 51] fit, config: {'current_round': 21, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m Epoch 1: train loss 0.00016370743105653673, accuracy 0.6296296296296297\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m [Client 58] fit, config: {'current_round': 21, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m Epoch 1: train loss 0.00015357445226982236, accuracy 0.6296296296296297\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m [Client 91] fit, config: {'current_round': 21, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m Epoch 1: train loss 0.00014486760483123362, accuracy 0.7962962962962963\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m [Client 14] fit, config: {'current_round': 21, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m Epoch 1: train loss 0.00015077347052283585, accuracy 0.7037037037037037\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m [Client 23] fit, config: {'current_round': 21, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m Epoch 1: train loss 0.0001603457931196317, accuracy 0.6111111111111112\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m [Client 87] fit, config: {'current_round': 21, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m Epoch 1: train loss 0.00015378707030322403, accuracy 0.6666666666666666\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m [Client 11] fit, config: {'current_round': 21, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m Epoch 1: train loss 0.00015026044275145978, accuracy 0.6666666666666666\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m [Client 67] fit, config: {'current_round': 21, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m [Client 30] fit, config: {'current_round': 21, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m [Client 7] fit, config: {'current_round': 21, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m Epoch 1: train loss 0.0001649519253987819, accuracy 0.5925925925925926\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m Epoch 1: train loss 0.000150074643897824, accuracy 0.6851851851851852\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m [Client 60] fit, config: {'current_round': 21, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m Epoch 1: train loss 0.00015583868662361056, accuracy 0.6666666666666666\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m [Client 53] fit, config: {'current_round': 21, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m [Client 49] fit, config: {'current_round': 21, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m Epoch 1: train loss 0.00017205851327162236, accuracy 0.6296296296296297\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m [Client 2] fit, config: {'current_round': 21, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m [Client 5] fit, config: {'current_round': 21, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m Epoch 1: train loss 0.0001680440327618271, accuracy 0.5370370370370371\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m Epoch 1: train loss 0.00015200312191154808, accuracy 0.6481481481481481\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m [Client 70] fit, config: {'current_round': 21, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m Epoch 1: train loss 0.00015395117225125432, accuracy 0.6666666666666666\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m [Client 77] fit, config: {'current_round': 21, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m Epoch 1: train loss 0.00016245416190940887, accuracy 0.5185185185185185\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m Epoch 1: train loss 0.00015618986799381673, accuracy 0.5740740740740741\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m [Client 76] fit, config: {'current_round': 21, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m Epoch 1: train loss 0.00015409734623972327, accuracy 0.7222222222222222\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m Epoch 1: train loss 0.00014416660997085273, accuracy 0.6296296296296297\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m [Client 97] fit, config: {'current_round': 21, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m Epoch 1: train loss 0.0001553828187752515, accuracy 0.6851851851851852\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 12:19:56,565 | server.py:216 | fit_round received 30 results and 0 failures\n",
      "DEBUG flower 2023-02-01 12:19:56,603 | server.py:157 | evaluate_round: strategy sampled 30 clients (out of 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m [Client 57] fit, config: {'current_round': 21, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m [Client 79] fit, config: {'current_round': 21, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m [Client 71] fit, config: {'current_round': 21, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m Epoch 1: train loss 0.00014936027582734823, accuracy 0.7222222222222222\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m [Client 83] fit, config: {'current_round': 21, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m Epoch 1: train loss 0.00016168611182365566, accuracy 0.6481481481481481\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m Epoch 1: train loss 0.00013449828838929534, accuracy 0.7037037037037037\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m [Client 21] fit, config: {'current_round': 21, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m [Client 96] fit, config: {'current_round': 21, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m Epoch 1: train loss 0.0001587822480360046, accuracy 0.6481481481481481\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m Epoch 1: train loss 0.00016030365077313036, accuracy 0.6481481481481481\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m [Client 88] fit, config: {'current_round': 21, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m Epoch 1: train loss 0.00014509411994367838, accuracy 0.6851851851851852\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m [Client 1] fit, config: {'current_round': 21, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m Epoch 1: train loss 0.00012975436402484775, accuracy 0.7962962962962963\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m [Client 34] fit, config: {'current_round': 21, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m Epoch 1: train loss 0.00014788263069931418, accuracy 0.6481481481481481\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m [Client 4] fit, config: {'current_round': 21, 'local_epochs': 3}\n",
      "Saving round 21 aggregated_parameters...\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m Epoch 1: train loss 0.00015679771604482085, accuracy 0.6851851851851852\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m Epoch 1: train loss 0.00015118287410587072, accuracy 0.6666666666666666\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38341)\u001b[0m [Client 98] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38335)\u001b[0m [Client 66] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38335)\u001b[0m [Client 73] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38335)\u001b[0m [Client 74] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38341)\u001b[0m [Client 38] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38341)\u001b[0m [Client 56] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38335)\u001b[0m [Client 64] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38341)\u001b[0m [Client 11] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38340)\u001b[0m [Client 85] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38335)\u001b[0m [Client 57] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38341)\u001b[0m [Client 55] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38341)\u001b[0m [Client 54] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38341)\u001b[0m [Client 7] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38341)\u001b[0m [Client 39] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38341)\u001b[0m [Client 8] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38340)\u001b[0m [Client 19] evaluate, config: {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 12:19:58,284 | server.py:170 | evaluate_round received 0 results and 30 failures\n",
      "DEBUG flower 2023-02-01 12:19:58,285 | server.py:203 | fit_round: strategy sampled 30 clients (out of 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38340)\u001b[0m [Client 61] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38341)\u001b[0m [Client 68] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38340)\u001b[0m [Client 41] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38335)\u001b[0m [Client 26] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38340)\u001b[0m [Client 23] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38334)\u001b[0m [Client 78] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38341)\u001b[0m [Client 69] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38341)\u001b[0m [Client 72] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38338)\u001b[0m [Client 90] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38336)\u001b[0m [Client 83] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38339)\u001b[0m [Client 81] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38340)\u001b[0m [Client 32] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38337)\u001b[0m [Client 89] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38335)\u001b[0m [Client 82] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m [Client 96] fit, config: {'current_round': 22, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m Epoch 1: train loss 0.0001510587171651423, accuracy 0.6296296296296297\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m [Client 15] fit, config: {'current_round': 22, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m Epoch 1: train loss 0.00016543114907108247, accuracy 0.5370370370370371\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m [Client 47] fit, config: {'current_round': 22, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m Epoch 1: train loss 0.00015710580919403583, accuracy 0.5740740740740741\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m [Client 28] fit, config: {'current_round': 22, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m Epoch 1: train loss 0.00013282470172271132, accuracy 0.7222222222222222\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m [Client 17] fit, config: {'current_round': 22, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m [Client 32] fit, config: {'current_round': 22, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m Epoch 1: train loss 0.000166417594300583, accuracy 0.5185185185185185\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m [Client 52] fit, config: {'current_round': 22, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m Epoch 1: train loss 0.00014718607417307794, accuracy 0.6481481481481481\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m Epoch 1: train loss 0.00016613597108516842, accuracy 0.5\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m [Client 26] fit, config: {'current_round': 22, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m Epoch 1: train loss 0.00015655808965675533, accuracy 0.6666666666666666\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m [Client 84] fit, config: {'current_round': 22, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m [Client 42] fit, config: {'current_round': 22, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m Epoch 1: train loss 0.0001580319949425757, accuracy 0.5555555555555556\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m Epoch 1: train loss 0.00016597453213762492, accuracy 0.46296296296296297\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m [Client 18] fit, config: {'current_round': 22, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m Epoch 1: train loss 0.00015539965534117073, accuracy 0.5370370370370371\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m [Client 59] fit, config: {'current_round': 22, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m Epoch 1: train loss 0.0001635708031244576, accuracy 0.6111111111111112\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m [Client 78] fit, config: {'current_round': 22, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m Epoch 1: train loss 0.00014912521874066442, accuracy 0.5740740740740741\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m [Client 21] fit, config: {'current_round': 22, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m [Client 2] fit, config: {'current_round': 22, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m Epoch 1: train loss 0.00015387449820991606, accuracy 0.6481481481481481\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m [Client 90] fit, config: {'current_round': 22, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m Epoch 1: train loss 0.00014588051999453455, accuracy 0.5555555555555556\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m Epoch 1: train loss 0.00015386796439997852, accuracy 0.5740740740740741\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m [Client 9] fit, config: {'current_round': 22, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m Epoch 1: train loss 0.00015521448221988976, accuracy 0.5\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m [Client 64] fit, config: {'current_round': 22, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m [Client 56] fit, config: {'current_round': 22, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m Epoch 1: train loss 0.00017039725207723677, accuracy 0.5\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m [Client 63] fit, config: {'current_round': 22, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m Epoch 1: train loss 0.0001488983689341694, accuracy 0.6296296296296297\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m Epoch 1: train loss 0.0001602474949322641, accuracy 0.5370370370370371\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m [Client 11] fit, config: {'current_round': 22, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m [Client 36] fit, config: {'current_round': 22, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m Epoch 1: train loss 0.0001534722396172583, accuracy 0.5370370370370371\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 12:20:00,080 | server.py:216 | fit_round received 30 results and 0 failures\n",
      "DEBUG flower 2023-02-01 12:20:00,114 | server.py:157 | evaluate_round: strategy sampled 30 clients (out of 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m Epoch 1: train loss 0.00014008631114847958, accuracy 0.6481481481481481\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m [Client 31] fit, config: {'current_round': 22, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m [Client 82] fit, config: {'current_round': 22, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m [Client 99] fit, config: {'current_round': 22, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m [Client 25] fit, config: {'current_round': 22, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m Epoch 1: train loss 0.00015628820983693004, accuracy 0.5740740740740741\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m [Client 55] fit, config: {'current_round': 22, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m Epoch 1: train loss 0.00014322076458483934, accuracy 0.6111111111111112\n",
      "Saving round 22 aggregated_parameters...\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m [Client 43] fit, config: {'current_round': 22, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m Epoch 1: train loss 0.00015678010822739452, accuracy 0.5740740740740741\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m [Client 4] fit, config: {'current_round': 22, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m Epoch 1: train loss 0.0001492775190854445, accuracy 0.6851851851851852\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m Epoch 1: train loss 0.0001448919647373259, accuracy 0.6481481481481481\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m Epoch 1: train loss 0.00016137809143401682, accuracy 0.5\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m Epoch 1: train loss 0.00015486650227103382, accuracy 0.5185185185185185\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m [Client 13] fit, config: {'current_round': 22, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m Epoch 1: train loss 0.0001543614052934572, accuracy 0.6666666666666666\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38334)\u001b[0m [Client 73] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38334)\u001b[0m [Client 16] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38341)\u001b[0m [Client 87] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38341)\u001b[0m [Client 0] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38337)\u001b[0m [Client 11] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38341)\u001b[0m [Client 22] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38341)\u001b[0m [Client 82] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38341)\u001b[0m [Client 93] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38334)\u001b[0m [Client 61] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38341)\u001b[0m [Client 2] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38338)\u001b[0m [Client 41] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38336)\u001b[0m [Client 68] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38337)\u001b[0m [Client 38] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38341)\u001b[0m [Client 75] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38339)\u001b[0m [Client 51] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38337)\u001b[0m [Client 12] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38335)\u001b[0m [Client 50] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38341)\u001b[0m [Client 28] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38339)\u001b[0m [Client 31] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38337)\u001b[0m [Client 70] evaluate, config: {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 12:20:01,887 | server.py:170 | evaluate_round received 0 results and 30 failures\n",
      "DEBUG flower 2023-02-01 12:20:01,887 | server.py:203 | fit_round: strategy sampled 30 clients (out of 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38334)\u001b[0m [Client 27] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38341)\u001b[0m [Client 7] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38338)\u001b[0m [Client 90] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38339)\u001b[0m [Client 72] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38337)\u001b[0m [Client 49] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38335)\u001b[0m [Client 34] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38341)\u001b[0m [Client 77] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38336)\u001b[0m [Client 83] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38340)\u001b[0m [Client 79] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38337)\u001b[0m [Client 53] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m [Client 72] fit, config: {'current_round': 23, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m Epoch 1: train loss 0.00015851361968088895, accuracy 0.5925925925925926\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m [Client 94] fit, config: {'current_round': 23, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m [Client 6] fit, config: {'current_round': 23, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m [Client 20] fit, config: {'current_round': 23, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m Epoch 1: train loss 0.0001461156498407945, accuracy 0.5925925925925926\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m Epoch 1: train loss 0.00016149634029716253, accuracy 0.6481481481481481\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m [Client 48] fit, config: {'current_round': 23, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m Epoch 1: train loss 0.00014627458585891873, accuracy 0.6481481481481481\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m Epoch 1: train loss 0.00015183634241111577, accuracy 0.6111111111111112\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m [Client 92] fit, config: {'current_round': 23, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m Epoch 1: train loss 0.00014707152149640024, accuracy 0.6481481481481481\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m [Client 39] fit, config: {'current_round': 23, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m [Client 30] fit, config: {'current_round': 23, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m Epoch 1: train loss 0.00016172887990251184, accuracy 0.5\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m Epoch 1: train loss 0.0001622696581762284, accuracy 0.5555555555555556\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m [Client 31] fit, config: {'current_round': 23, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m Epoch 1: train loss 0.000147640093928203, accuracy 0.6666666666666666\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m [Client 5] fit, config: {'current_round': 23, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m [Client 73] fit, config: {'current_round': 23, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m Epoch 1: train loss 0.00014463761181104928, accuracy 0.5555555555555556\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m Epoch 1: train loss 0.00015144902863539755, accuracy 0.5555555555555556\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m [Client 88] fit, config: {'current_round': 23, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m [Client 58] fit, config: {'current_round': 23, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m Epoch 1: train loss 0.00014445403940044343, accuracy 0.6296296296296297\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m [Client 12] fit, config: {'current_round': 23, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m Epoch 1: train loss 0.0001463068329030648, accuracy 0.7037037037037037\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m Epoch 1: train loss 0.0001369366655126214, accuracy 0.7222222222222222\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m [Client 53] fit, config: {'current_round': 23, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m Epoch 1: train loss 0.00013804489572066814, accuracy 0.6296296296296297\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m [Client 85] fit, config: {'current_round': 23, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m Epoch 1: train loss 0.00014306249795481563, accuracy 0.6481481481481481\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m [Client 47] fit, config: {'current_round': 23, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m Epoch 1: train loss 0.00015654358139727265, accuracy 0.5555555555555556\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m [Client 18] fit, config: {'current_round': 23, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m Epoch 1: train loss 0.00014699430903419852, accuracy 0.6666666666666666\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m [Client 36] fit, config: {'current_round': 23, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m [Client 49] fit, config: {'current_round': 23, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m Epoch 1: train loss 0.0001641460257815197, accuracy 0.6111111111111112\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m [Client 75] fit, config: {'current_round': 23, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m Epoch 1: train loss 0.0001537366333650425, accuracy 0.6111111111111112\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m Epoch 1: train loss 0.00014595034008380026, accuracy 0.6111111111111112\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 12:20:03,697 | server.py:216 | fit_round received 30 results and 0 failures\n",
      "DEBUG flower 2023-02-01 12:20:03,738 | server.py:157 | evaluate_round: strategy sampled 30 clients (out of 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m [Client 70] fit, config: {'current_round': 23, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m Epoch 1: train loss 0.00014694670971948653, accuracy 0.6111111111111112\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m [Client 87] fit, config: {'current_round': 23, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m Epoch 1: train loss 0.00014974235091358423, accuracy 0.5740740740740741\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m [Client 93] fit, config: {'current_round': 23, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m Epoch 1: train loss 0.00014123451546765864, accuracy 0.6111111111111112\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m [Client 13] fit, config: {'current_round': 23, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m Epoch 1: train loss 0.00014437561912927777, accuracy 0.7777777777777778\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m [Client 82] fit, config: {'current_round': 23, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m Epoch 1: train loss 0.0001572666660649702, accuracy 0.5740740740740741\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m [Client 97] fit, config: {'current_round': 23, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m Epoch 1: train loss 0.00014951096090953797, accuracy 0.6481481481481481\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m [Client 81] fit, config: {'current_round': 23, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m Epoch 1: train loss 0.0001558121293783188, accuracy 0.6111111111111112\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m [Client 65] fit, config: {'current_round': 23, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m Epoch 1: train loss 0.00014856521738693118, accuracy 0.6666666666666666\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m [Client 24] fit, config: {'current_round': 23, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m Epoch 1: train loss 0.00014470807218458503, accuracy 0.6481481481481481\n",
      "Saving round 23 aggregated_parameters...\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38334)\u001b[0m [Client 86] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38334)\u001b[0m [Client 61] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38338)\u001b[0m [Client 30] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38338)\u001b[0m [Client 78] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38338)\u001b[0m [Client 34] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38334)\u001b[0m [Client 6] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38338)\u001b[0m [Client 56] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38338)\u001b[0m [Client 36] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38334)\u001b[0m [Client 85] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38338)\u001b[0m [Client 77] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38334)\u001b[0m [Client 14] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38334)\u001b[0m [Client 32] evaluate, config: {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 12:20:05,565 | server.py:170 | evaluate_round received 0 results and 30 failures\n",
      "DEBUG flower 2023-02-01 12:20:05,566 | server.py:203 | fit_round: strategy sampled 30 clients (out of 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38338)\u001b[0m [Client 55] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38339)\u001b[0m [Client 46] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38340)\u001b[0m [Client 10] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38335)\u001b[0m [Client 75] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38334)\u001b[0m [Client 64] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38341)\u001b[0m [Client 3] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38338)\u001b[0m [Client 84] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38336)\u001b[0m [Client 31] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38339)\u001b[0m [Client 91] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38337)\u001b[0m [Client 83] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38335)\u001b[0m [Client 42] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38338)\u001b[0m [Client 28] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38336)\u001b[0m [Client 18] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38337)\u001b[0m [Client 90] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38335)\u001b[0m [Client 4] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38334)\u001b[0m [Client 2] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38341)\u001b[0m [Client 73] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38339)\u001b[0m [Client 25] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m [Client 2] fit, config: {'current_round': 24, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m Epoch 1: train loss 0.00014372258738148957, accuracy 0.6851851851851852\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m [Client 86] fit, config: {'current_round': 24, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m Epoch 1: train loss 0.0001397526211803779, accuracy 0.6111111111111112\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m [Client 60] fit, config: {'current_round': 24, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m Epoch 1: train loss 0.00013561872765421867, accuracy 0.6296296296296297\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m [Client 17] fit, config: {'current_round': 24, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m Epoch 1: train loss 0.00015958200674504042, accuracy 0.5370370370370371\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m [Client 68] fit, config: {'current_round': 24, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m Epoch 1: train loss 0.00015101282042451203, accuracy 0.5555555555555556\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m [Client 56] fit, config: {'current_round': 24, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m Epoch 1: train loss 0.00016266580496449023, accuracy 0.5740740740740741\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m [Client 33] fit, config: {'current_round': 24, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m Epoch 1: train loss 0.00015697152412030846, accuracy 0.5555555555555556\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m [Client 29] fit, config: {'current_round': 24, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m Epoch 1: train loss 0.00014805744285695255, accuracy 0.5555555555555556\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(raylet)\u001b[0m Spilled 65672 MiB, 2170 objects, write throughput 1462 MiB/s.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m [Client 37] fit, config: {'current_round': 24, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m Epoch 1: train loss 0.0001408645766787231, accuracy 0.6296296296296297\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m [Client 81] fit, config: {'current_round': 24, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m [Client 94] fit, config: {'current_round': 24, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m Epoch 1: train loss 0.00014214139082469046, accuracy 0.6111111111111112\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m Epoch 1: train loss 0.00014812842709943652, accuracy 0.6296296296296297\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m [Client 22] fit, config: {'current_round': 24, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m Epoch 1: train loss 0.0001411624252796173, accuracy 0.5740740740740741\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m [Client 18] fit, config: {'current_round': 24, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m Epoch 1: train loss 0.00014708405069541186, accuracy 0.5740740740740741\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m [Client 27] fit, config: {'current_round': 24, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m Epoch 1: train loss 0.00015172251733019948, accuracy 0.6296296296296297\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m [Client 19] fit, config: {'current_round': 24, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m Epoch 1: train loss 0.00013363741163630038, accuracy 0.6296296296296297\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m [Client 53] fit, config: {'current_round': 24, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m Epoch 1: train loss 0.00013002257037442178, accuracy 0.7222222222222222\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m [Client 8] fit, config: {'current_round': 24, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m Epoch 1: train loss 0.00015899245045147836, accuracy 0.48148148148148145\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m [Client 90] fit, config: {'current_round': 24, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m Epoch 1: train loss 0.0001377116423100233, accuracy 0.5740740740740741\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m [Client 82] fit, config: {'current_round': 24, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m [Client 70] fit, config: {'current_round': 24, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m [Client 54] fit, config: {'current_round': 24, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m Epoch 1: train loss 0.0001527818967588246, accuracy 0.5370370370370371\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m [Client 58] fit, config: {'current_round': 24, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m Epoch 1: train loss 0.00015234290913213044, accuracy 0.6481481481481481\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m [Client 92] fit, config: {'current_round': 24, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m Epoch 1: train loss 0.0001447038957849145, accuracy 0.6851851851851852\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m Epoch 1: train loss 0.00013913029397372156, accuracy 0.6111111111111112\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m Epoch 1: train loss 0.000150696694618091, accuracy 0.6666666666666666\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m [Client 0] fit, config: {'current_round': 24, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m [Client 57] fit, config: {'current_round': 24, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m Epoch 1: train loss 0.00011560552957234904, accuracy 0.7407407407407407\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m [Client 20] fit, config: {'current_round': 24, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m Epoch 1: train loss 0.0001487916597397998, accuracy 0.6296296296296297\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m [Client 87] fit, config: {'current_round': 24, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m Epoch 1: train loss 0.00014302025374490768, accuracy 0.6296296296296297\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m [Client 5] fit, config: {'current_round': 24, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m [Client 32] fit, config: {'current_round': 24, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m Epoch 1: train loss 0.00015701772645115852, accuracy 0.5740740740740741\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 12:20:07,936 | server.py:216 | fit_round received 30 results and 0 failures\n",
      "DEBUG flower 2023-02-01 12:20:07,990 | server.py:157 | evaluate_round: strategy sampled 30 clients (out of 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving round 24 aggregated_parameters...\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m [Client 66] fit, config: {'current_round': 24, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m Epoch 1: train loss 0.00014354052837006748, accuracy 0.6111111111111112\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m Epoch 1: train loss 0.00015169622201938182, accuracy 0.5185185185185185\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m Epoch 1: train loss 0.0001329059014096856, accuracy 0.6666666666666666\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38341)\u001b[0m [Client 91] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38341)\u001b[0m [Client 46] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38341)\u001b[0m [Client 2] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38341)\u001b[0m [Client 85] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38341)\u001b[0m [Client 82] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38341)\u001b[0m [Client 27] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38341)\u001b[0m [Client 68] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38338)\u001b[0m [Client 48] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38337)\u001b[0m [Client 3] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38341)\u001b[0m [Client 42] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38336)\u001b[0m [Client 62] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38339)\u001b[0m [Client 29] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38340)\u001b[0m [Client 84] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38339)\u001b[0m [Client 86] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38340)\u001b[0m [Client 61] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38339)\u001b[0m [Client 97] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38340)\u001b[0m [Client 79] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38339)\u001b[0m [Client 26] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38336)\u001b[0m [Client 81] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38339)\u001b[0m [Client 44] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38340)\u001b[0m [Client 12] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38341)\u001b[0m [Client 8] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38336)\u001b[0m [Client 28] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38339)\u001b[0m [Client 37] evaluate, config: {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 12:20:10,201 | server.py:170 | evaluate_round received 0 results and 30 failures\n",
      "DEBUG flower 2023-02-01 12:20:10,203 | server.py:203 | fit_round: strategy sampled 30 clients (out of 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38338)\u001b[0m [Client 92] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38336)\u001b[0m [Client 75] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38339)\u001b[0m [Client 87] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38340)\u001b[0m [Client 14] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38337)\u001b[0m [Client 89] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38335)\u001b[0m [Client 57] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m [Client 88] fit, config: {'current_round': 25, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m [Client 95] fit, config: {'current_round': 25, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m Epoch 1: train loss 0.00012749937013722956, accuracy 0.7592592592592593\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m Epoch 1: train loss 0.0001338540605502203, accuracy 0.6666666666666666\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m [Client 36] fit, config: {'current_round': 25, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m Epoch 1: train loss 0.00013693221262656152, accuracy 0.6666666666666666\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m [Client 98] fit, config: {'current_round': 25, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m Epoch 1: train loss 0.00013977685011923313, accuracy 0.6666666666666666\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m [Client 48] fit, config: {'current_round': 25, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m [Client 3] fit, config: {'current_round': 25, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m [Client 80] fit, config: {'current_round': 25, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m Epoch 1: train loss 0.0001434785663150251, accuracy 0.6666666666666666\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m [Client 68] fit, config: {'current_round': 25, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m Epoch 1: train loss 0.000148164268466644, accuracy 0.6666666666666666\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m [Client 54] fit, config: {'current_round': 25, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m [Client 21] fit, config: {'current_round': 25, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m [Client 20] fit, config: {'current_round': 25, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m Epoch 1: train loss 0.00014423744869418442, accuracy 0.6481481481481481\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m [Client 42] fit, config: {'current_round': 25, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m Epoch 1: train loss 0.0001366227661492303, accuracy 0.6481481481481481\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m Epoch 1: train loss 0.00014123012078925967, accuracy 0.7037037037037037\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m Epoch 1: train loss 0.000142332399263978, accuracy 0.6481481481481481\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m Epoch 1: train loss 0.00013797436258755624, accuracy 0.6111111111111112\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m [Client 2] fit, config: {'current_round': 25, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m Epoch 1: train loss 0.00014992432261351496, accuracy 0.5370370370370371\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m [Client 19] fit, config: {'current_round': 25, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m [Client 9] fit, config: {'current_round': 25, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m [Client 52] fit, config: {'current_round': 25, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m Epoch 1: train loss 0.00014246307546272874, accuracy 0.6296296296296297\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m Epoch 1: train loss 0.0001335632987320423, accuracy 0.6666666666666666\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m Epoch 1: train loss 0.0001309230865444988, accuracy 0.7407407407407407\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m Epoch 1: train loss 0.00014955356891732663, accuracy 0.6111111111111112\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m [Client 93] fit, config: {'current_round': 25, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m [Client 39] fit, config: {'current_round': 25, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m Epoch 1: train loss 0.00015668151900172234, accuracy 0.5370370370370371\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m [Client 10] fit, config: {'current_round': 25, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m [Client 31] fit, config: {'current_round': 25, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m Epoch 1: train loss 0.0001344312186120078, accuracy 0.6296296296296297\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m [Client 81] fit, config: {'current_round': 25, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m [Client 74] fit, config: {'current_round': 25, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m [Client 89] fit, config: {'current_round': 25, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m Epoch 1: train loss 0.00014369648124556988, accuracy 0.6296296296296297\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m Epoch 1: train loss 0.00013468028919305652, accuracy 0.7222222222222222\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m Epoch 1: train loss 0.0001410639233654365, accuracy 0.6666666666666666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 12:20:12,559 | server.py:216 | fit_round received 30 results and 0 failures\n",
      "DEBUG flower 2023-02-01 12:20:12,613 | server.py:157 | evaluate_round: strategy sampled 30 clients (out of 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m [Client 53] fit, config: {'current_round': 25, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m Epoch 1: train loss 0.00014815972826909274, accuracy 0.6111111111111112\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m Epoch 1: train loss 0.00014307076344266534, accuracy 0.6481481481481481\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m [Client 69] fit, config: {'current_round': 25, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m [Client 23] fit, config: {'current_round': 25, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m Epoch 1: train loss 0.00014401637599803507, accuracy 0.6296296296296297\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m [Client 99] fit, config: {'current_round': 25, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m Epoch 1: train loss 0.0001426903036190197, accuracy 0.6481481481481481\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m [Client 13] fit, config: {'current_round': 25, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m Epoch 1: train loss 0.0001352833933196962, accuracy 0.7592592592592593\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m Epoch 1: train loss 0.00012985074135940522, accuracy 0.6481481481481481\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m [Client 94] fit, config: {'current_round': 25, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m Epoch 1: train loss 0.000137451701448299, accuracy 0.6296296296296297\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m Epoch 1: train loss 0.00013836214202456176, accuracy 0.6296296296296297\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m [Client 70] fit, config: {'current_round': 25, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m Epoch 1: train loss 0.00013844046043232083, accuracy 0.6111111111111112\n",
      "Saving round 25 aggregated_parameters...\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38340)\u001b[0m [Client 72] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38340)\u001b[0m [Client 68] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38334)\u001b[0m [Client 59] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38340)\u001b[0m [Client 57] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38334)\u001b[0m [Client 79] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38340)\u001b[0m [Client 17] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38334)\u001b[0m [Client 74] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38340)\u001b[0m [Client 95] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38334)\u001b[0m [Client 3] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38336)\u001b[0m [Client 52] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38340)\u001b[0m [Client 70] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38340)\u001b[0m [Client 48] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38336)\u001b[0m [Client 41] evaluate, config: {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 12:20:14,841 | server.py:170 | evaluate_round received 0 results and 30 failures\n",
      "DEBUG flower 2023-02-01 12:20:14,841 | server.py:203 | fit_round: strategy sampled 30 clients (out of 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38340)\u001b[0m [Client 60] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38335)\u001b[0m [Client 94] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38341)\u001b[0m [Client 65] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38340)\u001b[0m [Client 10] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38339)\u001b[0m [Client 20] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38334)\u001b[0m [Client 23] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38338)\u001b[0m [Client 69] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38336)\u001b[0m [Client 32] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38340)\u001b[0m [Client 56] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38337)\u001b[0m [Client 27] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38335)\u001b[0m [Client 42] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38334)\u001b[0m [Client 1] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38338)\u001b[0m [Client 12] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38340)\u001b[0m [Client 5] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38337)\u001b[0m [Client 90] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38335)\u001b[0m [Client 28] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38336)\u001b[0m [Client 33] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m [Client 99] fit, config: {'current_round': 26, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m Epoch 1: train loss 0.00013756468251813203, accuracy 0.5370370370370371\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m [Client 74] fit, config: {'current_round': 26, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m Epoch 1: train loss 0.00014319914043881, accuracy 0.5740740740740741\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m [Client 57] fit, config: {'current_round': 26, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m Epoch 1: train loss 0.00010819385352078825, accuracy 0.7222222222222222\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m [Client 32] fit, config: {'current_round': 26, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m Epoch 1: train loss 0.00014874883345328271, accuracy 0.5925925925925926\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m [Client 28] fit, config: {'current_round': 26, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m Epoch 1: train loss 0.00011555380478966981, accuracy 0.7777777777777778\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m [Client 54] fit, config: {'current_round': 26, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m Epoch 1: train loss 0.00014168363122735173, accuracy 0.6481481481481481\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m [Client 11] fit, config: {'current_round': 26, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m Epoch 1: train loss 0.00012428993068169802, accuracy 0.6481481481481481\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m [Client 73] fit, config: {'current_round': 26, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m [Client 60] fit, config: {'current_round': 26, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m Epoch 1: train loss 0.00012581443297676742, accuracy 0.6851851851851852\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m [Client 52] fit, config: {'current_round': 26, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m [Client 81] fit, config: {'current_round': 26, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m [Client 12] fit, config: {'current_round': 26, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m [Client 37] fit, config: {'current_round': 26, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m Epoch 1: train loss 0.00015152395644690841, accuracy 0.5740740740740741\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m [Client 15] fit, config: {'current_round': 26, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m Epoch 1: train loss 0.00013131616287864745, accuracy 0.6851851851851852\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m Epoch 1: train loss 0.0001407424861099571, accuracy 0.6296296296296297\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m Epoch 1: train loss 0.0001469271956011653, accuracy 0.6111111111111112\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m Epoch 1: train loss 0.00013440180919133127, accuracy 0.6481481481481481\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m [Client 42] fit, config: {'current_round': 26, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m Epoch 1: train loss 0.00014218396972864866, accuracy 0.5740740740740741\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m [Client 13] fit, config: {'current_round': 26, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m Epoch 1: train loss 0.00013730276259593666, accuracy 0.6481481481481481\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m [Client 67] fit, config: {'current_round': 26, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m Epoch 1: train loss 0.0001479683123761788, accuracy 0.6111111111111112\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m [Client 87] fit, config: {'current_round': 26, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m Epoch 1: train loss 0.00013540114741772413, accuracy 0.6481481481481481\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m [Client 16] fit, config: {'current_round': 26, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m Epoch 1: train loss 0.0001253040973097086, accuracy 0.7037037037037037\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m Epoch 1: train loss 0.00013416177534963936, accuracy 0.7037037037037037\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m [Client 62] fit, config: {'current_round': 26, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m Epoch 1: train loss 0.00012582173803821206, accuracy 0.7222222222222222\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m [Client 65] fit, config: {'current_round': 26, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m Epoch 1: train loss 0.0001285031612496823, accuracy 0.6481481481481481\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 12:20:17,362 | server.py:216 | fit_round received 30 results and 0 failures\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m [Client 91] fit, config: {'current_round': 26, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m [Client 88] fit, config: {'current_round': 26, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m Epoch 1: train loss 0.00012356606021057814, accuracy 0.5740740740740741\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m [Client 25] fit, config: {'current_round': 26, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m Epoch 1: train loss 0.00013902297359891236, accuracy 0.6111111111111112\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m Epoch 1: train loss 0.0001249027845915407, accuracy 0.7407407407407407\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m [Client 51] fit, config: {'current_round': 26, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m [Client 24] fit, config: {'current_round': 26, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m Epoch 1: train loss 0.0001383830967824906, accuracy 0.5925925925925926\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m [Client 89] fit, config: {'current_round': 26, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m Epoch 1: train loss 0.0001396471488988027, accuracy 0.6851851851851852\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m [Client 66] fit, config: {'current_round': 26, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m Epoch 1: train loss 0.00013550087169278413, accuracy 0.6666666666666666\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m [Client 9] fit, config: {'current_round': 26, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m Epoch 1: train loss 0.0001386410294799134, accuracy 0.6111111111111112\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m [Client 10] fit, config: {'current_round': 26, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m Epoch 1: train loss 0.00013868362293578684, accuracy 0.6111111111111112\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m Epoch 1: train loss 0.00013554033648688346, accuracy 0.5925925925925926\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 12:20:17,433 | server.py:157 | evaluate_round: strategy sampled 30 clients (out of 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving round 26 aggregated_parameters...\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38336)\u001b[0m [Client 14] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38334)\u001b[0m [Client 29] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38340)\u001b[0m [Client 55] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38334)\u001b[0m [Client 90] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38334)\u001b[0m [Client 75] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38334)\u001b[0m [Client 38] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38340)\u001b[0m [Client 86] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38336)\u001b[0m [Client 46] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38341)\u001b[0m [Client 33] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38334)\u001b[0m [Client 68] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38341)\u001b[0m [Client 87] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38336)\u001b[0m [Client 58] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38334)\u001b[0m [Client 10] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38341)\u001b[0m [Client 12] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38336)\u001b[0m [Client 94] evaluate, config: {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 12:20:19,684 | server.py:170 | evaluate_round received 0 results and 30 failures\n",
      "DEBUG flower 2023-02-01 12:20:19,685 | server.py:203 | fit_round: strategy sampled 30 clients (out of 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38334)\u001b[0m [Client 89] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38334)\u001b[0m [Client 31] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38341)\u001b[0m [Client 39] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38336)\u001b[0m [Client 42] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38341)\u001b[0m [Client 48] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38338)\u001b[0m [Client 24] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38340)\u001b[0m [Client 45] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38337)\u001b[0m [Client 62] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38335)\u001b[0m [Client 98] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38334)\u001b[0m [Client 6] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38341)\u001b[0m [Client 52] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38338)\u001b[0m [Client 37] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38340)\u001b[0m [Client 41] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38337)\u001b[0m [Client 25] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38335)\u001b[0m [Client 44] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m [Client 43] fit, config: {'current_round': 27, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m Epoch 1: train loss 0.00012998822785448283, accuracy 0.6111111111111112\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m [Client 18] fit, config: {'current_round': 27, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m Epoch 1: train loss 0.0001300637813983485, accuracy 0.6666666666666666\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m [Client 2] fit, config: {'current_round': 27, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m Epoch 1: train loss 0.00012453955423552543, accuracy 0.6851851851851852\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m [Client 85] fit, config: {'current_round': 27, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m Epoch 1: train loss 0.00012131860421504825, accuracy 0.6851851851851852\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m [Client 75] fit, config: {'current_round': 27, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m [Client 22] fit, config: {'current_round': 27, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m Epoch 1: train loss 0.00013238181418273598, accuracy 0.6851851851851852\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m [Client 76] fit, config: {'current_round': 27, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m Epoch 1: train loss 0.0001286953192902729, accuracy 0.7407407407407407\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m Epoch 1: train loss 0.00013496614701580256, accuracy 0.6851851851851852\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m [Client 63] fit, config: {'current_round': 27, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m [Client 45] fit, config: {'current_round': 27, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m Epoch 1: train loss 0.00012146795052103698, accuracy 0.7222222222222222\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m Epoch 1: train loss 0.00013764829782303423, accuracy 0.6296296296296297\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m [Client 53] fit, config: {'current_round': 27, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m Epoch 1: train loss 0.00012082868488505483, accuracy 0.6481481481481481\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m [Client 74] fit, config: {'current_round': 27, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m Epoch 1: train loss 0.00013283593580126762, accuracy 0.6481481481481481\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m [Client 65] fit, config: {'current_round': 27, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m Epoch 1: train loss 0.00013044988736510277, accuracy 0.7407407407407407\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m [Client 8] fit, config: {'current_round': 27, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m Epoch 1: train loss 0.00013984627730678767, accuracy 0.5555555555555556\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m [Client 15] fit, config: {'current_round': 27, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m Epoch 1: train loss 0.00013344900798983872, accuracy 0.7037037037037037\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m [Client 83] fit, config: {'current_round': 27, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m Epoch 1: train loss 0.00013625246356241405, accuracy 0.7222222222222222\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m [Client 62] fit, config: {'current_round': 27, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m [Client 88] fit, config: {'current_round': 27, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m Epoch 1: train loss 0.00011670935055008158, accuracy 0.7962962962962963\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m [Client 21] fit, config: {'current_round': 27, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m Epoch 1: train loss 0.0001259624696103856, accuracy 0.6666666666666666\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m [Client 16] fit, config: {'current_round': 27, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m Epoch 1: train loss 0.00012114935816498473, accuracy 0.7037037037037037\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m Epoch 1: train loss 0.0001324441545875743, accuracy 0.6481481481481481\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m [Client 77] fit, config: {'current_round': 27, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m [Client 68] fit, config: {'current_round': 27, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m Epoch 1: train loss 0.00013958221825305372, accuracy 0.5370370370370371\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m Epoch 1: train loss 0.00013906789536122233, accuracy 0.7222222222222222\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m [Client 33] fit, config: {'current_round': 27, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m Epoch 1: train loss 0.00013970719010103494, accuracy 0.5370370370370371\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m [Client 55] fit, config: {'current_round': 27, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m [Client 30] fit, config: {'current_round': 27, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m [Client 66] fit, config: {'current_round': 27, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m Epoch 1: train loss 0.00012644936214201152, accuracy 0.7592592592592593\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m [Client 11] fit, config: {'current_round': 27, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m Epoch 1: train loss 0.00012979547318536788, accuracy 0.7037037037037037\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m [Client 69] fit, config: {'current_round': 27, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m Epoch 1: train loss 0.0001295324764214456, accuracy 0.6666666666666666\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m [Client 12] fit, config: {'current_round': 27, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m [Client 57] fit, config: {'current_round': 27, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m Epoch 1: train loss 0.00011262859334237874, accuracy 0.7037037037037037\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m Epoch 1: train loss 0.00011884633568115532, accuracy 0.7037037037037037\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m Epoch 1: train loss 0.00014449856826104224, accuracy 0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 12:20:22,174 | server.py:216 | fit_round received 30 results and 0 failures\n",
      "DEBUG flower 2023-02-01 12:20:22,229 | server.py:157 | evaluate_round: strategy sampled 30 clients (out of 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m Epoch 1: train loss 0.00012786778097506613, accuracy 0.7592592592592593\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m [Client 36] fit, config: {'current_round': 27, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m Epoch 1: train loss 0.0001279426651308313, accuracy 0.6851851851851852\n",
      "Saving round 27 aggregated_parameters...\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38339)\u001b[0m [Client 64] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38336)\u001b[0m [Client 82] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38336)\u001b[0m [Client 95] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38336)\u001b[0m [Client 16] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38336)\u001b[0m [Client 2] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38339)\u001b[0m [Client 70] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38340)\u001b[0m [Client 59] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38339)\u001b[0m [Client 35] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38340)\u001b[0m [Client 27] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38339)\u001b[0m [Client 20] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38339)\u001b[0m [Client 91] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38339)\u001b[0m [Client 13] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38334)\u001b[0m [Client 1] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38341)\u001b[0m [Client 57] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38336)\u001b[0m [Client 63] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38339)\u001b[0m [Client 38] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38340)\u001b[0m [Client 71] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38338)\u001b[0m [Client 37] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38339)\u001b[0m [Client 26] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38335)\u001b[0m [Client 8] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38341)\u001b[0m [Client 23] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38338)\u001b[0m [Client 49] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38336)\u001b[0m [Client 33] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38339)\u001b[0m [Client 4] evaluate, config: {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 12:20:24,653 | server.py:170 | evaluate_round received 0 results and 30 failures\n",
      "DEBUG flower 2023-02-01 12:20:24,654 | server.py:203 | fit_round: strategy sampled 30 clients (out of 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38334)\u001b[0m [Client 80] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38339)\u001b[0m [Client 34] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38340)\u001b[0m [Client 48] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38337)\u001b[0m [Client 96] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38335)\u001b[0m [Client 62] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38338)\u001b[0m [Client 67] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m [Client 69] fit, config: {'current_round': 28, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m [Client 98] fit, config: {'current_round': 28, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m Epoch 1: train loss 0.00012582491035573184, accuracy 0.7407407407407407\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m [Client 32] fit, config: {'current_round': 28, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m Epoch 1: train loss 0.0001417443563695997, accuracy 0.6111111111111112\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m Epoch 1: train loss 0.00013482918438967317, accuracy 0.6666666666666666\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m [Client 86] fit, config: {'current_round': 28, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m Epoch 1: train loss 0.00012284678814467043, accuracy 0.7037037037037037\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m [Client 5] fit, config: {'current_round': 28, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m Epoch 1: train loss 0.0001159754756372422, accuracy 0.7777777777777778\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m [Client 63] fit, config: {'current_round': 28, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m Epoch 1: train loss 0.0001202095954795368, accuracy 0.7777777777777778\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m [Client 60] fit, config: {'current_round': 28, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m Epoch 1: train loss 0.0001177661688416265, accuracy 0.6851851851851852\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m [Client 25] fit, config: {'current_round': 28, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m [Client 6] fit, config: {'current_round': 28, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m Epoch 1: train loss 0.0001317440182901919, accuracy 0.6666666666666666\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m Epoch 1: train loss 0.00012791815970558673, accuracy 0.6481481481481481\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m [Client 93] fit, config: {'current_round': 28, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m Epoch 1: train loss 0.0001295433467021212, accuracy 0.7407407407407407\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m [Client 23] fit, config: {'current_round': 28, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m Epoch 1: train loss 0.0001341831375611946, accuracy 0.6481481481481481\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m [Client 39] fit, config: {'current_round': 28, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m Epoch 1: train loss 0.0001387902448186651, accuracy 0.6296296296296297\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m [Client 75] fit, config: {'current_round': 28, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m [Client 82] fit, config: {'current_round': 28, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m [Client 87] fit, config: {'current_round': 28, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m [Client 97] fit, config: {'current_round': 28, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m Epoch 1: train loss 0.00011867052671732381, accuracy 0.7962962962962963\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m [Client 74] fit, config: {'current_round': 28, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m Epoch 1: train loss 0.00013812517863698304, accuracy 0.6296296296296297\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m [Client 9] fit, config: {'current_round': 28, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m Epoch 1: train loss 0.0001288249040953815, accuracy 0.6666666666666666\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m [Client 99] fit, config: {'current_round': 28, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m [Client 22] fit, config: {'current_round': 28, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m Epoch 1: train loss 0.00012946277274750173, accuracy 0.6481481481481481\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m Epoch 1: train loss 0.0001349817612208426, accuracy 0.6296296296296297\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m [Client 20] fit, config: {'current_round': 28, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m Epoch 1: train loss 0.0001382823393214494, accuracy 0.5555555555555556\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m Epoch 1: train loss 0.0001296787231694907, accuracy 0.5925925925925926\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m Epoch 1: train loss 0.00012668318231590092, accuracy 0.6111111111111112\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m [Client 44] fit, config: {'current_round': 28, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m Epoch 1: train loss 0.00011240954336244613, accuracy 0.7222222222222222\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m [Client 85] fit, config: {'current_round': 28, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m Epoch 1: train loss 0.00011546088353497908, accuracy 0.6666666666666666\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m Epoch 1: train loss 0.00013146683340892196, accuracy 0.6666666666666666\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m [Client 52] fit, config: {'current_round': 28, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m Epoch 1: train loss 0.00012278107169549912, accuracy 0.7037037037037037\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m [Client 70] fit, config: {'current_round': 28, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m [Client 34] fit, config: {'current_round': 28, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m Epoch 1: train loss 0.00011988815094809979, accuracy 0.7037037037037037\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 12:20:27,125 | server.py:216 | fit_round received 30 results and 0 failures\n",
      "DEBUG flower 2023-02-01 12:20:27,189 | server.py:157 | evaluate_round: strategy sampled 30 clients (out of 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m [Client 33] fit, config: {'current_round': 28, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m Epoch 1: train loss 0.00013801775639876723, accuracy 0.6851851851851852\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m Epoch 1: train loss 0.0001228221954079345, accuracy 0.6481481481481481\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m [Client 49] fit, config: {'current_round': 28, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m Epoch 1: train loss 0.00013942591613158584, accuracy 0.6851851851851852\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m [Client 92] fit, config: {'current_round': 28, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m Epoch 1: train loss 0.00012680396321229637, accuracy 0.7407407407407407\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m [Client 77] fit, config: {'current_round': 28, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m Epoch 1: train loss 0.00013251687050797045, accuracy 0.5370370370370371\n",
      "Saving round 28 aggregated_parameters...\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38340)\u001b[0m [Client 12] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38339)\u001b[0m [Client 46] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38340)\u001b[0m [Client 63] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38339)\u001b[0m [Client 68] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38339)\u001b[0m [Client 65] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38339)\u001b[0m [Client 55] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38339)\u001b[0m [Client 77] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38340)\u001b[0m [Client 23] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38340)\u001b[0m [Client 25] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38334)\u001b[0m [Client 49] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38339)\u001b[0m [Client 24] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38340)\u001b[0m [Client 56] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38334)\u001b[0m [Client 90] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38334)\u001b[0m [Client 37] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38340)\u001b[0m [Client 1] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38340)\u001b[0m [Client 70] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38334)\u001b[0m [Client 7] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38339)\u001b[0m [Client 45] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38340)\u001b[0m [Client 42] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38338)\u001b[0m [Client 62] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38336)\u001b[0m [Client 35] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38337)\u001b[0m [Client 16] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38335)\u001b[0m [Client 28] evaluate, config: {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 12:20:29,308 | server.py:170 | evaluate_round received 0 results and 30 failures\n",
      "DEBUG flower 2023-02-01 12:20:29,310 | server.py:203 | fit_round: strategy sampled 30 clients (out of 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38338)\u001b[0m [Client 0] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38336)\u001b[0m [Client 95] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38336)\u001b[0m [Client 43] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38338)\u001b[0m [Client 84] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38340)\u001b[0m [Client 10] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38337)\u001b[0m [Client 6] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38335)\u001b[0m [Client 11] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m [Client 25] fit, config: {'current_round': 29, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m [Client 69] fit, config: {'current_round': 29, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m Epoch 1: train loss 0.00012065434566466138, accuracy 0.7037037037037037\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m Epoch 1: train loss 0.00012383004650473595, accuracy 0.7037037037037037\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m [Client 31] fit, config: {'current_round': 29, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m [Client 64] fit, config: {'current_round': 29, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m Epoch 1: train loss 0.00012588180834427476, accuracy 0.6481481481481481\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m Epoch 1: train loss 0.00012225008686073124, accuracy 0.6666666666666666\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m [Client 50] fit, config: {'current_round': 29, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m [Client 63] fit, config: {'current_round': 29, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m Epoch 1: train loss 0.00012828584294766188, accuracy 0.6851851851851852\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m Epoch 1: train loss 0.0001326992060057819, accuracy 0.6111111111111112\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m [Client 84] fit, config: {'current_round': 29, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m Epoch 1: train loss 0.0001299608702538535, accuracy 0.6481481481481481\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m [Client 75] fit, config: {'current_round': 29, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m [Client 56] fit, config: {'current_round': 29, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m Epoch 1: train loss 0.00013414832937996835, accuracy 0.5740740740740741\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m Epoch 1: train loss 0.0001247819745913148, accuracy 0.6851851851851852\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m [Client 28] fit, config: {'current_round': 29, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m Epoch 1: train loss 0.00010899142944253981, accuracy 0.8333333333333334\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m [Client 40] fit, config: {'current_round': 29, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m Epoch 1: train loss 9.960367606254295e-05, accuracy 0.7592592592592593\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m [Client 49] fit, config: {'current_round': 29, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m [Client 18] fit, config: {'current_round': 29, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m Epoch 1: train loss 0.00012099586456315592, accuracy 0.7222222222222222\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m [Client 81] fit, config: {'current_round': 29, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m Epoch 1: train loss 0.00012969537056051195, accuracy 0.6666666666666666\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m Epoch 1: train loss 0.0001354287232970819, accuracy 0.7037037037037037\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m [Client 95] fit, config: {'current_round': 29, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m Epoch 1: train loss 0.00011703878408297896, accuracy 0.7222222222222222\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m [Client 90] fit, config: {'current_round': 29, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m Epoch 1: train loss 0.00011266390356468037, accuracy 0.7407407407407407\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m [Client 20] fit, config: {'current_round': 29, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m Epoch 1: train loss 0.00012558570597320795, accuracy 0.6481481481481481\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m [Client 72] fit, config: {'current_round': 29, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m [Client 41] fit, config: {'current_round': 29, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m Epoch 1: train loss 0.00013763474998995662, accuracy 0.6111111111111112\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m Epoch 1: train loss 0.00013286210014484823, accuracy 0.6481481481481481\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m [Client 35] fit, config: {'current_round': 29, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m Epoch 1: train loss 0.00012441445142030716, accuracy 0.6111111111111112\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m [Client 60] fit, config: {'current_round': 29, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m Epoch 1: train loss 0.00012258515926077962, accuracy 0.7222222222222222\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 12:20:31,717 | server.py:216 | fit_round received 30 results and 0 failures\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m [Client 11] fit, config: {'current_round': 29, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m Epoch 1: train loss 0.00012332115147728473, accuracy 0.7037037037037037\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m [Client 4] fit, config: {'current_round': 29, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m Epoch 1: train loss 0.00011873323819600046, accuracy 0.7037037037037037\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m [Client 23] fit, config: {'current_round': 29, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m Epoch 1: train loss 0.00012678558414336294, accuracy 0.6851851851851852\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m [Client 74] fit, config: {'current_round': 29, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m Epoch 1: train loss 0.0001246892788913101, accuracy 0.7222222222222222\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m [Client 91] fit, config: {'current_round': 29, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m Epoch 1: train loss 0.00010566603305051103, accuracy 0.8888888888888888\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m [Client 54] fit, config: {'current_round': 29, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m Epoch 1: train loss 0.00012136434088461101, accuracy 0.7777777777777778\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m [Client 10] fit, config: {'current_round': 29, 'local_epochs': 3}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 12:20:31,808 | server.py:157 | evaluate_round: strategy sampled 30 clients (out of 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m [Client 46] fit, config: {'current_round': 29, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m Epoch 1: train loss 0.00012605407391674817, accuracy 0.7037037037037037\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m [Client 6] fit, config: {'current_round': 29, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m Epoch 1: train loss 0.00013620700337924063, accuracy 0.7407407407407407\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m Epoch 1: train loss 0.00011662124597933143, accuracy 0.7962962962962963\n",
      "Saving round 29 aggregated_parameters...\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38339)\u001b[0m [Client 6] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38339)\u001b[0m [Client 88] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38339)\u001b[0m [Client 16] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38338)\u001b[0m [Client 92] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38340)\u001b[0m [Client 85] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38337)\u001b[0m [Client 75] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38337)\u001b[0m [Client 14] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38340)\u001b[0m [Client 11] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38337)\u001b[0m [Client 1] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38340)\u001b[0m [Client 71] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38337)\u001b[0m [Client 29] evaluate, config: {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 12:20:33,914 | server.py:170 | evaluate_round received 0 results and 30 failures\n",
      "DEBUG flower 2023-02-01 12:20:33,915 | server.py:203 | fit_round: strategy sampled 30 clients (out of 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38340)\u001b[0m [Client 72] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38338)\u001b[0m [Client 9] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38340)\u001b[0m [Client 87] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38337)\u001b[0m [Client 20] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38338)\u001b[0m [Client 89] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38337)\u001b[0m [Client 69] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38338)\u001b[0m [Client 37] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38337)\u001b[0m [Client 60] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38337)\u001b[0m [Client 44] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38334)\u001b[0m [Client 56] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38341)\u001b[0m [Client 84] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38338)\u001b[0m [Client 41] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38336)\u001b[0m [Client 94] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38339)\u001b[0m [Client 80] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38340)\u001b[0m [Client 58] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38337)\u001b[0m [Client 28] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38335)\u001b[0m [Client 99] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38338)\u001b[0m [Client 22] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38337)\u001b[0m [Client 66] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m [Client 2] fit, config: {'current_round': 30, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m Epoch 1: train loss 0.00011928514140890911, accuracy 0.7407407407407407\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m [Client 54] fit, config: {'current_round': 30, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m Epoch 1: train loss 0.00012319168308749795, accuracy 0.7407407407407407\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m [Client 41] fit, config: {'current_round': 30, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m Epoch 1: train loss 0.00013031343405600637, accuracy 0.6851851851851852\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m [Client 46] fit, config: {'current_round': 30, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m Epoch 1: train loss 0.00012521866301540285, accuracy 0.6481481481481481\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m [Client 3] fit, config: {'current_round': 30, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m Epoch 1: train loss 0.0001257563999388367, accuracy 0.7407407407407407\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m [Client 67] fit, config: {'current_round': 30, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m [Client 98] fit, config: {'current_round': 30, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m [Client 44] fit, config: {'current_round': 30, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m Epoch 1: train loss 0.00010690530325518921, accuracy 0.7407407407407407\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m Epoch 1: train loss 0.0001189869872177951, accuracy 0.7037037037037037\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m Epoch 1: train loss 0.00012950424570590258, accuracy 0.6481481481481481\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m [Client 99] fit, config: {'current_round': 30, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m Epoch 1: train loss 0.00012477026029955596, accuracy 0.5740740740740741\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m [Client 12] fit, config: {'current_round': 30, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m [Client 79] fit, config: {'current_round': 30, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m Epoch 1: train loss 0.00012462251470424235, accuracy 0.6111111111111112\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m Epoch 1: train loss 0.00013088167179375887, accuracy 0.6296296296296297\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m [Client 96] fit, config: {'current_round': 30, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m [Client 19] fit, config: {'current_round': 30, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m Epoch 1: train loss 0.00010900689085246995, accuracy 0.6851851851851852\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m [Client 81] fit, config: {'current_round': 30, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m Epoch 1: train loss 0.00012466017506085336, accuracy 0.7037037037037037\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m Epoch 1: train loss 0.00011770169658120722, accuracy 0.7222222222222222\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m [Client 70] fit, config: {'current_round': 30, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m [Client 97] fit, config: {'current_round': 30, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m Epoch 1: train loss 0.00010949864372378215, accuracy 0.7592592592592593\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m Epoch 1: train loss 0.00011366116086719558, accuracy 0.7407407407407407\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m [Client 48] fit, config: {'current_round': 30, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m Epoch 1: train loss 0.00011791085125878453, accuracy 0.7407407407407407\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m [Client 68] fit, config: {'current_round': 30, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m Epoch 1: train loss 0.00012626132229343057, accuracy 0.7037037037037037\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m [Client 17] fit, config: {'current_round': 30, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m Epoch 1: train loss 0.0001423938083462417, accuracy 0.5740740740740741\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m [Client 74] fit, config: {'current_round': 30, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m Epoch 1: train loss 0.00012670680007431656, accuracy 0.6666666666666666\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m [Client 86] fit, config: {'current_round': 30, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m [Client 91] fit, config: {'current_round': 30, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m Epoch 1: train loss 0.00010747049964265898, accuracy 0.8333333333333334\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m Epoch 1: train loss 0.0001155194768216461, accuracy 0.7222222222222222\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m [Client 83] fit, config: {'current_round': 30, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m Epoch 1: train loss 0.00012674843310378492, accuracy 0.6111111111111112\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m [Client 18] fit, config: {'current_round': 30, 'local_epochs': 3}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 12:20:36,369 | server.py:216 | fit_round received 30 results and 0 failures\n",
      "DEBUG flower 2023-02-01 12:20:36,433 | server.py:157 | evaluate_round: strategy sampled 30 clients (out of 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m [Client 30] fit, config: {'current_round': 30, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m Epoch 1: train loss 0.00013086420949548483, accuracy 0.6296296296296297\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m [Client 35] fit, config: {'current_round': 30, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m Epoch 1: train loss 0.00011008614092133939, accuracy 0.7592592592592593\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m [Client 10] fit, config: {'current_round': 30, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m Epoch 1: train loss 0.00012377247912809253, accuracy 0.6481481481481481\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m [Client 88] fit, config: {'current_round': 30, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m Epoch 1: train loss 0.00010971213487209752, accuracy 0.6851851851851852\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m [Client 56] fit, config: {'current_round': 30, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m Epoch 1: train loss 0.00014189760258886963, accuracy 0.6851851851851852\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m Epoch 1: train loss 0.0001269235071958974, accuracy 0.6296296296296297\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m [Client 21] fit, config: {'current_round': 30, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m Epoch 1: train loss 0.00011779546912293881, accuracy 0.7037037037037037\n",
      "Saving round 30 aggregated_parameters...\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38338)\u001b[0m [Client 6] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38338)\u001b[0m [Client 30] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38341)\u001b[0m [Client 84] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38336)\u001b[0m [Client 71] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38341)\u001b[0m [Client 78] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38341)\u001b[0m [Client 9] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38341)\u001b[0m [Client 60] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38338)\u001b[0m [Client 21] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38336)\u001b[0m [Client 48] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38341)\u001b[0m [Client 13] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38338)\u001b[0m [Client 68] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38341)\u001b[0m [Client 10] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38341)\u001b[0m [Client 65] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38341)\u001b[0m [Client 79] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38341)\u001b[0m [Client 35] evaluate, config: {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 12:20:38,628 | server.py:170 | evaluate_round received 0 results and 30 failures\n",
      "DEBUG flower 2023-02-01 12:20:38,631 | server.py:203 | fit_round: strategy sampled 30 clients (out of 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38338)\u001b[0m [Client 3] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38336)\u001b[0m [Client 40] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38339)\u001b[0m [Client 86] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38340)\u001b[0m [Client 59] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38335)\u001b[0m [Client 22] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38335)\u001b[0m [Client 17] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38341)\u001b[0m [Client 66] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38341)\u001b[0m [Client 85] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38339)\u001b[0m [Client 67] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38335)\u001b[0m [Client 56] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38338)\u001b[0m [Client 44] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38336)\u001b[0m [Client 90] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38340)\u001b[0m [Client 62] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38335)\u001b[0m [Client 98] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38337)\u001b[0m [Client 82] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m [Client 42] fit, config: {'current_round': 31, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m Epoch 1: train loss 0.0001295628462685272, accuracy 0.5370370370370371\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m [Client 7] fit, config: {'current_round': 31, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m Epoch 1: train loss 0.00012688689457718283, accuracy 0.7222222222222222\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m [Client 24] fit, config: {'current_round': 31, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m [Client 45] fit, config: {'current_round': 31, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m Epoch 1: train loss 0.00010483647929504514, accuracy 0.7592592592592593\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m Epoch 1: train loss 0.00011162275040987879, accuracy 0.6851851851851852\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m [Client 63] fit, config: {'current_round': 31, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m Epoch 1: train loss 0.0001231186033692211, accuracy 0.6666666666666666\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m [Client 78] fit, config: {'current_round': 31, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m Epoch 1: train loss 0.00010777398711070418, accuracy 0.6666666666666666\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m [Client 64] fit, config: {'current_round': 31, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m Epoch 1: train loss 0.00011977853864664212, accuracy 0.6666666666666666\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m [Client 23] fit, config: {'current_round': 31, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m [Client 32] fit, config: {'current_round': 31, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m Epoch 1: train loss 0.00012153807620052248, accuracy 0.6666666666666666\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m Epoch 1: train loss 0.00011979994451394305, accuracy 0.6481481481481481\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m [Client 8] fit, config: {'current_round': 31, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m [Client 53] fit, config: {'current_round': 31, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m Epoch 1: train loss 0.00012302721734158695, accuracy 0.6481481481481481\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m Epoch 1: train loss 0.00010835256398422644, accuracy 0.7407407407407407\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m [Client 30] fit, config: {'current_round': 31, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m Epoch 1: train loss 0.00013259942352306098, accuracy 0.5925925925925926\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m [Client 94] fit, config: {'current_round': 31, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m Epoch 1: train loss 0.00011432206520112231, accuracy 0.7037037037037037\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m [Client 70] fit, config: {'current_round': 31, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m Epoch 1: train loss 0.00011439024092396721, accuracy 0.6296296296296297\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m [Client 38] fit, config: {'current_round': 31, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m [Client 31] fit, config: {'current_round': 31, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m [Client 88] fit, config: {'current_round': 31, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m Epoch 1: train loss 0.00010488906991668046, accuracy 0.7592592592592593\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m Epoch 1: train loss 0.00011661493772407994, accuracy 0.6666666666666666\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m Epoch 1: train loss 9.948113438440487e-05, accuracy 0.8518518518518519\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m [Client 6] fit, config: {'current_round': 31, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m Epoch 1: train loss 0.00013003095227759331, accuracy 0.6481481481481481\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m [Client 10] fit, config: {'current_round': 31, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m [Client 18] fit, config: {'current_round': 31, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m Epoch 1: train loss 0.00010803707846207544, accuracy 0.7777777777777778\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m [Client 46] fit, config: {'current_round': 31, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m [Client 66] fit, config: {'current_round': 31, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m [Client 98] fit, config: {'current_round': 31, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m Epoch 1: train loss 0.0001174045100924559, accuracy 0.7037037037037037\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m Epoch 1: train loss 0.00011513689969433472, accuracy 0.7407407407407407\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m Epoch 1: train loss 0.00010911245044553652, accuracy 0.7962962962962963\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m Epoch 1: train loss 0.00011831951269414276, accuracy 0.7407407407407407\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m [Client 48] fit, config: {'current_round': 31, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m Epoch 1: train loss 0.00011293730494799092, accuracy 0.6666666666666666\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m [Client 58] fit, config: {'current_round': 31, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m [Client 33] fit, config: {'current_round': 31, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m [Client 79] fit, config: {'current_round': 31, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m Epoch 1: train loss 0.00011322813952574506, accuracy 0.6666666666666666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 12:20:40,935 | server.py:216 | fit_round received 30 results and 0 failures\n",
      "DEBUG flower 2023-02-01 12:20:40,995 | server.py:157 | evaluate_round: strategy sampled 30 clients (out of 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m Epoch 1: train loss 0.0001226213644258678, accuracy 0.5740740740740741\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m Epoch 1: train loss 0.00011378681665519252, accuracy 0.7592592592592593\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m [Client 15] fit, config: {'current_round': 31, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m Epoch 1: train loss 0.00011574609379749745, accuracy 0.7592592592592593\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m [Client 67] fit, config: {'current_round': 31, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m Epoch 1: train loss 0.00010964248212985694, accuracy 0.7592592592592593\n",
      "Saving round 31 aggregated_parameters...\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m [Client 47] fit, config: {'current_round': 31, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m Epoch 1: train loss 0.0001249483466381207, accuracy 0.6851851851851852\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38336)\u001b[0m [Client 86] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38340)\u001b[0m [Client 23] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38338)\u001b[0m [Client 72] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38339)\u001b[0m [Client 64] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38337)\u001b[0m [Client 84] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38335)\u001b[0m [Client 12] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38341)\u001b[0m [Client 36] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38338)\u001b[0m [Client 63] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38336)\u001b[0m [Client 75] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38336)\u001b[0m [Client 79] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38336)\u001b[0m [Client 27] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38341)\u001b[0m [Client 90] evaluate, config: {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 12:20:43,289 | server.py:170 | evaluate_round received 0 results and 30 failures\n",
      "DEBUG flower 2023-02-01 12:20:43,290 | server.py:203 | fit_round: strategy sampled 30 clients (out of 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38336)\u001b[0m [Client 15] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38336)\u001b[0m [Client 55] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38335)\u001b[0m [Client 91] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38334)\u001b[0m [Client 25] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38341)\u001b[0m [Client 76] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38338)\u001b[0m [Client 66] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38336)\u001b[0m [Client 7] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38339)\u001b[0m [Client 6] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38340)\u001b[0m [Client 99] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38337)\u001b[0m [Client 34] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38335)\u001b[0m [Client 97] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38334)\u001b[0m [Client 89] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38341)\u001b[0m [Client 5] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38336)\u001b[0m [Client 80] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38340)\u001b[0m [Client 37] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38335)\u001b[0m [Client 56] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38339)\u001b[0m [Client 3] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38337)\u001b[0m [Client 42] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m [Client 26] fit, config: {'current_round': 32, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m Epoch 1: train loss 0.00011492597695905715, accuracy 0.6666666666666666\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m [Client 90] fit, config: {'current_round': 32, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m Epoch 1: train loss 0.00011097826063632965, accuracy 0.7037037037037037\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m [Client 86] fit, config: {'current_round': 32, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m Epoch 1: train loss 0.00010806256614159793, accuracy 0.7592592592592593\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m [Client 79] fit, config: {'current_round': 32, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m Epoch 1: train loss 0.00011426423589000478, accuracy 0.6481481481481481\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m [Client 96] fit, config: {'current_round': 32, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m [Client 88] fit, config: {'current_round': 32, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m [Client 43] fit, config: {'current_round': 32, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m Epoch 1: train loss 0.0001235926174558699, accuracy 0.6851851851851852\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m Epoch 1: train loss 0.00011013311450369656, accuracy 0.7777777777777778\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m [Client 80] fit, config: {'current_round': 32, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m [Client 14] fit, config: {'current_round': 32, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m Epoch 1: train loss 9.872927330434322e-05, accuracy 0.7592592592592593\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m [Client 46] fit, config: {'current_round': 32, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m Epoch 1: train loss 0.00011697053560055792, accuracy 0.6851851851851852\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m [Client 21] fit, config: {'current_round': 32, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m Epoch 1: train loss 0.00010822906187968329, accuracy 0.7222222222222222\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m Epoch 1: train loss 0.00010990850569214672, accuracy 0.7222222222222222\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m [Client 1] fit, config: {'current_round': 32, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m Epoch 1: train loss 8.816487388685346e-05, accuracy 0.8148148148148148\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m Epoch 1: train loss 0.00011608171189436689, accuracy 0.7037037037037037\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m [Client 18] fit, config: {'current_round': 32, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m Epoch 1: train loss 0.00011959162657149136, accuracy 0.6296296296296297\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m [Client 22] fit, config: {'current_round': 32, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m Epoch 1: train loss 0.00011653151159407571, accuracy 0.6481481481481481\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m [Client 10] fit, config: {'current_round': 32, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m Epoch 1: train loss 0.00011505010479595512, accuracy 0.6481481481481481\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m [Client 29] fit, config: {'current_round': 32, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m Epoch 1: train loss 0.00011054825881728902, accuracy 0.7592592592592593\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m [Client 44] fit, config: {'current_round': 32, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m Epoch 1: train loss 9.828190377447754e-05, accuracy 0.7407407407407407\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m [Client 61] fit, config: {'current_round': 32, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m Epoch 1: train loss 0.00012118756421841681, accuracy 0.7777777777777778\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m [Client 89] fit, config: {'current_round': 32, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m [Client 36] fit, config: {'current_round': 32, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m [Client 39] fit, config: {'current_round': 32, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m [Client 0] fit, config: {'current_round': 32, 'local_epochs': 3}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 12:20:45,448 | server.py:216 | fit_round received 30 results and 0 failures\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m Epoch 1: train loss 0.00012047492054989561, accuracy 0.7037037037037037\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m [Client 56] fit, config: {'current_round': 32, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m Epoch 1: train loss 0.00012362062989268452, accuracy 0.7222222222222222\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m [Client 54] fit, config: {'current_round': 32, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m Epoch 1: train loss 0.00012047201744280756, accuracy 0.6851851851851852\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m [Client 77] fit, config: {'current_round': 32, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m Epoch 1: train loss 0.00011800236825365573, accuracy 0.5925925925925926\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m [Client 27] fit, config: {'current_round': 32, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m [Client 25] fit, config: {'current_round': 32, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m Epoch 1: train loss 0.00011015952622983605, accuracy 0.7407407407407407\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m Epoch 1: train loss 0.0001348889054497704, accuracy 0.7037037037037037\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m Epoch 1: train loss 0.00011506055307108909, accuracy 0.7407407407407407\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m [Client 4] fit, config: {'current_round': 32, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m Epoch 1: train loss 0.00010590817691991106, accuracy 0.8148148148148148\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m [Client 35] fit, config: {'current_round': 32, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m Epoch 1: train loss 0.00010432070848764852, accuracy 0.7962962962962963\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m Epoch 1: train loss 0.00012610296835191548, accuracy 0.6851851851851852\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m Epoch 1: train loss 0.00011175137478858232, accuracy 0.7407407407407407\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 12:20:45,503 | server.py:157 | evaluate_round: strategy sampled 30 clients (out of 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m [Client 60] fit, config: {'current_round': 32, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m Epoch 1: train loss 9.993686398956925e-05, accuracy 0.7592592592592593\n",
      "Saving round 32 aggregated_parameters...\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38334)\u001b[0m [Client 62] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38339)\u001b[0m [Client 86] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38339)\u001b[0m [Client 46] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38334)\u001b[0m [Client 53] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38339)\u001b[0m [Client 16] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38334)\u001b[0m [Client 0] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38339)\u001b[0m [Client 1] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38340)\u001b[0m [Client 83] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38337)\u001b[0m [Client 58] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38334)\u001b[0m [Client 35] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38339)\u001b[0m [Client 5] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38340)\u001b[0m [Client 3] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38337)\u001b[0m [Client 84] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38334)\u001b[0m [Client 57] evaluate, config: {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 12:20:47,647 | server.py:170 | evaluate_round received 0 results and 30 failures\n",
      "DEBUG flower 2023-02-01 12:20:47,649 | server.py:203 | fit_round: strategy sampled 30 clients (out of 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38340)\u001b[0m [Client 24] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38334)\u001b[0m [Client 6] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38340)\u001b[0m [Client 76] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38340)\u001b[0m [Client 68] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38334)\u001b[0m [Client 99] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38337)\u001b[0m [Client 81] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38340)\u001b[0m [Client 8] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38337)\u001b[0m [Client 90] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38334)\u001b[0m [Client 71] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38338)\u001b[0m [Client 11] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38336)\u001b[0m [Client 54] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38340)\u001b[0m [Client 14] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38337)\u001b[0m [Client 27] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38341)\u001b[0m [Client 20] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38339)\u001b[0m [Client 75] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38335)\u001b[0m [Client 37] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m [Client 65] fit, config: {'current_round': 33, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m Epoch 1: train loss 0.00010759599535958841, accuracy 0.7592592592592593\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m [Client 70] fit, config: {'current_round': 33, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m Epoch 1: train loss 0.0001065636970452033, accuracy 0.6296296296296297\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m [Client 90] fit, config: {'current_round': 33, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m Epoch 1: train loss 9.838780533755198e-05, accuracy 0.7407407407407407\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m [Client 98] fit, config: {'current_round': 33, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m Epoch 1: train loss 0.00011244266352150589, accuracy 0.7222222222222222\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m [Client 17] fit, config: {'current_round': 33, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m Epoch 1: train loss 0.00011849619477288797, accuracy 0.6111111111111112\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m [Client 35] fit, config: {'current_round': 33, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m Epoch 1: train loss 0.00011391891166567802, accuracy 0.6111111111111112\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m [Client 64] fit, config: {'current_round': 33, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m Epoch 1: train loss 0.00011177892884006724, accuracy 0.6851851851851852\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m [Client 77] fit, config: {'current_round': 33, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m Epoch 1: train loss 0.0001178509701276198, accuracy 0.6111111111111112\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m [Client 16] fit, config: {'current_round': 33, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m Epoch 1: train loss 0.00010257789108436555, accuracy 0.7407407407407407\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m [Client 85] fit, config: {'current_round': 33, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m [Client 32] fit, config: {'current_round': 33, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m Epoch 1: train loss 0.00011631232337094843, accuracy 0.6666666666666666\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m [Client 12] fit, config: {'current_round': 33, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m Epoch 1: train loss 0.00010200987162534148, accuracy 0.7777777777777778\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m Epoch 1: train loss 9.569908434059471e-05, accuracy 0.7592592592592593\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m [Client 46] fit, config: {'current_round': 33, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m Epoch 1: train loss 0.000110077831777744, accuracy 0.7222222222222222\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m [Client 27] fit, config: {'current_round': 33, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m [Client 37] fit, config: {'current_round': 33, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m Epoch 1: train loss 0.00011706907389452681, accuracy 0.6851851851851852\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m [Client 13] fit, config: {'current_round': 33, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m Epoch 1: train loss 0.0001011138447211124, accuracy 0.7407407407407407\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m Epoch 1: train loss 0.0001139405503636226, accuracy 0.6481481481481481\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m [Client 55] fit, config: {'current_round': 33, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m Epoch 1: train loss 9.89144027698785e-05, accuracy 0.7222222222222222\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m [Client 63] fit, config: {'current_round': 33, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m [Client 75] fit, config: {'current_round': 33, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m Epoch 1: train loss 0.00011024177365470678, accuracy 0.7222222222222222\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m Epoch 1: train loss 0.00011740940681193024, accuracy 0.6851851851851852\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m [Client 79] fit, config: {'current_round': 33, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m Epoch 1: train loss 0.00010693216609070078, accuracy 0.7592592592592593\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m [Client 36] fit, config: {'current_round': 33, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m Epoch 1: train loss 0.00010559408838162199, accuracy 0.7222222222222222\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m [Client 10] fit, config: {'current_round': 33, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m [Client 7] fit, config: {'current_round': 33, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m Epoch 1: train loss 0.00012064542534062639, accuracy 0.7222222222222222\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m [Client 73] fit, config: {'current_round': 33, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m Epoch 1: train loss 0.00010444433428347111, accuracy 0.7037037037037037\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m [Client 38] fit, config: {'current_round': 33, 'local_epochs': 3}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 12:20:49,915 | server.py:216 | fit_round received 30 results and 0 failures\n",
      "DEBUG flower 2023-02-01 12:20:49,972 | server.py:157 | evaluate_round: strategy sampled 30 clients (out of 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m [Client 43] fit, config: {'current_round': 33, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m Epoch 1: train loss 0.0001110958110075444, accuracy 0.6111111111111112\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m [Client 33] fit, config: {'current_round': 33, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m Epoch 1: train loss 0.00011788145639002323, accuracy 0.6111111111111112\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m Epoch 1: train loss 0.00010147125431103632, accuracy 0.7962962962962963\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m [Client 66] fit, config: {'current_round': 33, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m [Client 95] fit, config: {'current_round': 33, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m Epoch 1: train loss 0.0001039255948853679, accuracy 0.7037037037037037\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m [Client 28] fit, config: {'current_round': 33, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m Epoch 1: train loss 9.77578092715703e-05, accuracy 0.8333333333333334\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m Epoch 1: train loss 9.872590453596786e-05, accuracy 0.7777777777777778\n",
      "Saving round 33 aggregated_parameters...\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m Epoch 1: train loss 0.00010239725088467821, accuracy 0.7592592592592593\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38339)\u001b[0m [Client 99] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38339)\u001b[0m [Client 30] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38339)\u001b[0m [Client 66] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38339)\u001b[0m [Client 37] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38340)\u001b[0m [Client 93] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38340)\u001b[0m [Client 92] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38340)\u001b[0m [Client 32] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38339)\u001b[0m [Client 85] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38337)\u001b[0m [Client 53] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38334)\u001b[0m [Client 91] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38341)\u001b[0m [Client 54] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38336)\u001b[0m [Client 47] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38340)\u001b[0m [Client 73] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38338)\u001b[0m [Client 7] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38339)\u001b[0m [Client 6] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38337)\u001b[0m [Client 89] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38335)\u001b[0m [Client 97] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38337)\u001b[0m [Client 80] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38338)\u001b[0m [Client 14] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38337)\u001b[0m [Client 55] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38335)\u001b[0m [Client 46] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38338)\u001b[0m [Client 70] evaluate, config: {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 12:20:52,444 | server.py:170 | evaluate_round received 0 results and 30 failures\n",
      "DEBUG flower 2023-02-01 12:20:52,447 | server.py:203 | fit_round: strategy sampled 30 clients (out of 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38341)\u001b[0m [Client 88] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38338)\u001b[0m [Client 19] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38336)\u001b[0m [Client 94] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38339)\u001b[0m [Client 13] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38340)\u001b[0m [Client 65] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38337)\u001b[0m [Client 9] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38334)\u001b[0m [Client 51] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38335)\u001b[0m [Client 79] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m [Client 67] fit, config: {'current_round': 34, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m Epoch 1: train loss 0.0001041890136548318, accuracy 0.7407407407407407\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m [Client 96] fit, config: {'current_round': 34, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m Epoch 1: train loss 0.00010247293539578095, accuracy 0.8148148148148148\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m [Client 97] fit, config: {'current_round': 34, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m Epoch 1: train loss 9.241904626833275e-05, accuracy 0.8518518518518519\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m [Client 38] fit, config: {'current_round': 34, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m Epoch 1: train loss 0.00010361957538407296, accuracy 0.7592592592592593\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m [Client 20] fit, config: {'current_round': 34, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m Epoch 1: train loss 0.00010741032019723207, accuracy 0.7777777777777778\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m [Client 48] fit, config: {'current_round': 34, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m [Client 98] fit, config: {'current_round': 34, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m [Client 36] fit, config: {'current_round': 34, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m Epoch 1: train loss 0.00010369589290348813, accuracy 0.7592592592592593\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m Epoch 1: train loss 0.0001004796358756721, accuracy 0.7592592592592593\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m Epoch 1: train loss 0.00011492456542328, accuracy 0.7222222222222222\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m [Client 28] fit, config: {'current_round': 34, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m Epoch 1: train loss 8.914530917536467e-05, accuracy 0.8518518518518519\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m [Client 44] fit, config: {'current_round': 34, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m [Client 34] fit, config: {'current_round': 34, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m [Client 77] fit, config: {'current_round': 34, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m Epoch 1: train loss 9.236117330146953e-05, accuracy 0.7777777777777778\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m [Client 93] fit, config: {'current_round': 34, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m Epoch 1: train loss 0.00011066882871091366, accuracy 0.7222222222222222\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m Epoch 1: train loss 0.00010097084305016324, accuracy 0.7592592592592593\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m [Client 79] fit, config: {'current_round': 34, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m Epoch 1: train loss 0.00010719484271248803, accuracy 0.6851851851851852\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m Epoch 1: train loss 0.0001107439529732801, accuracy 0.6666666666666666\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m [Client 16] fit, config: {'current_round': 34, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m Epoch 1: train loss 9.776297520147637e-05, accuracy 0.7222222222222222\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m [Client 13] fit, config: {'current_round': 34, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m Epoch 1: train loss 0.00010591565660433844, accuracy 0.7777777777777778\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m [Client 25] fit, config: {'current_round': 34, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m Epoch 1: train loss 0.000104202248621732, accuracy 0.7592592592592593\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 12:20:54,949 | server.py:216 | fit_round received 30 results and 0 failures\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m [Client 49] fit, config: {'current_round': 34, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m Epoch 1: train loss 0.0001140696185757406, accuracy 0.7592592592592593\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m [Client 61] fit, config: {'current_round': 34, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m Epoch 1: train loss 0.00011596025433391333, accuracy 0.7592592592592593\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m [Client 88] fit, config: {'current_round': 34, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m Epoch 1: train loss 9.381253767060116e-05, accuracy 0.7407407407407407\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m [Client 45] fit, config: {'current_round': 34, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m [Client 70] fit, config: {'current_round': 34, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m Epoch 1: train loss 9.90927146631293e-05, accuracy 0.7407407407407407\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m [Client 76] fit, config: {'current_round': 34, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m Epoch 1: train loss 9.333763591712341e-05, accuracy 0.7592592592592593\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m [Client 78] fit, config: {'current_round': 34, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m [Client 30] fit, config: {'current_round': 34, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m Epoch 1: train loss 0.00011881388491019607, accuracy 0.6296296296296297\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m [Client 42] fit, config: {'current_round': 34, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m Epoch 1: train loss 0.00011617580457823351, accuracy 0.7407407407407407\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m [Client 46] fit, config: {'current_round': 34, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m Epoch 1: train loss 0.00010984617256326601, accuracy 0.6666666666666666\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m [Client 5] fit, config: {'current_round': 34, 'local_epochs': 3}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 12:20:55,008 | server.py:157 | evaluate_round: strategy sampled 30 clients (out of 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving round 34 aggregated_parameters...\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m [Client 0] fit, config: {'current_round': 34, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m Epoch 1: train loss 0.00011349643318681046, accuracy 0.6851851851851852\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m Epoch 1: train loss 0.00010374229896115139, accuracy 0.7407407407407407\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m Epoch 1: train loss 9.884221799438819e-05, accuracy 0.7592592592592593\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m Epoch 1: train loss 9.305161802330986e-05, accuracy 0.8333333333333334\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m [Client 50] fit, config: {'current_round': 34, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m Epoch 1: train loss 0.00012527765647973865, accuracy 0.6481481481481481\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38334)\u001b[0m [Client 62] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38341)\u001b[0m [Client 7] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38336)\u001b[0m [Client 83] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38335)\u001b[0m [Client 90] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38341)\u001b[0m [Client 58] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38338)\u001b[0m [Client 51] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38341)\u001b[0m [Client 49] evaluate, config: {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 12:20:57,125 | server.py:170 | evaluate_round received 0 results and 30 failures\n",
      "DEBUG flower 2023-02-01 12:20:57,126 | server.py:203 | fit_round: strategy sampled 30 clients (out of 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38334)\u001b[0m [Client 45] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38341)\u001b[0m [Client 82] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38335)\u001b[0m [Client 39] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38338)\u001b[0m [Client 57] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38336)\u001b[0m [Client 66] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38339)\u001b[0m [Client 1] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38337)\u001b[0m [Client 41] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38335)\u001b[0m [Client 54] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38339)\u001b[0m [Client 43] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38339)\u001b[0m [Client 99] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38335)\u001b[0m [Client 48] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38339)\u001b[0m [Client 35] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38335)\u001b[0m [Client 81] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38341)\u001b[0m [Client 67] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38335)\u001b[0m [Client 50] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38334)\u001b[0m [Client 78] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38341)\u001b[0m [Client 59] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38338)\u001b[0m [Client 88] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38336)\u001b[0m [Client 72] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38339)\u001b[0m [Client 6] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38340)\u001b[0m [Client 42] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38337)\u001b[0m [Client 29] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38335)\u001b[0m [Client 18] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m [Client 40] fit, config: {'current_round': 35, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m Epoch 1: train loss 7.953129534143955e-05, accuracy 0.8148148148148148\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m [Client 99] fit, config: {'current_round': 35, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m [Client 26] fit, config: {'current_round': 35, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m Epoch 1: train loss 0.00010200082033406943, accuracy 0.7407407407407407\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m Epoch 1: train loss 0.00010523717355681583, accuracy 0.6851851851851852\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m [Client 74] fit, config: {'current_round': 35, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m Epoch 1: train loss 0.00010480928176548332, accuracy 0.7592592592592593\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m [Client 37] fit, config: {'current_round': 35, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m Epoch 1: train loss 0.00011087025632150471, accuracy 0.7037037037037037\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m [Client 71] fit, config: {'current_round': 35, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m Epoch 1: train loss 9.698089706944302e-05, accuracy 0.7592592592592593\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m [Client 67] fit, config: {'current_round': 35, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m [Client 49] fit, config: {'current_round': 35, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m Epoch 1: train loss 0.00011411790910642594, accuracy 0.7407407407407407\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m Epoch 1: train loss 9.721655078465119e-05, accuracy 0.7777777777777778\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m [Client 16] fit, config: {'current_round': 35, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m [Client 61] fit, config: {'current_round': 35, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m [Client 13] fit, config: {'current_round': 35, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m Epoch 1: train loss 9.441551083000377e-05, accuracy 0.7407407407407407\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m [Client 7] fit, config: {'current_round': 35, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m Epoch 1: train loss 9.787618910195306e-05, accuracy 0.7592592592592593\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m Epoch 1: train loss 0.00012070058437529951, accuracy 0.6851851851851852\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m [Client 90] fit, config: {'current_round': 35, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m Epoch 1: train loss 9.243954991688952e-05, accuracy 0.7592592592592593\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m [Client 89] fit, config: {'current_round': 35, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m [Client 45] fit, config: {'current_round': 35, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m Epoch 1: train loss 0.00011398936476325616, accuracy 0.7407407407407407\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m Epoch 1: train loss 0.00011492972407722846, accuracy 0.6666666666666666\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m [Client 17] fit, config: {'current_round': 35, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m Epoch 1: train loss 0.00011373133747838438, accuracy 0.6296296296296297\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m Epoch 1: train loss 9.136243170360103e-05, accuracy 0.7777777777777778\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m [Client 14] fit, config: {'current_round': 35, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m Epoch 1: train loss 9.683379175839946e-05, accuracy 0.7962962962962963\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m [Client 6] fit, config: {'current_round': 35, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m Epoch 1: train loss 0.00011828874266939238, accuracy 0.6851851851851852\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 12:20:59,302 | server.py:216 | fit_round received 30 results and 0 failures\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m [Client 98] fit, config: {'current_round': 35, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m [Client 19] fit, config: {'current_round': 35, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m Epoch 1: train loss 9.414373926119879e-05, accuracy 0.7592592592592593\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m [Client 59] fit, config: {'current_round': 35, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m [Client 83] fit, config: {'current_round': 35, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m Epoch 1: train loss 0.00010583269613562152, accuracy 0.7407407407407407\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m [Client 22] fit, config: {'current_round': 35, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m Epoch 1: train loss 0.0001100451554520987, accuracy 0.7222222222222222\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m [Client 30] fit, config: {'current_round': 35, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m Epoch 1: train loss 0.00012130601680837572, accuracy 0.6296296296296297\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m [Client 52] fit, config: {'current_round': 35, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m Epoch 1: train loss 0.00010855325672309846, accuracy 0.6481481481481481\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m Epoch 1: train loss 0.00011675513815134764, accuracy 0.6851851851851852\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m [Client 56] fit, config: {'current_round': 35, 'local_epochs': 3}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 12:20:59,361 | server.py:157 | evaluate_round: strategy sampled 30 clients (out of 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m Epoch 1: train loss 0.0001091484518838115, accuracy 0.7037037037037037\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m [Client 75] fit, config: {'current_round': 35, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m Epoch 1: train loss 0.0001025496021611616, accuracy 0.7037037037037037\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m [Client 51] fit, config: {'current_round': 35, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m Epoch 1: train loss 0.0001204802974825725, accuracy 0.6481481481481481\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m [Client 82] fit, config: {'current_round': 35, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m Epoch 1: train loss 0.00011778120824601501, accuracy 0.6481481481481481\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m [Client 72] fit, config: {'current_round': 35, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m Epoch 1: train loss 0.0001118965883506462, accuracy 0.6851851851851852\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m Epoch 1: train loss 0.00011424098920542747, accuracy 0.6296296296296297\n",
      "Saving round 35 aggregated_parameters...\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38341)\u001b[0m [Client 78] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38341)\u001b[0m [Client 80] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38341)\u001b[0m [Client 25] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38341)\u001b[0m [Client 42] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38337)\u001b[0m [Client 11] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38341)\u001b[0m [Client 63] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38338)\u001b[0m [Client 31] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38340)\u001b[0m [Client 96] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38337)\u001b[0m [Client 19] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38338)\u001b[0m [Client 29] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38338)\u001b[0m [Client 35] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38337)\u001b[0m [Client 72] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38338)\u001b[0m [Client 97] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38340)\u001b[0m [Client 69] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38337)\u001b[0m [Client 1] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38334)\u001b[0m [Client 2] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38341)\u001b[0m [Client 9] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38338)\u001b[0m [Client 75] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38340)\u001b[0m [Client 27] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38337)\u001b[0m [Client 56] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38335)\u001b[0m [Client 34] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38338)\u001b[0m [Client 30] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38336)\u001b[0m [Client 39] evaluate, config: {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 12:21:01,632 | server.py:170 | evaluate_round received 0 results and 30 failures\n",
      "DEBUG flower 2023-02-01 12:21:01,633 | server.py:203 | fit_round: strategy sampled 30 clients (out of 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38334)\u001b[0m [Client 83] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38341)\u001b[0m [Client 92] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38338)\u001b[0m [Client 59] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38336)\u001b[0m [Client 41] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38340)\u001b[0m [Client 76] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38337)\u001b[0m [Client 67] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38335)\u001b[0m [Client 43] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m [Client 4] fit, config: {'current_round': 36, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m Epoch 1: train loss 9.357662202091888e-05, accuracy 0.7777777777777778\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m [Client 85] fit, config: {'current_round': 36, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m Epoch 1: train loss 8.16863466752693e-05, accuracy 0.7962962962962963\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m [Client 81] fit, config: {'current_round': 36, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m [Client 13] fit, config: {'current_round': 36, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m [Client 84] fit, config: {'current_round': 36, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m Epoch 1: train loss 0.00011742571950890124, accuracy 0.6296296296296297\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m [Client 42] fit, config: {'current_round': 36, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m [Client 91] fit, config: {'current_round': 36, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m Epoch 1: train loss 8.586759213358164e-05, accuracy 0.8518518518518519\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m Epoch 1: train loss 0.00010511893196962774, accuracy 0.7592592592592593\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m Epoch 1: train loss 0.00010071868018712848, accuracy 0.7592592592592593\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m [Client 36] fit, config: {'current_round': 36, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m Epoch 1: train loss 9.958176087820902e-05, accuracy 0.7962962962962963\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m Epoch 1: train loss 0.00011377337068552151, accuracy 0.7592592592592593\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m [Client 38] fit, config: {'current_round': 36, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m Epoch 1: train loss 9.966178186004981e-05, accuracy 0.7592592592592593\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m [Client 48] fit, config: {'current_round': 36, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m [Client 34] fit, config: {'current_round': 36, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m Epoch 1: train loss 9.913415124174207e-05, accuracy 0.7592592592592593\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m [Client 61] fit, config: {'current_round': 36, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m Epoch 1: train loss 9.642382065067068e-05, accuracy 0.7407407407407407\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m Epoch 1: train loss 0.00011060041288146749, accuracy 0.7592592592592593\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m [Client 27] fit, config: {'current_round': 36, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m Epoch 1: train loss 0.00011708249076036736, accuracy 0.6851851851851852\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m [Client 1] fit, config: {'current_round': 36, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m [Client 6] fit, config: {'current_round': 36, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m Epoch 1: train loss 0.00010401496547274292, accuracy 0.7592592592592593\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m Epoch 1: train loss 7.636614463990554e-05, accuracy 0.8148148148148148\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m [Client 29] fit, config: {'current_round': 36, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m Epoch 1: train loss 9.858240809990093e-05, accuracy 0.7222222222222222\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m [Client 64] fit, config: {'current_round': 36, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m [Client 23] fit, config: {'current_round': 36, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m Epoch 1: train loss 0.00010464704246260226, accuracy 0.7407407407407407\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m Epoch 1: train loss 0.00010869541438296437, accuracy 0.7407407407407407\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m [Client 50] fit, config: {'current_round': 36, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m Epoch 1: train loss 0.00012375455116853118, accuracy 0.6481481481481481\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m [Client 9] fit, config: {'current_round': 36, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m Epoch 1: train loss 0.00010459381155669689, accuracy 0.7222222222222222\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m [Client 93] fit, config: {'current_round': 36, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m Epoch 1: train loss 0.00010548989666858688, accuracy 0.7777777777777778\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m [Client 41] fit, config: {'current_round': 36, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m [Client 53] fit, config: {'current_round': 36, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m Epoch 1: train loss 8.836387132760137e-05, accuracy 0.8148148148148148\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m Epoch 1: train loss 0.00011384305980755016, accuracy 0.7037037037037037\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m [Client 43] fit, config: {'current_round': 36, 'local_epochs': 3}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 12:21:03,874 | server.py:216 | fit_round received 30 results and 0 failures\n",
      "DEBUG flower 2023-02-01 12:21:03,933 | server.py:157 | evaluate_round: strategy sampled 30 clients (out of 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m [Client 56] fit, config: {'current_round': 36, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m Epoch 1: train loss 0.00012383668217808008, accuracy 0.7592592592592593\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m [Client 47] fit, config: {'current_round': 36, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m Epoch 1: train loss 0.00011380165960872546, accuracy 0.6851851851851852\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m [Client 99] fit, config: {'current_round': 36, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m [Client 66] fit, config: {'current_round': 36, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m Epoch 1: train loss 9.868200140772387e-05, accuracy 0.7222222222222222\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m Epoch 1: train loss 0.00010215222573606297, accuracy 0.7037037037037037\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m [Client 32] fit, config: {'current_round': 36, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m Epoch 1: train loss 0.00011681543401209638, accuracy 0.7037037037037037\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m [Client 40] fit, config: {'current_round': 36, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m Epoch 1: train loss 8.452434849459678e-05, accuracy 0.7592592592592593\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m Epoch 1: train loss 0.0001062139417626895, accuracy 0.6111111111111112\n",
      "Saving round 36 aggregated_parameters...\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38341)\u001b[0m [Client 23] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38337)\u001b[0m [Client 59] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38337)\u001b[0m [Client 70] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38337)\u001b[0m [Client 95] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38337)\u001b[0m [Client 39] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38341)\u001b[0m [Client 85] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38337)\u001b[0m [Client 65] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38341)\u001b[0m [Client 55] evaluate, config: {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 12:21:06,060 | server.py:170 | evaluate_round received 0 results and 30 failures\n",
      "DEBUG flower 2023-02-01 12:21:06,062 | server.py:203 | fit_round: strategy sampled 30 clients (out of 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38341)\u001b[0m [Client 12] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38338)\u001b[0m [Client 32] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38340)\u001b[0m [Client 72] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38337)\u001b[0m [Client 35] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38341)\u001b[0m [Client 88] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38335)\u001b[0m [Client 91] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38335)\u001b[0m [Client 75] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38335)\u001b[0m [Client 46] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38341)\u001b[0m [Client 11] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38335)\u001b[0m [Client 97] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38338)\u001b[0m [Client 29] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38340)\u001b[0m [Client 5] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38337)\u001b[0m [Client 74] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38334)\u001b[0m [Client 98] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38341)\u001b[0m [Client 31] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38338)\u001b[0m [Client 92] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38338)\u001b[0m [Client 93] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38340)\u001b[0m [Client 77] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38337)\u001b[0m [Client 45] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38335)\u001b[0m [Client 16] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38336)\u001b[0m [Client 10] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38339)\u001b[0m [Client 21] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m [Client 78] fit, config: {'current_round': 37, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m [Client 30] fit, config: {'current_round': 37, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m [Client 43] fit, config: {'current_round': 37, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m [Client 32] fit, config: {'current_round': 37, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m Epoch 1: train loss 8.925471775000915e-05, accuracy 0.7222222222222222\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m Epoch 1: train loss 0.00011718366295099258, accuracy 0.5925925925925926\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m [Client 70] fit, config: {'current_round': 37, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m Epoch 1: train loss 0.00010211986227659509, accuracy 0.6296296296296297\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m Epoch 1: train loss 0.00010260043200105429, accuracy 0.6851851851851852\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m [Client 38] fit, config: {'current_round': 37, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m Epoch 1: train loss 8.582065493101254e-05, accuracy 0.7962962962962963\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m Epoch 1: train loss 9.657881309976801e-05, accuracy 0.6296296296296297\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m [Client 37] fit, config: {'current_round': 37, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m [Client 99] fit, config: {'current_round': 37, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m Epoch 1: train loss 0.00010031314741354436, accuracy 0.6851851851851852\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m Epoch 1: train loss 0.0001075858817785047, accuracy 0.6851851851851852\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m [Client 77] fit, config: {'current_round': 37, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m Epoch 1: train loss 0.00010658927203621715, accuracy 0.6666666666666666\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m [Client 87] fit, config: {'current_round': 37, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m Epoch 1: train loss 0.00011756756430258974, accuracy 0.6296296296296297\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m [Client 2] fit, config: {'current_round': 37, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m Epoch 1: train loss 8.6808497144375e-05, accuracy 0.7592592592592593\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m [Client 48] fit, config: {'current_round': 37, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m Epoch 1: train loss 9.551525727147236e-05, accuracy 0.7037037037037037\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m [Client 60] fit, config: {'current_round': 37, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m Epoch 1: train loss 9.75258881226182e-05, accuracy 0.7037037037037037\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m [Client 19] fit, config: {'current_round': 37, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m [Client 97] fit, config: {'current_round': 37, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m Epoch 1: train loss 8.918148523662239e-05, accuracy 0.7777777777777778\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m [Client 90] fit, config: {'current_round': 37, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m Epoch 1: train loss 8.810096915112808e-05, accuracy 0.7222222222222222\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m Epoch 1: train loss 9.481964661972597e-05, accuracy 0.7222222222222222\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m [Client 35] fit, config: {'current_round': 37, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m Epoch 1: train loss 0.00010707875480875373, accuracy 0.6296296296296297\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m [Client 39] fit, config: {'current_round': 37, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m [Client 69] fit, config: {'current_round': 37, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m Epoch 1: train loss 9.559425961924717e-05, accuracy 0.7592592592592593\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m [Client 40] fit, config: {'current_round': 37, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m Epoch 1: train loss 7.403630297631025e-05, accuracy 0.7962962962962963\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m [Client 7] fit, config: {'current_round': 37, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m Epoch 1: train loss 0.00011031182657461613, accuracy 0.7407407407407407\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m Epoch 1: train loss 0.00012198297918075696, accuracy 0.6296296296296297\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m [Client 20] fit, config: {'current_round': 37, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m Epoch 1: train loss 0.00010246641613775864, accuracy 0.6851851851851852\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m [Client 51] fit, config: {'current_round': 37, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m [Client 11] fit, config: {'current_round': 37, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m Epoch 1: train loss 0.00010436856973683462, accuracy 0.7037037037037037\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m Epoch 1: train loss 0.00011886918218806386, accuracy 0.6481481481481481\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 12:21:08,315 | server.py:216 | fit_round received 30 results and 0 failures\n",
      "DEBUG flower 2023-02-01 12:21:08,367 | server.py:157 | evaluate_round: strategy sampled 30 clients (out of 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m [Client 72] fit, config: {'current_round': 37, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m Epoch 1: train loss 0.00010924893285846338, accuracy 0.6666666666666666\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m [Client 73] fit, config: {'current_round': 37, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m Epoch 1: train loss 9.463521564612165e-05, accuracy 0.7037037037037037\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m [Client 46] fit, config: {'current_round': 37, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m Epoch 1: train loss 9.900137956719846e-05, accuracy 0.7222222222222222\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m [Client 63] fit, config: {'current_round': 37, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m Epoch 1: train loss 0.000107469895738177, accuracy 0.7037037037037037\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m [Client 81] fit, config: {'current_round': 37, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m Epoch 1: train loss 0.00010580552770989016, accuracy 0.6481481481481481\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m [Client 5] fit, config: {'current_round': 37, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m Epoch 1: train loss 0.00010581658716546372, accuracy 0.6111111111111112\n",
      "Saving round 37 aggregated_parameters...\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38339)\u001b[0m [Client 7] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38339)\u001b[0m [Client 49] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38338)\u001b[0m [Client 84] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38339)\u001b[0m [Client 88] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38337)\u001b[0m [Client 33] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38339)\u001b[0m [Client 51] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38337)\u001b[0m [Client 63] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38334)\u001b[0m [Client 78] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38334)\u001b[0m [Client 40] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38338)\u001b[0m [Client 31] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38338)\u001b[0m [Client 86] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38334)\u001b[0m [Client 23] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38338)\u001b[0m [Client 29] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38338)\u001b[0m [Client 3] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38339)\u001b[0m [Client 92] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38337)\u001b[0m [Client 97] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38339)\u001b[0m [Client 90] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38337)\u001b[0m [Client 68] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38338)\u001b[0m [Client 16] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38339)\u001b[0m [Client 99] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38337)\u001b[0m [Client 24] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38339)\u001b[0m [Client 87] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38334)\u001b[0m [Client 48] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38341)\u001b[0m [Client 41] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38338)\u001b[0m [Client 12] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38337)\u001b[0m [Client 80] evaluate, config: {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 12:21:10,670 | server.py:170 | evaluate_round received 0 results and 30 failures\n",
      "DEBUG flower 2023-02-01 12:21:10,671 | server.py:203 | fit_round: strategy sampled 30 clients (out of 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38336)\u001b[0m [Client 26] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38339)\u001b[0m [Client 37] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38340)\u001b[0m [Client 66] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38335)\u001b[0m [Client 20] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m [Client 54] fit, config: {'current_round': 38, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m Epoch 1: train loss 9.74528884398751e-05, accuracy 0.7407407407407407\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m [Client 79] fit, config: {'current_round': 38, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m [Client 37] fit, config: {'current_round': 38, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m Epoch 1: train loss 9.991023398470134e-05, accuracy 0.6481481481481481\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m Epoch 1: train loss 9.889034845400602e-05, accuracy 0.7407407407407407\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m [Client 60] fit, config: {'current_round': 38, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m Epoch 1: train loss 8.441237878287211e-05, accuracy 0.8148148148148148\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m [Client 61] fit, config: {'current_round': 38, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m [Client 23] fit, config: {'current_round': 38, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m Epoch 1: train loss 0.0001013157598208636, accuracy 0.7592592592592593\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m [Client 82] fit, config: {'current_round': 38, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m Epoch 1: train loss 0.00011037200602004305, accuracy 0.5925925925925926\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m Epoch 1: train loss 0.00010533114982536063, accuracy 0.7777777777777778\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m [Client 16] fit, config: {'current_round': 38, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m Epoch 1: train loss 9.070838859770447e-05, accuracy 0.7407407407407407\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m [Client 38] fit, config: {'current_round': 38, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m [Client 75] fit, config: {'current_round': 38, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m Epoch 1: train loss 9.503379260422662e-05, accuracy 0.7777777777777778\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m Epoch 1: train loss 0.00010527268750593066, accuracy 0.6666666666666666\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m [Client 88] fit, config: {'current_round': 38, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m Epoch 1: train loss 8.607291238149628e-05, accuracy 0.7407407407407407\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m [Client 11] fit, config: {'current_round': 38, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m Epoch 1: train loss 9.035060065798461e-05, accuracy 0.7592592592592593\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m [Client 64] fit, config: {'current_round': 38, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m [Client 13] fit, config: {'current_round': 38, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m Epoch 1: train loss 9.839686390478164e-05, accuracy 0.7777777777777778\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 12:21:12,933 | server.py:216 | fit_round received 30 results and 0 failures\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m [Client 20] fit, config: {'current_round': 38, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m Epoch 1: train loss 0.00010726774053182453, accuracy 0.7407407407407407\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m [Client 87] fit, config: {'current_round': 38, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m Epoch 1: train loss 0.00010502679651835933, accuracy 0.6666666666666666\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m Epoch 1: train loss 9.710475569590926e-05, accuracy 0.7777777777777778\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m [Client 0] fit, config: {'current_round': 38, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m Epoch 1: train loss 0.00010665547597454861, accuracy 0.7037037037037037\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m [Client 98] fit, config: {'current_round': 38, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m Epoch 1: train loss 0.00010903340444201604, accuracy 0.6851851851851852\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m [Client 80] fit, config: {'current_round': 38, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m Epoch 1: train loss 9.204226080328226e-05, accuracy 0.7407407407407407\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m [Client 15] fit, config: {'current_round': 38, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m Epoch 1: train loss 0.0001088075150619261, accuracy 0.6851851851851852\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m [Client 27] fit, config: {'current_round': 38, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m Epoch 1: train loss 0.00011533148062881082, accuracy 0.6851851851851852\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m [Client 62] fit, config: {'current_round': 38, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m Epoch 1: train loss 8.631466334918514e-05, accuracy 0.8148148148148148\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m [Client 72] fit, config: {'current_round': 38, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m Epoch 1: train loss 9.315846546087414e-05, accuracy 0.8333333333333334\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m [Client 95] fit, config: {'current_round': 38, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m Epoch 1: train loss 8.373995660804212e-05, accuracy 0.7962962962962963\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m [Client 47] fit, config: {'current_round': 38, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m Epoch 1: train loss 9.731274622026831e-05, accuracy 0.7592592592592593\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m [Client 33] fit, config: {'current_round': 38, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m Epoch 1: train loss 0.00011166905460413545, accuracy 0.7037037037037037\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m [Client 29] fit, config: {'current_round': 38, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m Epoch 1: train loss 9.38252269406803e-05, accuracy 0.7407407407407407\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m [Client 7] fit, config: {'current_round': 38, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m Epoch 1: train loss 9.444572788197547e-05, accuracy 0.7962962962962963\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m [Client 43] fit, config: {'current_round': 38, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m [Client 74] fit, config: {'current_round': 38, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m Epoch 1: train loss 0.00010174076305702329, accuracy 0.7407407407407407\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 12:21:12,992 | server.py:157 | evaluate_round: strategy sampled 30 clients (out of 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving round 38 aggregated_parameters...\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m Epoch 1: train loss 0.00011160648864461109, accuracy 0.7037037037037037\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38337)\u001b[0m [Client 30] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38337)\u001b[0m [Client 17] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38337)\u001b[0m [Client 63] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38337)\u001b[0m [Client 20] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38339)\u001b[0m [Client 28] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38339)\u001b[0m [Client 48] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38340)\u001b[0m [Client 98] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38337)\u001b[0m [Client 29] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38335)\u001b[0m [Client 4] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38339)\u001b[0m [Client 66] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38335)\u001b[0m [Client 91] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38340)\u001b[0m [Client 93] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38340)\u001b[0m [Client 73] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38335)\u001b[0m [Client 22] evaluate, config: {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 12:21:15,232 | server.py:170 | evaluate_round received 0 results and 30 failures\n",
      "DEBUG flower 2023-02-01 12:21:15,233 | server.py:203 | fit_round: strategy sampled 30 clients (out of 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38338)\u001b[0m [Client 14] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38336)\u001b[0m [Client 34] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38339)\u001b[0m [Client 8] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38340)\u001b[0m [Client 37] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38337)\u001b[0m [Client 7] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38334)\u001b[0m [Client 12] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38341)\u001b[0m [Client 16] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38338)\u001b[0m [Client 39] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38337)\u001b[0m [Client 52] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38335)\u001b[0m [Client 89] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38334)\u001b[0m [Client 2] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38338)\u001b[0m [Client 27] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38339)\u001b[0m [Client 19] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38341)\u001b[0m [Client 71] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38337)\u001b[0m [Client 21] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38335)\u001b[0m [Client 13] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m [Client 97] fit, config: {'current_round': 39, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m Epoch 1: train loss 8.752848953008652e-05, accuracy 0.7962962962962963\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m [Client 64] fit, config: {'current_round': 39, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m Epoch 1: train loss 9.363572462461889e-05, accuracy 0.7592592592592593\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m [Client 95] fit, config: {'current_round': 39, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m Epoch 1: train loss 8.546868775738403e-05, accuracy 0.7592592592592593\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m [Client 76] fit, config: {'current_round': 39, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m Epoch 1: train loss 8.634258847450837e-05, accuracy 0.7777777777777778\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m [Client 68] fit, config: {'current_round': 39, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m Epoch 1: train loss 0.00010252118954667822, accuracy 0.7777777777777778\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m [Client 83] fit, config: {'current_round': 39, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m Epoch 1: train loss 9.576786396792158e-05, accuracy 0.7777777777777778\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m [Client 88] fit, config: {'current_round': 39, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m Epoch 1: train loss 7.066815305734053e-05, accuracy 0.9074074074074074\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m [Client 62] fit, config: {'current_round': 39, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m [Client 48] fit, config: {'current_round': 39, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m Epoch 1: train loss 9.183910879073665e-05, accuracy 0.6666666666666666\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m [Client 78] fit, config: {'current_round': 39, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m [Client 59] fit, config: {'current_round': 39, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m Epoch 1: train loss 0.00011093389912275597, accuracy 0.6851851851851852\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m [Client 61] fit, config: {'current_round': 39, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m Epoch 1: train loss 0.00011252184776822105, accuracy 0.6851851851851852\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m Epoch 1: train loss 9.11547540454194e-05, accuracy 0.7222222222222222\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m [Client 53] fit, config: {'current_round': 39, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m Epoch 1: train loss 8.965766755864024e-05, accuracy 0.7777777777777778\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m Epoch 1: train loss 8.34126039990224e-05, accuracy 0.7037037037037037\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m [Client 46] fit, config: {'current_round': 39, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m Epoch 1: train loss 9.353294444736093e-05, accuracy 0.7222222222222222\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m [Client 54] fit, config: {'current_round': 39, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m Epoch 1: train loss 8.785895624896511e-05, accuracy 0.7592592592592593\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m [Client 8] fit, config: {'current_round': 39, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m Epoch 1: train loss 0.00010171037865802646, accuracy 0.6666666666666666\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m [Client 31] fit, config: {'current_round': 39, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m Epoch 1: train loss 9.134953143075109e-05, accuracy 0.7592592592592593\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m [Client 11] fit, config: {'current_round': 39, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m Epoch 1: train loss 9.886921907309443e-05, accuracy 0.7037037037037037\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m [Client 92] fit, config: {'current_round': 39, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m Epoch 1: train loss 8.645714842714369e-05, accuracy 0.7592592592592593\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m [Client 44] fit, config: {'current_round': 39, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m Epoch 1: train loss 8.984180021798238e-05, accuracy 0.7407407407407407\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m [Client 50] fit, config: {'current_round': 39, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m Epoch 1: train loss 0.00010820242459885776, accuracy 0.6666666666666666\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m [Client 52] fit, config: {'current_round': 39, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m Epoch 1: train loss 0.00010059043415822089, accuracy 0.6481481481481481\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m [Client 16] fit, config: {'current_round': 39, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m Epoch 1: train loss 8.762942889006808e-05, accuracy 0.7407407407407407\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 12:21:17,481 | server.py:216 | fit_round received 30 results and 0 failures\n",
      "DEBUG flower 2023-02-01 12:21:17,535 | server.py:157 | evaluate_round: strategy sampled 30 clients (out of 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m [Client 73] fit, config: {'current_round': 39, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m Epoch 1: train loss 9.006876643979922e-05, accuracy 0.7222222222222222\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m [Client 60] fit, config: {'current_round': 39, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m Epoch 1: train loss 8.949269249569625e-05, accuracy 0.7777777777777778\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m [Client 4] fit, config: {'current_round': 39, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m [Client 15] fit, config: {'current_round': 39, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m [Client 55] fit, config: {'current_round': 39, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m Epoch 1: train loss 8.589339995523915e-05, accuracy 0.7407407407407407\n",
      "Saving round 39 aggregated_parameters...\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m Epoch 1: train loss 8.666519715916365e-05, accuracy 0.7592592592592593\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m Epoch 1: train loss 9.45726060308516e-05, accuracy 0.7407407407407407\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m [Client 66] fit, config: {'current_round': 39, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m Epoch 1: train loss 8.271758269984275e-05, accuracy 0.8148148148148148\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m [Client 14] fit, config: {'current_round': 39, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m Epoch 1: train loss 8.756530587561429e-05, accuracy 0.7962962962962963\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38339)\u001b[0m [Client 41] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38339)\u001b[0m [Client 51] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38337)\u001b[0m [Client 85] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38337)\u001b[0m [Client 68] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38337)\u001b[0m [Client 82] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38337)\u001b[0m [Client 1] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38339)\u001b[0m [Client 74] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38337)\u001b[0m [Client 6] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38336)\u001b[0m [Client 65] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38336)\u001b[0m [Client 33] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38336)\u001b[0m [Client 5] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38339)\u001b[0m [Client 20] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38337)\u001b[0m [Client 49] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38336)\u001b[0m [Client 19] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38339)\u001b[0m [Client 58] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38337)\u001b[0m [Client 50] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38336)\u001b[0m [Client 2] evaluate, config: {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 12:21:19,773 | server.py:170 | evaluate_round received 0 results and 30 failures\n",
      "DEBUG flower 2023-02-01 12:21:19,774 | server.py:203 | fit_round: strategy sampled 30 clients (out of 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38337)\u001b[0m [Client 56] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38334)\u001b[0m [Client 52] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38340)\u001b[0m [Client 37] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38334)\u001b[0m [Client 67] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38336)\u001b[0m [Client 12] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38340)\u001b[0m [Client 21] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38337)\u001b[0m [Client 91] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38335)\u001b[0m [Client 76] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38334)\u001b[0m [Client 95] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38341)\u001b[0m [Client 26] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38338)\u001b[0m [Client 10] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38339)\u001b[0m [Client 32] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38340)\u001b[0m [Client 72] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m [Client 1] fit, config: {'current_round': 40, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m [Client 5] fit, config: {'current_round': 40, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m Epoch 1: train loss 7.676135282963514e-05, accuracy 0.8333333333333334\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m Epoch 1: train loss 6.397457764251158e-05, accuracy 0.8888888888888888\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m [Client 33] fit, config: {'current_round': 40, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m Epoch 1: train loss 0.00010093912715092301, accuracy 0.7592592592592593\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m [Client 29] fit, config: {'current_round': 40, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m Epoch 1: train loss 8.688049274496734e-05, accuracy 0.7592592592592593\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m [Client 25] fit, config: {'current_round': 40, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m Epoch 1: train loss 8.916701335692778e-05, accuracy 0.7777777777777778\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m [Client 98] fit, config: {'current_round': 40, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m Epoch 1: train loss 0.00010179756645811722, accuracy 0.7037037037037037\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m [Client 69] fit, config: {'current_round': 40, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m Epoch 1: train loss 8.809262362774462e-05, accuracy 0.7777777777777778\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m [Client 43] fit, config: {'current_round': 40, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m Epoch 1: train loss 0.00010592033504508436, accuracy 0.6851851851851852\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m [Client 2] fit, config: {'current_round': 40, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m [Client 21] fit, config: {'current_round': 40, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m Epoch 1: train loss 8.532546053174883e-05, accuracy 0.7777777777777778\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m Epoch 1: train loss 8.317131141666323e-05, accuracy 0.7592592592592593\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m [Client 65] fit, config: {'current_round': 40, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m [Client 88] fit, config: {'current_round': 40, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m Epoch 1: train loss 8.000793604878709e-05, accuracy 0.7592592592592593\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m Epoch 1: train loss 8.090082701528445e-05, accuracy 0.8333333333333334\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m [Client 92] fit, config: {'current_round': 40, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m Epoch 1: train loss 8.388476999243721e-05, accuracy 0.8333333333333334\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m [Client 16] fit, config: {'current_round': 40, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m Epoch 1: train loss 8.683576015755534e-05, accuracy 0.7407407407407407\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m [Client 83] fit, config: {'current_round': 40, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m Epoch 1: train loss 9.890379442367703e-05, accuracy 0.6851851851851852\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m [Client 77] fit, config: {'current_round': 40, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m Epoch 1: train loss 9.483895701123402e-05, accuracy 0.7037037037037037\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m [Client 57] fit, config: {'current_round': 40, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m Epoch 1: train loss 6.390483031282201e-05, accuracy 0.8703703703703703\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 12:21:22,127 | server.py:216 | fit_round received 30 results and 0 failures\n",
      "DEBUG flower 2023-02-01 12:21:22,191 | server.py:157 | evaluate_round: strategy sampled 30 clients (out of 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m [Client 38] fit, config: {'current_round': 40, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m [Client 95] fit, config: {'current_round': 40, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m [Client 81] fit, config: {'current_round': 40, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m Epoch 1: train loss 9.588054672349244e-05, accuracy 0.7592592592592593\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m [Client 59] fit, config: {'current_round': 40, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m [Client 31] fit, config: {'current_round': 40, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m Epoch 1: train loss 8.363497909158468e-05, accuracy 0.7777777777777778\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m Epoch 1: train loss 8.73409298947081e-05, accuracy 0.7592592592592593\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m Epoch 1: train loss 7.579703378723934e-05, accuracy 0.8333333333333334\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m [Client 97] fit, config: {'current_round': 40, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m Epoch 1: train loss 7.61666233302094e-05, accuracy 0.8518518518518519\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m Epoch 1: train loss 0.00010991100134560838, accuracy 0.6851851851851852\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m [Client 80] fit, config: {'current_round': 40, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m [Client 40] fit, config: {'current_round': 40, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m Epoch 1: train loss 7.586765423184261e-05, accuracy 0.7777777777777778\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m [Client 75] fit, config: {'current_round': 40, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m Epoch 1: train loss 9.901555313263088e-05, accuracy 0.7037037037037037\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m [Client 34] fit, config: {'current_round': 40, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m Epoch 1: train loss 8.850406447891146e-05, accuracy 0.7222222222222222\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m [Client 10] fit, config: {'current_round': 40, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m Epoch 1: train loss 9.491889068158343e-05, accuracy 0.7037037037037037\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m Epoch 1: train loss 8.463687117910013e-05, accuracy 0.8148148148148148\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m [Client 7] fit, config: {'current_round': 40, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m Epoch 1: train loss 9.16364006116055e-05, accuracy 0.7962962962962963\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m [Client 26] fit, config: {'current_round': 40, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m Epoch 1: train loss 9.535782010061666e-05, accuracy 0.7222222222222222\n",
      "Saving round 40 aggregated_parameters...\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38341)\u001b[0m [Client 50] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38340)\u001b[0m [Client 16] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38341)\u001b[0m [Client 37] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38340)\u001b[0m [Client 1] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38341)\u001b[0m [Client 44] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38340)\u001b[0m [Client 99] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38337)\u001b[0m [Client 31] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38341)\u001b[0m [Client 39] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38340)\u001b[0m [Client 69] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38334)\u001b[0m [Client 96] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38341)\u001b[0m [Client 88] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38338)\u001b[0m [Client 59] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38340)\u001b[0m [Client 46] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38337)\u001b[0m [Client 22] evaluate, config: {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 12:21:24,403 | server.py:170 | evaluate_round received 0 results and 30 failures\n",
      "DEBUG flower 2023-02-01 12:21:24,404 | server.py:203 | fit_round: strategy sampled 30 clients (out of 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38338)\u001b[0m [Client 71] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38340)\u001b[0m [Client 87] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38334)\u001b[0m [Client 20] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38338)\u001b[0m [Client 57] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38340)\u001b[0m [Client 61] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38334)\u001b[0m [Client 17] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38341)\u001b[0m [Client 63] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38337)\u001b[0m [Client 34] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38341)\u001b[0m [Client 12] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38337)\u001b[0m [Client 18] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38334)\u001b[0m [Client 6] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38341)\u001b[0m [Client 86] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38338)\u001b[0m [Client 72] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38338)\u001b[0m [Client 28] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38337)\u001b[0m [Client 82] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38340)\u001b[0m [Client 84] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m [Client 43] fit, config: {'current_round': 41, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m Epoch 1: train loss 9.275080810766667e-05, accuracy 0.6666666666666666\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m [Client 95] fit, config: {'current_round': 41, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m Epoch 1: train loss 8.472245099255815e-05, accuracy 0.7222222222222222\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m [Client 28] fit, config: {'current_round': 41, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m Epoch 1: train loss 8.204700134228915e-05, accuracy 0.8518518518518519\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m [Client 93] fit, config: {'current_round': 41, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m Epoch 1: train loss 8.86732668732293e-05, accuracy 0.7407407407407407\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m [Client 77] fit, config: {'current_round': 41, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m Epoch 1: train loss 9.742179827298969e-05, accuracy 0.6666666666666666\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m [Client 2] fit, config: {'current_round': 41, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m Epoch 1: train loss 7.673797517782077e-05, accuracy 0.7777777777777778\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m [Client 0] fit, config: {'current_round': 41, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m Epoch 1: train loss 8.476325456285849e-05, accuracy 0.7777777777777778\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m [Client 94] fit, config: {'current_round': 41, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m Epoch 1: train loss 8.822348900139332e-05, accuracy 0.7222222222222222\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m [Client 4] fit, config: {'current_round': 41, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m Epoch 1: train loss 8.370955765713006e-05, accuracy 0.8148148148148148\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m [Client 61] fit, config: {'current_round': 41, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m Epoch 1: train loss 0.00010765157639980316, accuracy 0.7222222222222222\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m [Client 13] fit, config: {'current_round': 41, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m Epoch 1: train loss 7.940772047732025e-05, accuracy 0.7777777777777778\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m [Client 46] fit, config: {'current_round': 41, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m Epoch 1: train loss 8.782079385127872e-05, accuracy 0.7222222222222222\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m [Client 42] fit, config: {'current_round': 41, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m Epoch 1: train loss 0.00011227797222090885, accuracy 0.5740740740740741\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m [Client 37] fit, config: {'current_round': 41, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m [Client 67] fit, config: {'current_round': 41, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m Epoch 1: train loss 8.388531568925828e-05, accuracy 0.7962962962962963\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m Epoch 1: train loss 9.980908362194896e-05, accuracy 0.7222222222222222\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m [Client 8] fit, config: {'current_round': 41, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m Epoch 1: train loss 9.60530960583128e-05, accuracy 0.7407407407407407\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m [Client 60] fit, config: {'current_round': 41, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m Epoch 1: train loss 8.779736526776105e-05, accuracy 0.7222222222222222\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m [Client 82] fit, config: {'current_round': 41, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m Epoch 1: train loss 0.00010595663479762152, accuracy 0.6481481481481481\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m [Client 11] fit, config: {'current_round': 41, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m Epoch 1: train loss 9.674191824160516e-05, accuracy 0.7222222222222222\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m [Client 88] fit, config: {'current_round': 41, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m [Client 25] fit, config: {'current_round': 41, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m Epoch 1: train loss 8.869548764778301e-05, accuracy 0.7592592592592593\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m [Client 91] fit, config: {'current_round': 41, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m [Client 87] fit, config: {'current_round': 41, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m Epoch 1: train loss 6.653807213297114e-05, accuracy 0.8888888888888888\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m [Client 30] fit, config: {'current_round': 41, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m Epoch 1: train loss 6.612281140405685e-05, accuracy 0.8888888888888888\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 12:21:26,657 | server.py:216 | fit_round received 30 results and 0 failures\n",
      "DEBUG flower 2023-02-01 12:21:26,712 | server.py:157 | evaluate_round: strategy sampled 30 clients (out of 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m Epoch 1: train loss 0.0001120475644711405, accuracy 0.6481481481481481\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m [Client 26] fit, config: {'current_round': 41, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m Epoch 1: train loss 8.72504388098605e-05, accuracy 0.7777777777777778\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m Epoch 1: train loss 0.00010905188537435606, accuracy 0.6296296296296297\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m [Client 64] fit, config: {'current_round': 41, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m Epoch 1: train loss 9.288823639508337e-05, accuracy 0.7222222222222222\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m [Client 98] fit, config: {'current_round': 41, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m Epoch 1: train loss 9.34894778765738e-05, accuracy 0.7407407407407407\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m [Client 29] fit, config: {'current_round': 41, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m Epoch 1: train loss 7.980663212947547e-05, accuracy 0.7962962962962963\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m [Client 38] fit, config: {'current_round': 41, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m Epoch 1: train loss 7.576624921057373e-05, accuracy 0.8148148148148148\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m [Client 44] fit, config: {'current_round': 41, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m Epoch 1: train loss 8.578798588132486e-05, accuracy 0.7592592592592593\n",
      "Saving round 41 aggregated_parameters...\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38339)\u001b[0m [Client 95] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38335)\u001b[0m [Client 82] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38339)\u001b[0m [Client 62] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38339)\u001b[0m [Client 81] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38335)\u001b[0m [Client 85] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38339)\u001b[0m [Client 31] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38335)\u001b[0m [Client 75] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38336)\u001b[0m [Client 50] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38336)\u001b[0m [Client 42] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38335)\u001b[0m [Client 1] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38341)\u001b[0m [Client 93] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38339)\u001b[0m [Client 48] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38340)\u001b[0m [Client 71] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38337)\u001b[0m [Client 54] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38334)\u001b[0m [Client 60] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38338)\u001b[0m [Client 45] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38336)\u001b[0m [Client 14] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38335)\u001b[0m [Client 79] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38334)\u001b[0m [Client 6] evaluate, config: {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 12:21:28,990 | server.py:170 | evaluate_round received 0 results and 30 failures\n",
      "DEBUG flower 2023-02-01 12:21:28,992 | server.py:203 | fit_round: strategy sampled 30 clients (out of 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38334)\u001b[0m [Client 13] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38336)\u001b[0m [Client 58] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38337)\u001b[0m [Client 2] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38335)\u001b[0m [Client 26] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38334)\u001b[0m [Client 84] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38341)\u001b[0m [Client 61] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38338)\u001b[0m [Client 55] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38336)\u001b[0m [Client 67] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38339)\u001b[0m [Client 49] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38340)\u001b[0m [Client 11] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38335)\u001b[0m [Client 98] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m [Client 58] fit, config: {'current_round': 42, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m [Client 80] fit, config: {'current_round': 42, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m Epoch 1: train loss 8.158706623362377e-05, accuracy 0.7407407407407407\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m Epoch 1: train loss 0.00010159464000025764, accuracy 0.7037037037037037\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m [Client 24] fit, config: {'current_round': 42, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m Epoch 1: train loss 9.04646294657141e-05, accuracy 0.7222222222222222\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m [Client 9] fit, config: {'current_round': 42, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m Epoch 1: train loss 9.54320203163661e-05, accuracy 0.7777777777777778\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m [Client 99] fit, config: {'current_round': 42, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m Epoch 1: train loss 9.431327634956688e-05, accuracy 0.6296296296296297\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m [Client 4] fit, config: {'current_round': 42, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m Epoch 1: train loss 7.917031325632706e-05, accuracy 0.8333333333333334\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m [Client 39] fit, config: {'current_round': 42, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m Epoch 1: train loss 0.00010053830192191526, accuracy 0.7407407407407407\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m [Client 23] fit, config: {'current_round': 42, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m Epoch 1: train loss 9.375676017953083e-05, accuracy 0.7407407407407407\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m [Client 87] fit, config: {'current_round': 42, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m Epoch 1: train loss 9.63568381848745e-05, accuracy 0.6851851851851852\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m [Client 30] fit, config: {'current_round': 42, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m [Client 97] fit, config: {'current_round': 42, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m [Client 35] fit, config: {'current_round': 42, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m Epoch 1: train loss 0.00010721148282755166, accuracy 0.6481481481481481\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m [Client 52] fit, config: {'current_round': 42, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m Epoch 1: train loss 7.282409933395684e-05, accuracy 0.8148148148148148\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m [Client 94] fit, config: {'current_round': 42, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m Epoch 1: train loss 8.54551763040945e-05, accuracy 0.7777777777777778\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m Epoch 1: train loss 7.927772094262764e-05, accuracy 0.7962962962962963\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m [Client 28] fit, config: {'current_round': 42, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m Epoch 1: train loss 8.422516839345917e-05, accuracy 0.7777777777777778\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m [Client 0] fit, config: {'current_round': 42, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m Epoch 1: train loss 9.67830274021253e-05, accuracy 0.7222222222222222\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m [Client 13] fit, config: {'current_round': 42, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m [Client 86] fit, config: {'current_round': 42, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m Epoch 1: train loss 8.61042644828558e-05, accuracy 0.7777777777777778\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m Epoch 1: train loss 7.486820686608553e-05, accuracy 0.8888888888888888\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m [Client 31] fit, config: {'current_round': 42, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m Epoch 1: train loss 7.90831254562363e-05, accuracy 0.7777777777777778\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m Epoch 1: train loss 8.853188046487048e-05, accuracy 0.7777777777777778\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m [Client 50] fit, config: {'current_round': 42, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m Epoch 1: train loss 0.00011756952153518796, accuracy 0.7037037037037037\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 12:21:31,399 | server.py:216 | fit_round received 30 results and 0 failures\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m [Client 22] fit, config: {'current_round': 42, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m [Client 48] fit, config: {'current_round': 42, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m [Client 8] fit, config: {'current_round': 42, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m [Client 41] fit, config: {'current_round': 42, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m [Client 42] fit, config: {'current_round': 42, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m Epoch 1: train loss 9.981289622373879e-05, accuracy 0.6851851851851852\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m Epoch 1: train loss 8.134297240758315e-05, accuracy 0.7222222222222222\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m [Client 79] fit, config: {'current_round': 42, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m Epoch 1: train loss 0.00010822615877259523, accuracy 0.6296296296296297\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m Epoch 1: train loss 0.00010122433013748378, accuracy 0.7777777777777778\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m [Client 60] fit, config: {'current_round': 42, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m Epoch 1: train loss 7.501976506318897e-05, accuracy 0.7962962962962963\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m [Client 89] fit, config: {'current_round': 42, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m Epoch 1: train loss 0.0001001515265670605, accuracy 0.7777777777777778\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m [Client 71] fit, config: {'current_round': 42, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m Epoch 1: train loss 8.973258809419349e-05, accuracy 0.7222222222222222\n",
      "Saving round 42 aggregated_parameters...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 12:21:31,462 | server.py:157 | evaluate_round: strategy sampled 30 clients (out of 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m Epoch 1: train loss 0.00010389636736363173, accuracy 0.7037037037037037\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m [Client 6] fit, config: {'current_round': 42, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m Epoch 1: train loss 8.920176333049312e-05, accuracy 0.7407407407407407\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m Epoch 1: train loss 7.697538967477158e-05, accuracy 0.8333333333333334\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38341)\u001b[0m [Client 4] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38341)\u001b[0m [Client 32] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38341)\u001b[0m [Client 5] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38334)\u001b[0m [Client 18] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38341)\u001b[0m [Client 97] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38338)\u001b[0m [Client 77] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38341)\u001b[0m [Client 7] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38338)\u001b[0m [Client 85] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38334)\u001b[0m [Client 98] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38341)\u001b[0m [Client 33] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38336)\u001b[0m [Client 14] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38341)\u001b[0m [Client 30] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38341)\u001b[0m [Client 19] evaluate, config: {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 12:21:33,722 | server.py:170 | evaluate_round received 0 results and 30 failures\n",
      "DEBUG flower 2023-02-01 12:21:33,723 | server.py:203 | fit_round: strategy sampled 30 clients (out of 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38334)\u001b[0m [Client 11] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38341)\u001b[0m [Client 17] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38341)\u001b[0m [Client 34] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38336)\u001b[0m [Client 21] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38334)\u001b[0m [Client 29] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38337)\u001b[0m [Client 31] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38334)\u001b[0m [Client 45] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38341)\u001b[0m [Client 75] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38338)\u001b[0m [Client 43] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38341)\u001b[0m [Client 59] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38338)\u001b[0m [Client 39] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38334)\u001b[0m [Client 52] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38341)\u001b[0m [Client 50] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38338)\u001b[0m [Client 79] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38337)\u001b[0m [Client 99] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38336)\u001b[0m [Client 48] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38335)\u001b[0m [Client 95] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m [Client 20] fit, config: {'current_round': 43, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m Epoch 1: train loss 8.778004121268168e-05, accuracy 0.6296296296296297\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m [Client 87] fit, config: {'current_round': 43, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m Epoch 1: train loss 0.00010621463297866285, accuracy 0.6851851851851852\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m [Client 38] fit, config: {'current_round': 43, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m Epoch 1: train loss 7.1186717832461e-05, accuracy 0.8333333333333334\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m [Client 83] fit, config: {'current_round': 43, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m [Client 61] fit, config: {'current_round': 43, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m Epoch 1: train loss 8.90926385181956e-05, accuracy 0.7407407407407407\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m [Client 32] fit, config: {'current_round': 43, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m Epoch 1: train loss 9.016005060402676e-05, accuracy 0.7777777777777778\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m [Client 68] fit, config: {'current_round': 43, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m Epoch 1: train loss 0.00010604017006698996, accuracy 0.7037037037037037\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m [Client 98] fit, config: {'current_round': 43, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m Epoch 1: train loss 8.738465839996934e-05, accuracy 0.7962962962962963\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m [Client 79] fit, config: {'current_round': 43, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m Epoch 1: train loss 7.697180262766778e-05, accuracy 0.8333333333333334\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m Epoch 1: train loss 9.617736941436306e-05, accuracy 0.7777777777777778\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m [Client 6] fit, config: {'current_round': 43, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m Epoch 1: train loss 0.000102167010481935, accuracy 0.7037037037037037\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m [Client 91] fit, config: {'current_round': 43, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m [Client 75] fit, config: {'current_round': 43, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m Epoch 1: train loss 8.43661036924459e-05, accuracy 0.7222222222222222\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m [Client 35] fit, config: {'current_round': 43, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m Epoch 1: train loss 6.1033784731989726e-05, accuracy 0.9074074074074074\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m Epoch 1: train loss 9.165340452454984e-05, accuracy 0.6851851851851852\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m [Client 12] fit, config: {'current_round': 43, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m Epoch 1: train loss 7.480315980501473e-05, accuracy 0.7962962962962963\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m [Client 45] fit, config: {'current_round': 43, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m [Client 94] fit, config: {'current_round': 43, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m Epoch 1: train loss 8.383178646909073e-05, accuracy 0.7592592592592593\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m [Client 80] fit, config: {'current_round': 43, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m [Client 33] fit, config: {'current_round': 43, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m Epoch 1: train loss 7.482417277060449e-05, accuracy 0.8148148148148148\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m [Client 51] fit, config: {'current_round': 43, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m [Client 22] fit, config: {'current_round': 43, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m Epoch 1: train loss 9.63661223067902e-05, accuracy 0.7592592592592593\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m [Client 27] fit, config: {'current_round': 43, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m Epoch 1: train loss 9.146773663815111e-05, accuracy 0.7222222222222222\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m Epoch 1: train loss 7.620269752806053e-05, accuracy 0.7777777777777778\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m [Client 25] fit, config: {'current_round': 43, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m Epoch 1: train loss 9.246384433936328e-05, accuracy 0.6666666666666666\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m [Client 56] fit, config: {'current_round': 43, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m Epoch 1: train loss 0.00010609404125716537, accuracy 0.6666666666666666\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m [Client 84] fit, config: {'current_round': 43, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m Epoch 1: train loss 8.382639498449862e-05, accuracy 0.7962962962962963\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m Epoch 1: train loss 9.417210821993649e-05, accuracy 0.7407407407407407\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m Epoch 1: train loss 9.314882481703535e-05, accuracy 0.7037037037037037\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 12:21:36,122 | server.py:216 | fit_round received 30 results and 0 failures\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m [Client 97] fit, config: {'current_round': 43, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m Epoch 1: train loss 7.855841977288947e-05, accuracy 0.7962962962962963\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m [Client 50] fit, config: {'current_round': 43, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m Epoch 1: train loss 0.00010012726852437481, accuracy 0.7037037037037037\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m [Client 16] fit, config: {'current_round': 43, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m Epoch 1: train loss 8.144127059495077e-05, accuracy 0.7407407407407407\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m [Client 17] fit, config: {'current_round': 43, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m Epoch 1: train loss 9.775941725820303e-05, accuracy 0.7037037037037037\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m [Client 2] fit, config: {'current_round': 43, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m Epoch 1: train loss 7.322540477616712e-05, accuracy 0.7592592592592593\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 12:21:36,170 | server.py:157 | evaluate_round: strategy sampled 30 clients (out of 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving round 43 aggregated_parameters...\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m [Client 66] fit, config: {'current_round': 43, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m Epoch 1: train loss 7.286787877092138e-05, accuracy 0.8148148148148148\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38341)\u001b[0m [Client 40] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38339)\u001b[0m [Client 50] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38341)\u001b[0m [Client 45] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38334)\u001b[0m [Client 97] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38338)\u001b[0m [Client 58] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38339)\u001b[0m [Client 26] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38340)\u001b[0m [Client 55] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38340)\u001b[0m [Client 67] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38340)\u001b[0m [Client 90] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38334)\u001b[0m [Client 82] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38340)\u001b[0m [Client 16] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38340)\u001b[0m [Client 87] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38334)\u001b[0m [Client 78] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38340)\u001b[0m [Client 17] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38334)\u001b[0m [Client 31] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38340)\u001b[0m [Client 9] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38334)\u001b[0m [Client 66] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38341)\u001b[0m [Client 73] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38338)\u001b[0m [Client 99] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38339)\u001b[0m [Client 33] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38340)\u001b[0m [Client 28] evaluate, config: {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 12:21:38,307 | server.py:170 | evaluate_round received 0 results and 30 failures\n",
      "DEBUG flower 2023-02-01 12:21:38,308 | server.py:203 | fit_round: strategy sampled 30 clients (out of 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38341)\u001b[0m [Client 57] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38338)\u001b[0m [Client 27] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38339)\u001b[0m [Client 48] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38334)\u001b[0m [Client 60] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38341)\u001b[0m [Client 30] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38336)\u001b[0m [Client 68] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38340)\u001b[0m [Client 92] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38337)\u001b[0m [Client 81] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38335)\u001b[0m [Client 52] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m [Client 71] fit, config: {'current_round': 44, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m Epoch 1: train loss 7.219989493023604e-05, accuracy 0.8518518518518519\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m [Client 84] fit, config: {'current_round': 44, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m [Client 17] fit, config: {'current_round': 44, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m Epoch 1: train loss 0.00011742609785869718, accuracy 0.7037037037037037\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m [Client 12] fit, config: {'current_round': 44, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m [Client 10] fit, config: {'current_round': 44, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m Epoch 1: train loss 9.003440936794505e-05, accuracy 0.6851851851851852\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m \n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m Epoch 1: train loss 0.00010101633233716711, accuracy 0.7222222222222222\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m [Client 89] fit, config: {'current_round': 44, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m [Client 85] fit, config: {'current_round': 44, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m Epoch 1: train loss 6.0504567954922095e-05, accuracy 0.8333333333333334\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m [Client 93] fit, config: {'current_round': 44, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m Epoch 1: train loss 8.978504774859175e-05, accuracy 0.7222222222222222\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m Epoch 1: train loss 8.894340135157108e-05, accuracy 0.7407407407407407\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m Epoch 1: train loss 9.933114779414609e-05, accuracy 0.7222222222222222\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m [Client 9] fit, config: {'current_round': 44, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m Epoch 1: train loss 9.136175503954291e-05, accuracy 0.7777777777777778\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m [Client 97] fit, config: {'current_round': 44, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m Epoch 1: train loss 6.857315020170063e-05, accuracy 0.8333333333333334\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m [Client 2] fit, config: {'current_round': 44, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m Epoch 1: train loss 7.723407907178625e-05, accuracy 0.8333333333333334\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m [Client 55] fit, config: {'current_round': 44, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m Epoch 1: train loss 8.634806727059186e-05, accuracy 0.7037037037037037\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m [Client 86] fit, config: {'current_round': 44, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m [Client 6] fit, config: {'current_round': 44, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m [Client 59] fit, config: {'current_round': 44, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m [Client 91] fit, config: {'current_round': 44, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m [Client 74] fit, config: {'current_round': 44, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m Epoch 1: train loss 8.325135422637686e-05, accuracy 0.7407407407407407\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m [Client 82] fit, config: {'current_round': 44, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m Epoch 1: train loss 0.00010040470078820363, accuracy 0.5925925925925926\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m [Client 39] fit, config: {'current_round': 44, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m Epoch 1: train loss 9.792157652555034e-05, accuracy 0.7592592592592593\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m Epoch 1: train loss 8.46475813887082e-05, accuracy 0.7592592592592593\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m Epoch 1: train loss 0.00010688716429285705, accuracy 0.7222222222222222\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m Epoch 1: train loss 6.508544902317226e-05, accuracy 0.8888888888888888\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m Epoch 1: train loss 8.818745845928788e-05, accuracy 0.7222222222222222\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m [Client 43] fit, config: {'current_round': 44, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m Epoch 1: train loss 9.99318654066883e-05, accuracy 0.7222222222222222\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m [Client 96] fit, config: {'current_round': 44, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m Epoch 1: train loss 8.385164983337745e-05, accuracy 0.8333333333333334\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m [Client 30] fit, config: {'current_round': 44, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m Epoch 1: train loss 0.00010525459219934419, accuracy 0.6296296296296297\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m [Client 32] fit, config: {'current_round': 44, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m Epoch 1: train loss 9.962687909137458e-05, accuracy 0.7222222222222222\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 12:21:40,698 | server.py:216 | fit_round received 30 results and 0 failures\n",
      "DEBUG flower 2023-02-01 12:21:40,753 | server.py:157 | evaluate_round: strategy sampled 30 clients (out of 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m [Client 21] fit, config: {'current_round': 44, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m Epoch 1: train loss 7.637697126483545e-05, accuracy 0.7777777777777778\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m [Client 81] fit, config: {'current_round': 44, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m Epoch 1: train loss 9.035848779603839e-05, accuracy 0.7407407407407407\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m [Client 87] fit, config: {'current_round': 44, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m Epoch 1: train loss 9.280790982302278e-05, accuracy 0.7037037037037037\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m [Client 45] fit, config: {'current_round': 44, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m Epoch 1: train loss 7.426673255395144e-05, accuracy 0.7592592592592593\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m [Client 1] fit, config: {'current_round': 44, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m Epoch 1: train loss 5.6555873015895486e-05, accuracy 0.8888888888888888\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m [Client 0] fit, config: {'current_round': 44, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m Epoch 1: train loss 9.278390643885359e-05, accuracy 0.7407407407407407\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m [Client 18] fit, config: {'current_round': 44, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m Epoch 1: train loss 9.490376396570355e-05, accuracy 0.6481481481481481\n",
      "Saving round 44 aggregated_parameters...\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38338)\u001b[0m [Client 43] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38341)\u001b[0m [Client 67] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38338)\u001b[0m [Client 34] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38341)\u001b[0m [Client 54] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38341)\u001b[0m [Client 44] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38341)\u001b[0m [Client 76] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38341)\u001b[0m [Client 65] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38341)\u001b[0m [Client 66] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38338)\u001b[0m [Client 29] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38341)\u001b[0m [Client 45] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38338)\u001b[0m [Client 87] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38339)\u001b[0m [Client 50] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38338)\u001b[0m [Client 72] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38341)\u001b[0m [Client 12] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38338)\u001b[0m [Client 18] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38341)\u001b[0m [Client 96] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38341)\u001b[0m [Client 36] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38338)\u001b[0m [Client 73] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38339)\u001b[0m [Client 68] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38340)\u001b[0m [Client 27] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38337)\u001b[0m [Client 63] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38340)\u001b[0m [Client 33] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38339)\u001b[0m [Client 60] evaluate, config: {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 12:21:42,946 | server.py:170 | evaluate_round received 0 results and 30 failures\n",
      "DEBUG flower 2023-02-01 12:21:42,947 | server.py:203 | fit_round: strategy sampled 30 clients (out of 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38341)\u001b[0m [Client 70] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38338)\u001b[0m [Client 52] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38336)\u001b[0m [Client 25] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38339)\u001b[0m [Client 91] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38340)\u001b[0m [Client 57] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38337)\u001b[0m [Client 86] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38334)\u001b[0m [Client 95] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m [Client 18] fit, config: {'current_round': 45, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m Epoch 1: train loss 8.723521023057401e-05, accuracy 0.7407407407407407\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m [Client 25] fit, config: {'current_round': 45, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m Epoch 1: train loss 8.386237459490076e-05, accuracy 0.7407407407407407\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m [Client 9] fit, config: {'current_round': 45, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m [Client 56] fit, config: {'current_round': 45, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m Epoch 1: train loss 9.336147195426747e-05, accuracy 0.7222222222222222\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m Epoch 1: train loss 9.27634391700849e-05, accuracy 0.6851851851851852\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m [Client 61] fit, config: {'current_round': 45, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m Epoch 1: train loss 0.00010612196638248861, accuracy 0.6851851851851852\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m [Client 95] fit, config: {'current_round': 45, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m Epoch 1: train loss 7.403214112855494e-05, accuracy 0.7777777777777778\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m [Client 26] fit, config: {'current_round': 45, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m Epoch 1: train loss 8.198932482628152e-05, accuracy 0.7777777777777778\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m [Client 17] fit, config: {'current_round': 45, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m Epoch 1: train loss 9.605332161299884e-05, accuracy 0.7222222222222222\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m [Client 97] fit, config: {'current_round': 45, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m [Client 47] fit, config: {'current_round': 45, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m Epoch 1: train loss 9.403495641890913e-05, accuracy 0.7037037037037037\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m Epoch 1: train loss 7.771280070301145e-05, accuracy 0.7962962962962963\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m [Client 10] fit, config: {'current_round': 45, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m Epoch 1: train loss 7.40013929316774e-05, accuracy 0.7962962962962963\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m [Client 15] fit, config: {'current_round': 45, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m Epoch 1: train loss 8.398773934459314e-05, accuracy 0.7407407407407407\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m [Client 13] fit, config: {'current_round': 45, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m [Client 6] fit, config: {'current_round': 45, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m Epoch 1: train loss 7.359893061220646e-05, accuracy 0.7592592592592593\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m Epoch 1: train loss 0.00010198247764492407, accuracy 0.6851851851851852\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m [Client 75] fit, config: {'current_round': 45, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m [Client 81] fit, config: {'current_round': 45, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m Epoch 1: train loss 8.862910908646882e-05, accuracy 0.7222222222222222\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m [Client 21] fit, config: {'current_round': 45, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m [Client 87] fit, config: {'current_round': 45, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m [Client 76] fit, config: {'current_round': 45, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m Epoch 1: train loss 8.461347169941291e-05, accuracy 0.6851851851851852\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m Epoch 1: train loss 8.374745812034234e-05, accuracy 0.7222222222222222\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m Epoch 1: train loss 0.00010710791684687138, accuracy 0.6481481481481481\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m Epoch 1: train loss 7.252266368595883e-05, accuracy 0.7777777777777778\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m [Client 63] fit, config: {'current_round': 45, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m Epoch 1: train loss 9.436141408514231e-05, accuracy 0.7407407407407407\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m [Client 69] fit, config: {'current_round': 45, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m Epoch 1: train loss 7.862361235311255e-05, accuracy 0.7777777777777778\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m [Client 93] fit, config: {'current_round': 45, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m Epoch 1: train loss 8.490267646266147e-05, accuracy 0.6851851851851852\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m [Client 54] fit, config: {'current_round': 45, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m Epoch 1: train loss 7.755243859719485e-05, accuracy 0.7777777777777778\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m [Client 12] fit, config: {'current_round': 45, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m [Client 85] fit, config: {'current_round': 45, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m Epoch 1: train loss 6.719142402289435e-05, accuracy 0.7777777777777778\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m [Client 29] fit, config: {'current_round': 45, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m Epoch 1: train loss 7.466100942110643e-05, accuracy 0.8148148148148148\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m [Client 80] fit, config: {'current_round': 45, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m [Client 72] fit, config: {'current_round': 45, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m Epoch 1: train loss 9.128999226959422e-05, accuracy 0.7222222222222222\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m [Client 51] fit, config: {'current_round': 45, 'local_epochs': 3}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 12:21:45,306 | server.py:216 | fit_round received 30 results and 0 failures\n",
      "DEBUG flower 2023-02-01 12:21:45,360 | server.py:157 | evaluate_round: strategy sampled 30 clients (out of 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m Epoch 1: train loss 7.332653331104666e-05, accuracy 0.7962962962962963\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m Epoch 1: train loss 7.34223795006983e-05, accuracy 0.7777777777777778\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m [Client 67] fit, config: {'current_round': 45, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m Epoch 1: train loss 7.806838402757421e-05, accuracy 0.7592592592592593\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m Epoch 1: train loss 0.00010855477739823982, accuracy 0.6481481481481481\n",
      "Saving round 45 aggregated_parameters...\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38340)\u001b[0m [Client 19] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38340)\u001b[0m [Client 96] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38335)\u001b[0m [Client 16] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38340)\u001b[0m [Client 72] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38335)\u001b[0m [Client 26] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38340)\u001b[0m [Client 91] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38341)\u001b[0m [Client 98] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38335)\u001b[0m [Client 65] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38341)\u001b[0m [Client 4] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38339)\u001b[0m [Client 66] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38340)\u001b[0m [Client 30] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38335)\u001b[0m [Client 88] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38339)\u001b[0m [Client 28] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38341)\u001b[0m [Client 23] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38339)\u001b[0m [Client 42] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38339)\u001b[0m [Client 55] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38340)\u001b[0m [Client 17] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38335)\u001b[0m [Client 53] evaluate, config: {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 12:21:47,425 | server.py:170 | evaluate_round received 0 results and 30 failures\n",
      "DEBUG flower 2023-02-01 12:21:47,426 | server.py:203 | fit_round: strategy sampled 30 clients (out of 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38335)\u001b[0m [Client 22] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38335)\u001b[0m [Client 20] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38341)\u001b[0m [Client 89] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38339)\u001b[0m [Client 24] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38340)\u001b[0m [Client 62] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38337)\u001b[0m [Client 35] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38335)\u001b[0m [Client 83] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38341)\u001b[0m [Client 63] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38339)\u001b[0m [Client 44] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38340)\u001b[0m [Client 57] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38337)\u001b[0m [Client 18] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38335)\u001b[0m [Client 0] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m [Client 16] fit, config: {'current_round': 46, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m Epoch 1: train loss 7.834940333850682e-05, accuracy 0.7777777777777778\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m [Client 10] fit, config: {'current_round': 46, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m Epoch 1: train loss 8.763430378166959e-05, accuracy 0.6851851851851852\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m [Client 80] fit, config: {'current_round': 46, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m Epoch 1: train loss 7.339430885622278e-05, accuracy 0.7407407407407407\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m [Client 28] fit, config: {'current_round': 46, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m Epoch 1: train loss 7.069129060255364e-05, accuracy 0.8703703703703703\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m [Client 77] fit, config: {'current_round': 46, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m Epoch 1: train loss 8.360057108802721e-05, accuracy 0.7777777777777778\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m [Client 55] fit, config: {'current_round': 46, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m Epoch 1: train loss 8.429706940660253e-05, accuracy 0.7222222222222222\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m [Client 43] fit, config: {'current_round': 46, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m [Client 98] fit, config: {'current_round': 46, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m Epoch 1: train loss 9.549904643790796e-05, accuracy 0.7037037037037037\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m [Client 32] fit, config: {'current_round': 46, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m Epoch 1: train loss 9.743201371748e-05, accuracy 0.7222222222222222\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m Epoch 1: train loss 9.830299677560106e-05, accuracy 0.7407407407407407\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m [Client 57] fit, config: {'current_round': 46, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m Epoch 1: train loss 5.4850719607202336e-05, accuracy 0.8888888888888888\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m [Client 22] fit, config: {'current_round': 46, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m Epoch 1: train loss 9.31874310481362e-05, accuracy 0.7037037037037037\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m [Client 44] fit, config: {'current_round': 46, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m Epoch 1: train loss 6.770157779101282e-05, accuracy 0.8703703703703703\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m [Client 37] fit, config: {'current_round': 46, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m Epoch 1: train loss 8.28010233817622e-05, accuracy 0.7592592592592593\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m [Client 88] fit, config: {'current_round': 46, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m Epoch 1: train loss 6.816242239437997e-05, accuracy 0.7777777777777778\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m [Client 3] fit, config: {'current_round': 46, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m Epoch 1: train loss 8.49846110213548e-05, accuracy 0.7962962962962963\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m [Client 24] fit, config: {'current_round': 46, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m Epoch 1: train loss 8.283919305540621e-05, accuracy 0.7592592592592593\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m [Client 56] fit, config: {'current_round': 46, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m [Client 93] fit, config: {'current_round': 46, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m Epoch 1: train loss 0.00010751192894531414, accuracy 0.7777777777777778\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m Epoch 1: train loss 8.601140143582597e-05, accuracy 0.7592592592592593\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m [Client 58] fit, config: {'current_round': 46, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m Epoch 1: train loss 9.687756391940638e-05, accuracy 0.6666666666666666\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m [Client 65] fit, config: {'current_round': 46, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m [Client 17] fit, config: {'current_round': 46, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m Epoch 1: train loss 7.28950763004832e-05, accuracy 0.8703703703703703\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m [Client 79] fit, config: {'current_round': 46, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m [Client 11] fit, config: {'current_round': 46, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m Epoch 1: train loss 7.730767538305372e-05, accuracy 0.7962962962962963\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m Epoch 1: train loss 0.00011703107156790793, accuracy 0.6666666666666666\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m [Client 96] fit, config: {'current_round': 46, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m Epoch 1: train loss 8.162682206602767e-05, accuracy 0.8703703703703703\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m [Client 54] fit, config: {'current_round': 46, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m Epoch 1: train loss 8.175675611710176e-05, accuracy 0.7962962962962963\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m [Client 25] fit, config: {'current_round': 46, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m Epoch 1: train loss 8.327278192155063e-05, accuracy 0.7592592592592593\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(raylet)\u001b[0m Spilled 131451 MiB, 4344 objects, write throughput 1233 MiB/s.\n",
      "DEBUG flower 2023-02-01 12:21:49,971 | server.py:216 | fit_round received 30 results and 0 failures\n",
      "DEBUG flower 2023-02-01 12:21:50,043 | server.py:157 | evaluate_round: strategy sampled 30 clients (out of 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m [Client 48] fit, config: {'current_round': 46, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m Epoch 1: train loss 7.287551125045866e-05, accuracy 0.7777777777777778\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m Epoch 1: train loss 7.680015551159158e-05, accuracy 0.7962962962962963\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m [Client 33] fit, config: {'current_round': 46, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m [Client 29] fit, config: {'current_round': 46, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m Epoch 1: train loss 7.318279676837847e-05, accuracy 0.7407407407407407\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m [Client 76] fit, config: {'current_round': 46, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m Epoch 1: train loss 8.502582932123914e-05, accuracy 0.7777777777777778\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m Epoch 1: train loss 9.79323813226074e-05, accuracy 0.7592592592592593\n",
      "Saving round 46 aggregated_parameters...\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38337)\u001b[0m [Client 37] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38338)\u001b[0m [Client 13] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38338)\u001b[0m [Client 26] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38338)\u001b[0m [Client 83] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38337)\u001b[0m [Client 66] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38335)\u001b[0m [Client 62] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38341)\u001b[0m [Client 8] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38341)\u001b[0m [Client 28] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38335)\u001b[0m [Client 47] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38335)\u001b[0m [Client 81] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38341)\u001b[0m [Client 22] evaluate, config: {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 12:21:52,278 | server.py:170 | evaluate_round received 0 results and 30 failures\n",
      "DEBUG flower 2023-02-01 12:21:52,278 | server.py:203 | fit_round: strategy sampled 30 clients (out of 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38341)\u001b[0m [Client 49] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38341)\u001b[0m [Client 17] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38337)\u001b[0m [Client 42] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38335)\u001b[0m [Client 89] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38338)\u001b[0m [Client 71] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38338)\u001b[0m [Client 43] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38337)\u001b[0m [Client 38] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38341)\u001b[0m [Client 48] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38338)\u001b[0m [Client 73] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38340)\u001b[0m [Client 11] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38338)\u001b[0m [Client 14] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38337)\u001b[0m [Client 79] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38335)\u001b[0m [Client 56] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38341)\u001b[0m [Client 86] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38338)\u001b[0m [Client 98] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38339)\u001b[0m [Client 52] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38340)\u001b[0m [Client 6] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38335)\u001b[0m [Client 19] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38334)\u001b[0m [Client 74] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m [Client 99] fit, config: {'current_round': 47, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m Epoch 1: train loss 8.461973629891872e-05, accuracy 0.7592592592592593\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m [Client 45] fit, config: {'current_round': 47, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m Epoch 1: train loss 7.096151966834441e-05, accuracy 0.8148148148148148\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m [Client 71] fit, config: {'current_round': 47, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m Epoch 1: train loss 7.702784932916984e-05, accuracy 0.8148148148148148\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m [Client 50] fit, config: {'current_round': 47, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m Epoch 1: train loss 9.650310676079243e-05, accuracy 0.7037037037037037\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m [Client 21] fit, config: {'current_round': 47, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m Epoch 1: train loss 8.349834388354793e-05, accuracy 0.6851851851851852\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m [Client 95] fit, config: {'current_round': 47, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m Epoch 1: train loss 7.041772914817557e-05, accuracy 0.7777777777777778\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m [Client 17] fit, config: {'current_round': 47, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m Epoch 1: train loss 9.297313954448327e-05, accuracy 0.7222222222222222\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m [Client 97] fit, config: {'current_round': 47, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m Epoch 1: train loss 7.354423723882064e-05, accuracy 0.7777777777777778\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m [Client 37] fit, config: {'current_round': 47, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m Epoch 1: train loss 9.320834215031937e-05, accuracy 0.7037037037037037\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m [Client 14] fit, config: {'current_round': 47, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m Epoch 1: train loss 7.360996096394956e-05, accuracy 0.8148148148148148\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m [Client 79] fit, config: {'current_round': 47, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m Epoch 1: train loss 7.264162559295073e-05, accuracy 0.8333333333333334\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m [Client 72] fit, config: {'current_round': 47, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m Epoch 1: train loss 8.562742004869506e-05, accuracy 0.7407407407407407\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m [Client 65] fit, config: {'current_round': 47, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m Epoch 1: train loss 7.517838821513578e-05, accuracy 0.8148148148148148\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m [Client 26] fit, config: {'current_round': 47, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m Epoch 1: train loss 7.880299381213263e-05, accuracy 0.7962962962962963\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m [Client 75] fit, config: {'current_round': 47, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m [Client 51] fit, config: {'current_round': 47, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m Epoch 1: train loss 8.011504542082548e-05, accuracy 0.7407407407407407\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m [Client 89] fit, config: {'current_round': 47, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m Epoch 1: train loss 0.00010501184442546219, accuracy 0.6111111111111112\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m Epoch 1: train loss 9.070210944628343e-05, accuracy 0.6481481481481481\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m [Client 78] fit, config: {'current_round': 47, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m [Client 92] fit, config: {'current_round': 47, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m Epoch 1: train loss 7.048593397485092e-05, accuracy 0.8148148148148148\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m [Client 0] fit, config: {'current_round': 47, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m Epoch 1: train loss 7.52696578274481e-05, accuracy 0.7407407407407407\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m [Client 74] fit, config: {'current_round': 47, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m Epoch 1: train loss 6.519648741232231e-05, accuracy 0.7222222222222222\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m Epoch 1: train loss 8.218777657020837e-05, accuracy 0.7592592592592593\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m [Client 46] fit, config: {'current_round': 47, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m Epoch 1: train loss 7.902614015620202e-05, accuracy 0.7222222222222222\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m [Client 91] fit, config: {'current_round': 47, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m Epoch 1: train loss 5.5500840971944854e-05, accuracy 0.9074074074074074\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m [Client 87] fit, config: {'current_round': 47, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m Epoch 1: train loss 0.0001035940513247624, accuracy 0.7222222222222222\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m [Client 52] fit, config: {'current_round': 47, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m [Client 84] fit, config: {'current_round': 47, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m Epoch 1: train loss 8.824838732834905e-05, accuracy 0.7222222222222222\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m [Client 39] fit, config: {'current_round': 47, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m Epoch 1: train loss 0.00010796864080475643, accuracy 0.6296296296296297\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m [Client 22] fit, config: {'current_round': 47, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m Epoch 1: train loss 9.329276508651674e-05, accuracy 0.7592592592592593\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m [Client 42] fit, config: {'current_round': 47, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m Epoch 1: train loss 0.00010586815915303305, accuracy 0.6296296296296297\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m Epoch 1: train loss 9.006107575260103e-05, accuracy 0.6481481481481481\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 12:21:54,652 | server.py:216 | fit_round received 30 results and 0 failures\n",
      "DEBUG flower 2023-02-01 12:21:54,700 | server.py:157 | evaluate_round: strategy sampled 30 clients (out of 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving round 47 aggregated_parameters...\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m [Client 96] fit, config: {'current_round': 47, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m Epoch 1: train loss 8.56930564623326e-05, accuracy 0.7777777777777778\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38334)\u001b[0m [Client 69] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38336)\u001b[0m [Client 19] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38339)\u001b[0m [Client 71] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38339)\u001b[0m [Client 0] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38339)\u001b[0m [Client 43] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38336)\u001b[0m [Client 34] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38336)\u001b[0m [Client 96] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38339)\u001b[0m [Client 44] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38339)\u001b[0m [Client 31] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38339)\u001b[0m [Client 82] evaluate, config: {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 12:21:56,732 | server.py:170 | evaluate_round received 0 results and 30 failures\n",
      "DEBUG flower 2023-02-01 12:21:56,735 | server.py:203 | fit_round: strategy sampled 30 clients (out of 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38334)\u001b[0m [Client 81] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38336)\u001b[0m [Client 65] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38339)\u001b[0m [Client 56] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38337)\u001b[0m [Client 39] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38341)\u001b[0m [Client 51] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38340)\u001b[0m [Client 30] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38337)\u001b[0m [Client 38] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38335)\u001b[0m [Client 86] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38337)\u001b[0m [Client 22] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38340)\u001b[0m [Client 92] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38341)\u001b[0m [Client 32] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38338)\u001b[0m [Client 15] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38336)\u001b[0m [Client 83] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38339)\u001b[0m [Client 63] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38340)\u001b[0m [Client 85] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38340)\u001b[0m [Client 67] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38337)\u001b[0m [Client 16] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38335)\u001b[0m [Client 50] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38334)\u001b[0m [Client 98] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38337)\u001b[0m [Client 18] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m [Client 30] fit, config: {'current_round': 48, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m Epoch 1: train loss 0.00010310151265002787, accuracy 0.6481481481481481\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m [Client 73] fit, config: {'current_round': 48, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m Epoch 1: train loss 0.00010434541763970628, accuracy 0.6851851851851852\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m [Client 8] fit, config: {'current_round': 48, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m [Client 36] fit, config: {'current_round': 48, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m Epoch 1: train loss 7.663601718377322e-05, accuracy 0.8148148148148148\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m [Client 99] fit, config: {'current_round': 48, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m [Client 66] fit, config: {'current_round': 48, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m Epoch 1: train loss 7.330952939810231e-05, accuracy 0.7777777777777778\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m Epoch 1: train loss 9.691761079011485e-05, accuracy 0.6481481481481481\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m [Client 21] fit, config: {'current_round': 48, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m Epoch 1: train loss 6.870277866255492e-05, accuracy 0.8148148148148148\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m Epoch 1: train loss 8.501695992890745e-05, accuracy 0.7222222222222222\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m [Client 47] fit, config: {'current_round': 48, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m Epoch 1: train loss 8.085113950073719e-05, accuracy 0.7962962962962963\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m [Client 64] fit, config: {'current_round': 48, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m Epoch 1: train loss 9.076545393327251e-05, accuracy 0.7222222222222222\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m [Client 19] fit, config: {'current_round': 48, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m Epoch 1: train loss 7.09187297616154e-05, accuracy 0.7777777777777778\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m [Client 28] fit, config: {'current_round': 48, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m [Client 83] fit, config: {'current_round': 48, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m [Client 58] fit, config: {'current_round': 48, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m [Client 95] fit, config: {'current_round': 48, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m [Client 79] fit, config: {'current_round': 48, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m Epoch 1: train loss 6.862536974949762e-05, accuracy 0.8888888888888888\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m Epoch 1: train loss 8.615811384515837e-05, accuracy 0.7407407407407407\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m Epoch 1: train loss 9.461924491915852e-05, accuracy 0.7037037037037037\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m [Client 57] fit, config: {'current_round': 48, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m Epoch 1: train loss 6.470803054980934e-05, accuracy 0.8148148148148148\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m Epoch 1: train loss 5.252634946373291e-05, accuracy 0.9074074074074074\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m [Client 23] fit, config: {'current_round': 48, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m Epoch 1: train loss 7.878376345615834e-05, accuracy 0.7407407407407407\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m [Client 11] fit, config: {'current_round': 48, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m Epoch 1: train loss 7.474402809748426e-05, accuracy 0.7777777777777778\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m [Client 5] fit, config: {'current_round': 48, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m Epoch 1: train loss 8.524455915903673e-05, accuracy 0.7407407407407407\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m [Client 46] fit, config: {'current_round': 48, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m Epoch 1: train loss 8.330191485583782e-05, accuracy 0.7037037037037037\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m Epoch 1: train loss 6.138136086519808e-05, accuracy 0.8518518518518519\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m [Client 85] fit, config: {'current_round': 48, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m Epoch 1: train loss 5.3224874136503786e-05, accuracy 0.8518518518518519\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m [Client 53] fit, config: {'current_round': 48, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m Epoch 1: train loss 7.019934128038585e-05, accuracy 0.7962962962962963\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m [Client 82] fit, config: {'current_round': 48, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m Epoch 1: train loss 9.210165444528684e-05, accuracy 0.5925925925925926\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m [Client 77] fit, config: {'current_round': 48, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m [Client 20] fit, config: {'current_round': 48, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m Epoch 1: train loss 7.32111802790314e-05, accuracy 0.8148148148148148\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 12:21:58,931 | server.py:216 | fit_round received 30 results and 0 failures\n",
      "DEBUG flower 2023-02-01 12:21:58,985 | server.py:157 | evaluate_round: strategy sampled 30 clients (out of 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m [Client 14] fit, config: {'current_round': 48, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m Epoch 1: train loss 9.093915286939591e-05, accuracy 0.7222222222222222\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m [Client 31] fit, config: {'current_round': 48, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m Epoch 1: train loss 6.863902672193944e-05, accuracy 0.7962962962962963\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m Epoch 1: train loss 7.970722072059289e-05, accuracy 0.7592592592592593\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m [Client 52] fit, config: {'current_round': 48, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m Epoch 1: train loss 7.319188443943858e-05, accuracy 0.8518518518518519\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m [Client 0] fit, config: {'current_round': 48, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m [Client 90] fit, config: {'current_round': 48, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m Epoch 1: train loss 8.764495578361675e-05, accuracy 0.6666666666666666\n",
      "Saving round 48 aggregated_parameters...\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m Epoch 1: train loss 8.67645358084701e-05, accuracy 0.7222222222222222\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38337)\u001b[0m [Client 13] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38337)\u001b[0m [Client 49] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38341)\u001b[0m [Client 47] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38339)\u001b[0m [Client 98] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38337)\u001b[0m [Client 95] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38335)\u001b[0m [Client 57] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38341)\u001b[0m [Client 33] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38341)\u001b[0m [Client 42] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38335)\u001b[0m [Client 12] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38335)\u001b[0m [Client 38] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38336)\u001b[0m [Client 75] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38339)\u001b[0m [Client 2] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38335)\u001b[0m [Client 10] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38341)\u001b[0m [Client 68] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38339)\u001b[0m [Client 24] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38335)\u001b[0m [Client 69] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38334)\u001b[0m [Client 80] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38341)\u001b[0m [Client 41] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38338)\u001b[0m [Client 78] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38337)\u001b[0m [Client 79] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38338)\u001b[0m [Client 93] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38338)\u001b[0m [Client 77] evaluate, config: {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 12:22:01,177 | server.py:170 | evaluate_round received 0 results and 30 failures\n",
      "DEBUG flower 2023-02-01 12:22:01,178 | server.py:203 | fit_round: strategy sampled 30 clients (out of 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38334)\u001b[0m [Client 23] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38341)\u001b[0m [Client 25] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38338)\u001b[0m [Client 8] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38336)\u001b[0m [Client 44] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38339)\u001b[0m [Client 27] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38340)\u001b[0m [Client 20] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38337)\u001b[0m [Client 14] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38335)\u001b[0m [Client 83] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m [Client 54] fit, config: {'current_round': 49, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m Epoch 1: train loss 7.38472372177057e-05, accuracy 0.7962962962962963\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m [Client 50] fit, config: {'current_round': 49, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m Epoch 1: train loss 9.495377162238583e-05, accuracy 0.7222222222222222\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m [Client 30] fit, config: {'current_round': 49, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m Epoch 1: train loss 9.70717374002561e-05, accuracy 0.7407407407407407\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m [Client 59] fit, config: {'current_round': 49, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m Epoch 1: train loss 9.791651245905086e-05, accuracy 0.6851851851851852\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m [Client 98] fit, config: {'current_round': 49, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m Epoch 1: train loss 7.874441507738084e-05, accuracy 0.7777777777777778\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m [Client 23] fit, config: {'current_round': 49, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m Epoch 1: train loss 8.12340949778445e-05, accuracy 0.7407407407407407\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m [Client 52] fit, config: {'current_round': 49, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m [Client 12] fit, config: {'current_round': 49, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m Epoch 1: train loss 8.790512947598472e-05, accuracy 0.6481481481481481\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m [Client 91] fit, config: {'current_round': 49, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m Epoch 1: train loss 6.836969987489283e-05, accuracy 0.7962962962962963\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m Epoch 1: train loss 5.30509787495248e-05, accuracy 0.9074074074074074\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m [Client 55] fit, config: {'current_round': 49, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m Epoch 1: train loss 6.950490205781534e-05, accuracy 0.7777777777777778\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m [Client 66] fit, config: {'current_round': 49, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m [Client 89] fit, config: {'current_round': 49, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m Epoch 1: train loss 8.748027175897732e-05, accuracy 0.7037037037037037\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m [Client 41] fit, config: {'current_round': 49, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m Epoch 1: train loss 6.347831367747858e-05, accuracy 0.8333333333333334\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m [Client 0] fit, config: {'current_round': 49, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m Epoch 1: train loss 0.00010335886327084154, accuracy 0.6296296296296297\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m [Client 19] fit, config: {'current_round': 49, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m Epoch 1: train loss 6.665335968136787e-05, accuracy 0.7962962962962963\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m [Client 58] fit, config: {'current_round': 49, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m [Client 65] fit, config: {'current_round': 49, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m [Client 5] fit, config: {'current_round': 49, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m [Client 92] fit, config: {'current_round': 49, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m Epoch 1: train loss 6.671528535662219e-05, accuracy 0.7962962962962963\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m Epoch 1: train loss 7.219505641842261e-05, accuracy 0.7777777777777778\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m Epoch 1: train loss 6.981255137361586e-05, accuracy 0.7777777777777778\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m Epoch 1: train loss 7.170928438426927e-05, accuracy 0.7962962962962963\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m Epoch 1: train loss 8.143746526911855e-05, accuracy 0.7407407407407407\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m [Client 75] fit, config: {'current_round': 49, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m [Client 56] fit, config: {'current_round': 49, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m Epoch 1: train loss 8.291377889690921e-05, accuracy 0.7407407407407407\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m [Client 9] fit, config: {'current_round': 49, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m Epoch 1: train loss 8.665806672070175e-05, accuracy 0.7962962962962963\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m Epoch 1: train loss 7.749186625005677e-05, accuracy 0.7222222222222222\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 12:22:03,676 | server.py:216 | fit_round received 30 results and 0 failures\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m [Client 67] fit, config: {'current_round': 49, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m [Client 15] fit, config: {'current_round': 49, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m Epoch 1: train loss 8.151352085405961e-05, accuracy 0.7592592592592593\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m [Client 88] fit, config: {'current_round': 49, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m [Client 21] fit, config: {'current_round': 49, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m [Client 31] fit, config: {'current_round': 49, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m [Client 3] fit, config: {'current_round': 49, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m Epoch 1: train loss 8.022183465072885e-05, accuracy 0.7037037037037037\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m [Client 95] fit, config: {'current_round': 49, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m Epoch 1: train loss 7.260518032126129e-05, accuracy 0.7962962962962963\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 12:22:03,766 | server.py:157 | evaluate_round: strategy sampled 30 clients (out of 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m [Client 39] fit, config: {'current_round': 49, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m Epoch 1: train loss 0.00010563866089796647, accuracy 0.6666666666666666\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m Epoch 1: train loss 5.3345662308856845e-05, accuracy 0.8333333333333334\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m Epoch 1: train loss 8.158005948644131e-05, accuracy 0.7037037037037037\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m Epoch 1: train loss 7.540101069025695e-05, accuracy 0.7592592592592593\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m Epoch 1: train loss 6.623772787861526e-05, accuracy 0.8333333333333334\n",
      "Saving round 49 aggregated_parameters...\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38334)\u001b[0m [Client 6] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38337)\u001b[0m [Client 39] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38334)\u001b[0m [Client 38] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38334)\u001b[0m [Client 12] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38334)\u001b[0m [Client 55] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38339)\u001b[0m [Client 17] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38337)\u001b[0m [Client 18] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38339)\u001b[0m [Client 98] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38339)\u001b[0m [Client 52] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38339)\u001b[0m [Client 67] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38334)\u001b[0m [Client 19] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38341)\u001b[0m [Client 22] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38338)\u001b[0m [Client 11] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38340)\u001b[0m [Client 10] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38337)\u001b[0m [Client 62] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38336)\u001b[0m [Client 4] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38339)\u001b[0m [Client 35] evaluate, config: {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 12:22:06,134 | server.py:170 | evaluate_round received 0 results and 30 failures\n",
      "DEBUG flower 2023-02-01 12:22:06,135 | server.py:203 | fit_round: strategy sampled 30 clients (out of 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38336)\u001b[0m [Client 24] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38339)\u001b[0m [Client 43] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38336)\u001b[0m [Client 53] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38339)\u001b[0m [Client 23] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38336)\u001b[0m [Client 47] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38334)\u001b[0m [Client 64] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38338)\u001b[0m [Client 8] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38336)\u001b[0m [Client 75] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38339)\u001b[0m [Client 30] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38340)\u001b[0m [Client 73] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38341)\u001b[0m [Client 74] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38337)\u001b[0m [Client 36] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38335)\u001b[0m [Client 50] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m [Client 85] fit, config: {'current_round': 50, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m Epoch 1: train loss 4.86167409690097e-05, accuracy 0.8333333333333334\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m [Client 4] fit, config: {'current_round': 50, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m [Client 1] fit, config: {'current_round': 50, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m Epoch 1: train loss 4.44190991402138e-05, accuracy 0.8703703703703703\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m Epoch 1: train loss 6.36581753497012e-05, accuracy 0.8148148148148148\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m [Client 80] fit, config: {'current_round': 50, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m Epoch 1: train loss 6.328489689622074e-05, accuracy 0.7962962962962963\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m [Client 8] fit, config: {'current_round': 50, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m Epoch 1: train loss 9.223822416970506e-05, accuracy 0.6851851851851852\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m [Client 11] fit, config: {'current_round': 50, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m Epoch 1: train loss 7.075550820445642e-05, accuracy 0.7777777777777778\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m [Client 46] fit, config: {'current_round': 50, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m Epoch 1: train loss 7.939000352052972e-05, accuracy 0.6851851851851852\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m [Client 15] fit, config: {'current_round': 50, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m Epoch 1: train loss 7.854026625864208e-05, accuracy 0.7962962962962963\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m [Client 32] fit, config: {'current_round': 50, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m Epoch 1: train loss 8.845190313877538e-05, accuracy 0.7407407407407407\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m [Client 62] fit, config: {'current_round': 50, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m Epoch 1: train loss 6.527771620312706e-05, accuracy 0.8888888888888888\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m [Client 93] fit, config: {'current_round': 50, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m Epoch 1: train loss 7.476830796804279e-05, accuracy 0.8148148148148148\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m [Client 7] fit, config: {'current_round': 50, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m Epoch 1: train loss 7.244846347020939e-05, accuracy 0.7962962962962963\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m [Client 79] fit, config: {'current_round': 50, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m [Client 2] fit, config: {'current_round': 50, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m [Client 35] fit, config: {'current_round': 50, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m Epoch 1: train loss 7.341695163631812e-05, accuracy 0.7777777777777778\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m Epoch 1: train loss 6.637760088779032e-05, accuracy 0.8333333333333334\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m [Client 82] fit, config: {'current_round': 50, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m [Client 66] fit, config: {'current_round': 50, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m Epoch 1: train loss 6.814033258706331e-05, accuracy 0.7777777777777778\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m Epoch 1: train loss 6.526740617118776e-05, accuracy 0.8518518518518519\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m [Client 13] fit, config: {'current_round': 50, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m Epoch 1: train loss 8.493027416989207e-05, accuracy 0.7037037037037037\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m [Client 22] fit, config: {'current_round': 50, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m Epoch 1: train loss 8.631626405986026e-05, accuracy 0.6851851851851852\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m Epoch 1: train loss 7.137496140785515e-05, accuracy 0.8148148148148148\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m [Client 16] fit, config: {'current_round': 50, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m Epoch 1: train loss 7.468322291970253e-05, accuracy 0.7777777777777778\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m [Client 81] fit, config: {'current_round': 50, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m Epoch 1: train loss 8.002324466360733e-05, accuracy 0.7777777777777778\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m [Client 40] fit, config: {'current_round': 50, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m Epoch 1: train loss 5.6213451898656785e-05, accuracy 0.8148148148148148\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m [Client 23] fit, config: {'current_round': 50, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m Epoch 1: train loss 8.025971328606829e-05, accuracy 0.7407407407407407\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m [Client 27] fit, config: {'current_round': 50, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m [Client 67] fit, config: {'current_round': 50, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m Epoch 1: train loss 7.554290641564876e-05, accuracy 0.7592592592592593\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m [Client 26] fit, config: {'current_round': 50, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m Epoch 1: train loss 7.420779002131894e-05, accuracy 0.7222222222222222\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m [Client 84] fit, config: {'current_round': 50, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m [Client 97] fit, config: {'current_round': 50, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m Epoch 1: train loss 5.9975285694235936e-05, accuracy 0.8518518518518519\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m [Client 87] fit, config: {'current_round': 50, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m [Client 0] fit, config: {'current_round': 50, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m Epoch 1: train loss 8.043417619774118e-05, accuracy 0.7777777777777778\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 12:22:08,491 | server.py:216 | fit_round received 30 results and 0 failures\n",
      "DEBUG flower 2023-02-01 12:22:08,570 | server.py:157 | evaluate_round: strategy sampled 30 clients (out of 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving round 50 aggregated_parameters...\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m Epoch 1: train loss 9.641580982133746e-05, accuracy 0.7407407407407407\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m Epoch 1: train loss 9.106619108933955e-05, accuracy 0.7037037037037037\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m Epoch 1: train loss 8.270607213489711e-05, accuracy 0.7407407407407407\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38334)\u001b[0m [Client 63] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38336)\u001b[0m [Client 82] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38340)\u001b[0m [Client 79] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38336)\u001b[0m [Client 6] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38336)\u001b[0m [Client 17] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38336)\u001b[0m [Client 86] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38340)\u001b[0m [Client 29] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38340)\u001b[0m [Client 13] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38334)\u001b[0m [Client 5] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38336)\u001b[0m [Client 91] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38340)\u001b[0m [Client 36] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38340)\u001b[0m [Client 27] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38334)\u001b[0m [Client 30] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38338)\u001b[0m [Client 43] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38336)\u001b[0m [Client 60] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38340)\u001b[0m [Client 97] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38338)\u001b[0m [Client 68] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38336)\u001b[0m [Client 40] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38336)\u001b[0m [Client 87] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38338)\u001b[0m [Client 8] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38336)\u001b[0m [Client 59] evaluate, config: {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 12:22:11,110 | server.py:170 | evaluate_round received 0 results and 30 failures\n",
      "DEBUG flower 2023-02-01 12:22:11,111 | server.py:203 | fit_round: strategy sampled 30 clients (out of 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38334)\u001b[0m [Client 89] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38341)\u001b[0m [Client 20] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38338)\u001b[0m [Client 38] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38340)\u001b[0m [Client 84] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38335)\u001b[0m [Client 99] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38334)\u001b[0m [Client 0] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38336)\u001b[0m [Client 81] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38339)\u001b[0m [Client 4] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38337)\u001b[0m [Client 61] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m [Client 52] fit, config: {'current_round': 51, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m Epoch 1: train loss 8.91919044079259e-05, accuracy 0.6666666666666666\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m [Client 96] fit, config: {'current_round': 51, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m Epoch 1: train loss 8.287179662147537e-05, accuracy 0.7592592592592593\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m [Client 78] fit, config: {'current_round': 51, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m [Client 57] fit, config: {'current_round': 51, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m [Client 39] fit, config: {'current_round': 51, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m Epoch 1: train loss 5.976653847028501e-05, accuracy 0.7222222222222222\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m Epoch 1: train loss 5.7541896239854395e-05, accuracy 0.7777777777777778\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m [Client 20] fit, config: {'current_round': 51, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m Epoch 1: train loss 0.00010726296750362962, accuracy 0.6481481481481481\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m Epoch 1: train loss 8.165718463715166e-05, accuracy 0.6666666666666666\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m [Client 37] fit, config: {'current_round': 51, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m Epoch 1: train loss 8.98230355232954e-05, accuracy 0.7037037037037037\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m [Client 82] fit, config: {'current_round': 51, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m Epoch 1: train loss 9.873517410596833e-05, accuracy 0.6481481481481481\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m [Client 98] fit, config: {'current_round': 51, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m Epoch 1: train loss 7.839097088435665e-05, accuracy 0.7777777777777778\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m [Client 73] fit, config: {'current_round': 51, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m Epoch 1: train loss 7.343577453866601e-05, accuracy 0.7407407407407407\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m [Client 8] fit, config: {'current_round': 51, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m [Client 31] fit, config: {'current_round': 51, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m Epoch 1: train loss 7.346401980612427e-05, accuracy 0.7407407407407407\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m Epoch 1: train loss 8.416220225626603e-05, accuracy 0.7222222222222222\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m [Client 35] fit, config: {'current_round': 51, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m Epoch 1: train loss 8.323058136738837e-05, accuracy 0.6851851851851852\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m [Client 97] fit, config: {'current_round': 51, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m [Client 99] fit, config: {'current_round': 51, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m Epoch 1: train loss 8.372015145141631e-05, accuracy 0.6851851851851852\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m Epoch 1: train loss 6.965809734538198e-05, accuracy 0.7962962962962963\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m [Client 32] fit, config: {'current_round': 51, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m [Client 64] fit, config: {'current_round': 51, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m [Client 84] fit, config: {'current_round': 51, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m [Client 51] fit, config: {'current_round': 51, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m Epoch 1: train loss 8.583066664868966e-05, accuracy 0.7592592592592593\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m [Client 68] fit, config: {'current_round': 51, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m Epoch 1: train loss 9.139327448792756e-05, accuracy 0.7777777777777778\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m [Client 17] fit, config: {'current_round': 51, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m Epoch 1: train loss 8.885013812687248e-05, accuracy 0.7037037037037037\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m [Client 61] fit, config: {'current_round': 51, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m Epoch 1: train loss 8.016076753847301e-05, accuracy 0.7777777777777778\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m Epoch 1: train loss 8.329864067491144e-05, accuracy 0.7222222222222222\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m Epoch 1: train loss 0.0001039913622662425, accuracy 0.6296296296296297\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m Epoch 1: train loss 0.00010226404992863536, accuracy 0.6481481481481481\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m [Client 43] fit, config: {'current_round': 51, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m Epoch 1: train loss 8.082276326604187e-05, accuracy 0.7037037037037037\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 12:22:14,209 | server.py:216 | fit_round received 30 results and 0 failures\n",
      "DEBUG flower 2023-02-01 12:22:14,322 | server.py:157 | evaluate_round: strategy sampled 30 clients (out of 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m [Client 47] fit, config: {'current_round': 51, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m Epoch 1: train loss 8.618550054961815e-05, accuracy 0.7592592592592593\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m [Client 38] fit, config: {'current_round': 51, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m [Client 87] fit, config: {'current_round': 51, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m [Client 83] fit, config: {'current_round': 51, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m Epoch 1: train loss 8.119067206280306e-05, accuracy 0.7592592592592593\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m [Client 22] fit, config: {'current_round': 51, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m Epoch 1: train loss 9.04552434803918e-05, accuracy 0.7222222222222222\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m Epoch 1: train loss 6.329519965220243e-05, accuracy 0.8148148148148148\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m Epoch 1: train loss 9.909482469083741e-05, accuracy 0.6666666666666666\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m [Client 69] fit, config: {'current_round': 51, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m Epoch 1: train loss 6.947446672711521e-05, accuracy 0.7962962962962963\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m [Client 92] fit, config: {'current_round': 51, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m Epoch 1: train loss 6.487622886197641e-05, accuracy 0.8148148148148148\n",
      "Saving round 51 aggregated_parameters...\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38340)\u001b[0m [Client 63] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38335)\u001b[0m [Client 13] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38340)\u001b[0m [Client 67] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38340)\u001b[0m [Client 32] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38335)\u001b[0m [Client 80] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38335)\u001b[0m [Client 84] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38334)\u001b[0m [Client 71] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38340)\u001b[0m [Client 21] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38335)\u001b[0m [Client 29] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38339)\u001b[0m [Client 99] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38338)\u001b[0m [Client 0] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38338)\u001b[0m [Client 72] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38338)\u001b[0m [Client 16] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38338)\u001b[0m [Client 59] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38340)\u001b[0m [Client 15] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38335)\u001b[0m [Client 86] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38334)\u001b[0m [Client 35] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38335)\u001b[0m [Client 36] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38341)\u001b[0m [Client 12] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38338)\u001b[0m [Client 75] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38339)\u001b[0m [Client 31] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38340)\u001b[0m [Client 81] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38337)\u001b[0m [Client 91] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38337)\u001b[0m [Client 22] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38337)\u001b[0m [Client 53] evaluate, config: {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 12:22:17,965 | server.py:170 | evaluate_round received 0 results and 30 failures\n",
      "DEBUG flower 2023-02-01 12:22:17,966 | server.py:203 | fit_round: strategy sampled 30 clients (out of 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38338)\u001b[0m [Client 96] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38339)\u001b[0m [Client 69] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38341)\u001b[0m [Client 14] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38340)\u001b[0m [Client 24] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38335)\u001b[0m [Client 62] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m [Client 0] fit, config: {'current_round': 52, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m Epoch 1: train loss 7.936324982438236e-05, accuracy 0.7777777777777778\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m [Client 16] fit, config: {'current_round': 52, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m Epoch 1: train loss 7.304886821657419e-05, accuracy 0.8148148148148148\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m [Client 19] fit, config: {'current_round': 52, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m Epoch 1: train loss 6.74064431223087e-05, accuracy 0.7592592592592593\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m [Client 36] fit, config: {'current_round': 52, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m Epoch 1: train loss 7.065634417813271e-05, accuracy 0.8333333333333334\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m [Client 22] fit, config: {'current_round': 52, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m Epoch 1: train loss 8.504203287884593e-05, accuracy 0.7222222222222222\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m [Client 18] fit, config: {'current_round': 52, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m Epoch 1: train loss 8.374683238798752e-05, accuracy 0.6851851851851852\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m [Client 15] fit, config: {'current_round': 52, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m [Client 33] fit, config: {'current_round': 52, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m Epoch 1: train loss 7.807372458046302e-05, accuracy 0.7592592592592593\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m [Client 68] fit, config: {'current_round': 52, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m Epoch 1: train loss 7.459055632352829e-05, accuracy 0.7592592592592593\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m Epoch 1: train loss 8.803405944490805e-05, accuracy 0.7777777777777778\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m [Client 1] fit, config: {'current_round': 52, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m [Client 65] fit, config: {'current_round': 52, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m Epoch 1: train loss 6.584153015865013e-05, accuracy 0.8703703703703703\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m [Client 99] fit, config: {'current_round': 52, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m Epoch 1: train loss 4.222836287226528e-05, accuracy 0.9074074074074074\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m Epoch 1: train loss 7.754028774797916e-05, accuracy 0.7592592592592593\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m [Client 46] fit, config: {'current_round': 52, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m Epoch 1: train loss 7.724705938016996e-05, accuracy 0.7037037037037037\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m [Client 44] fit, config: {'current_round': 52, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m Epoch 1: train loss 5.6519096688134596e-05, accuracy 0.8888888888888888\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m [Client 94] fit, config: {'current_round': 52, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m Epoch 1: train loss 6.756626680726185e-05, accuracy 0.8148148148148148\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m [Client 89] fit, config: {'current_round': 52, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m Epoch 1: train loss 9.030922956299037e-05, accuracy 0.7407407407407407\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m [Client 56] fit, config: {'current_round': 52, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m Epoch 1: train loss 9.817855607252568e-05, accuracy 0.7592592592592593\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m [Client 61] fit, config: {'current_round': 52, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m [Client 72] fit, config: {'current_round': 52, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m [Client 7] fit, config: {'current_round': 52, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m Epoch 1: train loss 7.436409214278683e-05, accuracy 0.7962962962962963\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m Epoch 1: train loss 7.832560368115082e-05, accuracy 0.8703703703703703\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m Epoch 1: train loss 6.36325275991112e-05, accuracy 0.8333333333333334\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m [Client 45] fit, config: {'current_round': 52, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m [Client 83] fit, config: {'current_round': 52, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m [Client 87] fit, config: {'current_round': 52, 'local_epochs': 3}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 12:22:21,330 | server.py:216 | fit_round received 30 results and 0 failures\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m [Client 52] fit, config: {'current_round': 52, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m [Client 41] fit, config: {'current_round': 52, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m [Client 90] fit, config: {'current_round': 52, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m Epoch 1: train loss 6.512303662020713e-05, accuracy 0.7777777777777778\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m Epoch 1: train loss 7.904344238340855e-05, accuracy 0.7407407407407407\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m [Client 85] fit, config: {'current_round': 52, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m Epoch 1: train loss 8.082968997769058e-05, accuracy 0.7407407407407407\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m Epoch 1: train loss 6.642299558734521e-05, accuracy 0.8333333333333334\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m [Client 10] fit, config: {'current_round': 52, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m Epoch 1: train loss 7.988426659721881e-05, accuracy 0.7037037037037037\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m Epoch 1: train loss 8.334507583640516e-05, accuracy 0.8333333333333334\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m Epoch 1: train loss 8.281024929601699e-05, accuracy 0.7222222222222222\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m [Client 21] fit, config: {'current_round': 52, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m Epoch 1: train loss 6.329180905595422e-05, accuracy 0.8333333333333334\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m Epoch 1: train loss 4.6758566895732656e-05, accuracy 0.8888888888888888\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m [Client 34] fit, config: {'current_round': 52, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m Epoch 1: train loss 8.209911902667955e-05, accuracy 0.7222222222222222\n",
      "Saving round 52 aggregated_parameters...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 12:22:21,435 | server.py:157 | evaluate_round: strategy sampled 30 clients (out of 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38335)\u001b[0m [Client 39] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38335)\u001b[0m [Client 25] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38339)\u001b[0m [Client 94] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38339)\u001b[0m [Client 95] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38335)\u001b[0m [Client 22] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38339)\u001b[0m [Client 42] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38339)\u001b[0m [Client 91] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38335)\u001b[0m [Client 75] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38341)\u001b[0m [Client 86] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38336)\u001b[0m [Client 97] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38341)\u001b[0m [Client 15] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38336)\u001b[0m [Client 40] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38336)\u001b[0m [Client 5] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38336)\u001b[0m [Client 21] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38341)\u001b[0m [Client 6] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38336)\u001b[0m [Client 14] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38339)\u001b[0m [Client 52] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38341)\u001b[0m [Client 19] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38335)\u001b[0m [Client 37] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38339)\u001b[0m [Client 9] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38337)\u001b[0m [Client 99] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38336)\u001b[0m [Client 30] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38336)\u001b[0m [Client 54] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38337)\u001b[0m [Client 98] evaluate, config: {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 12:22:24,375 | server.py:170 | evaluate_round received 0 results and 30 failures\n",
      "DEBUG flower 2023-02-01 12:22:24,377 | server.py:203 | fit_round: strategy sampled 30 clients (out of 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38334)\u001b[0m [Client 0] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38341)\u001b[0m [Client 41] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38338)\u001b[0m [Client 12] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38339)\u001b[0m [Client 70] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38337)\u001b[0m [Client 57] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38335)\u001b[0m [Client 62] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m [Client 8] fit, config: {'current_round': 53, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m [Client 60] fit, config: {'current_round': 53, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m Epoch 1: train loss 6.596287130378187e-05, accuracy 0.8148148148148148\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m Epoch 1: train loss 7.964432734297588e-05, accuracy 0.7592592592592593\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m [Client 62] fit, config: {'current_round': 53, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m Epoch 1: train loss 7.291716610779986e-05, accuracy 0.7407407407407407\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m [Client 20] fit, config: {'current_round': 53, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m Epoch 1: train loss 7.796023419359699e-05, accuracy 0.7037037037037037\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m [Client 12] fit, config: {'current_round': 53, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m Epoch 1: train loss 6.489815859822556e-05, accuracy 0.8148148148148148\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m [Client 45] fit, config: {'current_round': 53, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m Epoch 1: train loss 6.471861706813797e-05, accuracy 0.7962962962962963\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m [Client 73] fit, config: {'current_round': 53, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m [Client 70] fit, config: {'current_round': 53, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m [Client 51] fit, config: {'current_round': 53, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m [Client 32] fit, config: {'current_round': 53, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m [Client 22] fit, config: {'current_round': 53, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m Epoch 1: train loss 6.874126120237634e-05, accuracy 0.7962962962962963\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m Epoch 1: train loss 8.057110972004011e-05, accuracy 0.7962962962962963\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m Epoch 1: train loss 0.00010076236503664404, accuracy 0.6296296296296297\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m Epoch 1: train loss 8.615280967205763e-05, accuracy 0.7962962962962963\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m [Client 34] fit, config: {'current_round': 53, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m Epoch 1: train loss 6.875999679323286e-05, accuracy 0.7777777777777778\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m [Client 17] fit, config: {'current_round': 53, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m [Client 15] fit, config: {'current_round': 53, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m [Client 26] fit, config: {'current_round': 53, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m Epoch 1: train loss 7.331791857723147e-05, accuracy 0.8333333333333334\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m Epoch 1: train loss 8.265116775874048e-05, accuracy 0.7592592592592593\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m [Client 90] fit, config: {'current_round': 53, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m [Client 65] fit, config: {'current_round': 53, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m [Client 67] fit, config: {'current_round': 53, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m Epoch 1: train loss 8.47264745971188e-05, accuracy 0.7407407407407407\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m Epoch 1: train loss 6.934095290489495e-05, accuracy 0.7962962962962963\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m Epoch 1: train loss 7.898733747424558e-05, accuracy 0.7407407407407407\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m Epoch 1: train loss 6.453636160586029e-05, accuracy 0.7777777777777778\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m Epoch 1: train loss 6.49036155664362e-05, accuracy 0.8148148148148148\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m [Client 74] fit, config: {'current_round': 53, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m Epoch 1: train loss 7.673251093365252e-05, accuracy 0.7962962962962963\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m [Client 2] fit, config: {'current_round': 53, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m [Client 9] fit, config: {'current_round': 53, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m [Client 10] fit, config: {'current_round': 53, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m [Client 55] fit, config: {'current_round': 53, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m [Client 7] fit, config: {'current_round': 53, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m Epoch 1: train loss 6.227862468222156e-05, accuracy 0.7962962962962963\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m [Client 69] fit, config: {'current_round': 53, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m Epoch 1: train loss 6.573146674782038e-05, accuracy 0.8148148148148148\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m Epoch 1: train loss 7.979483780218288e-05, accuracy 0.7962962962962963\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m Epoch 1: train loss 6.446048791985959e-05, accuracy 0.7962962962962963\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m [Client 25] fit, config: {'current_round': 53, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m Epoch 1: train loss 7.107875717338175e-05, accuracy 0.8148148148148148\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m Epoch 1: train loss 6.587768439203501e-05, accuracy 0.7962962962962963\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m Epoch 1: train loss 8.660426829010248e-05, accuracy 0.7592592592592593\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m [Client 54] fit, config: {'current_round': 53, 'local_epochs': 3}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 12:22:27,440 | server.py:216 | fit_round received 30 results and 0 failures\n",
      "DEBUG flower 2023-02-01 12:22:27,518 | server.py:157 | evaluate_round: strategy sampled 30 clients (out of 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m [Client 75] fit, config: {'current_round': 53, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m [Client 99] fit, config: {'current_round': 53, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m Epoch 1: train loss 7.997081411303952e-05, accuracy 0.7222222222222222\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m [Client 30] fit, config: {'current_round': 53, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m Epoch 1: train loss 9.160717308986932e-05, accuracy 0.7407407407407407\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m Epoch 1: train loss 6.915593985468149e-05, accuracy 0.7962962962962963\n",
      "Saving round 53 aggregated_parameters...\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m Epoch 1: train loss 7.523639942519367e-05, accuracy 0.7222222222222222\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38341)\u001b[0m [Client 40] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38341)\u001b[0m [Client 99] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38338)\u001b[0m [Client 37] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38336)\u001b[0m [Client 98] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38336)\u001b[0m [Client 28] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38336)\u001b[0m [Client 41] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38336)\u001b[0m [Client 25] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38334)\u001b[0m [Client 14] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38338)\u001b[0m [Client 18] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38336)\u001b[0m [Client 32] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38335)\u001b[0m [Client 21] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38341)\u001b[0m [Client 58] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38338)\u001b[0m [Client 13] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38336)\u001b[0m [Client 5] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38339)\u001b[0m [Client 72] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38340)\u001b[0m [Client 16] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38337)\u001b[0m [Client 43] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38335)\u001b[0m [Client 7] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38334)\u001b[0m [Client 17] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38334)\u001b[0m [Client 1] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38336)\u001b[0m [Client 55] evaluate, config: {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 12:22:30,349 | server.py:170 | evaluate_round received 0 results and 30 failures\n",
      "DEBUG flower 2023-02-01 12:22:30,352 | server.py:203 | fit_round: strategy sampled 30 clients (out of 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38338)\u001b[0m [Client 96] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38340)\u001b[0m [Client 52] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38337)\u001b[0m [Client 50] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38334)\u001b[0m [Client 4] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38341)\u001b[0m [Client 53] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38336)\u001b[0m [Client 2] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38337)\u001b[0m [Client 97] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38335)\u001b[0m [Client 88] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38339)\u001b[0m [Client 51] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m [Client 37] fit, config: {'current_round': 54, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m Epoch 1: train loss 7.009301771176979e-05, accuracy 0.7592592592592593\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m [Client 27] fit, config: {'current_round': 54, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m [Client 10] fit, config: {'current_round': 54, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m Epoch 1: train loss 9.504624176770449e-05, accuracy 0.7222222222222222\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m [Client 21] fit, config: {'current_round': 54, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m [Client 83] fit, config: {'current_round': 54, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m Epoch 1: train loss 7.779434235999361e-05, accuracy 0.7777777777777778\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m Epoch 1: train loss 7.867928798077628e-05, accuracy 0.6851851851851852\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m Epoch 1: train loss 6.144683720776811e-05, accuracy 0.8703703703703703\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m [Client 54] fit, config: {'current_round': 54, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m Epoch 1: train loss 7.030281267361715e-05, accuracy 0.8148148148148148\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m [Client 38] fit, config: {'current_round': 54, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m Epoch 1: train loss 6.19507918599993e-05, accuracy 0.8148148148148148\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m [Client 89] fit, config: {'current_round': 54, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m Epoch 1: train loss 9.141374175669625e-05, accuracy 0.7037037037037037\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m [Client 81] fit, config: {'current_round': 54, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m [Client 50] fit, config: {'current_round': 54, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m Epoch 1: train loss 0.00010719279089244083, accuracy 0.7222222222222222\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m Epoch 1: train loss 7.804080814821646e-05, accuracy 0.7962962962962963\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m [Client 34] fit, config: {'current_round': 54, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m Epoch 1: train loss 8.38200721773319e-05, accuracy 0.7407407407407407\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m [Client 22] fit, config: {'current_round': 54, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m Epoch 1: train loss 8.290493133245036e-05, accuracy 0.7037037037037037\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m [Client 84] fit, config: {'current_round': 54, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m Epoch 1: train loss 8.891197649063542e-05, accuracy 0.7037037037037037\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m [Client 70] fit, config: {'current_round': 54, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m Epoch 1: train loss 7.393691339530051e-05, accuracy 0.7407407407407407\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m [Client 15] fit, config: {'current_round': 54, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m [Client 48] fit, config: {'current_round': 54, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m [Client 57] fit, config: {'current_round': 54, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m Epoch 1: train loss 7.137162901926786e-05, accuracy 0.7962962962962963\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m Epoch 1: train loss 5.76375714445021e-05, accuracy 0.8333333333333334\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m [Client 80] fit, config: {'current_round': 54, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m Epoch 1: train loss 6.168682011775672e-05, accuracy 0.8148148148148148\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m Epoch 1: train loss 4.677179458667524e-05, accuracy 0.8703703703703703\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m [Client 36] fit, config: {'current_round': 54, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m Epoch 1: train loss 6.688362191198394e-05, accuracy 0.8148148148148148\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m [Client 24] fit, config: {'current_round': 54, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m Epoch 1: train loss 6.905900227138773e-05, accuracy 0.7407407407407407\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m [Client 19] fit, config: {'current_round': 54, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m Epoch 1: train loss 6.653126183664426e-05, accuracy 0.7962962962962963\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 12:22:33,279 | server.py:216 | fit_round received 30 results and 0 failures\n",
      "DEBUG flower 2023-02-01 12:22:33,333 | server.py:157 | evaluate_round: strategy sampled 30 clients (out of 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m [Client 1] fit, config: {'current_round': 54, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m [Client 65] fit, config: {'current_round': 54, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m Epoch 1: train loss 6.522914918605238e-05, accuracy 0.8888888888888888\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m [Client 93] fit, config: {'current_round': 54, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m [Client 64] fit, config: {'current_round': 54, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m Epoch 1: train loss 4.139851807849482e-05, accuracy 0.8888888888888888\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m [Client 63] fit, config: {'current_round': 54, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m Epoch 1: train loss 5.859009615960531e-05, accuracy 0.8518518518518519\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m [Client 11] fit, config: {'current_round': 54, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m [Client 95] fit, config: {'current_round': 54, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m Epoch 1: train loss 6.116204895079136e-05, accuracy 0.8333333333333334\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m [Client 73] fit, config: {'current_round': 54, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m Epoch 1: train loss 9.785513248061761e-05, accuracy 0.6851851851851852\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m Epoch 1: train loss 6.947229849174619e-05, accuracy 0.8333333333333334\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m Epoch 1: train loss 8.732335118111223e-05, accuracy 0.7222222222222222\n",
      "Saving round 54 aggregated_parameters...\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m [Client 12] fit, config: {'current_round': 54, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m Epoch 1: train loss 6.707413558615372e-05, accuracy 0.7777777777777778\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m Epoch 1: train loss 6.809284968767315e-05, accuracy 0.7962962962962963\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38341)\u001b[0m [Client 18] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38341)\u001b[0m [Client 51] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38336)\u001b[0m [Client 31] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38340)\u001b[0m [Client 30] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38341)\u001b[0m [Client 88] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38336)\u001b[0m [Client 54] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38340)\u001b[0m [Client 20] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38341)\u001b[0m [Client 17] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38341)\u001b[0m [Client 24] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38341)\u001b[0m [Client 10] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38336)\u001b[0m [Client 43] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38340)\u001b[0m [Client 50] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38339)\u001b[0m [Client 71] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38339)\u001b[0m [Client 47] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38339)\u001b[0m [Client 40] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38336)\u001b[0m [Client 26] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38339)\u001b[0m [Client 46] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38336)\u001b[0m [Client 63] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38336)\u001b[0m [Client 91] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38339)\u001b[0m [Client 83] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38336)\u001b[0m [Client 29] evaluate, config: {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 12:22:35,455 | server.py:170 | evaluate_round received 0 results and 30 failures\n",
      "DEBUG flower 2023-02-01 12:22:35,456 | server.py:203 | fit_round: strategy sampled 30 clients (out of 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38334)\u001b[0m [Client 52] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38339)\u001b[0m [Client 5] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38337)\u001b[0m [Client 78] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38341)\u001b[0m [Client 32] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38338)\u001b[0m [Client 37] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38336)\u001b[0m [Client 35] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38339)\u001b[0m [Client 12] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38340)\u001b[0m [Client 66] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38335)\u001b[0m [Client 21] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m [Client 89] fit, config: {'current_round': 55, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m [Client 75] fit, config: {'current_round': 55, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m Epoch 1: train loss 7.445854134857655e-05, accuracy 0.7222222222222222\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m Epoch 1: train loss 7.978732901392505e-05, accuracy 0.7222222222222222\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m [Client 9] fit, config: {'current_round': 55, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m [Client 51] fit, config: {'current_round': 55, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m Epoch 1: train loss 0.00010207132436335087, accuracy 0.6296296296296297\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m [Client 81] fit, config: {'current_round': 55, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m Epoch 1: train loss 7.691387872910127e-05, accuracy 0.7777777777777778\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m [Client 62] fit, config: {'current_round': 55, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m Epoch 1: train loss 7.756924605928361e-05, accuracy 0.7222222222222222\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m [Client 8] fit, config: {'current_round': 55, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m Epoch 1: train loss 8.261798939201981e-05, accuracy 0.7222222222222222\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m Epoch 1: train loss 6.842627772130072e-05, accuracy 0.7592592592592593\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m [Client 28] fit, config: {'current_round': 55, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m Epoch 1: train loss 7.220344559755176e-05, accuracy 0.8148148148148148\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m [Client 67] fit, config: {'current_round': 55, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m [Client 31] fit, config: {'current_round': 55, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m [Client 71] fit, config: {'current_round': 55, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m Epoch 1: train loss 6.98246294632554e-05, accuracy 0.7592592592592593\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m Epoch 1: train loss 6.948438385734335e-05, accuracy 0.7777777777777778\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m [Client 0] fit, config: {'current_round': 55, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m Epoch 1: train loss 6.682586536044255e-05, accuracy 0.8518518518518519\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m Epoch 1: train loss 7.120741793187335e-05, accuracy 0.8148148148148148\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m [Client 84] fit, config: {'current_round': 55, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m [Client 82] fit, config: {'current_round': 55, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m Epoch 1: train loss 9.362789569422603e-05, accuracy 0.7037037037037037\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m [Client 70] fit, config: {'current_round': 55, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m Epoch 1: train loss 7.897064642747864e-05, accuracy 0.7037037037037037\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m [Client 47] fit, config: {'current_round': 55, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m [Client 22] fit, config: {'current_round': 55, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m Epoch 1: train loss 8.597773557994515e-05, accuracy 0.7407407407407407\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m [Client 77] fit, config: {'current_round': 55, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m Epoch 1: train loss 9.316101932199672e-05, accuracy 0.6666666666666666\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m Epoch 1: train loss 6.7713568569161e-05, accuracy 0.8148148148148148\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m Epoch 1: train loss 8.349950076080859e-05, accuracy 0.7777777777777778\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m [Client 58] fit, config: {'current_round': 55, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m Epoch 1: train loss 6.519276212202385e-05, accuracy 0.7962962962962963\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m [Client 21] fit, config: {'current_round': 55, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m Epoch 1: train loss 7.670256309211254e-05, accuracy 0.7407407407407407\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m [Client 25] fit, config: {'current_round': 55, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m Epoch 1: train loss 7.297466072486714e-05, accuracy 0.7592592592592593\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m [Client 15] fit, config: {'current_round': 55, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m [Client 85] fit, config: {'current_round': 55, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m [Client 42] fit, config: {'current_round': 55, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m [Client 56] fit, config: {'current_round': 55, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m Epoch 1: train loss 7.455977174686268e-05, accuracy 0.7962962962962963\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m Epoch 1: train loss 8.401219383813441e-05, accuracy 0.6851851851851852\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m [Client 63] fit, config: {'current_round': 55, 'local_epochs': 3}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 12:22:38,096 | server.py:216 | fit_round received 30 results and 0 failures\n",
      "DEBUG flower 2023-02-01 12:22:38,163 | server.py:157 | evaluate_round: strategy sampled 30 clients (out of 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m Epoch 1: train loss 5.610762309515849e-05, accuracy 0.8148148148148148\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m Epoch 1: train loss 0.00010301486327080056, accuracy 0.6851851851851852\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m [Client 37] fit, config: {'current_round': 55, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m [Client 41] fit, config: {'current_round': 55, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m Epoch 1: train loss 9.9729593785014e-05, accuracy 0.6481481481481481\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m [Client 69] fit, config: {'current_round': 55, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m Epoch 1: train loss 6.411086360458285e-05, accuracy 0.8148148148148148\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m Epoch 1: train loss 8.094159420579672e-05, accuracy 0.7962962962962963\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m [Client 40] fit, config: {'current_round': 55, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m Epoch 1: train loss 4.931180228595622e-05, accuracy 0.8703703703703703\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m Epoch 1: train loss 8.581492147641256e-05, accuracy 0.7222222222222222\n",
      "Saving round 55 aggregated_parameters...\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38336)\u001b[0m [Client 34] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38336)\u001b[0m [Client 92] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38340)\u001b[0m [Client 80] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38336)\u001b[0m [Client 84] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38340)\u001b[0m [Client 42] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38336)\u001b[0m [Client 77] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38340)\u001b[0m [Client 55] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38335)\u001b[0m [Client 47] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38335)\u001b[0m [Client 13] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38340)\u001b[0m [Client 18] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38341)\u001b[0m [Client 98] evaluate, config: {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 12:22:40,482 | server.py:170 | evaluate_round received 0 results and 30 failures\n",
      "DEBUG flower 2023-02-01 12:22:40,483 | server.py:203 | fit_round: strategy sampled 30 clients (out of 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38338)\u001b[0m [Client 12] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38336)\u001b[0m [Client 15] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38335)\u001b[0m [Client 44] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38334)\u001b[0m [Client 10] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38338)\u001b[0m [Client 7] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38339)\u001b[0m [Client 91] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38340)\u001b[0m [Client 20] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38337)\u001b[0m [Client 61] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38335)\u001b[0m [Client 53] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38338)\u001b[0m [Client 0] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38340)\u001b[0m [Client 73] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38337)\u001b[0m [Client 14] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38335)\u001b[0m [Client 65] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38334)\u001b[0m [Client 63] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38341)\u001b[0m [Client 22] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38338)\u001b[0m [Client 39] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38336)\u001b[0m [Client 52] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38339)\u001b[0m [Client 21] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38340)\u001b[0m [Client 31] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m [Client 41] fit, config: {'current_round': 56, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m Epoch 1: train loss 8.024764974834397e-05, accuracy 0.8148148148148148\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m [Client 61] fit, config: {'current_round': 56, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m Epoch 1: train loss 7.338480645557866e-05, accuracy 0.8333333333333334\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m [Client 62] fit, config: {'current_round': 56, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m Epoch 1: train loss 6.612565630348399e-05, accuracy 0.8333333333333334\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m [Client 1] fit, config: {'current_round': 56, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m Epoch 1: train loss 3.936503344448283e-05, accuracy 0.8888888888888888\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m [Client 5] fit, config: {'current_round': 56, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m Epoch 1: train loss 5.285616498440504e-05, accuracy 0.8333333333333334\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m [Client 15] fit, config: {'current_round': 56, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m Epoch 1: train loss 6.613765435758978e-05, accuracy 0.7592592592592593\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m [Client 12] fit, config: {'current_round': 56, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m Epoch 1: train loss 6.200133066158742e-05, accuracy 0.8148148148148148\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m [Client 66] fit, config: {'current_round': 56, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m [Client 11] fit, config: {'current_round': 56, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m Epoch 1: train loss 6.538419984281063e-05, accuracy 0.8148148148148148\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m [Client 82] fit, config: {'current_round': 56, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m Epoch 1: train loss 7.83174837124534e-05, accuracy 0.7777777777777778\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m Epoch 1: train loss 5.826004780828953e-05, accuracy 0.8333333333333334\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m [Client 60] fit, config: {'current_round': 56, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m Epoch 1: train loss 6.041763845132664e-05, accuracy 0.7592592592592593\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m [Client 3] fit, config: {'current_round': 56, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m [Client 23] fit, config: {'current_round': 56, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m [Client 17] fit, config: {'current_round': 56, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m Epoch 1: train loss 6.827017932664603e-05, accuracy 0.8518518518518519\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m [Client 39] fit, config: {'current_round': 56, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m Epoch 1: train loss 7.998970249900594e-05, accuracy 0.7962962962962963\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m [Client 14] fit, config: {'current_round': 56, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m Epoch 1: train loss 8.77928760019131e-05, accuracy 0.7777777777777778\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m Epoch 1: train loss 7.078404451021925e-05, accuracy 0.7407407407407407\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m Epoch 1: train loss 0.00010743072198238224, accuracy 0.6851851851851852\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m [Client 25] fit, config: {'current_round': 56, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m Epoch 1: train loss 6.111102266004309e-05, accuracy 0.8518518518518519\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m [Client 49] fit, config: {'current_round': 56, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m Epoch 1: train loss 6.729293818352744e-05, accuracy 0.8333333333333334\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m [Client 51] fit, config: {'current_round': 56, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m Epoch 1: train loss 6.818812835263088e-05, accuracy 0.8148148148148148\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m [Client 44] fit, config: {'current_round': 56, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m Epoch 1: train loss 5.371301085688174e-05, accuracy 0.8888888888888888\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m [Client 99] fit, config: {'current_round': 56, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m [Client 47] fit, config: {'current_round': 56, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m Epoch 1: train loss 7.686219032621011e-05, accuracy 0.7962962962962963\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m [Client 24] fit, config: {'current_round': 56, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m [Client 13] fit, config: {'current_round': 56, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m [Client 75] fit, config: {'current_round': 56, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m Epoch 1: train loss 6.546945951413363e-05, accuracy 0.7777777777777778\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m Epoch 1: train loss 6.96451825206168e-05, accuracy 0.7777777777777778\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m Epoch 1: train loss 6.584444781765342e-05, accuracy 0.8333333333333334\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m Epoch 1: train loss 6.997273158049211e-05, accuracy 0.7777777777777778\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m [Client 37] fit, config: {'current_round': 56, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m Epoch 1: train loss 6.469286745414138e-05, accuracy 0.8148148148148148\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 12:22:43,023 | server.py:216 | fit_round received 30 results and 0 failures\n",
      "DEBUG flower 2023-02-01 12:22:43,081 | server.py:157 | evaluate_round: strategy sampled 30 clients (out of 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m [Client 2] fit, config: {'current_round': 56, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m Epoch 1: train loss 5.6829845561878756e-05, accuracy 0.8518518518518519\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m [Client 32] fit, config: {'current_round': 56, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m Epoch 1: train loss 7.981181988725439e-05, accuracy 0.7407407407407407\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m [Client 63] fit, config: {'current_round': 56, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m [Client 57] fit, config: {'current_round': 56, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m Epoch 1: train loss 4.6914279664633796e-05, accuracy 0.8333333333333334\n",
      "Saving round 56 aggregated_parameters...\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m Epoch 1: train loss 5.9340567531762645e-05, accuracy 0.8518518518518519\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38341)\u001b[0m [Client 51] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38336)\u001b[0m [Client 81] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38339)\u001b[0m [Client 57] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38339)\u001b[0m [Client 69] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38335)\u001b[0m [Client 63] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38336)\u001b[0m [Client 37] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38336)\u001b[0m [Client 62] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38339)\u001b[0m [Client 72] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38339)\u001b[0m [Client 86] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38334)\u001b[0m [Client 26] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38341)\u001b[0m [Client 89] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38338)\u001b[0m [Client 24] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38336)\u001b[0m [Client 88] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38339)\u001b[0m [Client 53] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38340)\u001b[0m [Client 90] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38337)\u001b[0m [Client 50] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38335)\u001b[0m [Client 10] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38338)\u001b[0m [Client 23] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38336)\u001b[0m [Client 0] evaluate, config: {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 12:22:45,386 | server.py:170 | evaluate_round received 0 results and 30 failures\n",
      "DEBUG flower 2023-02-01 12:22:45,388 | server.py:203 | fit_round: strategy sampled 30 clients (out of 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38334)\u001b[0m [Client 98] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38341)\u001b[0m [Client 66] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38338)\u001b[0m [Client 47] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38336)\u001b[0m [Client 67] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38337)\u001b[0m [Client 60] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38334)\u001b[0m [Client 15] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38341)\u001b[0m [Client 43] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38338)\u001b[0m [Client 55] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38339)\u001b[0m [Client 91] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38340)\u001b[0m [Client 80] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38335)\u001b[0m [Client 20] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m [Client 20] fit, config: {'current_round': 57, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m Epoch 1: train loss 7.215945515781641e-05, accuracy 0.7777777777777778\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m [Client 91] fit, config: {'current_round': 57, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m Epoch 1: train loss 4.3872016249224544e-05, accuracy 0.9259259259259259\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m [Client 70] fit, config: {'current_round': 57, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m Epoch 1: train loss 6.403015868272632e-05, accuracy 0.7777777777777778\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m [Client 92] fit, config: {'current_round': 57, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m Epoch 1: train loss 5.236954166321084e-05, accuracy 0.8703703703703703\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m [Client 44] fit, config: {'current_round': 57, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m [Client 39] fit, config: {'current_round': 57, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m Epoch 1: train loss 0.00010045013186754659, accuracy 0.7222222222222222\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m Epoch 1: train loss 7.361616735579446e-05, accuracy 0.7407407407407407\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m [Client 41] fit, config: {'current_round': 57, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m Epoch 1: train loss 9.537262667436153e-05, accuracy 0.6851851851851852\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m [Client 7] fit, config: {'current_round': 57, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m Epoch 1: train loss 8.875726052792743e-05, accuracy 0.7592592592592593\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m [Client 4] fit, config: {'current_round': 57, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m [Client 12] fit, config: {'current_round': 57, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m [Client 68] fit, config: {'current_round': 57, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m Epoch 1: train loss 7.951611041789874e-05, accuracy 0.7777777777777778\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m [Client 17] fit, config: {'current_round': 57, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m Epoch 1: train loss 7.985989941516891e-05, accuracy 0.7962962962962963\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m Epoch 1: train loss 5.655239874613471e-05, accuracy 0.8333333333333334\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m Epoch 1: train loss 6.431437213905156e-05, accuracy 0.8148148148148148\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m [Client 5] fit, config: {'current_round': 57, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m Epoch 1: train loss 6.51861191727221e-05, accuracy 0.7962962962962963\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m [Client 56] fit, config: {'current_round': 57, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m Epoch 1: train loss 6.912032404216006e-05, accuracy 0.8148148148148148\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m [Client 98] fit, config: {'current_round': 57, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m [Client 65] fit, config: {'current_round': 57, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m Epoch 1: train loss 6.047565329936333e-05, accuracy 0.8333333333333334\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m [Client 76] fit, config: {'current_round': 57, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m Epoch 1: train loss 6.869449862278998e-05, accuracy 0.8518518518518519\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m Epoch 1: train loss 5.880155003978871e-05, accuracy 0.8333333333333334\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m [Client 36] fit, config: {'current_round': 57, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m Epoch 1: train loss 6.671257870038971e-05, accuracy 0.7592592592592593\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m [Client 95] fit, config: {'current_round': 57, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m Epoch 1: train loss 5.282652273308486e-05, accuracy 0.8333333333333334\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m [Client 2] fit, config: {'current_round': 57, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m [Client 50] fit, config: {'current_round': 57, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m [Client 37] fit, config: {'current_round': 57, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m Epoch 1: train loss 7.950338476803154e-05, accuracy 0.7407407407407407\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m [Client 97] fit, config: {'current_round': 57, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m Epoch 1: train loss 5.7891673350241035e-05, accuracy 0.8518518518518519\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m Epoch 1: train loss 8.517097012372687e-05, accuracy 0.7592592592592593\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m [Client 60] fit, config: {'current_round': 57, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m Epoch 1: train loss 5.8938501751981676e-05, accuracy 0.8518518518518519\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m [Client 75] fit, config: {'current_round': 57, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m [Client 87] fit, config: {'current_round': 57, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m Epoch 1: train loss 8.337776671396568e-05, accuracy 0.7407407407407407\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m [Client 26] fit, config: {'current_round': 57, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m Epoch 1: train loss 7.076947076711804e-05, accuracy 0.8148148148148148\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 12:22:47,924 | server.py:216 | fit_round received 30 results and 0 failures\n",
      "DEBUG flower 2023-02-01 12:22:47,988 | server.py:157 | evaluate_round: strategy sampled 30 clients (out of 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m Epoch 1: train loss 7.383865886367857e-05, accuracy 0.7592592592592593\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m [Client 71] fit, config: {'current_round': 57, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m Epoch 1: train loss 6.863327871542424e-05, accuracy 0.7962962962962963\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m Epoch 1: train loss 5.9121535741724074e-05, accuracy 0.8148148148148148\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m [Client 53] fit, config: {'current_round': 57, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m Epoch 1: train loss 7.45986690162681e-05, accuracy 0.7962962962962963\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m [Client 84] fit, config: {'current_round': 57, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m Epoch 1: train loss 7.31498803361319e-05, accuracy 0.7962962962962963\n",
      "Saving round 57 aggregated_parameters...\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38341)\u001b[0m [Client 26] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38335)\u001b[0m [Client 30] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38340)\u001b[0m [Client 14] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38340)\u001b[0m [Client 53] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38340)\u001b[0m [Client 45] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38340)\u001b[0m [Client 37] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38340)\u001b[0m [Client 87] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38335)\u001b[0m [Client 48] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38334)\u001b[0m [Client 41] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38341)\u001b[0m [Client 24] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38340)\u001b[0m [Client 36] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38335)\u001b[0m [Client 11] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38334)\u001b[0m [Client 10] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38335)\u001b[0m [Client 28] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38334)\u001b[0m [Client 99] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38335)\u001b[0m [Client 22] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38335)\u001b[0m [Client 21] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38334)\u001b[0m [Client 2] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38341)\u001b[0m [Client 61] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38340)\u001b[0m [Client 92] evaluate, config: {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 12:22:50,102 | server.py:170 | evaluate_round received 0 results and 30 failures\n",
      "DEBUG flower 2023-02-01 12:22:50,103 | server.py:203 | fit_round: strategy sampled 30 clients (out of 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38334)\u001b[0m [Client 91] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38338)\u001b[0m [Client 81] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38334)\u001b[0m [Client 25] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38341)\u001b[0m [Client 7] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38338)\u001b[0m [Client 65] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38339)\u001b[0m [Client 88] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38340)\u001b[0m [Client 62] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38337)\u001b[0m [Client 55] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38335)\u001b[0m [Client 80] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38336)\u001b[0m [Client 12] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m [Client 97] fit, config: {'current_round': 58, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m Epoch 1: train loss 5.370841608964838e-05, accuracy 0.8888888888888888\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m [Client 51] fit, config: {'current_round': 58, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m [Client 40] fit, config: {'current_round': 58, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m Epoch 1: train loss 6.540206231875345e-05, accuracy 0.7962962962962963\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m [Client 66] fit, config: {'current_round': 58, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m [Client 47] fit, config: {'current_round': 58, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m Epoch 1: train loss 7.549647125415504e-05, accuracy 0.7962962962962963\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m Epoch 1: train loss 4.5450338802766055e-05, accuracy 0.8333333333333334\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m Epoch 1: train loss 5.8074903790839016e-05, accuracy 0.8148148148148148\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m [Client 41] fit, config: {'current_round': 58, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m Epoch 1: train loss 7.525223190896213e-05, accuracy 0.7777777777777778\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m [Client 55] fit, config: {'current_round': 58, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m Epoch 1: train loss 7.117485802154988e-05, accuracy 0.7777777777777778\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m [Client 57] fit, config: {'current_round': 58, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m Epoch 1: train loss 4.6530993131455034e-05, accuracy 0.8148148148148148\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m [Client 10] fit, config: {'current_round': 58, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m Epoch 1: train loss 7.720507710473612e-05, accuracy 0.7222222222222222\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m [Client 14] fit, config: {'current_round': 58, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m Epoch 1: train loss 8.55470570968464e-05, accuracy 0.7777777777777778\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m [Client 7] fit, config: {'current_round': 58, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m [Client 79] fit, config: {'current_round': 58, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m Epoch 1: train loss 6.263279647100717e-05, accuracy 0.7962962962962963\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m Epoch 1: train loss 6.625003152294084e-05, accuracy 0.7777777777777778\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m [Client 94] fit, config: {'current_round': 58, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m Epoch 1: train loss 6.456991104641929e-05, accuracy 0.7962962962962963\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m [Client 52] fit, config: {'current_round': 58, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m Epoch 1: train loss 6.285833660513163e-05, accuracy 0.8333333333333334\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m [Client 3] fit, config: {'current_round': 58, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m Epoch 1: train loss 6.755825597792864e-05, accuracy 0.8518518518518519\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 12:22:52,299 | server.py:216 | fit_round received 30 results and 0 failures\n",
      "DEBUG flower 2023-02-01 12:22:52,349 | server.py:157 | evaluate_round: strategy sampled 30 clients (out of 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m [Client 20] fit, config: {'current_round': 58, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m Epoch 1: train loss 5.773705197498202e-05, accuracy 0.8518518518518519\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m [Client 31] fit, config: {'current_round': 58, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m [Client 28] fit, config: {'current_round': 58, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m [Client 38] fit, config: {'current_round': 58, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m Epoch 1: train loss 5.632634201901965e-05, accuracy 0.7962962962962963\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m [Client 81] fit, config: {'current_round': 58, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m Epoch 1: train loss 7.346484926529229e-05, accuracy 0.8333333333333334\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m Epoch 1: train loss 5.4913914937060326e-05, accuracy 0.8518518518518519\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m Epoch 1: train loss 6.357997335726395e-05, accuracy 0.8518518518518519\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m [Client 58] fit, config: {'current_round': 58, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m Epoch 1: train loss 8.064766734605655e-05, accuracy 0.7592592592592593\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m [Client 25] fit, config: {'current_round': 58, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m Epoch 1: train loss 6.143592327134684e-05, accuracy 0.8148148148148148\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m [Client 11] fit, config: {'current_round': 58, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m Epoch 1: train loss 6.189951091073453e-05, accuracy 0.8333333333333334\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m [Client 80] fit, config: {'current_round': 58, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m Epoch 1: train loss 5.4061329137766734e-05, accuracy 0.8703703703703703\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m [Client 98] fit, config: {'current_round': 58, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m Epoch 1: train loss 8.310913835885003e-05, accuracy 0.7222222222222222\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m [Client 76] fit, config: {'current_round': 58, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m Epoch 1: train loss 7.181313412729651e-05, accuracy 0.7777777777777778\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m [Client 15] fit, config: {'current_round': 58, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m Epoch 1: train loss 6.382416177075356e-05, accuracy 0.8148148148148148\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m [Client 30] fit, config: {'current_round': 58, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m Epoch 1: train loss 0.0001012906213873066, accuracy 0.7037037037037037\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m [Client 93] fit, config: {'current_round': 58, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m Epoch 1: train loss 6.086254143156111e-05, accuracy 0.8703703703703703\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m [Client 67] fit, config: {'current_round': 58, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m Epoch 1: train loss 6.848518387414515e-05, accuracy 0.7962962962962963\n",
      "Saving round 58 aggregated_parameters...\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38337)\u001b[0m [Client 6] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38335)\u001b[0m [Client 46] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38339)\u001b[0m [Client 59] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38335)\u001b[0m [Client 71] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38336)\u001b[0m [Client 19] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38335)\u001b[0m [Client 58] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38336)\u001b[0m [Client 12] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38335)\u001b[0m [Client 82] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38335)\u001b[0m [Client 39] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38335)\u001b[0m [Client 48] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38336)\u001b[0m [Client 26] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38335)\u001b[0m [Client 69] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38336)\u001b[0m [Client 47] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38339)\u001b[0m [Client 15] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38335)\u001b[0m [Client 92] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38339)\u001b[0m [Client 66] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38336)\u001b[0m [Client 54] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38339)\u001b[0m [Client 16] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38335)\u001b[0m [Client 25] evaluate, config: {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 12:22:54,745 | server.py:170 | evaluate_round received 0 results and 30 failures\n",
      "DEBUG flower 2023-02-01 12:22:54,746 | server.py:203 | fit_round: strategy sampled 30 clients (out of 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38336)\u001b[0m [Client 34] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38339)\u001b[0m [Client 85] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38335)\u001b[0m [Client 49] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38336)\u001b[0m [Client 67] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38334)\u001b[0m [Client 99] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38341)\u001b[0m [Client 23] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38338)\u001b[0m [Client 14] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38336)\u001b[0m [Client 27] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38339)\u001b[0m [Client 52] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38337)\u001b[0m [Client 17] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38335)\u001b[0m [Client 95] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m [Client 54] fit, config: {'current_round': 59, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m [Client 8] fit, config: {'current_round': 59, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m Epoch 1: train loss 7.708140765316784e-05, accuracy 0.7222222222222222\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m Epoch 1: train loss 6.680993101326749e-05, accuracy 0.7962962962962963\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m [Client 75] fit, config: {'current_round': 59, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m Epoch 1: train loss 7.48832244426012e-05, accuracy 0.7592592592592593\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m [Client 87] fit, config: {'current_round': 59, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m Epoch 1: train loss 8.266094664577395e-05, accuracy 0.7592592592592593\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m [Client 27] fit, config: {'current_round': 59, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m Epoch 1: train loss 7.957983325468376e-05, accuracy 0.7407407407407407\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m [Client 62] fit, config: {'current_round': 59, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m Epoch 1: train loss 6.397005927283317e-05, accuracy 0.7777777777777778\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m [Client 59] fit, config: {'current_round': 59, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m Epoch 1: train loss 9.037153358804062e-05, accuracy 0.7222222222222222\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m [Client 66] fit, config: {'current_round': 59, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m Epoch 1: train loss 5.434752529254183e-05, accuracy 0.8333333333333334\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m [Client 50] fit, config: {'current_round': 59, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m Epoch 1: train loss 8.598605199949816e-05, accuracy 0.7592592592592593\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m [Client 30] fit, config: {'current_round': 59, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m [Client 32] fit, config: {'current_round': 59, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m Epoch 1: train loss 7.905720121925697e-05, accuracy 0.7592592592592593\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m [Client 0] fit, config: {'current_round': 59, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m Epoch 1: train loss 6.507326907012612e-05, accuracy 0.8148148148148148\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m [Client 38] fit, config: {'current_round': 59, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m Epoch 1: train loss 5.6328011851292104e-05, accuracy 0.8518518518518519\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m Epoch 1: train loss 8.795498433755711e-05, accuracy 0.7407407407407407\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m [Client 4] fit, config: {'current_round': 59, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m Epoch 1: train loss 5.380812945077196e-05, accuracy 0.8518518518518519\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m [Client 18] fit, config: {'current_round': 59, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m Epoch 1: train loss 7.176052167778835e-05, accuracy 0.7592592592592593\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m [Client 36] fit, config: {'current_round': 59, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m Epoch 1: train loss 6.635979661950842e-05, accuracy 0.7592592592592593\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m [Client 44] fit, config: {'current_round': 59, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m Epoch 1: train loss 7.522956002503633e-05, accuracy 0.7222222222222222\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m [Client 81] fit, config: {'current_round': 59, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m [Client 52] fit, config: {'current_round': 59, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m Epoch 1: train loss 8.318571781273931e-05, accuracy 0.7592592592592593\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m [Client 41] fit, config: {'current_round': 59, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m Epoch 1: train loss 9.570885595167056e-05, accuracy 0.6851851851851852\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m Epoch 1: train loss 7.585002458654344e-05, accuracy 0.7407407407407407\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m [Client 85] fit, config: {'current_round': 59, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m Epoch 1: train loss 5.19721579621546e-05, accuracy 0.8518518518518519\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 12:22:56,900 | server.py:216 | fit_round received 30 results and 0 failures\n",
      "DEBUG flower 2023-02-01 12:22:56,951 | server.py:157 | evaluate_round: strategy sampled 30 clients (out of 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m [Client 39] fit, config: {'current_round': 59, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m Epoch 1: train loss 0.00010135662887478247, accuracy 0.6851851851851852\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m [Client 84] fit, config: {'current_round': 59, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m Epoch 1: train loss 7.287693006219342e-05, accuracy 0.7592592592592593\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m [Client 56] fit, config: {'current_round': 59, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m [Client 23] fit, config: {'current_round': 59, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m [Client 98] fit, config: {'current_round': 59, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m Epoch 1: train loss 6.655608012806624e-05, accuracy 0.7962962962962963\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m [Client 40] fit, config: {'current_round': 59, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m Epoch 1: train loss 4.6015044063096866e-05, accuracy 0.9074074074074074\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m [Client 22] fit, config: {'current_round': 59, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m Epoch 1: train loss 8.232016261899844e-05, accuracy 0.7222222222222222\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m [Client 93] fit, config: {'current_round': 59, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m Epoch 1: train loss 7.138191722333431e-05, accuracy 0.7962962962962963\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m [Client 5] fit, config: {'current_round': 59, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m Epoch 1: train loss 6.703687540721148e-05, accuracy 0.7962962962962963\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m Epoch 1: train loss 6.95408380124718e-05, accuracy 0.8148148148148148\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m Epoch 1: train loss 6.935883720871061e-05, accuracy 0.7592592592592593\n",
      "Saving round 59 aggregated_parameters...\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38334)\u001b[0m [Client 20] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38334)\u001b[0m [Client 63] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38334)\u001b[0m [Client 85] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38334)\u001b[0m [Client 64] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38334)\u001b[0m [Client 60] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38334)\u001b[0m [Client 8] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38338)\u001b[0m [Client 27] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38340)\u001b[0m [Client 21] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38334)\u001b[0m [Client 74] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38338)\u001b[0m [Client 39] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38340)\u001b[0m [Client 7] evaluate, config: {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 12:22:59,058 | server.py:170 | evaluate_round received 0 results and 30 failures\n",
      "DEBUG flower 2023-02-01 12:22:59,059 | server.py:203 | fit_round: strategy sampled 30 clients (out of 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38334)\u001b[0m [Client 1] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38338)\u001b[0m [Client 55] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38340)\u001b[0m [Client 3] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38334)\u001b[0m [Client 61] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38338)\u001b[0m [Client 71] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38334)\u001b[0m [Client 13] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38338)\u001b[0m [Client 54] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38334)\u001b[0m [Client 89] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38338)\u001b[0m [Client 87] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38334)\u001b[0m [Client 78] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38338)\u001b[0m [Client 10] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38339)\u001b[0m [Client 81] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38340)\u001b[0m [Client 41] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38338)\u001b[0m [Client 14] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38339)\u001b[0m [Client 65] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38334)\u001b[0m [Client 30] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38341)\u001b[0m [Client 99] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38340)\u001b[0m [Client 73] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38337)\u001b[0m [Client 76] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m [Client 29] fit, config: {'current_round': 60, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m Epoch 1: train loss 5.1818798965541646e-05, accuracy 0.8333333333333334\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m [Client 97] fit, config: {'current_round': 60, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m Epoch 1: train loss 5.178376522962935e-05, accuracy 0.8518518518518519\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m [Client 65] fit, config: {'current_round': 60, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m [Client 17] fit, config: {'current_round': 60, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m Epoch 1: train loss 9.92099303402938e-05, accuracy 0.7407407407407407\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m Epoch 1: train loss 6.038854189682752e-05, accuracy 0.8703703703703703\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m [Client 80] fit, config: {'current_round': 60, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m [Client 95] fit, config: {'current_round': 60, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m Epoch 1: train loss 5.6092016166076064e-05, accuracy 0.8518518518518519\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m [Client 96] fit, config: {'current_round': 60, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m Epoch 1: train loss 7.04642734490335e-05, accuracy 0.8703703703703703\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m [Client 8] fit, config: {'current_round': 60, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m Epoch 1: train loss 7.860473851906136e-05, accuracy 0.7407407407407407\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m Epoch 1: train loss 5.3444320656126365e-05, accuracy 0.8703703703703703\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m [Client 51] fit, config: {'current_round': 60, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m Epoch 1: train loss 6.513453990919515e-05, accuracy 0.7777777777777778\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m [Client 14] fit, config: {'current_round': 60, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m Epoch 1: train loss 8.220534073188901e-05, accuracy 0.7777777777777778\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m [Client 57] fit, config: {'current_round': 60, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m Epoch 1: train loss 4.117834396311082e-05, accuracy 0.8518518518518519\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m [Client 21] fit, config: {'current_round': 60, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m Epoch 1: train loss 5.446599607239477e-05, accuracy 0.8703703703703703\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m [Client 31] fit, config: {'current_round': 60, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m Epoch 1: train loss 5.393957326305099e-05, accuracy 0.8518518518518519\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m [Client 52] fit, config: {'current_round': 60, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m Epoch 1: train loss 5.906043588765897e-05, accuracy 0.8333333333333334\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m [Client 35] fit, config: {'current_round': 60, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m [Client 94] fit, config: {'current_round': 60, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m Epoch 1: train loss 5.7920020481105894e-05, accuracy 0.8148148148148148\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m [Client 4] fit, config: {'current_round': 60, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m Epoch 1: train loss 5.053900895291008e-05, accuracy 0.9444444444444444\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m Epoch 1: train loss 5.994159073452465e-05, accuracy 0.8333333333333334\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m [Client 49] fit, config: {'current_round': 60, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m Epoch 1: train loss 5.9511028666747734e-05, accuracy 0.8333333333333334\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m [Client 60] fit, config: {'current_round': 60, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m [Client 16] fit, config: {'current_round': 60, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m Epoch 1: train loss 6.976348959142342e-05, accuracy 0.7407407407407407\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m Epoch 1: train loss 5.392212187871337e-05, accuracy 0.7962962962962963\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m [Client 15] fit, config: {'current_round': 60, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m Epoch 1: train loss 5.961527131148614e-05, accuracy 0.8148148148148148\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m [Client 3] fit, config: {'current_round': 60, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m [Client 75] fit, config: {'current_round': 60, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m [Client 67] fit, config: {'current_round': 60, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m Epoch 1: train loss 6.81357123539783e-05, accuracy 0.8148148148148148\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m Epoch 1: train loss 6.289556040428579e-05, accuracy 0.8148148148148148\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m [Client 6] fit, config: {'current_round': 60, 'local_epochs': 3}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 12:23:02,033 | server.py:216 | fit_round received 30 results and 0 failures\n",
      "DEBUG flower 2023-02-01 12:23:02,114 | server.py:157 | evaluate_round: strategy sampled 30 clients (out of 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m [Client 18] fit, config: {'current_round': 60, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m Epoch 1: train loss 6.387136090779677e-05, accuracy 0.7962962962962963\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m [Client 34] fit, config: {'current_round': 60, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m Epoch 1: train loss 5.847047577844933e-05, accuracy 0.8888888888888888\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m [Client 45] fit, config: {'current_round': 60, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m Epoch 1: train loss 5.7974608353106305e-05, accuracy 0.8518518518518519\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m [Client 13] fit, config: {'current_round': 60, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m Epoch 1: train loss 5.89252776990179e-05, accuracy 0.8333333333333334\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m Epoch 1: train loss 7.182275294326246e-05, accuracy 0.7222222222222222\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m [Client 87] fit, config: {'current_round': 60, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m Epoch 1: train loss 7.460027700290084e-05, accuracy 0.8148148148148148\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m Epoch 1: train loss 7.984798139659688e-05, accuracy 0.7777777777777778\n",
      "Saving round 60 aggregated_parameters...\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38338)\u001b[0m [Client 15] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38338)\u001b[0m [Client 29] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38336)\u001b[0m [Client 13] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38336)\u001b[0m [Client 6] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38336)\u001b[0m [Client 74] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38334)\u001b[0m [Client 27] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38338)\u001b[0m [Client 10] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38337)\u001b[0m [Client 51] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38335)\u001b[0m [Client 47] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38337)\u001b[0m [Client 57] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38335)\u001b[0m [Client 32] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38335)\u001b[0m [Client 25] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38334)\u001b[0m [Client 46] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38338)\u001b[0m [Client 0] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38337)\u001b[0m [Client 37] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38334)\u001b[0m [Client 92] evaluate, config: {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 12:23:04,487 | server.py:170 | evaluate_round received 0 results and 30 failures\n",
      "DEBUG flower 2023-02-01 12:23:04,488 | server.py:203 | fit_round: strategy sampled 30 clients (out of 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38334)\u001b[0m [Client 88] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38338)\u001b[0m [Client 16] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38334)\u001b[0m [Client 21] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38336)\u001b[0m [Client 39] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38340)\u001b[0m [Client 96] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38337)\u001b[0m [Client 72] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38335)\u001b[0m [Client 65] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38334)\u001b[0m [Client 70] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38341)\u001b[0m [Client 50] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38338)\u001b[0m [Client 30] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38339)\u001b[0m [Client 3] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38337)\u001b[0m [Client 95] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38341)\u001b[0m [Client 54] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38337)\u001b[0m [Client 33] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m [Client 99] fit, config: {'current_round': 61, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m [Client 63] fit, config: {'current_round': 61, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m Epoch 1: train loss 7.18718147254549e-05, accuracy 0.7777777777777778\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m Epoch 1: train loss 8.237363363150507e-05, accuracy 0.7222222222222222\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m [Client 72] fit, config: {'current_round': 61, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m Epoch 1: train loss 6.223747914191335e-05, accuracy 0.8148148148148148\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m [Client 81] fit, config: {'current_round': 61, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m [Client 3] fit, config: {'current_round': 61, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m [Client 15] fit, config: {'current_round': 61, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m Epoch 1: train loss 7.478050974896178e-05, accuracy 0.7592592592592593\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m Epoch 1: train loss 7.794799603288993e-05, accuracy 0.7592592592592593\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m Epoch 1: train loss 8.536396489944309e-05, accuracy 0.7222222222222222\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m [Client 61] fit, config: {'current_round': 61, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m Epoch 1: train loss 9.765364666236565e-05, accuracy 0.6666666666666666\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m [Client 86] fit, config: {'current_round': 61, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m Epoch 1: train loss 7.178044324973598e-05, accuracy 0.7777777777777778\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m [Client 55] fit, config: {'current_round': 61, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m Epoch 1: train loss 6.302633846644312e-05, accuracy 0.7962962962962963\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m [Client 10] fit, config: {'current_round': 61, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m Epoch 1: train loss 6.379459955496714e-05, accuracy 0.8148148148148148\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m [Client 84] fit, config: {'current_round': 61, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m Epoch 1: train loss 7.27481092326343e-05, accuracy 0.7777777777777778\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m [Client 32] fit, config: {'current_round': 61, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m Epoch 1: train loss 7.898475450929254e-05, accuracy 0.7222222222222222\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m [Client 8] fit, config: {'current_round': 61, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m Epoch 1: train loss 7.907776307547465e-05, accuracy 0.7407407407407407\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m [Client 34] fit, config: {'current_round': 61, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m Epoch 1: train loss 7.483299123123288e-05, accuracy 0.7592592592592593\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m [Client 28] fit, config: {'current_round': 61, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m Epoch 1: train loss 6.930830568308011e-05, accuracy 0.8333333333333334\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m [Client 9] fit, config: {'current_round': 61, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m [Client 27] fit, config: {'current_round': 61, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m Epoch 1: train loss 8.03412840468809e-05, accuracy 0.7407407407407407\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m [Client 2] fit, config: {'current_round': 61, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m [Client 13] fit, config: {'current_round': 61, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m Epoch 1: train loss 6.500861491076648e-05, accuracy 0.8333333333333334\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m Epoch 1: train loss 7.224454020615667e-05, accuracy 0.7962962962962963\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m [Client 31] fit, config: {'current_round': 61, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m Epoch 1: train loss 6.159476470202208e-05, accuracy 0.8333333333333334\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m [Client 65] fit, config: {'current_round': 61, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m Epoch 1: train loss 5.670848986483179e-05, accuracy 0.8333333333333334\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m [Client 87] fit, config: {'current_round': 61, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m Epoch 1: train loss 7.637163798790425e-05, accuracy 0.7222222222222222\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m Epoch 1: train loss 6.662118539679796e-05, accuracy 0.7962962962962963\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m [Client 33] fit, config: {'current_round': 61, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m Epoch 1: train loss 6.594848673557863e-05, accuracy 0.7777777777777778\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m [Client 71] fit, config: {'current_round': 61, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m Epoch 1: train loss 6.890601071063429e-05, accuracy 0.7962962962962963\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m [Client 91] fit, config: {'current_round': 61, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m Epoch 1: train loss 4.2745901737362146e-05, accuracy 0.8888888888888888\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m [Client 89] fit, config: {'current_round': 61, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m Epoch 1: train loss 7.1796661359258e-05, accuracy 0.7962962962962963\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 12:23:07,868 | server.py:216 | fit_round received 30 results and 0 failures\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m [Client 40] fit, config: {'current_round': 61, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m [Client 98] fit, config: {'current_round': 61, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m Epoch 1: train loss 6.666157423751429e-05, accuracy 0.7777777777777778\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m [Client 30] fit, config: {'current_round': 61, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m Epoch 1: train loss 8.657032594783232e-05, accuracy 0.7407407407407407\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m [Client 58] fit, config: {'current_round': 61, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m Epoch 1: train loss 5.928267273702659e-05, accuracy 0.8333333333333334\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m Epoch 1: train loss 4.622506821760908e-05, accuracy 0.8703703703703703\n",
      "Saving round 61 aggregated_parameters...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 12:23:07,994 | server.py:157 | evaluate_round: strategy sampled 30 clients (out of 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38338)\u001b[0m [Client 78] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38338)\u001b[0m [Client 11] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38338)\u001b[0m [Client 73] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38338)\u001b[0m [Client 32] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38337)\u001b[0m [Client 52] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38335)\u001b[0m [Client 88] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38334)\u001b[0m [Client 80] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38339)\u001b[0m [Client 17] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38341)\u001b[0m [Client 41] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38336)\u001b[0m [Client 74] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38340)\u001b[0m [Client 4] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38337)\u001b[0m [Client 6] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38335)\u001b[0m [Client 67] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38334)\u001b[0m [Client 31] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38341)\u001b[0m [Client 53] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38341)\u001b[0m [Client 99] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38334)\u001b[0m [Client 97] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38336)\u001b[0m [Client 61] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38337)\u001b[0m [Client 72] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38334)\u001b[0m [Client 59] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38341)\u001b[0m [Client 96] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38338)\u001b[0m [Client 38] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38336)\u001b[0m [Client 56] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38339)\u001b[0m [Client 37] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38340)\u001b[0m [Client 40] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38335)\u001b[0m [Client 82] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38337)\u001b[0m [Client 15] evaluate, config: {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 12:23:11,328 | server.py:170 | evaluate_round received 0 results and 30 failures\n",
      "DEBUG flower 2023-02-01 12:23:11,330 | server.py:203 | fit_round: strategy sampled 30 clients (out of 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38338)\u001b[0m [Client 35] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38339)\u001b[0m [Client 2] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38337)\u001b[0m [Client 76] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m [Client 5] fit, config: {'current_round': 62, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m Epoch 1: train loss 5.389652869780548e-05, accuracy 0.7777777777777778\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m [Client 21] fit, config: {'current_round': 62, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m Epoch 1: train loss 5.4635853302897885e-05, accuracy 0.8518518518518519\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m [Client 25] fit, config: {'current_round': 62, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m Epoch 1: train loss 5.511920971912332e-05, accuracy 0.8518518518518519\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m [Client 56] fit, config: {'current_round': 62, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m Epoch 1: train loss 8.345218520844355e-05, accuracy 0.7037037037037037\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m [Client 50] fit, config: {'current_round': 62, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m Epoch 1: train loss 9.998908353736624e-05, accuracy 0.7222222222222222\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m [Client 24] fit, config: {'current_round': 62, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m [Client 46] fit, config: {'current_round': 62, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m Epoch 1: train loss 6.316808867268264e-05, accuracy 0.7777777777777778\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m [Client 63] fit, config: {'current_round': 62, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m [Client 75] fit, config: {'current_round': 62, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m Epoch 1: train loss 5.7201374147553e-05, accuracy 0.7962962962962963\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m Epoch 1: train loss 6.002091686241329e-05, accuracy 0.7962962962962963\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m Epoch 1: train loss 6.0664446209557354e-05, accuracy 0.8333333333333334\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m [Client 89] fit, config: {'current_round': 62, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m Epoch 1: train loss 8.855285705067217e-05, accuracy 0.7407407407407407\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m [Client 91] fit, config: {'current_round': 62, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m [Client 16] fit, config: {'current_round': 62, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m Epoch 1: train loss 7.002467464189976e-05, accuracy 0.7407407407407407\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m Epoch 1: train loss 3.110198667855002e-05, accuracy 0.9444444444444444\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m [Client 93] fit, config: {'current_round': 62, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m Epoch 1: train loss 5.371669976739213e-05, accuracy 0.8703703703703703\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m [Client 47] fit, config: {'current_round': 62, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m Epoch 1: train loss 7.523522072006017e-05, accuracy 0.8148148148148148\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m [Client 40] fit, config: {'current_round': 62, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m Epoch 1: train loss 3.878631832776591e-05, accuracy 0.8703703703703703\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m [Client 44] fit, config: {'current_round': 62, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m Epoch 1: train loss 4.873748912359588e-05, accuracy 0.8703703703703703\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m [Client 26] fit, config: {'current_round': 62, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m [Client 43] fit, config: {'current_round': 62, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m Epoch 1: train loss 6.10538772889413e-05, accuracy 0.8333333333333334\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m [Client 96] fit, config: {'current_round': 62, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m Epoch 1: train loss 8.375351899303496e-05, accuracy 0.7962962962962963\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m [Client 78] fit, config: {'current_round': 62, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m [Client 35] fit, config: {'current_round': 62, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m Epoch 1: train loss 5.6880206102505326e-05, accuracy 0.8703703703703703\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 12:23:14,982 | server.py:216 | fit_round received 30 results and 0 failures\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m Epoch 1: train loss 7.016876770649105e-05, accuracy 0.8888888888888888\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m [Client 69] fit, config: {'current_round': 62, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m [Client 49] fit, config: {'current_round': 62, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m Epoch 1: train loss 5.862433317815885e-05, accuracy 0.8148148148148148\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m [Client 32] fit, config: {'current_round': 62, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m Epoch 1: train loss 6.707244756398723e-05, accuracy 0.8148148148148148\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m [Client 95] fit, config: {'current_round': 62, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m Epoch 1: train loss 6.662159285042435e-05, accuracy 0.7777777777777778\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m [Client 68] fit, config: {'current_round': 62, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m Epoch 1: train loss 5.962001159787178e-05, accuracy 0.8518518518518519\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m [Client 65] fit, config: {'current_round': 62, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m Epoch 1: train loss 6.108985689934343e-05, accuracy 0.8518518518518519\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m [Client 88] fit, config: {'current_round': 62, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m Epoch 1: train loss 5.8565445215208456e-05, accuracy 0.7777777777777778\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m [Client 52] fit, config: {'current_round': 62, 'local_epochs': 3}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 12:23:15,102 | server.py:157 | evaluate_round: strategy sampled 30 clients (out of 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m Epoch 1: train loss 7.334021211136132e-05, accuracy 0.8148148148148148\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m [Client 85] fit, config: {'current_round': 62, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m Epoch 1: train loss 4.060592982568778e-05, accuracy 0.9074074074074074\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m Epoch 1: train loss 4.84555093862582e-05, accuracy 0.8333333333333334\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m Epoch 1: train loss 6.128315726527944e-05, accuracy 0.8518518518518519\n",
      "Saving round 62 aggregated_parameters...\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38335)\u001b[0m [Client 50] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38338)\u001b[0m [Client 13] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38339)\u001b[0m [Client 63] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38336)\u001b[0m [Client 89] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38335)\u001b[0m [Client 74] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38334)\u001b[0m [Client 31] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38341)\u001b[0m [Client 72] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38338)\u001b[0m [Client 78] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38335)\u001b[0m [Client 29] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38334)\u001b[0m [Client 49] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38335)\u001b[0m [Client 57] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38334)\u001b[0m [Client 40] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38334)\u001b[0m [Client 24] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38341)\u001b[0m [Client 15] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38338)\u001b[0m [Client 14] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38336)\u001b[0m [Client 85] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38335)\u001b[0m [Client 33] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38339)\u001b[0m [Client 22] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38340)\u001b[0m [Client 1] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38337)\u001b[0m [Client 46] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38334)\u001b[0m [Client 11] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38338)\u001b[0m [Client 75] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38334)\u001b[0m [Client 76] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38338)\u001b[0m [Client 55] evaluate, config: {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 12:23:18,353 | server.py:170 | evaluate_round received 0 results and 30 failures\n",
      "DEBUG flower 2023-02-01 12:23:18,355 | server.py:203 | fit_round: strategy sampled 30 clients (out of 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38334)\u001b[0m [Client 32] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38338)\u001b[0m [Client 7] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38336)\u001b[0m [Client 79] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38340)\u001b[0m [Client 77] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38337)\u001b[0m [Client 5] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38339)\u001b[0m [Client 39] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m [Client 92] fit, config: {'current_round': 63, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m Epoch 1: train loss 4.977900971425697e-05, accuracy 0.8888888888888888\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m [Client 90] fit, config: {'current_round': 63, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m Epoch 1: train loss 6.512470281450078e-05, accuracy 0.7592592592592593\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m [Client 77] fit, config: {'current_round': 63, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m Epoch 1: train loss 9.312312613474205e-05, accuracy 0.6666666666666666\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m [Client 22] fit, config: {'current_round': 63, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m Epoch 1: train loss 8.121084829326719e-05, accuracy 0.6851851851851852\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m [Client 14] fit, config: {'current_round': 63, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m Epoch 1: train loss 6.830930942669511e-05, accuracy 0.7777777777777778\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m [Client 6] fit, config: {'current_round': 63, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m [Client 53] fit, config: {'current_round': 63, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m Epoch 1: train loss 7.099957292666659e-05, accuracy 0.7037037037037037\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m Epoch 1: train loss 8.55972757562995e-05, accuracy 0.7222222222222222\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m [Client 81] fit, config: {'current_round': 63, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m Epoch 1: train loss 7.684480806346983e-05, accuracy 0.7407407407407407\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m [Client 45] fit, config: {'current_round': 63, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m [Client 0] fit, config: {'current_round': 63, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m Epoch 1: train loss 5.89552873861976e-05, accuracy 0.8333333333333334\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m Epoch 1: train loss 6.583117647096515e-05, accuracy 0.7962962962962963\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m [Client 16] fit, config: {'current_round': 63, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m Epoch 1: train loss 6.779003888368607e-05, accuracy 0.7407407407407407\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m [Client 76] fit, config: {'current_round': 63, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m [Client 63] fit, config: {'current_round': 63, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m Epoch 1: train loss 5.9779507864732295e-05, accuracy 0.8518518518518519\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m Epoch 1: train loss 6.772323104087263e-05, accuracy 0.8333333333333334\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m [Client 68] fit, config: {'current_round': 63, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m Epoch 1: train loss 7.483452645828947e-05, accuracy 0.7407407407407407\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m [Client 44] fit, config: {'current_round': 63, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m Epoch 1: train loss 7.29361709090881e-05, accuracy 0.7592592592592593\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m [Client 33] fit, config: {'current_round': 63, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m Epoch 1: train loss 6.530780956381932e-05, accuracy 0.7777777777777778\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m [Client 84] fit, config: {'current_round': 63, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m [Client 13] fit, config: {'current_round': 63, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m [Client 39] fit, config: {'current_round': 63, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m Epoch 1: train loss 0.0001019606352201663, accuracy 0.6666666666666666\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m Epoch 1: train loss 7.280796125996858e-05, accuracy 0.7962962962962963\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m [Client 29] fit, config: {'current_round': 63, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m [Client 27] fit, config: {'current_round': 63, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m [Client 93] fit, config: {'current_round': 63, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m [Client 34] fit, config: {'current_round': 63, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m Epoch 1: train loss 7.292052760021761e-05, accuracy 0.7592592592592593\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m [Client 87] fit, config: {'current_round': 63, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m Epoch 1: train loss 6.542374467244372e-05, accuracy 0.8333333333333334\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m [Client 57] fit, config: {'current_round': 63, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m Epoch 1: train loss 5.876057912246324e-05, accuracy 0.7777777777777778\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m Epoch 1: train loss 8.309103577630594e-05, accuracy 0.7407407407407407\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m Epoch 1: train loss 7.408939563902095e-05, accuracy 0.7592592592592593\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m Epoch 1: train loss 7.052726141409948e-05, accuracy 0.7592592592592593\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m Epoch 1: train loss 4.157081639277749e-05, accuracy 0.8888888888888888\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m [Client 97] fit, config: {'current_round': 63, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m Epoch 1: train loss 5.7396780903218314e-05, accuracy 0.7962962962962963\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 12:23:22,069 | server.py:216 | fit_round received 30 results and 0 failures\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m [Client 30] fit, config: {'current_round': 63, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m [Client 86] fit, config: {'current_round': 63, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m [Client 12] fit, config: {'current_round': 63, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m Epoch 1: train loss 8.868560689734295e-05, accuracy 0.6666666666666666\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m Epoch 1: train loss 6.799652328481898e-05, accuracy 0.7407407407407407\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m Epoch 1: train loss 7.124958938220516e-05, accuracy 0.7777777777777778\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m [Client 66] fit, config: {'current_round': 63, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m Epoch 1: train loss 5.659719681716524e-05, accuracy 0.8333333333333334\n",
      "Saving round 63 aggregated_parameters...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 12:23:22,186 | server.py:157 | evaluate_round: strategy sampled 30 clients (out of 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38335)\u001b[0m [Client 3] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38335)\u001b[0m [Client 4] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38335)\u001b[0m [Client 42] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38335)\u001b[0m [Client 18] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38334)\u001b[0m [Client 50] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38338)\u001b[0m [Client 23] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38337)\u001b[0m [Client 93] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38335)\u001b[0m [Client 35] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38334)\u001b[0m [Client 17] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38341)\u001b[0m [Client 54] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38337)\u001b[0m [Client 7] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38334)\u001b[0m [Client 88] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38341)\u001b[0m [Client 73] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38338)\u001b[0m [Client 87] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38334)\u001b[0m [Client 2] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38341)\u001b[0m [Client 70] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38338)\u001b[0m [Client 79] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38336)\u001b[0m [Client 29] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38335)\u001b[0m [Client 9] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38334)\u001b[0m [Client 13] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38341)\u001b[0m [Client 36] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38339)\u001b[0m [Client 46] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38337)\u001b[0m [Client 39] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38334)\u001b[0m [Client 56] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38341)\u001b[0m [Client 26] evaluate, config: {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 12:23:25,831 | server.py:170 | evaluate_round received 0 results and 30 failures\n",
      "DEBUG flower 2023-02-01 12:23:25,837 | server.py:203 | fit_round: strategy sampled 30 clients (out of 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38334)\u001b[0m [Client 1] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38337)\u001b[0m [Client 96] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38334)\u001b[0m [Client 20] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38341)\u001b[0m [Client 74] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38337)\u001b[0m [Client 48] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m [Client 43] fit, config: {'current_round': 64, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m Epoch 1: train loss 8.157062984537333e-05, accuracy 0.7962962962962963\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m [Client 41] fit, config: {'current_round': 64, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m Epoch 1: train loss 7.25521458662115e-05, accuracy 0.7592592592592593\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m [Client 71] fit, config: {'current_round': 64, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m Epoch 1: train loss 5.3204959840513766e-05, accuracy 0.8333333333333334\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m [Client 68] fit, config: {'current_round': 64, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m Epoch 1: train loss 7.67601522966288e-05, accuracy 0.7777777777777778\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m [Client 28] fit, config: {'current_round': 64, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m Epoch 1: train loss 6.554646824952215e-05, accuracy 0.8333333333333334\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m [Client 1] fit, config: {'current_round': 64, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m [Client 48] fit, config: {'current_round': 64, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m Epoch 1: train loss 4.745475962408818e-05, accuracy 0.8703703703703703\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m Epoch 1: train loss 3.503039988572709e-05, accuracy 0.8703703703703703\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m [Client 11] fit, config: {'current_round': 64, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m Epoch 1: train loss 6.044718611519784e-05, accuracy 0.8148148148148148\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m [Client 36] fit, config: {'current_round': 64, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m Epoch 1: train loss 5.574993338086642e-05, accuracy 0.8333333333333334\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m [Client 65] fit, config: {'current_round': 64, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m Epoch 1: train loss 6.056522033759393e-05, accuracy 0.8148148148148148\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m [Client 10] fit, config: {'current_round': 64, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m Epoch 1: train loss 7.146262942114845e-05, accuracy 0.7407407407407407\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m [Client 47] fit, config: {'current_round': 64, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m Epoch 1: train loss 7.577040378237143e-05, accuracy 0.7592592592592593\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m [Client 20] fit, config: {'current_round': 64, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m Epoch 1: train loss 5.3280091378837824e-05, accuracy 0.8148148148148148\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m [Client 74] fit, config: {'current_round': 64, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m [Client 26] fit, config: {'current_round': 64, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m Epoch 1: train loss 6.201116048032418e-05, accuracy 0.8148148148148148\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m [Client 96] fit, config: {'current_round': 64, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m Epoch 1: train loss 5.9704703744500875e-05, accuracy 0.8333333333333334\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m [Client 77] fit, config: {'current_round': 64, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m [Client 23] fit, config: {'current_round': 64, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m Epoch 1: train loss 7.084456592565402e-05, accuracy 0.8703703703703703\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m Epoch 1: train loss 6.229153223102912e-05, accuracy 0.8148148148148148\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m Epoch 1: train loss 6.304959242697805e-05, accuracy 0.7962962962962963\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m [Client 2] fit, config: {'current_round': 64, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m Epoch 1: train loss 4.6682325773872435e-05, accuracy 0.8703703703703703\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m [Client 67] fit, config: {'current_round': 64, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m Epoch 1: train loss 6.422348815249279e-05, accuracy 0.8148148148148148\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m [Client 98] fit, config: {'current_round': 64, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m Epoch 1: train loss 7.539306534454226e-05, accuracy 0.7777777777777778\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m [Client 86] fit, config: {'current_round': 64, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m Epoch 1: train loss 6.79562654113397e-05, accuracy 0.7777777777777778\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m [Client 9] fit, config: {'current_round': 64, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m [Client 84] fit, config: {'current_round': 64, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m Epoch 1: train loss 7.225529407151043e-05, accuracy 0.8148148148148148\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 12:23:29,233 | server.py:216 | fit_round received 30 results and 0 failures\n",
      "DEBUG flower 2023-02-01 12:23:29,311 | server.py:157 | evaluate_round: strategy sampled 30 clients (out of 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m [Client 24] fit, config: {'current_round': 64, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m Epoch 1: train loss 5.3935535106575117e-05, accuracy 0.7777777777777778\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m [Client 63] fit, config: {'current_round': 64, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m Epoch 1: train loss 6.23778541921638e-05, accuracy 0.8148148148148148\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m [Client 17] fit, config: {'current_round': 64, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m Epoch 1: train loss 9.67557352851145e-05, accuracy 0.6666666666666666\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m Epoch 1: train loss 7.724875467829406e-05, accuracy 0.7407407407407407\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m [Client 64] fit, config: {'current_round': 64, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m [Client 8] fit, config: {'current_round': 64, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m [Client 6] fit, config: {'current_round': 64, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m Epoch 1: train loss 6.036068225512281e-05, accuracy 0.8518518518518519\n",
      "Saving round 64 aggregated_parameters...\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m Epoch 1: train loss 8.229968807427213e-05, accuracy 0.7407407407407407\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m Epoch 1: train loss 7.413141429424286e-05, accuracy 0.7777777777777778\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38340)\u001b[0m [Client 42] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38337)\u001b[0m [Client 78] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38337)\u001b[0m [Client 27] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38340)\u001b[0m [Client 6] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38337)\u001b[0m [Client 21] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38337)\u001b[0m [Client 69] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38336)\u001b[0m [Client 25] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38340)\u001b[0m [Client 20] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38338)\u001b[0m [Client 33] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38338)\u001b[0m [Client 73] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38340)\u001b[0m [Client 84] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38337)\u001b[0m [Client 96] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38338)\u001b[0m [Client 24] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38336)\u001b[0m [Client 58] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38340)\u001b[0m [Client 34] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38338)\u001b[0m [Client 17] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38340)\u001b[0m [Client 72] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38336)\u001b[0m [Client 47] evaluate, config: {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 12:23:32,266 | server.py:170 | evaluate_round received 0 results and 30 failures\n",
      "DEBUG flower 2023-02-01 12:23:32,267 | server.py:203 | fit_round: strategy sampled 30 clients (out of 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38338)\u001b[0m [Client 53] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38336)\u001b[0m [Client 99] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38340)\u001b[0m [Client 9] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38337)\u001b[0m [Client 37] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38336)\u001b[0m [Client 68] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38337)\u001b[0m [Client 66] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38334)\u001b[0m [Client 30] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38341)\u001b[0m [Client 29] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38338)\u001b[0m [Client 50] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38339)\u001b[0m [Client 88] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38340)\u001b[0m [Client 80] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38335)\u001b[0m [Client 13] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m [Client 20] fit, config: {'current_round': 65, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m Epoch 1: train loss 6.68321517878212e-05, accuracy 0.7962962962962963\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m [Client 41] fit, config: {'current_round': 65, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m Epoch 1: train loss 8.918673120206222e-05, accuracy 0.6851851851851852\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m [Client 39] fit, config: {'current_round': 65, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m Epoch 1: train loss 9.736746869748458e-05, accuracy 0.7037037037037037\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m [Client 70] fit, config: {'current_round': 65, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m Epoch 1: train loss 6.199400377226993e-05, accuracy 0.7962962962962963\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m [Client 84] fit, config: {'current_round': 65, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m Epoch 1: train loss 7.04479098203592e-05, accuracy 0.7962962962962963\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m [Client 24] fit, config: {'current_round': 65, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m Epoch 1: train loss 6.784629658795893e-05, accuracy 0.7407407407407407\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m [Client 48] fit, config: {'current_round': 65, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m Epoch 1: train loss 6.13700904068537e-05, accuracy 0.7962962962962963\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m [Client 43] fit, config: {'current_round': 65, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m Epoch 1: train loss 7.526749686803669e-05, accuracy 0.7962962962962963\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m [Client 3] fit, config: {'current_round': 65, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m [Client 25] fit, config: {'current_round': 65, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m Epoch 1: train loss 7.75378430262208e-05, accuracy 0.7592592592592593\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m [Client 27] fit, config: {'current_round': 65, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m [Client 22] fit, config: {'current_round': 65, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m [Client 86] fit, config: {'current_round': 65, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m Epoch 1: train loss 6.491307431133464e-05, accuracy 0.7407407407407407\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m [Client 66] fit, config: {'current_round': 65, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m [Client 35] fit, config: {'current_round': 65, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m Epoch 1: train loss 7.749602082185447e-05, accuracy 0.7037037037037037\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m [Client 90] fit, config: {'current_round': 65, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m Epoch 1: train loss 6.317946099443361e-05, accuracy 0.7777777777777778\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m Epoch 1: train loss 6.625580135732889e-05, accuracy 0.7777777777777778\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m Epoch 1: train loss 5.4493713832926005e-05, accuracy 0.8518518518518519\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m Epoch 1: train loss 8.25153838377446e-05, accuracy 0.7592592592592593\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m [Client 72] fit, config: {'current_round': 65, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m Epoch 1: train loss 4.9930364184547216e-05, accuracy 0.7962962962962963\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m [Client 19] fit, config: {'current_round': 65, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m Epoch 1: train loss 5.0870203267550096e-05, accuracy 0.8333333333333334\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m [Client 16] fit, config: {'current_round': 65, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m Epoch 1: train loss 6.502080213977024e-05, accuracy 0.7592592592592593\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m [Client 54] fit, config: {'current_round': 65, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m Epoch 1: train loss 6.494958506664261e-05, accuracy 0.7962962962962963\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m Epoch 1: train loss 5.6085973483277485e-05, accuracy 0.8333333333333334\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m [Client 81] fit, config: {'current_round': 65, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m Epoch 1: train loss 7.179543899837881e-05, accuracy 0.7592592592592593\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m [Client 98] fit, config: {'current_round': 65, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m Epoch 1: train loss 6.810016930103302e-05, accuracy 0.7407407407407407\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m [Client 49] fit, config: {'current_round': 65, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m Epoch 1: train loss 8.25965398689732e-05, accuracy 0.7037037037037037\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m [Client 83] fit, config: {'current_round': 65, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m [Client 71] fit, config: {'current_round': 65, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m Epoch 1: train loss 6.280386151047423e-05, accuracy 0.8148148148148148\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 12:23:35,229 | server.py:216 | fit_round received 30 results and 0 failures\n",
      "DEBUG flower 2023-02-01 12:23:35,313 | server.py:157 | evaluate_round: strategy sampled 30 clients (out of 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m [Client 34] fit, config: {'current_round': 65, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m Epoch 1: train loss 6.925765046617016e-05, accuracy 0.7962962962962963\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m Epoch 1: train loss 7.024293154245242e-05, accuracy 0.7777777777777778\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m [Client 46] fit, config: {'current_round': 65, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m [Client 18] fit, config: {'current_round': 65, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m Epoch 1: train loss 6.813705113017932e-05, accuracy 0.7592592592592593\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m [Client 69] fit, config: {'current_round': 65, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m [Client 79] fit, config: {'current_round': 65, 'local_epochs': 3}\n",
      "Saving round 65 aggregated_parameters...\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m Epoch 1: train loss 6.649443821515888e-05, accuracy 0.7592592592592593\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m Epoch 1: train loss 5.7368095440324396e-05, accuracy 0.7962962962962963\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m Epoch 1: train loss 7.13913977961056e-05, accuracy 0.7777777777777778\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38337)\u001b[0m [Client 38] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38337)\u001b[0m [Client 12] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38335)\u001b[0m [Client 74] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38336)\u001b[0m [Client 79] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38339)\u001b[0m [Client 36] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38337)\u001b[0m [Client 24] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38335)\u001b[0m [Client 72] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38336)\u001b[0m [Client 64] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38336)\u001b[0m [Client 5] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38337)\u001b[0m [Client 46] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38336)\u001b[0m [Client 99] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38336)\u001b[0m [Client 88] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38337)\u001b[0m [Client 50] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38339)\u001b[0m [Client 35] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38335)\u001b[0m [Client 40] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38334)\u001b[0m [Client 6] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38341)\u001b[0m [Client 41] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38338)\u001b[0m [Client 23] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38340)\u001b[0m [Client 75] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38337)\u001b[0m [Client 48] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38335)\u001b[0m [Client 27] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38336)\u001b[0m [Client 76] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38335)\u001b[0m [Client 7] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38338)\u001b[0m [Client 10] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38336)\u001b[0m [Client 0] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38337)\u001b[0m [Client 39] evaluate, config: {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 12:23:38,276 | server.py:170 | evaluate_round received 0 results and 30 failures\n",
      "DEBUG flower 2023-02-01 12:23:38,277 | server.py:203 | fit_round: strategy sampled 30 clients (out of 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38334)\u001b[0m [Client 22] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38341)\u001b[0m [Client 43] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38340)\u001b[0m [Client 54] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38335)\u001b[0m [Client 29] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m [Client 1] fit, config: {'current_round': 66, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m [Client 93] fit, config: {'current_round': 66, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m Epoch 1: train loss 5.016854265704751e-05, accuracy 0.8703703703703703\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m Epoch 1: train loss 3.480117447907105e-05, accuracy 0.8518518518518519\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m [Client 56] fit, config: {'current_round': 66, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m Epoch 1: train loss 8.263062773039564e-05, accuracy 0.7222222222222222\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m [Client 17] fit, config: {'current_round': 66, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m Epoch 1: train loss 9.660115756560117e-05, accuracy 0.6666666666666666\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m [Client 78] fit, config: {'current_round': 66, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m Epoch 1: train loss 5.5717096984153613e-05, accuracy 0.7962962962962963\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m [Client 47] fit, config: {'current_round': 66, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m Epoch 1: train loss 7.636142254341394e-05, accuracy 0.7777777777777778\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m [Client 85] fit, config: {'current_round': 66, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m Epoch 1: train loss 4.456618626136333e-05, accuracy 0.8333333333333334\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m [Client 16] fit, config: {'current_round': 66, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m Epoch 1: train loss 7.159858068916947e-05, accuracy 0.7222222222222222\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m [Client 18] fit, config: {'current_round': 66, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m Epoch 1: train loss 6.902222958160564e-05, accuracy 0.7407407407407407\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m [Client 32] fit, config: {'current_round': 66, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m Epoch 1: train loss 6.534867861773819e-05, accuracy 0.8148148148148148\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m [Client 6] fit, config: {'current_round': 66, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m [Client 57] fit, config: {'current_round': 66, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m Epoch 1: train loss 4.579256346914917e-05, accuracy 0.8333333333333334\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m Epoch 1: train loss 6.021519948262721e-05, accuracy 0.8518518518518519\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m [Client 68] fit, config: {'current_round': 66, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m Epoch 1: train loss 7.82974311732687e-05, accuracy 0.7777777777777778\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m [Client 36] fit, config: {'current_round': 66, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m Epoch 1: train loss 5.5891621741466224e-05, accuracy 0.8518518518518519\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m [Client 22] fit, config: {'current_round': 66, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m Epoch 1: train loss 7.349500083364546e-05, accuracy 0.7407407407407407\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m [Client 38] fit, config: {'current_round': 66, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m Epoch 1: train loss 4.7209930926328525e-05, accuracy 0.8888888888888888\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m [Client 7] fit, config: {'current_round': 66, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m Epoch 1: train loss 6.156344170449302e-05, accuracy 0.7962962962962963\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m [Client 26] fit, config: {'current_round': 66, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m Epoch 1: train loss 6.0345704696374014e-05, accuracy 0.8148148148148148\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m [Client 25] fit, config: {'current_round': 66, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m Epoch 1: train loss 5.409385630628094e-05, accuracy 0.8518518518518519\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m [Client 41] fit, config: {'current_round': 66, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m [Client 45] fit, config: {'current_round': 66, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m Epoch 1: train loss 5.770327334175818e-05, accuracy 0.8518518518518519\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m Epoch 1: train loss 7.231422932818532e-05, accuracy 0.7962962962962963\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 12:23:40,837 | server.py:216 | fit_round received 30 results and 0 failures\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m [Client 58] fit, config: {'current_round': 66, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m Epoch 1: train loss 7.477737381123006e-05, accuracy 0.7962962962962963\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m [Client 74] fit, config: {'current_round': 66, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m [Client 71] fit, config: {'current_round': 66, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m Epoch 1: train loss 5.32237536390312e-05, accuracy 0.8333333333333334\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m [Client 54] fit, config: {'current_round': 66, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m [Client 72] fit, config: {'current_round': 66, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m [Client 48] fit, config: {'current_round': 66, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m [Client 42] fit, config: {'current_round': 66, 'local_epochs': 3}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 12:23:40,901 | server.py:157 | evaluate_round: strategy sampled 30 clients (out of 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m [Client 88] fit, config: {'current_round': 66, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m Epoch 1: train loss 4.8895242798607796e-05, accuracy 0.8333333333333334\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m Epoch 1: train loss 6.258673238335177e-05, accuracy 0.7962962962962963\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m Epoch 1: train loss 6.127161759650335e-05, accuracy 0.8333333333333334\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m Epoch 1: train loss 6.2621220422443e-05, accuracy 0.8518518518518519\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m Epoch 1: train loss 4.763933247886598e-05, accuracy 0.8333333333333334\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m [Client 30] fit, config: {'current_round': 66, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m Epoch 1: train loss 9.649732237448916e-05, accuracy 0.6666666666666666\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m Epoch 1: train loss 9.287858847528696e-05, accuracy 0.7407407407407407\n",
      "Saving round 66 aggregated_parameters...\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38334)\u001b[0m [Client 2] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38334)\u001b[0m [Client 67] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38336)\u001b[0m [Client 99] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38340)\u001b[0m [Client 19] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38337)\u001b[0m [Client 88] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38335)\u001b[0m [Client 32] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38335)\u001b[0m [Client 70] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38340)\u001b[0m [Client 48] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38336)\u001b[0m [Client 87] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38340)\u001b[0m [Client 65] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38335)\u001b[0m [Client 60] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38334)\u001b[0m [Client 80] evaluate, config: {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 12:23:43,510 | server.py:170 | evaluate_round received 0 results and 30 failures\n",
      "DEBUG flower 2023-02-01 12:23:43,511 | server.py:203 | fit_round: strategy sampled 30 clients (out of 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38336)\u001b[0m [Client 55] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38340)\u001b[0m [Client 59] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38336)\u001b[0m [Client 93] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38334)\u001b[0m [Client 84] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38340)\u001b[0m [Client 27] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38337)\u001b[0m [Client 50] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38338)\u001b[0m [Client 45] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38339)\u001b[0m [Client 1] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38335)\u001b[0m [Client 78] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38341)\u001b[0m [Client 15] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38336)\u001b[0m [Client 91] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38336)\u001b[0m [Client 89] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38334)\u001b[0m [Client 76] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38341)\u001b[0m [Client 98] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38338)\u001b[0m [Client 10] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38339)\u001b[0m [Client 42] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38340)\u001b[0m [Client 38] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38335)\u001b[0m [Client 28] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m [Client 32] fit, config: {'current_round': 67, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m Epoch 1: train loss 7.762829045532271e-05, accuracy 0.7592592592592593\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m [Client 67] fit, config: {'current_round': 67, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m Epoch 1: train loss 6.719095836160704e-05, accuracy 0.7777777777777778\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m [Client 89] fit, config: {'current_round': 67, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m Epoch 1: train loss 6.890377699164674e-05, accuracy 0.8148148148148148\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m [Client 23] fit, config: {'current_round': 67, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m [Client 77] fit, config: {'current_round': 67, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m Epoch 1: train loss 7.999166700756177e-05, accuracy 0.6666666666666666\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m [Client 60] fit, config: {'current_round': 67, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m [Client 90] fit, config: {'current_round': 67, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m Epoch 1: train loss 6.129402754595503e-05, accuracy 0.7777777777777778\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m Epoch 1: train loss 7.172924233600497e-05, accuracy 0.7037037037037037\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m Epoch 1: train loss 4.806358992937021e-05, accuracy 0.7962962962962963\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m [Client 81] fit, config: {'current_round': 67, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m [Client 4] fit, config: {'current_round': 67, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m Epoch 1: train loss 6.74839029670693e-05, accuracy 0.8148148148148148\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m [Client 11] fit, config: {'current_round': 67, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m Epoch 1: train loss 6.960600876482204e-05, accuracy 0.7407407407407407\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m [Client 69] fit, config: {'current_round': 67, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m Epoch 1: train loss 5.462925400934182e-05, accuracy 0.7962962962962963\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m [Client 94] fit, config: {'current_round': 67, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m [Client 63] fit, config: {'current_round': 67, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m [Client 3] fit, config: {'current_round': 67, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m Epoch 1: train loss 7.32085682102479e-05, accuracy 0.7592592592592593\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m Epoch 1: train loss 5.990444333292544e-05, accuracy 0.7777777777777778\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m Epoch 1: train loss 5.7431243476457894e-05, accuracy 0.8518518518518519\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m Epoch 1: train loss 4.8945905291475356e-05, accuracy 0.8148148148148148\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m [Client 24] fit, config: {'current_round': 67, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m [Client 93] fit, config: {'current_round': 67, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m [Client 86] fit, config: {'current_round': 67, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m [Client 17] fit, config: {'current_round': 67, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m [Client 8] fit, config: {'current_round': 67, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m Epoch 1: train loss 7.470716809621081e-05, accuracy 0.7592592592592593\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m Epoch 1: train loss 6.508224760182202e-05, accuracy 0.7407407407407407\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m Epoch 1: train loss 6.931137613719329e-05, accuracy 0.7592592592592593\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m Epoch 1: train loss 6.377413956215605e-05, accuracy 0.7777777777777778\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m Epoch 1: train loss 7.631011976627633e-05, accuracy 0.8148148148148148\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m [Client 70] fit, config: {'current_round': 67, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m Epoch 1: train loss 6.0430415032897145e-05, accuracy 0.7962962962962963\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m [Client 5] fit, config: {'current_round': 67, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m Epoch 1: train loss 5.053681888966821e-05, accuracy 0.8703703703703703\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m [Client 40] fit, config: {'current_round': 67, 'local_epochs': 3}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 12:23:46,032 | server.py:216 | fit_round received 30 results and 0 failures\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m [Client 38] fit, config: {'current_round': 67, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m Epoch 1: train loss 5.492326454259455e-05, accuracy 0.7962962962962963\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m [Client 59] fit, config: {'current_round': 67, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m [Client 95] fit, config: {'current_round': 67, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m Epoch 1: train loss 3.872975139529444e-05, accuracy 0.8888888888888888\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m Epoch 1: train loss 4.560130400932394e-05, accuracy 0.8333333333333334\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m [Client 16] fit, config: {'current_round': 67, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m [Client 83] fit, config: {'current_round': 67, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m Epoch 1: train loss 6.321759428828955e-05, accuracy 0.7962962962962963\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 12:23:46,093 | server.py:157 | evaluate_round: strategy sampled 30 clients (out of 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m [Client 50] fit, config: {'current_round': 67, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m Epoch 1: train loss 7.789336086716503e-05, accuracy 0.7962962962962963\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m Epoch 1: train loss 8.206117490772158e-05, accuracy 0.7592592592592593\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m [Client 13] fit, config: {'current_round': 67, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m Epoch 1: train loss 6.160532939247787e-05, accuracy 0.8148148148148148\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m [Client 36] fit, config: {'current_round': 67, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m Epoch 1: train loss 6.23084997641854e-05, accuracy 0.7962962962962963\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m Epoch 1: train loss 6.676583871012554e-05, accuracy 0.8148148148148148\n",
      "Saving round 67 aggregated_parameters...\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38334)\u001b[0m [Client 0] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38336)\u001b[0m [Client 58] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38334)\u001b[0m [Client 52] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38334)\u001b[0m [Client 98] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38334)\u001b[0m [Client 14] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38334)\u001b[0m [Client 26] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38338)\u001b[0m [Client 49] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38336)\u001b[0m [Client 53] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38341)\u001b[0m [Client 30] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38337)\u001b[0m [Client 51] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38335)\u001b[0m [Client 4] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38341)\u001b[0m [Client 48] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38338)\u001b[0m [Client 17] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38337)\u001b[0m [Client 2] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38335)\u001b[0m [Client 68] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38336)\u001b[0m [Client 18] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38336)\u001b[0m [Client 62] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38338)\u001b[0m [Client 55] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38336)\u001b[0m [Client 22] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38338)\u001b[0m [Client 89] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38336)\u001b[0m [Client 44] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38335)\u001b[0m [Client 88] evaluate, config: {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 12:23:48,691 | server.py:170 | evaluate_round received 0 results and 30 failures\n",
      "DEBUG flower 2023-02-01 12:23:48,692 | server.py:203 | fit_round: strategy sampled 30 clients (out of 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38336)\u001b[0m [Client 5] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38334)\u001b[0m [Client 70] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38341)\u001b[0m [Client 79] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38338)\u001b[0m [Client 77] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38339)\u001b[0m [Client 38] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38340)\u001b[0m [Client 73] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38337)\u001b[0m [Client 20] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38335)\u001b[0m [Client 54] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m [Client 67] fit, config: {'current_round': 68, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m Epoch 1: train loss 6.32625087746419e-05, accuracy 0.7962962962962963\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m [Client 54] fit, config: {'current_round': 68, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m [Client 63] fit, config: {'current_round': 68, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m Epoch 1: train loss 6.488516373792663e-05, accuracy 0.7592592592592593\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m [Client 78] fit, config: {'current_round': 68, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m [Client 8] fit, config: {'current_round': 68, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m Epoch 1: train loss 7.302187441382557e-05, accuracy 0.7592592592592593\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m Epoch 1: train loss 6.080275124986656e-05, accuracy 0.7962962962962963\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m Epoch 1: train loss 5.426325151347555e-05, accuracy 0.7962962962962963\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m [Client 46] fit, config: {'current_round': 68, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m Epoch 1: train loss 6.0140191635582596e-05, accuracy 0.7407407407407407\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m [Client 40] fit, config: {'current_round': 68, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m Epoch 1: train loss 3.782246494665742e-05, accuracy 0.8703703703703703\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m [Client 62] fit, config: {'current_round': 68, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m Epoch 1: train loss 7.309494685614482e-05, accuracy 0.7222222222222222\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m [Client 18] fit, config: {'current_round': 68, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m Epoch 1: train loss 7.024181832093745e-05, accuracy 0.7592592592592593\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m [Client 6] fit, config: {'current_round': 68, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m Epoch 1: train loss 6.286664574872702e-05, accuracy 0.8148148148148148\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m [Client 12] fit, config: {'current_round': 68, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m Epoch 1: train loss 4.597128281602636e-05, accuracy 0.8518518518518519\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m [Client 50] fit, config: {'current_round': 68, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m Epoch 1: train loss 9.848865738604218e-05, accuracy 0.7407407407407407\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m [Client 53] fit, config: {'current_round': 68, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m Epoch 1: train loss 7.421030750265345e-05, accuracy 0.7592592592592593\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m [Client 99] fit, config: {'current_round': 68, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m Epoch 1: train loss 5.911803964409046e-05, accuracy 0.8148148148148148\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m [Client 24] fit, config: {'current_round': 68, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m [Client 25] fit, config: {'current_round': 68, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m Epoch 1: train loss 5.263015555101447e-05, accuracy 0.8333333333333334\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m [Client 27] fit, config: {'current_round': 68, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m Epoch 1: train loss 7.682720752200112e-05, accuracy 0.8148148148148148\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m [Client 55] fit, config: {'current_round': 68, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m Epoch 1: train loss 6.341853440972045e-05, accuracy 0.7222222222222222\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m Epoch 1: train loss 4.873382567893714e-05, accuracy 0.8518518518518519\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m [Client 31] fit, config: {'current_round': 68, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m Epoch 1: train loss 4.868243559030816e-05, accuracy 0.8333333333333334\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m [Client 69] fit, config: {'current_round': 68, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m Epoch 1: train loss 6.0058147937525064e-05, accuracy 0.8148148148148148\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m [Client 71] fit, config: {'current_round': 68, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m Epoch 1: train loss 5.338912160368636e-05, accuracy 0.7777777777777778\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 12:23:51,270 | server.py:216 | fit_round received 30 results and 0 failures\n",
      "DEBUG flower 2023-02-01 12:23:51,330 | server.py:157 | evaluate_round: strategy sampled 30 clients (out of 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m [Client 85] fit, config: {'current_round': 68, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m Epoch 1: train loss 4.4418182369554415e-05, accuracy 0.8148148148148148\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m [Client 15] fit, config: {'current_round': 68, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m [Client 4] fit, config: {'current_round': 68, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m [Client 64] fit, config: {'current_round': 68, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m Epoch 1: train loss 7.879037002567202e-05, accuracy 0.7222222222222222\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m [Client 2] fit, config: {'current_round': 68, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m [Client 7] fit, config: {'current_round': 68, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m Epoch 1: train loss 5.95983219682239e-05, accuracy 0.7777777777777778\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m Epoch 1: train loss 4.7531560994684696e-05, accuracy 0.8518518518518519\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m [Client 80] fit, config: {'current_round': 68, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m Epoch 1: train loss 4.691435970016755e-05, accuracy 0.8333333333333334\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m Epoch 1: train loss 5.3072602895554155e-05, accuracy 0.7962962962962963\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m [Client 79] fit, config: {'current_round': 68, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m Epoch 1: train loss 5.602859164355323e-05, accuracy 0.7777777777777778\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m Epoch 1: train loss 4.7391600674018264e-05, accuracy 0.8518518518518519\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m [Client 16] fit, config: {'current_round': 68, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m Epoch 1: train loss 6.975818541832268e-05, accuracy 0.7222222222222222\n",
      "Saving round 68 aggregated_parameters...\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38339)\u001b[0m [Client 28] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38337)\u001b[0m [Client 85] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38338)\u001b[0m [Client 34] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38338)\u001b[0m [Client 59] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38338)\u001b[0m [Client 87] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38341)\u001b[0m [Client 5] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38336)\u001b[0m [Client 44] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38340)\u001b[0m [Client 18] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38334)\u001b[0m [Client 57] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38338)\u001b[0m [Client 82] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38339)\u001b[0m [Client 99] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38340)\u001b[0m [Client 31] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38337)\u001b[0m [Client 27] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38335)\u001b[0m [Client 76] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38335)\u001b[0m [Client 9] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38341)\u001b[0m [Client 56] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38336)\u001b[0m [Client 45] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38341)\u001b[0m [Client 94] evaluate, config: {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 12:23:53,992 | server.py:170 | evaluate_round received 0 results and 30 failures\n",
      "DEBUG flower 2023-02-01 12:23:53,993 | server.py:203 | fit_round: strategy sampled 30 clients (out of 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38341)\u001b[0m [Client 74] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38338)\u001b[0m [Client 63] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38336)\u001b[0m [Client 78] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38339)\u001b[0m [Client 51] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38335)\u001b[0m [Client 22] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38334)\u001b[0m [Client 19] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38341)\u001b[0m [Client 68] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38338)\u001b[0m [Client 52] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38339)\u001b[0m [Client 58] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38340)\u001b[0m [Client 13] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38337)\u001b[0m [Client 2] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38335)\u001b[0m [Client 90] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m [Client 42] fit, config: {'current_round': 69, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m Epoch 1: train loss 9.131888509728014e-05, accuracy 0.7222222222222222\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m [Client 30] fit, config: {'current_round': 69, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m [Client 89] fit, config: {'current_round': 69, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m Epoch 1: train loss 8.335107122547925e-05, accuracy 0.7222222222222222\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m Epoch 1: train loss 6.921296153450385e-05, accuracy 0.8148148148148148\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m [Client 57] fit, config: {'current_round': 69, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m Epoch 1: train loss 3.592805296648294e-05, accuracy 0.9259259259259259\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m [Client 96] fit, config: {'current_round': 69, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m Epoch 1: train loss 6.529875099658966e-05, accuracy 0.7962962962962963\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m [Client 27] fit, config: {'current_round': 69, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m [Client 14] fit, config: {'current_round': 69, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m Epoch 1: train loss 6.866455078125e-05, accuracy 0.7592592592592593\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m Epoch 1: train loss 7.950486178742722e-05, accuracy 0.7407407407407407\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m [Client 36] fit, config: {'current_round': 69, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m [Client 31] fit, config: {'current_round': 69, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m Epoch 1: train loss 5.645041892421432e-05, accuracy 0.8333333333333334\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m [Client 55] fit, config: {'current_round': 69, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m [Client 98] fit, config: {'current_round': 69, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m Epoch 1: train loss 6.951788964215666e-05, accuracy 0.7592592592592593\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m Epoch 1: train loss 6.17484183749184e-05, accuracy 0.7777777777777778\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m Epoch 1: train loss 6.183666118886322e-05, accuracy 0.7962962962962963\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m [Client 87] fit, config: {'current_round': 69, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m [Client 58] fit, config: {'current_round': 69, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m Epoch 1: train loss 6.965469219721854e-05, accuracy 0.7962962962962963\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m [Client 71] fit, config: {'current_round': 69, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m [Client 11] fit, config: {'current_round': 69, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m Epoch 1: train loss 6.970128015382215e-05, accuracy 0.7592592592592593\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m Epoch 1: train loss 6.154682341730222e-05, accuracy 0.7962962962962963\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m Epoch 1: train loss 5.73634279135149e-05, accuracy 0.8333333333333334\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m [Client 52] fit, config: {'current_round': 69, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m Epoch 1: train loss 6.913139804964885e-05, accuracy 0.7777777777777778\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m [Client 1] fit, config: {'current_round': 69, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m Epoch 1: train loss 2.6765254006022587e-05, accuracy 0.9629629629629629\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m [Client 10] fit, config: {'current_round': 69, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m Epoch 1: train loss 6.35241303825751e-05, accuracy 0.7962962962962963\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m [Client 28] fit, config: {'current_round': 69, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m [Client 17] fit, config: {'current_round': 69, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m Epoch 1: train loss 7.706147152930498e-05, accuracy 0.7962962962962963\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m [Client 90] fit, config: {'current_round': 69, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m Epoch 1: train loss 6.13329466432333e-05, accuracy 0.8148148148148148\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m Epoch 1: train loss 6.438083073589951e-05, accuracy 0.8518518518518519\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m [Client 9] fit, config: {'current_round': 69, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m [Client 5] fit, config: {'current_round': 69, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m [Client 80] fit, config: {'current_round': 69, 'local_epochs': 3}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 12:23:56,299 | server.py:216 | fit_round received 30 results and 0 failures\n",
      "DEBUG flower 2023-02-01 12:23:56,355 | server.py:157 | evaluate_round: strategy sampled 30 clients (out of 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m [Client 69] fit, config: {'current_round': 69, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m Epoch 1: train loss 5.486474037752487e-05, accuracy 0.8333333333333334\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m [Client 48] fit, config: {'current_round': 69, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m Epoch 1: train loss 5.8197969337925315e-05, accuracy 0.8148148148148148\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m [Client 22] fit, config: {'current_round': 69, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m Epoch 1: train loss 7.171024481067434e-05, accuracy 0.7222222222222222\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m Epoch 1: train loss 5.141081055626273e-05, accuracy 0.8518518518518519\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m Epoch 1: train loss 6.415828102035448e-05, accuracy 0.7777777777777778\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m Epoch 1: train loss 5.040837640990503e-05, accuracy 0.8518518518518519\n",
      "Saving round 69 aggregated_parameters...\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m [Client 8] fit, config: {'current_round': 69, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m Epoch 1: train loss 7.584325067000464e-05, accuracy 0.7222222222222222\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m [Client 50] fit, config: {'current_round': 69, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m Epoch 1: train loss 7.7138225606177e-05, accuracy 0.7777777777777778\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m [Client 45] fit, config: {'current_round': 69, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m Epoch 1: train loss 5.275914736557752e-05, accuracy 0.8703703703703703\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38334)\u001b[0m [Client 80] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38334)\u001b[0m [Client 65] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38334)\u001b[0m [Client 89] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38334)\u001b[0m [Client 25] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38340)\u001b[0m [Client 96] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38335)\u001b[0m [Client 49] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38335)\u001b[0m [Client 34] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38339)\u001b[0m [Client 60] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38338)\u001b[0m [Client 94] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38338)\u001b[0m [Client 48] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38339)\u001b[0m [Client 22] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38341)\u001b[0m [Client 35] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38335)\u001b[0m [Client 39] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38334)\u001b[0m [Client 97] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38338)\u001b[0m [Client 1] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38336)\u001b[0m [Client 79] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38339)\u001b[0m [Client 57] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38337)\u001b[0m [Client 26] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38335)\u001b[0m [Client 67] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38341)\u001b[0m [Client 59] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38340)\u001b[0m [Client 42] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38338)\u001b[0m [Client 13] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38336)\u001b[0m [Client 93] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38337)\u001b[0m [Client 85] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38335)\u001b[0m [Client 81] evaluate, config: {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 12:23:58,789 | server.py:170 | evaluate_round received 0 results and 30 failures\n",
      "DEBUG flower 2023-02-01 12:23:58,790 | server.py:203 | fit_round: strategy sampled 30 clients (out of 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38334)\u001b[0m [Client 15] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38341)\u001b[0m [Client 50] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38339)\u001b[0m [Client 29] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38340)\u001b[0m [Client 16] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38335)\u001b[0m [Client 92] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m [Client 54] fit, config: {'current_round': 70, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m [Client 84] fit, config: {'current_round': 70, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m Epoch 1: train loss 5.592391607933678e-05, accuracy 0.8888888888888888\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m Epoch 1: train loss 6.858805863885209e-05, accuracy 0.7407407407407407\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m [Client 15] fit, config: {'current_round': 70, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m Epoch 1: train loss 4.573758997139521e-05, accuracy 0.8518518518518519\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m [Client 22] fit, config: {'current_round': 70, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m Epoch 1: train loss 7.035542512312531e-05, accuracy 0.7407407407407407\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m [Client 5] fit, config: {'current_round': 70, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m [Client 77] fit, config: {'current_round': 70, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m Epoch 1: train loss 5.294889706419781e-05, accuracy 0.7962962962962963\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m [Client 88] fit, config: {'current_round': 70, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m Epoch 1: train loss 3.8022426451789215e-05, accuracy 0.8703703703703703\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m Epoch 1: train loss 6.0401995142456144e-05, accuracy 0.7962962962962963\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m [Client 23] fit, config: {'current_round': 70, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m Epoch 1: train loss 6.446498446166515e-05, accuracy 0.7962962962962963\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m [Client 98] fit, config: {'current_round': 70, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m [Client 6] fit, config: {'current_round': 70, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m [Client 80] fit, config: {'current_round': 70, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m Epoch 1: train loss 4.4941134547116235e-05, accuracy 0.8518518518518519\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m Epoch 1: train loss 6.170974666019902e-05, accuracy 0.8148148148148148\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m [Client 29] fit, config: {'current_round': 70, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m Epoch 1: train loss 4.621656989911571e-05, accuracy 0.8333333333333334\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m Epoch 1: train loss 5.799311838927679e-05, accuracy 0.8148148148148148\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m [Client 7] fit, config: {'current_round': 70, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m Epoch 1: train loss 5.976623288006522e-05, accuracy 0.7962962962962963\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m [Client 97] fit, config: {'current_round': 70, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m Epoch 1: train loss 5.178434730623849e-05, accuracy 0.7962962962962963\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m [Client 34] fit, config: {'current_round': 70, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m Epoch 1: train loss 8.054855425143614e-05, accuracy 0.7407407407407407\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m [Client 31] fit, config: {'current_round': 70, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m [Client 51] fit, config: {'current_round': 70, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m [Client 71] fit, config: {'current_round': 70, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m [Client 86] fit, config: {'current_round': 70, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m Epoch 1: train loss 4.643967258743942e-05, accuracy 0.8703703703703703\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m [Client 20] fit, config: {'current_round': 70, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m Epoch 1: train loss 4.9039786972571164e-05, accuracy 0.8148148148148148\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m [Client 72] fit, config: {'current_round': 70, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m Epoch 1: train loss 5.882573168491945e-05, accuracy 0.8333333333333334\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m Epoch 1: train loss 6.548548117280006e-05, accuracy 0.7777777777777778\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m [Client 69] fit, config: {'current_round': 70, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m Epoch 1: train loss 6.832725193817168e-05, accuracy 0.7777777777777778\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m Epoch 1: train loss 4.878217077930458e-05, accuracy 0.8148148148148148\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m [Client 38] fit, config: {'current_round': 70, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m [Client 21] fit, config: {'current_round': 70, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m Epoch 1: train loss 5.2992494602221996e-05, accuracy 0.8518518518518519\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m [Client 64] fit, config: {'current_round': 70, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m Epoch 1: train loss 4.447334140422754e-05, accuracy 0.9074074074074074\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m Epoch 1: train loss 5.0441671191947535e-05, accuracy 0.8333333333333334\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m Epoch 1: train loss 7.148200529627502e-05, accuracy 0.7592592592592593\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m [Client 10] fit, config: {'current_round': 70, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m Epoch 1: train loss 6.158993346616626e-05, accuracy 0.7962962962962963\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m [Client 44] fit, config: {'current_round': 70, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m Epoch 1: train loss 4.93434454256203e-05, accuracy 0.8703703703703703\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m [Client 99] fit, config: {'current_round': 70, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m Epoch 1: train loss 5.6478806072846055e-05, accuracy 0.7962962962962963\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m [Client 8] fit, config: {'current_round': 70, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m Epoch 1: train loss 6.715855852235109e-05, accuracy 0.7962962962962963\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m [Client 61] fit, config: {'current_round': 70, 'local_epochs': 3}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 12:24:01,359 | server.py:216 | fit_round received 30 results and 0 failures\n",
      "DEBUG flower 2023-02-01 12:24:01,426 | server.py:157 | evaluate_round: strategy sampled 30 clients (out of 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving round 70 aggregated_parameters...\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m Epoch 1: train loss 6.940923049114645e-05, accuracy 0.7777777777777778\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38334)\u001b[0m [Client 87] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38334)\u001b[0m [Client 78] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38341)\u001b[0m [Client 27] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38338)\u001b[0m [Client 94] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38340)\u001b[0m [Client 29] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38335)\u001b[0m [Client 96] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38334)\u001b[0m [Client 17] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38338)\u001b[0m [Client 68] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38336)\u001b[0m [Client 66] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38340)\u001b[0m [Client 48] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38337)\u001b[0m [Client 84] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38341)\u001b[0m [Client 59] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38339)\u001b[0m [Client 9] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38339)\u001b[0m [Client 74] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38341)\u001b[0m [Client 88] evaluate, config: {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 12:24:04,217 | server.py:170 | evaluate_round received 0 results and 30 failures\n",
      "DEBUG flower 2023-02-01 12:24:04,218 | server.py:203 | fit_round: strategy sampled 30 clients (out of 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38339)\u001b[0m [Client 55] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38334)\u001b[0m [Client 45] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38337)\u001b[0m [Client 67] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38334)\u001b[0m [Client 23] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38341)\u001b[0m [Client 39] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38338)\u001b[0m [Client 75] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38336)\u001b[0m [Client 93] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38339)\u001b[0m [Client 19] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38340)\u001b[0m [Client 25] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38338)\u001b[0m [Client 98] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38340)\u001b[0m [Client 0] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38341)\u001b[0m [Client 72] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38338)\u001b[0m [Client 58] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38340)\u001b[0m [Client 92] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38334)\u001b[0m [Client 34] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m [Client 64] fit, config: {'current_round': 71, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m Epoch 1: train loss 7.016157178441063e-05, accuracy 0.7592592592592593\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m [Client 21] fit, config: {'current_round': 71, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m Epoch 1: train loss 5.8111971156904474e-05, accuracy 0.8148148148148148\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m [Client 8] fit, config: {'current_round': 71, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m Epoch 1: train loss 7.33499982743524e-05, accuracy 0.7592592592592593\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m [Client 11] fit, config: {'current_round': 71, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m Epoch 1: train loss 6.407962791854516e-05, accuracy 0.7777777777777778\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m [Client 95] fit, config: {'current_round': 71, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m Epoch 1: train loss 3.729136733454652e-05, accuracy 0.9074074074074074\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m [Client 44] fit, config: {'current_round': 71, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m Epoch 1: train loss 5.6692821090109646e-05, accuracy 0.7777777777777778\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m [Client 69] fit, config: {'current_round': 71, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m Epoch 1: train loss 5.3254734666552395e-05, accuracy 0.8333333333333334\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m [Client 35] fit, config: {'current_round': 71, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m [Client 98] fit, config: {'current_round': 71, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m [Client 51] fit, config: {'current_round': 71, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m Epoch 1: train loss 6.947108340682462e-05, accuracy 0.7407407407407407\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m [Client 15] fit, config: {'current_round': 71, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m Epoch 1: train loss 4.2918189137708396e-05, accuracy 0.8703703703703703\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m [Client 58] fit, config: {'current_round': 71, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m Epoch 1: train loss 6.771313201170415e-05, accuracy 0.7962962962962963\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m [Client 89] fit, config: {'current_round': 71, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m [Client 56] fit, config: {'current_round': 71, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m Epoch 1: train loss 7.643237768206745e-05, accuracy 0.7962962962962963\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m Epoch 1: train loss 7.840540638426319e-05, accuracy 0.7037037037037037\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m [Client 25] fit, config: {'current_round': 71, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m [Client 61] fit, config: {'current_round': 71, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m Epoch 1: train loss 7.790808740537614e-05, accuracy 0.7407407407407407\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m Epoch 1: train loss 7.067494880175218e-05, accuracy 0.8148148148148148\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m [Client 91] fit, config: {'current_round': 71, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m Epoch 1: train loss 3.776238736463711e-05, accuracy 0.9259259259259259\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m [Client 82] fit, config: {'current_round': 71, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m Epoch 1: train loss 7.860508048906922e-05, accuracy 0.6481481481481481\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m Epoch 1: train loss 7.128882134566084e-05, accuracy 0.8148148148148148\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m Epoch 1: train loss 5.849104491062462e-05, accuracy 0.7962962962962963\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m [Client 74] fit, config: {'current_round': 71, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m Epoch 1: train loss 6.696292257402092e-05, accuracy 0.7222222222222222\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m [Client 32] fit, config: {'current_round': 71, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m [Client 10] fit, config: {'current_round': 71, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m Epoch 1: train loss 6.241439405130222e-05, accuracy 0.8148148148148148\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 12:24:07,088 | server.py:216 | fit_round received 30 results and 0 failures\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m Epoch 1: train loss 8.116231765598059e-05, accuracy 0.7592592592592593\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m [Client 26] fit, config: {'current_round': 71, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m [Client 42] fit, config: {'current_round': 71, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m [Client 6] fit, config: {'current_round': 71, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m [Client 7] fit, config: {'current_round': 71, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m Epoch 1: train loss 7.120140071492642e-05, accuracy 0.7777777777777778\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m Epoch 1: train loss 6.785406731069088e-05, accuracy 0.7777777777777778\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m [Client 34] fit, config: {'current_round': 71, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m Epoch 1: train loss 6.669359572697431e-05, accuracy 0.8148148148148148\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m Epoch 1: train loss 8.678829181008041e-05, accuracy 0.7037037037037037\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m [Client 3] fit, config: {'current_round': 71, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m Epoch 1: train loss 6.627368566114455e-05, accuracy 0.8333333333333334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 12:24:07,145 | server.py:157 | evaluate_round: strategy sampled 30 clients (out of 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving round 71 aggregated_parameters...\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m [Client 27] fit, config: {'current_round': 71, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m Epoch 1: train loss 7.987525168573484e-05, accuracy 0.7592592592592593\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m [Client 72] fit, config: {'current_round': 71, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m Epoch 1: train loss 4.885511225438677e-05, accuracy 0.9074074074074074\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m Epoch 1: train loss 7.139362423913553e-05, accuracy 0.7592592592592593\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m [Client 52] fit, config: {'current_round': 71, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m Epoch 1: train loss 6.3133287767414e-05, accuracy 0.7962962962962963\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38334)\u001b[0m [Client 25] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38336)\u001b[0m [Client 98] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38339)\u001b[0m [Client 78] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38337)\u001b[0m [Client 62] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38335)\u001b[0m [Client 95] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38336)\u001b[0m [Client 92] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38339)\u001b[0m [Client 99] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38336)\u001b[0m [Client 79] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38337)\u001b[0m [Client 96] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38334)\u001b[0m [Client 75] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38338)\u001b[0m [Client 50] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38336)\u001b[0m [Client 64] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38339)\u001b[0m [Client 56] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38340)\u001b[0m [Client 29] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38341)\u001b[0m [Client 15] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38340)\u001b[0m [Client 71] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38337)\u001b[0m [Client 31] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38335)\u001b[0m [Client 80] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38334)\u001b[0m [Client 47] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38336)\u001b[0m [Client 8] evaluate, config: {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 12:24:09,718 | server.py:170 | evaluate_round received 0 results and 30 failures\n",
      "DEBUG flower 2023-02-01 12:24:09,719 | server.py:203 | fit_round: strategy sampled 30 clients (out of 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38334)\u001b[0m [Client 23] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38334)\u001b[0m [Client 40] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38338)\u001b[0m [Client 65] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38336)\u001b[0m [Client 37] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38339)\u001b[0m [Client 72] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38337)\u001b[0m [Client 26] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38335)\u001b[0m [Client 84] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38341)\u001b[0m [Client 81] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38336)\u001b[0m [Client 20] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38340)\u001b[0m [Client 21] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m [Client 36] fit, config: {'current_round': 72, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m Epoch 1: train loss 5.3181658586254343e-05, accuracy 0.8148148148148148\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m [Client 50] fit, config: {'current_round': 72, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m [Client 47] fit, config: {'current_round': 72, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m [Client 63] fit, config: {'current_round': 72, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m Epoch 1: train loss 6.173505244078115e-05, accuracy 0.7407407407407407\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m Epoch 1: train loss 9.390618652105331e-05, accuracy 0.7777777777777778\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m Epoch 1: train loss 6.995938019827008e-05, accuracy 0.8333333333333334\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m [Client 96] fit, config: {'current_round': 72, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m Epoch 1: train loss 6.713679613312706e-05, accuracy 0.8333333333333334\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m [Client 53] fit, config: {'current_round': 72, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m [Client 69] fit, config: {'current_round': 72, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m [Client 37] fit, config: {'current_round': 72, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m Epoch 1: train loss 7.133003236958757e-05, accuracy 0.7777777777777778\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m [Client 13] fit, config: {'current_round': 72, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m Epoch 1: train loss 5.5909644288476557e-05, accuracy 0.8333333333333334\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m [Client 93] fit, config: {'current_round': 72, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m Epoch 1: train loss 5.013554618926719e-05, accuracy 0.8518518518518519\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m Epoch 1: train loss 5.850926027051173e-05, accuracy 0.8518518518518519\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m Epoch 1: train loss 5.581289951805957e-05, accuracy 0.8333333333333334\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m [Client 79] fit, config: {'current_round': 72, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m Epoch 1: train loss 4.8057314415927976e-05, accuracy 0.8333333333333334\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m [Client 32] fit, config: {'current_round': 72, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m Epoch 1: train loss 6.042513268766925e-05, accuracy 0.8888888888888888\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m [Client 94] fit, config: {'current_round': 72, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m Epoch 1: train loss 5.726904419134371e-05, accuracy 0.8333333333333334\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m [Client 84] fit, config: {'current_round': 72, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m Epoch 1: train loss 7.345288031501696e-05, accuracy 0.7407407407407407\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m [Client 60] fit, config: {'current_round': 72, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m [Client 99] fit, config: {'current_round': 72, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m Epoch 1: train loss 5.8344976423541084e-05, accuracy 0.7777777777777778\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m Epoch 1: train loss 5.5939806770766154e-05, accuracy 0.7777777777777778\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m [Client 61] fit, config: {'current_round': 72, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m Epoch 1: train loss 7.40015457267873e-05, accuracy 0.7407407407407407\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m [Client 56] fit, config: {'current_round': 72, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m [Client 33] fit, config: {'current_round': 72, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m Epoch 1: train loss 7.645021105417982e-05, accuracy 0.7222222222222222\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m [Client 81] fit, config: {'current_round': 72, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m Epoch 1: train loss 6.450991349993274e-05, accuracy 0.8148148148148148\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m [Client 75] fit, config: {'current_round': 72, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m Epoch 1: train loss 7.824921340215951e-05, accuracy 0.7407407407407407\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m [Client 54] fit, config: {'current_round': 72, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m Epoch 1: train loss 5.6927066907519475e-05, accuracy 0.7962962962962963\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 12:24:12,254 | server.py:216 | fit_round received 30 results and 0 failures\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m [Client 74] fit, config: {'current_round': 72, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m Epoch 1: train loss 5.681292896042578e-05, accuracy 0.8518518518518519\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m [Client 44] fit, config: {'current_round': 72, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m Epoch 1: train loss 5.237081495579332e-05, accuracy 0.8703703703703703\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m Epoch 1: train loss 5.687751036020927e-05, accuracy 0.8148148148148148\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m [Client 49] fit, config: {'current_round': 72, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m [Client 0] fit, config: {'current_round': 72, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m Epoch 1: train loss 6.401191058102995e-05, accuracy 0.8333333333333334\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m [Client 15] fit, config: {'current_round': 72, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m [Client 4] fit, config: {'current_round': 72, 'local_epochs': 3}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 12:24:12,325 | server.py:157 | evaluate_round: strategy sampled 30 clients (out of 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m Epoch 1: train loss 5.672530096489936e-05, accuracy 0.7962962962962963\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m [Client 30] fit, config: {'current_round': 72, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m Epoch 1: train loss 9.255125769414008e-05, accuracy 0.6851851851851852\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m [Client 64] fit, config: {'current_round': 72, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m Epoch 1: train loss 7.324133912334219e-05, accuracy 0.7592592592592593\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m Epoch 1: train loss 4.382350743981078e-05, accuracy 0.8703703703703703\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m Epoch 1: train loss 5.0292699597775936e-05, accuracy 0.8333333333333334\n",
      "Saving round 72 aggregated_parameters...\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38341)\u001b[0m [Client 74] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38336)\u001b[0m [Client 93] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38339)\u001b[0m [Client 3] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38340)\u001b[0m [Client 25] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38337)\u001b[0m [Client 91] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38335)\u001b[0m [Client 26] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38339)\u001b[0m [Client 0] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38340)\u001b[0m [Client 50] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38339)\u001b[0m [Client 67] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38340)\u001b[0m [Client 43] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38337)\u001b[0m [Client 61] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38340)\u001b[0m [Client 69] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38339)\u001b[0m [Client 65] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38340)\u001b[0m [Client 85] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38337)\u001b[0m [Client 38] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38339)\u001b[0m [Client 88] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38337)\u001b[0m [Client 48] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38339)\u001b[0m [Client 77] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38339)\u001b[0m [Client 73] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38340)\u001b[0m [Client 29] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38337)\u001b[0m [Client 64] evaluate, config: {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 12:24:14,750 | server.py:170 | evaluate_round received 0 results and 30 failures\n",
      "DEBUG flower 2023-02-01 12:24:14,751 | server.py:203 | fit_round: strategy sampled 30 clients (out of 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38339)\u001b[0m [Client 83] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38335)\u001b[0m [Client 40] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38341)\u001b[0m [Client 20] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38338)\u001b[0m [Client 80] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38340)\u001b[0m [Client 60] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38337)\u001b[0m [Client 97] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38335)\u001b[0m [Client 58] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38334)\u001b[0m [Client 96] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38336)\u001b[0m [Client 33] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m [Client 21] fit, config: {'current_round': 73, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m Epoch 1: train loss 6.156507151899859e-05, accuracy 0.8148148148148148\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m [Client 7] fit, config: {'current_round': 73, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m Epoch 1: train loss 7.609066960867494e-05, accuracy 0.7777777777777778\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m [Client 12] fit, config: {'current_round': 73, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m Epoch 1: train loss 6.656874757027254e-05, accuracy 0.7592592592592593\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m [Client 66] fit, config: {'current_round': 73, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m Epoch 1: train loss 5.021283504902385e-05, accuracy 0.8333333333333334\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m [Client 90] fit, config: {'current_round': 73, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m Epoch 1: train loss 5.957370376563631e-05, accuracy 0.7777777777777778\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m [Client 60] fit, config: {'current_round': 73, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m Epoch 1: train loss 4.713956150226295e-05, accuracy 0.7962962962962963\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m [Client 8] fit, config: {'current_round': 73, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m Epoch 1: train loss 7.31965119484812e-05, accuracy 0.7592592592592593\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m [Client 77] fit, config: {'current_round': 73, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m Epoch 1: train loss 7.4367766501382e-05, accuracy 0.7222222222222222\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m [Client 53] fit, config: {'current_round': 73, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m Epoch 1: train loss 6.177491013659164e-05, accuracy 0.7962962962962963\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m [Client 59] fit, config: {'current_round': 73, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m Epoch 1: train loss 7.862922211643308e-05, accuracy 0.7962962962962963\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m [Client 15] fit, config: {'current_round': 73, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m Epoch 1: train loss 8.318138861795887e-05, accuracy 0.7222222222222222\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m [Client 6] fit, config: {'current_round': 73, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m Epoch 1: train loss 7.004904182394966e-05, accuracy 0.7962962962962963\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m [Client 4] fit, config: {'current_round': 73, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m Epoch 1: train loss 5.0320708396611735e-05, accuracy 0.8333333333333334\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m [Client 32] fit, config: {'current_round': 73, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m Epoch 1: train loss 8.043205889407545e-05, accuracy 0.7222222222222222\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m [Client 54] fit, config: {'current_round': 73, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m Epoch 1: train loss 6.176882743602619e-05, accuracy 0.8148148148148148\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m [Client 14] fit, config: {'current_round': 73, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m Epoch 1: train loss 6.741673132637516e-05, accuracy 0.7407407407407407\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m [Client 76] fit, config: {'current_round': 73, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m Epoch 1: train loss 5.6242322898469865e-05, accuracy 0.8148148148148148\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m [Client 63] fit, config: {'current_round': 73, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m [Client 5] fit, config: {'current_round': 73, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m [Client 27] fit, config: {'current_round': 73, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m Epoch 1: train loss 5.3057454351801425e-05, accuracy 0.8703703703703703\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m Epoch 1: train loss 4.577499203151092e-05, accuracy 0.8703703703703703\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m Epoch 1: train loss 7.855160947656259e-05, accuracy 0.7222222222222222\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m [Client 68] fit, config: {'current_round': 73, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m [Client 70] fit, config: {'current_round': 73, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m Epoch 1: train loss 6.062887769076042e-05, accuracy 0.7962962962962963\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 12:24:17,247 | server.py:216 | fit_round received 30 results and 0 failures\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m [Client 28] fit, config: {'current_round': 73, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m [Client 65] fit, config: {'current_round': 73, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m Epoch 1: train loss 4.925889879814349e-05, accuracy 0.8888888888888888\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m [Client 72] fit, config: {'current_round': 73, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m [Client 67] fit, config: {'current_round': 73, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m [Client 85] fit, config: {'current_round': 73, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m Epoch 1: train loss 3.6884332075715065e-05, accuracy 0.8888888888888888\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m [Client 45] fit, config: {'current_round': 73, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m Epoch 1: train loss 5.15823885507416e-05, accuracy 0.8703703703703703\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m Epoch 1: train loss 6.227911944733933e-05, accuracy 0.8148148148148148\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m Epoch 1: train loss 6.194956949912012e-05, accuracy 0.8518518518518519\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m Epoch 1: train loss 5.193935794522986e-05, accuracy 0.9074074074074074\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m Epoch 1: train loss 6.859131826786324e-05, accuracy 0.7777777777777778\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m [Client 23] fit, config: {'current_round': 73, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m Epoch 1: train loss 6.961105827940628e-05, accuracy 0.7037037037037037\n",
      "Saving round 73 aggregated_parameters...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 12:24:17,306 | server.py:157 | evaluate_round: strategy sampled 30 clients (out of 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m [Client 93] fit, config: {'current_round': 73, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m Epoch 1: train loss 7.071772415656596e-05, accuracy 0.7777777777777778\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38338)\u001b[0m [Client 42] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38337)\u001b[0m [Client 43] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38335)\u001b[0m [Client 41] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38335)\u001b[0m [Client 47] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38337)\u001b[0m [Client 2] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38337)\u001b[0m [Client 68] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38337)\u001b[0m [Client 59] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38335)\u001b[0m [Client 8] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38337)\u001b[0m [Client 18] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38335)\u001b[0m [Client 99] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38338)\u001b[0m [Client 51] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38336)\u001b[0m [Client 79] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38340)\u001b[0m [Client 77] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38335)\u001b[0m [Client 17] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38334)\u001b[0m [Client 56] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38338)\u001b[0m [Client 50] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38336)\u001b[0m [Client 32] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38337)\u001b[0m [Client 6] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38334)\u001b[0m [Client 35] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38334)\u001b[0m [Client 83] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38338)\u001b[0m [Client 55] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38334)\u001b[0m [Client 90] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38340)\u001b[0m [Client 10] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38337)\u001b[0m [Client 29] evaluate, config: {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 12:24:19,667 | server.py:170 | evaluate_round received 0 results and 30 failures\n",
      "DEBUG flower 2023-02-01 12:24:19,669 | server.py:203 | fit_round: strategy sampled 30 clients (out of 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38341)\u001b[0m [Client 48] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38338)\u001b[0m [Client 53] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38336)\u001b[0m [Client 74] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38339)\u001b[0m [Client 67] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38340)\u001b[0m [Client 52] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38335)\u001b[0m [Client 86] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m [Client 79] fit, config: {'current_round': 74, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m Epoch 1: train loss 4.927282498101704e-05, accuracy 0.8518518518518519\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m [Client 76] fit, config: {'current_round': 74, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m Epoch 1: train loss 5.383450479712337e-05, accuracy 0.8333333333333334\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m [Client 92] fit, config: {'current_round': 74, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m Epoch 1: train loss 4.464633093448356e-05, accuracy 0.8703703703703703\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m [Client 16] fit, config: {'current_round': 74, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m Epoch 1: train loss 6.721314275637269e-05, accuracy 0.7407407407407407\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m [Client 5] fit, config: {'current_round': 74, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m Epoch 1: train loss 5.766116373706609e-05, accuracy 0.7592592592592593\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m [Client 91] fit, config: {'current_round': 74, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m Epoch 1: train loss 2.5933397409971803e-05, accuracy 0.9444444444444444\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m [Client 85] fit, config: {'current_round': 74, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m Epoch 1: train loss 3.85754719900433e-05, accuracy 0.8333333333333334\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m [Client 42] fit, config: {'current_round': 74, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m [Client 45] fit, config: {'current_round': 74, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m Epoch 1: train loss 5.41954577784054e-05, accuracy 0.8703703703703703\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m Epoch 1: train loss 8.336784958373755e-05, accuracy 0.6851851851851852\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m [Client 35] fit, config: {'current_round': 74, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m Epoch 1: train loss 7.14921043254435e-05, accuracy 0.7592592592592593\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m [Client 52] fit, config: {'current_round': 74, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m Epoch 1: train loss 6.15138269495219e-05, accuracy 0.7962962962962963\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m [Client 65] fit, config: {'current_round': 74, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m Epoch 1: train loss 5.424992923508398e-05, accuracy 0.8518518518518519\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m [Client 34] fit, config: {'current_round': 74, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m Epoch 1: train loss 8.306278323289007e-05, accuracy 0.7037037037037037\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m [Client 88] fit, config: {'current_round': 74, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m Epoch 1: train loss 4.2613621189957485e-05, accuracy 0.8333333333333334\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m [Client 86] fit, config: {'current_round': 74, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m Epoch 1: train loss 6.328823656076565e-05, accuracy 0.8518518518518519\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 12:24:22,273 | server.py:216 | fit_round received 30 results and 0 failures\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m [Client 6] fit, config: {'current_round': 74, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m [Client 78] fit, config: {'current_round': 74, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m Epoch 1: train loss 4.888733383268118e-05, accuracy 0.7962962962962963\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m [Client 84] fit, config: {'current_round': 74, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m Epoch 1: train loss 7.150589226512238e-05, accuracy 0.7407407407407407\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m Epoch 1: train loss 5.747628165408969e-05, accuracy 0.8518518518518519\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m [Client 75] fit, config: {'current_round': 74, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m Epoch 1: train loss 5.603941099252552e-05, accuracy 0.8333333333333334\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m [Client 98] fit, config: {'current_round': 74, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m Epoch 1: train loss 6.60865698591806e-05, accuracy 0.7592592592592593\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m [Client 25] fit, config: {'current_round': 74, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m Epoch 1: train loss 4.9801157729234546e-05, accuracy 0.8518518518518519\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m [Client 49] fit, config: {'current_round': 74, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m Epoch 1: train loss 5.5227690609171987e-05, accuracy 0.7962962962962963\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m [Client 73] fit, config: {'current_round': 74, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m Epoch 1: train loss 7.052478031255305e-05, accuracy 0.7222222222222222\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m [Client 38] fit, config: {'current_round': 74, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m [Client 39] fit, config: {'current_round': 74, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m Epoch 1: train loss 6.974526331759989e-05, accuracy 0.8333333333333334\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m [Client 44] fit, config: {'current_round': 74, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m [Client 83] fit, config: {'current_round': 74, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m Epoch 1: train loss 5.968463301542215e-05, accuracy 0.7962962962962963\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m Epoch 1: train loss 4.5267981477081776e-05, accuracy 0.8703703703703703\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m [Client 2] fit, config: {'current_round': 74, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m Epoch 1: train loss 4.595058271661401e-05, accuracy 0.8518518518518519\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m [Client 21] fit, config: {'current_round': 74, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m [Client 20] fit, config: {'current_round': 74, 'local_epochs': 3}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 12:24:22,355 | server.py:157 | evaluate_round: strategy sampled 30 clients (out of 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving round 74 aggregated_parameters...\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m Epoch 1: train loss 5.183458415558562e-05, accuracy 0.8703703703703703\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m Epoch 1: train loss 4.871820055996068e-05, accuracy 0.8148148148148148\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m Epoch 1: train loss 5.033917841501534e-05, accuracy 0.8148148148148148\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38338)\u001b[0m [Client 47] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38337)\u001b[0m [Client 90] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38338)\u001b[0m [Client 39] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38337)\u001b[0m [Client 20] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38338)\u001b[0m [Client 76] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38337)\u001b[0m [Client 12] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38335)\u001b[0m [Client 17] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38337)\u001b[0m [Client 79] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38335)\u001b[0m [Client 48] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38337)\u001b[0m [Client 87] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38335)\u001b[0m [Client 49] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38337)\u001b[0m [Client 61] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38335)\u001b[0m [Client 72] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38338)\u001b[0m [Client 23] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38337)\u001b[0m [Client 38] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38337)\u001b[0m [Client 1] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38337)\u001b[0m [Client 7] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38341)\u001b[0m [Client 71] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38338)\u001b[0m [Client 35] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38338)\u001b[0m [Client 30] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38336)\u001b[0m [Client 19] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38340)\u001b[0m [Client 99] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38337)\u001b[0m [Client 88] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38335)\u001b[0m [Client 54] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38339)\u001b[0m [Client 92] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38341)\u001b[0m [Client 97] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38339)\u001b[0m [Client 33] evaluate, config: {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 12:24:24,889 | server.py:170 | evaluate_round received 0 results and 30 failures\n",
      "DEBUG flower 2023-02-01 12:24:24,891 | server.py:203 | fit_round: strategy sampled 30 clients (out of 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38340)\u001b[0m [Client 68] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38337)\u001b[0m [Client 36] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38335)\u001b[0m [Client 32] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m [Client 87] fit, config: {'current_round': 75, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m Epoch 1: train loss 5.8250432630302384e-05, accuracy 0.8148148148148148\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m [Client 93] fit, config: {'current_round': 75, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m Epoch 1: train loss 6.656785262748599e-05, accuracy 0.7962962962962963\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m [Client 53] fit, config: {'current_round': 75, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m Epoch 1: train loss 6.0458922234829515e-05, accuracy 0.7962962962962963\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m [Client 48] fit, config: {'current_round': 75, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m [Client 39] fit, config: {'current_round': 75, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m Epoch 1: train loss 8.892663026927039e-05, accuracy 0.7777777777777778\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m [Client 27] fit, config: {'current_round': 75, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m [Client 33] fit, config: {'current_round': 75, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m [Client 76] fit, config: {'current_round': 75, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m Epoch 1: train loss 7.679266855120659e-05, accuracy 0.7777777777777778\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m Epoch 1: train loss 5.648059232044034e-05, accuracy 0.8518518518518519\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m [Client 9] fit, config: {'current_round': 75, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m Epoch 1: train loss 5.3920375648885965e-05, accuracy 0.8333333333333334\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m [Client 74] fit, config: {'current_round': 75, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m [Client 51] fit, config: {'current_round': 75, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m Epoch 1: train loss 5.2163224609103054e-05, accuracy 0.7962962962962963\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m [Client 0] fit, config: {'current_round': 75, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m Epoch 1: train loss 6.214833410922438e-05, accuracy 0.7592592592592593\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m Epoch 1: train loss 6.755718641215935e-05, accuracy 0.7407407407407407\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m Epoch 1: train loss 7.174888742156327e-05, accuracy 0.7962962962962963\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m [Client 99] fit, config: {'current_round': 75, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m Epoch 1: train loss 6.245113763725385e-05, accuracy 0.8148148148148148\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m Epoch 1: train loss 7.659211405552924e-05, accuracy 0.7037037037037037\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m [Client 36] fit, config: {'current_round': 75, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m Epoch 1: train loss 5.8160829212283716e-05, accuracy 0.8148148148148148\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m [Client 7] fit, config: {'current_round': 75, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m Epoch 1: train loss 7.55226137698628e-05, accuracy 0.7962962962962963\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m [Client 17] fit, config: {'current_round': 75, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m Epoch 1: train loss 7.491075666621327e-05, accuracy 0.8148148148148148\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m [Client 3] fit, config: {'current_round': 75, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m Epoch 1: train loss 7.091992301866412e-05, accuracy 0.7777777777777778\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m [Client 54] fit, config: {'current_round': 75, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m Epoch 1: train loss 6.009223579894751e-05, accuracy 0.8148148148148148\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m [Client 79] fit, config: {'current_round': 75, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m [Client 34] fit, config: {'current_round': 75, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m Epoch 1: train loss 6.495511479442939e-05, accuracy 0.7777777777777778\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m [Client 58] fit, config: {'current_round': 75, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m Epoch 1: train loss 6.613606819882989e-05, accuracy 0.7592592592592593\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m [Client 13] fit, config: {'current_round': 75, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m Epoch 1: train loss 6.109971582191065e-05, accuracy 0.8148148148148148\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m [Client 65] fit, config: {'current_round': 75, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m Epoch 1: train loss 4.7285524487961084e-05, accuracy 0.8888888888888888\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m Epoch 1: train loss 6.756281072739512e-05, accuracy 0.7962962962962963\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m [Client 90] fit, config: {'current_round': 75, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m Epoch 1: train loss 5.646749559673481e-05, accuracy 0.7777777777777778\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m [Client 28] fit, config: {'current_round': 75, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m [Client 59] fit, config: {'current_round': 75, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m [Client 71] fit, config: {'current_round': 75, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m Epoch 1: train loss 5.308157778927125e-05, accuracy 0.8148148148148148\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m [Client 68] fit, config: {'current_round': 75, 'local_epochs': 3}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 12:24:27,907 | server.py:216 | fit_round received 30 results and 0 failures\n",
      "DEBUG flower 2023-02-01 12:24:27,996 | server.py:157 | evaluate_round: strategy sampled 30 clients (out of 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m Epoch 1: train loss 6.137354648672044e-05, accuracy 0.8333333333333334\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m Epoch 1: train loss 7.691424252698198e-05, accuracy 0.7962962962962963\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m Epoch 1: train loss 6.156248127808794e-05, accuracy 0.8333333333333334\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m [Client 45] fit, config: {'current_round': 75, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m Epoch 1: train loss 5.0519687647465616e-05, accuracy 0.8703703703703703\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m [Client 60] fit, config: {'current_round': 75, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m Epoch 1: train loss 4.597054066834971e-05, accuracy 0.7962962962962963\n",
      "Saving round 75 aggregated_parameters...\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38334)\u001b[0m [Client 24] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38337)\u001b[0m [Client 37] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38338)\u001b[0m [Client 75] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38334)\u001b[0m [Client 32] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38338)\u001b[0m [Client 98] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38338)\u001b[0m [Client 30] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38334)\u001b[0m [Client 79] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38338)\u001b[0m [Client 72] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38336)\u001b[0m [Client 77] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38340)\u001b[0m [Client 47] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38337)\u001b[0m [Client 55] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38341)\u001b[0m [Client 87] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38338)\u001b[0m [Client 25] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38336)\u001b[0m [Client 48] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38339)\u001b[0m [Client 88] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38340)\u001b[0m [Client 11] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38337)\u001b[0m [Client 90] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38335)\u001b[0m [Client 2] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38334)\u001b[0m [Client 6] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38341)\u001b[0m [Client 84] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38338)\u001b[0m [Client 18] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38336)\u001b[0m [Client 69] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38339)\u001b[0m [Client 96] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38340)\u001b[0m [Client 73] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38337)\u001b[0m [Client 14] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38335)\u001b[0m [Client 91] evaluate, config: {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 12:24:30,253 | server.py:170 | evaluate_round received 0 results and 30 failures\n",
      "DEBUG flower 2023-02-01 12:24:30,255 | server.py:203 | fit_round: strategy sampled 30 clients (out of 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38341)\u001b[0m [Client 4] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38338)\u001b[0m [Client 28] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38339)\u001b[0m [Client 59] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38335)\u001b[0m [Client 86] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m [Client 40] fit, config: {'current_round': 76, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m Epoch 1: train loss 3.204207678209059e-05, accuracy 0.8703703703703703\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m [Client 41] fit, config: {'current_round': 76, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m Epoch 1: train loss 6.94223926984705e-05, accuracy 0.8148148148148148\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m [Client 7] fit, config: {'current_round': 76, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m Epoch 1: train loss 5.1347786211408675e-05, accuracy 0.8518518518518519\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m [Client 58] fit, config: {'current_round': 76, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m [Client 96] fit, config: {'current_round': 76, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m Epoch 1: train loss 6.164480873849243e-05, accuracy 0.7962962962962963\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m Epoch 1: train loss 6.451401714002714e-05, accuracy 0.9074074074074074\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m [Client 43] fit, config: {'current_round': 76, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m Epoch 1: train loss 6.992041744524613e-05, accuracy 0.8148148148148148\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m [Client 56] fit, config: {'current_round': 76, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m Epoch 1: train loss 7.121022645151243e-05, accuracy 0.7777777777777778\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m [Client 3] fit, config: {'current_round': 76, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m Epoch 1: train loss 5.4068194003775716e-05, accuracy 0.8148148148148148\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m [Client 95] fit, config: {'current_round': 76, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m [Client 35] fit, config: {'current_round': 76, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m Epoch 1: train loss 6.794289220124483e-05, accuracy 0.7592592592592593\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m [Client 20] fit, config: {'current_round': 76, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m Epoch 1: train loss 4.986512794857845e-05, accuracy 0.8148148148148148\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m Epoch 1: train loss 4.627902671927586e-05, accuracy 0.8703703703703703\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m [Client 4] fit, config: {'current_round': 76, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m Epoch 1: train loss 4.599758540280163e-05, accuracy 0.8518518518518519\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m [Client 30] fit, config: {'current_round': 76, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m Epoch 1: train loss 8.646014612168074e-05, accuracy 0.7407407407407407\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m [Client 12] fit, config: {'current_round': 76, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m Epoch 1: train loss 4.1321240132674575e-05, accuracy 0.9074074074074074\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m [Client 54] fit, config: {'current_round': 76, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m Epoch 1: train loss 5.05259886267595e-05, accuracy 0.8703703703703703\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m [Client 47] fit, config: {'current_round': 76, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m Epoch 1: train loss 6.963858322706074e-05, accuracy 0.8148148148148148\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m [Client 66] fit, config: {'current_round': 76, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m Epoch 1: train loss 4.297533450881019e-05, accuracy 0.8333333333333334\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m [Client 64] fit, config: {'current_round': 76, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m [Client 5] fit, config: {'current_round': 76, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m Epoch 1: train loss 5.4613537940895185e-05, accuracy 0.7407407407407407\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m Epoch 1: train loss 6.764050340279937e-05, accuracy 0.7777777777777778\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m [Client 22] fit, config: {'current_round': 76, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m Epoch 1: train loss 6.940533785382286e-05, accuracy 0.7592592592592593\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m [Client 61] fit, config: {'current_round': 76, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m Epoch 1: train loss 6.993172428337857e-05, accuracy 0.7222222222222222\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 12:24:33,105 | server.py:216 | fit_round received 30 results and 0 failures\n",
      "DEBUG flower 2023-02-01 12:24:33,167 | server.py:157 | evaluate_round: strategy sampled 30 clients (out of 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m [Client 62] fit, config: {'current_round': 76, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m [Client 68] fit, config: {'current_round': 76, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m [Client 10] fit, config: {'current_round': 76, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m [Client 27] fit, config: {'current_round': 76, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m [Client 79] fit, config: {'current_round': 76, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m [Client 45] fit, config: {'current_round': 76, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m [Client 78] fit, config: {'current_round': 76, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m Epoch 1: train loss 6.242979725357145e-05, accuracy 0.7962962962962963\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m Epoch 1: train loss 6.957961159059778e-05, accuracy 0.8333333333333334\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m [Client 82] fit, config: {'current_round': 76, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m Epoch 1: train loss 6.259734800551087e-05, accuracy 0.7592592592592593\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m Epoch 1: train loss 6.93020920152776e-05, accuracy 0.8148148148148148\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m Epoch 1: train loss 4.666514723794535e-05, accuracy 0.8518518518518519\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m [Client 69] fit, config: {'current_round': 76, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m Epoch 1: train loss 5.138379492564127e-05, accuracy 0.8333333333333334\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m Epoch 1: train loss 5.0860322517110035e-05, accuracy 0.8703703703703703\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m Epoch 1: train loss 4.5539953134721145e-05, accuracy 0.8148148148148148\n",
      "Saving round 76 aggregated_parameters...\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m Epoch 1: train loss 5.933630382060073e-05, accuracy 0.7962962962962963\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38341)\u001b[0m [Client 73] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38340)\u001b[0m [Client 88] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38341)\u001b[0m [Client 35] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38340)\u001b[0m [Client 97] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38341)\u001b[0m [Client 62] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38341)\u001b[0m [Client 65] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38341)\u001b[0m [Client 9] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38341)\u001b[0m [Client 55] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38340)\u001b[0m [Client 76] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38341)\u001b[0m [Client 47] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38336)\u001b[0m [Client 25] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38340)\u001b[0m [Client 71] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38337)\u001b[0m [Client 90] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38340)\u001b[0m [Client 30] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38341)\u001b[0m [Client 92] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38340)\u001b[0m [Client 82] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38341)\u001b[0m [Client 78] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38336)\u001b[0m [Client 33] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38340)\u001b[0m [Client 26] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38337)\u001b[0m [Client 43] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38336)\u001b[0m [Client 36] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38337)\u001b[0m [Client 34] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38337)\u001b[0m [Client 48] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38337)\u001b[0m [Client 20] evaluate, config: {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 12:24:35,680 | server.py:170 | evaluate_round received 0 results and 30 failures\n",
      "DEBUG flower 2023-02-01 12:24:35,683 | server.py:203 | fit_round: strategy sampled 30 clients (out of 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38341)\u001b[0m [Client 39] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38338)\u001b[0m [Client 10] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38336)\u001b[0m [Client 37] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38339)\u001b[0m [Client 86] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38340)\u001b[0m [Client 27] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38335)\u001b[0m [Client 79] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m [Client 67] fit, config: {'current_round': 77, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m Epoch 1: train loss 6.433216185541824e-05, accuracy 0.7777777777777778\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m [Client 47] fit, config: {'current_round': 77, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m Epoch 1: train loss 6.846622272860259e-05, accuracy 0.8518518518518519\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m [Client 61] fit, config: {'current_round': 77, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m Epoch 1: train loss 7.91843340266496e-05, accuracy 0.7407407407407407\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m [Client 44] fit, config: {'current_round': 77, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m Epoch 1: train loss 5.726420204155147e-05, accuracy 0.7962962962962963\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m [Client 16] fit, config: {'current_round': 77, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m [Client 28] fit, config: {'current_round': 77, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m Epoch 1: train loss 6.17260011495091e-05, accuracy 0.8518518518518519\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m Epoch 1: train loss 5.984200834063813e-05, accuracy 0.7962962962962963\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m [Client 29] fit, config: {'current_round': 77, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m [Client 85] fit, config: {'current_round': 77, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m [Client 64] fit, config: {'current_round': 77, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m Epoch 1: train loss 4.93302613904234e-05, accuracy 0.8333333333333334\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m Epoch 1: train loss 3.586457023629919e-05, accuracy 0.9259259259259259\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m Epoch 1: train loss 6.459018186433241e-05, accuracy 0.8148148148148148\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m [Client 79] fit, config: {'current_round': 77, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m Epoch 1: train loss 6.538903107866645e-05, accuracy 0.7777777777777778\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m [Client 39] fit, config: {'current_round': 77, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m [Client 51] fit, config: {'current_round': 77, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m Epoch 1: train loss 8.725933003006503e-05, accuracy 0.7592592592592593\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m Epoch 1: train loss 7.191714394139126e-05, accuracy 0.7962962962962963\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m [Client 17] fit, config: {'current_round': 77, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m [Client 63] fit, config: {'current_round': 77, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m Epoch 1: train loss 7.41988915251568e-05, accuracy 0.8148148148148148\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m Epoch 1: train loss 5.108334880787879e-05, accuracy 0.8703703703703703\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m [Client 53] fit, config: {'current_round': 77, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m Epoch 1: train loss 5.960956332273781e-05, accuracy 0.8148148148148148\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m [Client 62] fit, config: {'current_round': 77, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m Epoch 1: train loss 4.187411832390353e-05, accuracy 0.8518518518518519\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m [Client 75] fit, config: {'current_round': 77, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m Epoch 1: train loss 6.837795808678493e-05, accuracy 0.7777777777777778\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m [Client 36] fit, config: {'current_round': 77, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m Epoch 1: train loss 5.7326305977767333e-05, accuracy 0.8333333333333334\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m [Client 90] fit, config: {'current_round': 77, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m [Client 77] fit, config: {'current_round': 77, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m [Client 92] fit, config: {'current_round': 77, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m Epoch 1: train loss 3.817103788605891e-05, accuracy 0.9074074074074074\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m [Client 83] fit, config: {'current_round': 77, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m Epoch 1: train loss 6.23654923401773e-05, accuracy 0.8333333333333334\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m Epoch 1: train loss 5.536446406040341e-05, accuracy 0.7777777777777778\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m Epoch 1: train loss 7.315036782529205e-05, accuracy 0.7222222222222222\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m [Client 6] fit, config: {'current_round': 77, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m Epoch 1: train loss 6.697097705909982e-05, accuracy 0.8148148148148148\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m [Client 93] fit, config: {'current_round': 77, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m Epoch 1: train loss 6.46472253720276e-05, accuracy 0.7592592592592593\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m [Client 55] fit, config: {'current_round': 77, 'local_epochs': 3}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 12:24:38,565 | server.py:216 | fit_round received 30 results and 0 failures\n",
      "DEBUG flower 2023-02-01 12:24:38,627 | server.py:157 | evaluate_round: strategy sampled 30 clients (out of 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m [Client 30] fit, config: {'current_round': 77, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m [Client 68] fit, config: {'current_round': 77, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m Epoch 1: train loss 5.9720416174968705e-05, accuracy 0.7962962962962963\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m [Client 0] fit, config: {'current_round': 77, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m [Client 33] fit, config: {'current_round': 77, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m Epoch 1: train loss 6.078280057408847e-05, accuracy 0.8333333333333334\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m Epoch 1: train loss 7.842330523999408e-05, accuracy 0.7777777777777778\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m Epoch 1: train loss 6.046895214240067e-05, accuracy 0.8333333333333334\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m [Client 26] fit, config: {'current_round': 77, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m Epoch 1: train loss 6.58118151477538e-05, accuracy 0.7777777777777778\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m Epoch 1: train loss 5.632834290736355e-05, accuracy 0.8518518518518519\n",
      "Saving round 77 aggregated_parameters...\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38338)\u001b[0m [Client 87] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38337)\u001b[0m [Client 42] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38335)\u001b[0m [Client 95] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38335)\u001b[0m [Client 28] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38338)\u001b[0m [Client 86] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38337)\u001b[0m [Client 73] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38335)\u001b[0m [Client 40] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38337)\u001b[0m [Client 74] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38338)\u001b[0m [Client 44] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38338)\u001b[0m [Client 46] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38338)\u001b[0m [Client 27] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38337)\u001b[0m [Client 41] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38337)\u001b[0m [Client 17] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38338)\u001b[0m [Client 4] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38337)\u001b[0m [Client 91] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38335)\u001b[0m [Client 0] evaluate, config: {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 12:24:41,059 | server.py:170 | evaluate_round received 0 results and 30 failures\n",
      "DEBUG flower 2023-02-01 12:24:41,060 | server.py:203 | fit_round: strategy sampled 30 clients (out of 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38337)\u001b[0m [Client 1] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38335)\u001b[0m [Client 82] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38337)\u001b[0m [Client 71] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38337)\u001b[0m [Client 39] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38334)\u001b[0m [Client 57] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38341)\u001b[0m [Client 93] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38338)\u001b[0m [Client 70] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38336)\u001b[0m [Client 80] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38339)\u001b[0m [Client 30] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38340)\u001b[0m [Client 60] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38337)\u001b[0m [Client 32] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38337)\u001b[0m [Client 92] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38335)\u001b[0m [Client 98] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38335)\u001b[0m [Client 45] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m [Client 19] fit, config: {'current_round': 78, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m Epoch 1: train loss 4.814929707208648e-05, accuracy 0.8333333333333334\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m [Client 53] fit, config: {'current_round': 78, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m [Client 5] fit, config: {'current_round': 78, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m [Client 69] fit, config: {'current_round': 78, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m Epoch 1: train loss 5.1117218390572816e-05, accuracy 0.8333333333333334\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m [Client 66] fit, config: {'current_round': 78, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m Epoch 1: train loss 6.258215580601245e-05, accuracy 0.7777777777777778\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m Epoch 1: train loss 4.9448444769950584e-05, accuracy 0.8148148148148148\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m Epoch 1: train loss 3.974895298597403e-05, accuracy 0.8888888888888888\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m [Client 29] fit, config: {'current_round': 78, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m Epoch 1: train loss 4.2999534343834966e-05, accuracy 0.8518518518518519\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m [Client 40] fit, config: {'current_round': 78, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m [Client 94] fit, config: {'current_round': 78, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m Epoch 1: train loss 3.110184843535535e-05, accuracy 0.8888888888888888\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m [Client 13] fit, config: {'current_round': 78, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m Epoch 1: train loss 5.1897393859690055e-05, accuracy 0.8703703703703703\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m Epoch 1: train loss 5.205530032981187e-05, accuracy 0.8333333333333334\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m [Client 49] fit, config: {'current_round': 78, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m Epoch 1: train loss 4.902845830656588e-05, accuracy 0.8703703703703703\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m [Client 57] fit, config: {'current_round': 78, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m [Client 50] fit, config: {'current_round': 78, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m [Client 93] fit, config: {'current_round': 78, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m Epoch 1: train loss 4.415173680172302e-05, accuracy 0.8518518518518519\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m Epoch 1: train loss 3.761449261219241e-05, accuracy 0.8333333333333334\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m Epoch 1: train loss 8.916432125261053e-05, accuracy 0.7777777777777778\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m [Client 17] fit, config: {'current_round': 78, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m [Client 11] fit, config: {'current_round': 78, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m Epoch 1: train loss 5.2682535169878975e-05, accuracy 0.8148148148148148\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m Epoch 1: train loss 8.621298911748454e-05, accuracy 0.7962962962962963\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m [Client 27] fit, config: {'current_round': 78, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m [Client 16] fit, config: {'current_round': 78, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m Epoch 1: train loss 6.383482832461596e-05, accuracy 0.8148148148148148\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m Epoch 1: train loss 6.970758840907365e-05, accuracy 0.8333333333333334\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m [Client 45] fit, config: {'current_round': 78, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m Epoch 1: train loss 5.0142716645495966e-05, accuracy 0.8888888888888888\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m [Client 31] fit, config: {'current_round': 78, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m Epoch 1: train loss 4.404459468787536e-05, accuracy 0.8703703703703703\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m [Client 51] fit, config: {'current_round': 78, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m [Client 68] fit, config: {'current_round': 78, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m [Client 58] fit, config: {'current_round': 78, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m Epoch 1: train loss 5.870844688615762e-05, accuracy 0.7962962962962963\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m Epoch 1: train loss 6.705788837280124e-05, accuracy 0.8148148148148148\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 12:24:43,518 | server.py:216 | fit_round received 30 results and 0 failures\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m Epoch 1: train loss 6.574459257535636e-05, accuracy 0.7962962962962963\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m [Client 43] fit, config: {'current_round': 78, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m Epoch 1: train loss 7.00485470588319e-05, accuracy 0.8703703703703703\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m [Client 80] fit, config: {'current_round': 78, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m Epoch 1: train loss 4.063449887325987e-05, accuracy 0.8888888888888888\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m [Client 4] fit, config: {'current_round': 78, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m [Client 99] fit, config: {'current_round': 78, 'local_epochs': 3}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 12:24:43,590 | server.py:157 | evaluate_round: strategy sampled 30 clients (out of 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m [Client 41] fit, config: {'current_round': 78, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m Epoch 1: train loss 6.446643965318799e-05, accuracy 0.8333333333333334\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m Epoch 1: train loss 4.2922918510157615e-05, accuracy 0.8888888888888888\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m Epoch 1: train loss 5.299204713082872e-05, accuracy 0.8333333333333334\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m [Client 65] fit, config: {'current_round': 78, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m Epoch 1: train loss 5.0838458264479414e-05, accuracy 0.8518518518518519\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m [Client 82] fit, config: {'current_round': 78, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m Epoch 1: train loss 5.960852649877779e-05, accuracy 0.7592592592592593\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m [Client 47] fit, config: {'current_round': 78, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m Epoch 1: train loss 6.643538654316217e-05, accuracy 0.8703703703703703\n",
      "Saving round 78 aggregated_parameters...\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38335)\u001b[0m [Client 63] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38341)\u001b[0m [Client 42] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38340)\u001b[0m [Client 67] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38337)\u001b[0m [Client 22] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38335)\u001b[0m [Client 82] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38337)\u001b[0m [Client 85] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38337)\u001b[0m [Client 99] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38337)\u001b[0m [Client 32] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38338)\u001b[0m [Client 61] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38340)\u001b[0m [Client 49] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38337)\u001b[0m [Client 84] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38334)\u001b[0m [Client 31] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38341)\u001b[0m [Client 11] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38339)\u001b[0m [Client 80] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38335)\u001b[0m [Client 16] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38334)\u001b[0m [Client 60] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38338)\u001b[0m [Client 78] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38336)\u001b[0m [Client 14] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38340)\u001b[0m [Client 24] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38337)\u001b[0m [Client 83] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38334)\u001b[0m [Client 20] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38338)\u001b[0m [Client 95] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38336)\u001b[0m [Client 37] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38339)\u001b[0m [Client 48] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38340)\u001b[0m [Client 15] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38337)\u001b[0m [Client 44] evaluate, config: {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 12:24:46,172 | server.py:170 | evaluate_round received 0 results and 30 failures\n",
      "DEBUG flower 2023-02-01 12:24:46,173 | server.py:203 | fit_round: strategy sampled 30 clients (out of 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38334)\u001b[0m [Client 35] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38341)\u001b[0m [Client 10] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38338)\u001b[0m [Client 70] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38335)\u001b[0m [Client 36] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m [Client 23] fit, config: {'current_round': 79, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m Epoch 1: train loss 6.368618051055819e-05, accuracy 0.7222222222222222\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m [Client 26] fit, config: {'current_round': 79, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m Epoch 1: train loss 6.595715240109712e-05, accuracy 0.8148148148148148\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m [Client 45] fit, config: {'current_round': 79, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m Epoch 1: train loss 4.777674257638864e-05, accuracy 0.8703703703703703\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m [Client 14] fit, config: {'current_round': 79, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m Epoch 1: train loss 6.282439426286146e-05, accuracy 0.7592592592592593\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m [Client 89] fit, config: {'current_round': 79, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m [Client 39] fit, config: {'current_round': 79, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m Epoch 1: train loss 8.608300413470715e-05, accuracy 0.7592592592592593\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m Epoch 1: train loss 6.375173688866198e-05, accuracy 0.8333333333333334\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m [Client 16] fit, config: {'current_round': 79, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m Epoch 1: train loss 5.867731670150533e-05, accuracy 0.7962962962962963\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m [Client 49] fit, config: {'current_round': 79, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m Epoch 1: train loss 7.271867070812732e-05, accuracy 0.7407407407407407\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m [Client 42] fit, config: {'current_round': 79, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m Epoch 1: train loss 8.720233745407313e-05, accuracy 0.7222222222222222\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m [Client 2] fit, config: {'current_round': 79, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m Epoch 1: train loss 5.4491585615323856e-05, accuracy 0.8148148148148148\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m [Client 0] fit, config: {'current_round': 79, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m Epoch 1: train loss 5.846036219736561e-05, accuracy 0.8333333333333334\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m [Client 98] fit, config: {'current_round': 79, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m Epoch 1: train loss 6.178793410072103e-05, accuracy 0.7592592592592593\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m [Client 25] fit, config: {'current_round': 79, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m Epoch 1: train loss 5.6122513342415914e-05, accuracy 0.7777777777777778\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m [Client 6] fit, config: {'current_round': 79, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m [Client 53] fit, config: {'current_round': 79, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m Epoch 1: train loss 5.8255587646272033e-05, accuracy 0.8333333333333334\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m [Client 10] fit, config: {'current_round': 79, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m Epoch 1: train loss 5.906441219849512e-05, accuracy 0.7962962962962963\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m Epoch 1: train loss 6.679724174318835e-05, accuracy 0.7962962962962963\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m [Client 44] fit, config: {'current_round': 79, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m Epoch 1: train loss 5.8427733165444806e-05, accuracy 0.7962962962962963\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m [Client 36] fit, config: {'current_round': 79, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m [Client 63] fit, config: {'current_round': 79, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m Epoch 1: train loss 5.136319305165671e-05, accuracy 0.8518518518518519\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m Epoch 1: train loss 5.70186493860092e-05, accuracy 0.8148148148148148\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m [Client 5] fit, config: {'current_round': 79, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m Epoch 1: train loss 4.452774373930879e-05, accuracy 0.8703703703703703\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m [Client 4] fit, config: {'current_round': 79, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m Epoch 1: train loss 4.152879409957677e-05, accuracy 0.8888888888888888\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m [Client 22] fit, config: {'current_round': 79, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m [Client 56] fit, config: {'current_round': 79, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m Epoch 1: train loss 6.439301796490327e-05, accuracy 0.7962962962962963\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m [Client 50] fit, config: {'current_round': 79, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m [Client 43] fit, config: {'current_round': 79, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m Epoch 1: train loss 6.616530299652368e-05, accuracy 0.8148148148148148\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m Epoch 1: train loss 7.000328332651407e-05, accuracy 0.7777777777777778\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m [Client 41] fit, config: {'current_round': 79, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m Epoch 1: train loss 8.174854883691296e-05, accuracy 0.6851851851851852\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m [Client 54] fit, config: {'current_round': 79, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m Epoch 1: train loss 7.463036308763549e-05, accuracy 0.8148148148148148\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m [Client 87] fit, config: {'current_round': 79, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m [Client 46] fit, config: {'current_round': 79, 'local_epochs': 3}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 12:24:48,771 | server.py:216 | fit_round received 30 results and 0 failures\n",
      "DEBUG flower 2023-02-01 12:24:48,844 | server.py:157 | evaluate_round: strategy sampled 30 clients (out of 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m Epoch 1: train loss 5.772952499683015e-05, accuracy 0.7962962962962963\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m [Client 15] fit, config: {'current_round': 79, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m Epoch 1: train loss 7.734591781627387e-05, accuracy 0.7407407407407407\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m Epoch 1: train loss 5.4389049182645977e-05, accuracy 0.8148148148148148\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m Epoch 1: train loss 5.741899076383561e-05, accuracy 0.8148148148148148\n",
      "Saving round 79 aggregated_parameters...\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38339)\u001b[0m [Client 64] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38339)\u001b[0m [Client 53] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38340)\u001b[0m [Client 12] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38340)\u001b[0m [Client 63] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38340)\u001b[0m [Client 89] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38339)\u001b[0m [Client 0] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38335)\u001b[0m [Client 86] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38337)\u001b[0m [Client 10] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38335)\u001b[0m [Client 37] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38338)\u001b[0m [Client 96] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38340)\u001b[0m [Client 91] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38337)\u001b[0m [Client 77] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38334)\u001b[0m [Client 54] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38341)\u001b[0m [Client 66] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38338)\u001b[0m [Client 83] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38336)\u001b[0m [Client 98] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38339)\u001b[0m [Client 39] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38340)\u001b[0m [Client 58] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38335)\u001b[0m [Client 32] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38341)\u001b[0m [Client 94] evaluate, config: {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 12:24:51,276 | server.py:170 | evaluate_round received 0 results and 30 failures\n",
      "DEBUG flower 2023-02-01 12:24:51,277 | server.py:203 | fit_round: strategy sampled 30 clients (out of 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38334)\u001b[0m [Client 30] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38341)\u001b[0m [Client 78] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38336)\u001b[0m [Client 18] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38339)\u001b[0m [Client 67] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38340)\u001b[0m [Client 8] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38337)\u001b[0m [Client 92] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38335)\u001b[0m [Client 34] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38334)\u001b[0m [Client 57] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38338)\u001b[0m [Client 23] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38340)\u001b[0m [Client 87] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m [Client 56] fit, config: {'current_round': 80, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m Epoch 1: train loss 7.01666867826134e-05, accuracy 0.7592592592592593\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m [Client 87] fit, config: {'current_round': 80, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m Epoch 1: train loss 7.185169670265168e-05, accuracy 0.7222222222222222\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m [Client 5] fit, config: {'current_round': 80, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m Epoch 1: train loss 4.857224121224135e-05, accuracy 0.7962962962962963\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m [Client 68] fit, config: {'current_round': 80, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m Epoch 1: train loss 6.838737317593768e-05, accuracy 0.8148148148148148\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m [Client 93] fit, config: {'current_round': 80, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m [Client 72] fit, config: {'current_round': 80, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m Epoch 1: train loss 4.880577398580499e-05, accuracy 0.8518518518518519\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m [Client 40] fit, config: {'current_round': 80, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m Epoch 1: train loss 3.1297182431444526e-05, accuracy 0.8518518518518519\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m [Client 46] fit, config: {'current_round': 80, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m Epoch 1: train loss 4.995402196072973e-05, accuracy 0.8518518518518519\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m Epoch 1: train loss 4.210871338727884e-05, accuracy 0.8888888888888888\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m [Client 90] fit, config: {'current_round': 80, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m [Client 19] fit, config: {'current_round': 80, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m Epoch 1: train loss 4.829134195460938e-05, accuracy 0.8333333333333334\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m [Client 73] fit, config: {'current_round': 80, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m Epoch 1: train loss 6.721533281961456e-05, accuracy 0.7407407407407407\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m [Client 38] fit, config: {'current_round': 80, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m [Client 25] fit, config: {'current_round': 80, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m Epoch 1: train loss 5.894189598620869e-05, accuracy 0.7037037037037037\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m [Client 12] fit, config: {'current_round': 80, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m Epoch 1: train loss 3.872614252031781e-05, accuracy 0.9074074074074074\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m Epoch 1: train loss 3.975038998760283e-05, accuracy 0.9259259259259259\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m [Client 49] fit, config: {'current_round': 80, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m Epoch 1: train loss 4.374495256342925e-05, accuracy 0.8888888888888888\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m [Client 94] fit, config: {'current_round': 80, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m Epoch 1: train loss 5.241410690359771e-05, accuracy 0.8518518518518519\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m Epoch 1: train loss 4.8457841330673546e-05, accuracy 0.8333333333333334\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m [Client 22] fit, config: {'current_round': 80, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m Epoch 1: train loss 6.574333383468911e-05, accuracy 0.7777777777777778\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m [Client 39] fit, config: {'current_round': 80, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m Epoch 1: train loss 6.501485040644184e-05, accuracy 0.8518518518518519\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m [Client 75] fit, config: {'current_round': 80, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m [Client 16] fit, config: {'current_round': 80, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m Epoch 1: train loss 4.960055957781151e-05, accuracy 0.8703703703703703\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m Epoch 1: train loss 6.269230652833357e-05, accuracy 0.7962962962962963\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m [Client 7] fit, config: {'current_round': 80, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m [Client 85] fit, config: {'current_round': 80, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m Epoch 1: train loss 3.2617936085443944e-05, accuracy 0.9074074074074074\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m [Client 55] fit, config: {'current_round': 80, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m Epoch 1: train loss 5.6914119340945035e-05, accuracy 0.7592592592592593\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m [Client 86] fit, config: {'current_round': 80, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m Epoch 1: train loss 5.1600982260424644e-05, accuracy 0.7962962962962963\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m [Client 20] fit, config: {'current_round': 80, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m [Client 6] fit, config: {'current_round': 80, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m [Client 45] fit, config: {'current_round': 80, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m Epoch 1: train loss 5.957091343589127e-05, accuracy 0.8333333333333334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 12:24:53,913 | server.py:216 | fit_round received 30 results and 0 failures\n",
      "DEBUG flower 2023-02-01 12:24:53,970 | server.py:157 | evaluate_round: strategy sampled 30 clients (out of 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m Epoch 1: train loss 4.842441558139399e-05, accuracy 0.8888888888888888\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m [Client 84] fit, config: {'current_round': 80, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m Epoch 1: train loss 6.651229341514409e-05, accuracy 0.7962962962962963\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m [Client 29] fit, config: {'current_round': 80, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m Epoch 1: train loss 4.243863440933637e-05, accuracy 0.8703703703703703\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m [Client 88] fit, config: {'current_round': 80, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m Epoch 1: train loss 4.21151562477462e-05, accuracy 0.8518518518518519\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m Epoch 1: train loss 5.097004759591073e-05, accuracy 0.8703703703703703\n",
      "Saving round 80 aggregated_parameters...\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m Epoch 1: train loss 4.053488009958528e-05, accuracy 0.8518518518518519\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38334)\u001b[0m [Client 98] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38340)\u001b[0m [Client 8] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38341)\u001b[0m [Client 81] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38338)\u001b[0m [Client 94] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38337)\u001b[0m [Client 95] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38334)\u001b[0m [Client 48] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38339)\u001b[0m [Client 77] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38340)\u001b[0m [Client 13] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38335)\u001b[0m [Client 37] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38340)\u001b[0m [Client 34] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38340)\u001b[0m [Client 54] evaluate, config: {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 12:24:56,359 | server.py:170 | evaluate_round received 0 results and 30 failures\n",
      "DEBUG flower 2023-02-01 12:24:56,361 | server.py:203 | fit_round: strategy sampled 30 clients (out of 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38340)\u001b[0m [Client 31] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38340)\u001b[0m [Client 52] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38334)\u001b[0m [Client 55] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38341)\u001b[0m [Client 76] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38338)\u001b[0m [Client 17] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38339)\u001b[0m [Client 83] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38340)\u001b[0m [Client 65] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38337)\u001b[0m [Client 69] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38335)\u001b[0m [Client 15] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38341)\u001b[0m [Client 80] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38334)\u001b[0m [Client 12] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38341)\u001b[0m [Client 33] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38338)\u001b[0m [Client 30] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38336)\u001b[0m [Client 1] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38339)\u001b[0m [Client 85] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38340)\u001b[0m [Client 56] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38337)\u001b[0m [Client 16] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38335)\u001b[0m [Client 96] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38341)\u001b[0m [Client 74] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m [Client 22] fit, config: {'current_round': 81, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m Epoch 1: train loss 6.733767077093944e-05, accuracy 0.7592592592592593\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m [Client 61] fit, config: {'current_round': 81, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m [Client 4] fit, config: {'current_round': 81, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m Epoch 1: train loss 3.953919076593593e-05, accuracy 0.9259259259259259\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m Epoch 1: train loss 7.655883382540196e-05, accuracy 0.7037037037037037\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m [Client 81] fit, config: {'current_round': 81, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m Epoch 1: train loss 5.8738656662171707e-05, accuracy 0.8148148148148148\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m [Client 73] fit, config: {'current_round': 81, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m Epoch 1: train loss 6.520339229609817e-05, accuracy 0.7777777777777778\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m [Client 74] fit, config: {'current_round': 81, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m Epoch 1: train loss 6.0578848206205294e-05, accuracy 0.7962962962962963\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m [Client 83] fit, config: {'current_round': 81, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m Epoch 1: train loss 5.784718814538792e-05, accuracy 0.8148148148148148\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m [Client 58] fit, config: {'current_round': 81, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m Epoch 1: train loss 5.8182071370538324e-05, accuracy 0.7962962962962963\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m [Client 43] fit, config: {'current_round': 81, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m [Client 49] fit, config: {'current_round': 81, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m [Client 30] fit, config: {'current_round': 81, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m Epoch 1: train loss 7.613110938109457e-05, accuracy 0.7777777777777778\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m Epoch 1: train loss 6.371062772814184e-05, accuracy 0.7962962962962963\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m [Client 77] fit, config: {'current_round': 81, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m Epoch 1: train loss 7.281012221937999e-05, accuracy 0.7222222222222222\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m [Client 72] fit, config: {'current_round': 81, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m Epoch 1: train loss 4.365507629700005e-05, accuracy 0.9074074074074074\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m Epoch 1: train loss 6.964203203096986e-05, accuracy 0.7592592592592593\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m [Client 50] fit, config: {'current_round': 81, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m Epoch 1: train loss 7.339238072745502e-05, accuracy 0.7962962962962963\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m [Client 60] fit, config: {'current_round': 81, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m Epoch 1: train loss 4.07519873988349e-05, accuracy 0.8703703703703703\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m [Client 75] fit, config: {'current_round': 81, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m Epoch 1: train loss 6.714309711242095e-05, accuracy 0.7592592592592593\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m [Client 24] fit, config: {'current_round': 81, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m Epoch 1: train loss 5.7560209825169295e-05, accuracy 0.7407407407407407\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m [Client 64] fit, config: {'current_round': 81, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m [Client 25] fit, config: {'current_round': 81, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m [Client 97] fit, config: {'current_round': 81, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m [Client 47] fit, config: {'current_round': 81, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m Epoch 1: train loss 5.87889262533281e-05, accuracy 0.8148148148148148\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m [Client 29] fit, config: {'current_round': 81, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m Epoch 1: train loss 5.400099325925112e-05, accuracy 0.7592592592592593\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 12:24:58,984 | server.py:216 | fit_round received 30 results and 0 failures\n",
      "DEBUG flower 2023-02-01 12:24:59,040 | server.py:157 | evaluate_round: strategy sampled 30 clients (out of 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m [Client 6] fit, config: {'current_round': 81, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m Epoch 1: train loss 6.339266110444441e-05, accuracy 0.8518518518518519\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m Epoch 1: train loss 4.4892174628330395e-05, accuracy 0.8518518518518519\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m [Client 63] fit, config: {'current_round': 81, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m Epoch 1: train loss 4.7500627260887995e-05, accuracy 0.8703703703703703\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m [Client 32] fit, config: {'current_round': 81, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m Epoch 1: train loss 6.614861194975674e-05, accuracy 0.8333333333333334\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m [Client 80] fit, config: {'current_round': 81, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m Epoch 1: train loss 4.674308001995087e-05, accuracy 0.8333333333333334\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m [Client 94] fit, config: {'current_round': 81, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m [Client 85] fit, config: {'current_round': 81, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m Epoch 1: train loss 3.3968430216191337e-05, accuracy 0.9259259259259259\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m Epoch 1: train loss 7.014844595687464e-05, accuracy 0.7962962962962963\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m [Client 65] fit, config: {'current_round': 81, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m [Client 92] fit, config: {'current_round': 81, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m Epoch 1: train loss 3.626943362178281e-05, accuracy 0.9074074074074074\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m Epoch 1: train loss 5.0526643462944776e-05, accuracy 0.8148148148148148\n",
      "Saving round 81 aggregated_parameters...\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m Epoch 1: train loss 4.3088748498121276e-05, accuracy 0.9074074074074074\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m Epoch 1: train loss 4.248371260473505e-05, accuracy 0.8518518518518519\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38340)\u001b[0m [Client 33] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38339)\u001b[0m [Client 32] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38340)\u001b[0m [Client 9] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38341)\u001b[0m [Client 82] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38340)\u001b[0m [Client 49] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38339)\u001b[0m [Client 65] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38341)\u001b[0m [Client 41] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38339)\u001b[0m [Client 54] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38340)\u001b[0m [Client 60] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38337)\u001b[0m [Client 64] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38334)\u001b[0m [Client 93] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38338)\u001b[0m [Client 19] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38339)\u001b[0m [Client 13] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38335)\u001b[0m [Client 42] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38341)\u001b[0m [Client 87] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38336)\u001b[0m [Client 12] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38340)\u001b[0m [Client 3] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38337)\u001b[0m [Client 2] evaluate, config: {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 12:25:01,789 | server.py:170 | evaluate_round received 0 results and 30 failures\n",
      "DEBUG flower 2023-02-01 12:25:01,790 | server.py:203 | fit_round: strategy sampled 30 clients (out of 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38341)\u001b[0m [Client 68] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38337)\u001b[0m [Client 21] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38336)\u001b[0m [Client 63] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38339)\u001b[0m [Client 24] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38340)\u001b[0m [Client 66] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38335)\u001b[0m [Client 84] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38334)\u001b[0m [Client 25] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38341)\u001b[0m [Client 27] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38338)\u001b[0m [Client 52] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38336)\u001b[0m [Client 31] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38339)\u001b[0m [Client 76] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38337)\u001b[0m [Client 38] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m [Client 5] fit, config: {'current_round': 82, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m Epoch 1: train loss 5.0669335905695334e-05, accuracy 0.7962962962962963\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m [Client 62] fit, config: {'current_round': 82, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m Epoch 1: train loss 6.266850687097758e-05, accuracy 0.7962962962962963\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m [Client 24] fit, config: {'current_round': 82, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m Epoch 1: train loss 4.13978414144367e-05, accuracy 0.8888888888888888\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m [Client 84] fit, config: {'current_round': 82, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m Epoch 1: train loss 6.769627361791208e-05, accuracy 0.7777777777777778\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m [Client 69] fit, config: {'current_round': 82, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m Epoch 1: train loss 5.179756772122346e-05, accuracy 0.8148148148148148\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m [Client 91] fit, config: {'current_round': 82, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m Epoch 1: train loss 2.277359635627363e-05, accuracy 0.9444444444444444\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m [Client 88] fit, config: {'current_round': 82, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m Epoch 1: train loss 4.03272824769374e-05, accuracy 0.8703703703703703\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m [Client 19] fit, config: {'current_round': 82, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m [Client 27] fit, config: {'current_round': 82, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m Epoch 1: train loss 6.7645036324393e-05, accuracy 0.8333333333333334\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m [Client 57] fit, config: {'current_round': 82, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m Epoch 1: train loss 3.836896939901635e-05, accuracy 0.8518518518518519\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m Epoch 1: train loss 4.8776222683954984e-05, accuracy 0.8148148148148148\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m [Client 43] fit, config: {'current_round': 82, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m Epoch 1: train loss 6.718515942338854e-05, accuracy 0.8703703703703703\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m [Client 35] fit, config: {'current_round': 82, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m Epoch 1: train loss 6.443088932428509e-05, accuracy 0.7592592592592593\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m [Client 37] fit, config: {'current_round': 82, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m Epoch 1: train loss 5.04028721479699e-05, accuracy 0.8703703703703703\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m [Client 81] fit, config: {'current_round': 82, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m Epoch 1: train loss 6.037790808477439e-05, accuracy 0.8333333333333334\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m [Client 1] fit, config: {'current_round': 82, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m Epoch 1: train loss 2.8912105335621163e-05, accuracy 0.8888888888888888\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m [Client 59] fit, config: {'current_round': 82, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m [Client 21] fit, config: {'current_round': 82, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m Epoch 1: train loss 4.464290395844728e-05, accuracy 0.8518518518518519\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m [Client 74] fit, config: {'current_round': 82, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m Epoch 1: train loss 5.127230906509794e-05, accuracy 0.7777777777777778\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m [Client 61] fit, config: {'current_round': 82, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m Epoch 1: train loss 6.2435312429443e-05, accuracy 0.7962962962962963\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m Epoch 1: train loss 7.727537740720436e-05, accuracy 0.7592592592592593\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m [Client 25] fit, config: {'current_round': 82, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m [Client 47] fit, config: {'current_round': 82, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m Epoch 1: train loss 6.5332576923538e-05, accuracy 0.8518518518518519\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m [Client 54] fit, config: {'current_round': 82, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m Epoch 1: train loss 5.257885277387686e-05, accuracy 0.8333333333333334\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m Epoch 1: train loss 4.355041528469883e-05, accuracy 0.8888888888888888\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m [Client 80] fit, config: {'current_round': 82, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m Epoch 1: train loss 3.919442679034546e-05, accuracy 0.8888888888888888\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m [Client 44] fit, config: {'current_round': 82, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m [Client 48] fit, config: {'current_round': 82, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m Epoch 1: train loss 4.4281157897785306e-05, accuracy 0.9259259259259259\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 12:25:04,325 | server.py:216 | fit_round received 30 results and 0 failures\n",
      "DEBUG flower 2023-02-01 12:25:04,382 | server.py:157 | evaluate_round: strategy sampled 30 clients (out of 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m [Client 94] fit, config: {'current_round': 82, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m Epoch 1: train loss 5.289525506668724e-05, accuracy 0.8518518518518519\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m Epoch 1: train loss 4.499257920542732e-05, accuracy 0.8703703703703703\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m [Client 11] fit, config: {'current_round': 82, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m Epoch 1: train loss 5.1869010349037126e-05, accuracy 0.8148148148148148\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m [Client 73] fit, config: {'current_round': 82, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m Epoch 1: train loss 6.591444980585948e-05, accuracy 0.7592592592592593\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m [Client 0] fit, config: {'current_round': 82, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m Epoch 1: train loss 6.0425609262892976e-05, accuracy 0.8333333333333334\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m [Client 40] fit, config: {'current_round': 82, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m Epoch 1: train loss 3.0675961170345545e-05, accuracy 0.8703703703703703\n",
      "Saving round 82 aggregated_parameters...\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38338)\u001b[0m [Client 5] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38335)\u001b[0m [Client 95] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38335)\u001b[0m [Client 32] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38335)\u001b[0m [Client 25] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38335)\u001b[0m [Client 96] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38335)\u001b[0m [Client 82] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38335)\u001b[0m [Client 3] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38334)\u001b[0m [Client 20] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38338)\u001b[0m [Client 7] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38338)\u001b[0m [Client 46] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38340)\u001b[0m [Client 13] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38335)\u001b[0m [Client 42] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38338)\u001b[0m [Client 54] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38336)\u001b[0m [Client 17] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38339)\u001b[0m [Client 73] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38340)\u001b[0m [Client 37] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38337)\u001b[0m [Client 77] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38334)\u001b[0m [Client 29] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38341)\u001b[0m [Client 22] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38334)\u001b[0m [Client 45] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38341)\u001b[0m [Client 48] evaluate, config: {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 12:25:06,988 | server.py:170 | evaluate_round received 0 results and 30 failures\n",
      "DEBUG flower 2023-02-01 12:25:06,989 | server.py:203 | fit_round: strategy sampled 30 clients (out of 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38334)\u001b[0m [Client 51] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38341)\u001b[0m [Client 76] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38338)\u001b[0m [Client 39] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38336)\u001b[0m [Client 79] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38339)\u001b[0m [Client 12] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38340)\u001b[0m [Client 90] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38337)\u001b[0m [Client 64] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38335)\u001b[0m [Client 2] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38334)\u001b[0m [Client 55] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m [Client 35] fit, config: {'current_round': 83, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m [Client 99] fit, config: {'current_round': 83, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m Epoch 1: train loss 3.956658474635333e-05, accuracy 0.8518518518518519\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m [Client 48] fit, config: {'current_round': 83, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m [Client 72] fit, config: {'current_round': 83, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m Epoch 1: train loss 7.287465268746018e-05, accuracy 0.6851851851851852\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m Epoch 1: train loss 4.4321575842332095e-05, accuracy 0.9074074074074074\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m [Client 11] fit, config: {'current_round': 83, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m Epoch 1: train loss 6.0359663621056825e-05, accuracy 0.7777777777777778\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m [Client 98] fit, config: {'current_round': 83, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m Epoch 1: train loss 6.029263022355735e-05, accuracy 0.7777777777777778\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m [Client 46] fit, config: {'current_round': 83, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m [Client 13] fit, config: {'current_round': 83, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m Epoch 1: train loss 5.063626667833887e-05, accuracy 0.8333333333333334\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m Epoch 1: train loss 5.589450665866025e-05, accuracy 0.8148148148148148\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m Epoch 1: train loss 5.493806747836061e-05, accuracy 0.8333333333333334\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m [Client 85] fit, config: {'current_round': 83, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m Epoch 1: train loss 3.3932868973352015e-05, accuracy 0.9259259259259259\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m [Client 8] fit, config: {'current_round': 83, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m Epoch 1: train loss 6.784850847907364e-05, accuracy 0.7777777777777778\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m [Client 44] fit, config: {'current_round': 83, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m Epoch 1: train loss 5.5180007620947435e-05, accuracy 0.7962962962962963\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m [Client 9] fit, config: {'current_round': 83, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m [Client 6] fit, config: {'current_round': 83, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m Epoch 1: train loss 6.321872206171975e-05, accuracy 0.8333333333333334\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m [Client 80] fit, config: {'current_round': 83, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m Epoch 1: train loss 4.244605588610284e-05, accuracy 0.8333333333333334\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m [Client 71] fit, config: {'current_round': 83, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m [Client 69] fit, config: {'current_round': 83, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m Epoch 1: train loss 4.55968729511369e-05, accuracy 0.8148148148148148\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m Epoch 1: train loss 5.390017031459138e-05, accuracy 0.8148148148148148\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m [Client 33] fit, config: {'current_round': 83, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m [Client 66] fit, config: {'current_round': 83, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m Epoch 1: train loss 5.016520663048141e-05, accuracy 0.8333333333333334\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m [Client 91] fit, config: {'current_round': 83, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m Epoch 1: train loss 3.0353487090906128e-05, accuracy 0.9259259259259259\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m [Client 52] fit, config: {'current_round': 83, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m Epoch 1: train loss 6.29514834145084e-05, accuracy 0.7962962962962963\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m Epoch 1: train loss 5.335888999979943e-05, accuracy 0.8518518518518519\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m [Client 21] fit, config: {'current_round': 83, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m Epoch 1: train loss 5.6335764384130016e-05, accuracy 0.8148148148148148\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m Epoch 1: train loss 4.330523370299488e-05, accuracy 0.8518518518518519\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m [Client 58] fit, config: {'current_round': 83, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m Epoch 1: train loss 5.925891309743747e-05, accuracy 0.7962962962962963\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m [Client 18] fit, config: {'current_round': 83, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m Epoch 1: train loss 5.8454043028177693e-05, accuracy 0.7962962962962963\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m [Client 96] fit, config: {'current_round': 83, 'local_epochs': 3}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 12:25:09,585 | server.py:216 | fit_round received 30 results and 0 failures\n",
      "DEBUG flower 2023-02-01 12:25:09,654 | server.py:157 | evaluate_round: strategy sampled 30 clients (out of 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m [Client 32] fit, config: {'current_round': 83, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m Epoch 1: train loss 6.991261034272611e-05, accuracy 0.7962962962962963\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m [Client 37] fit, config: {'current_round': 83, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m Epoch 1: train loss 6.408189801732078e-05, accuracy 0.8148148148148148\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m [Client 95] fit, config: {'current_round': 83, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m [Client 19] fit, config: {'current_round': 83, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m Epoch 1: train loss 4.209327380522154e-05, accuracy 0.8703703703703703\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m Epoch 1: train loss 5.9503436204977334e-05, accuracy 0.8148148148148148\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m Epoch 1: train loss 3.1273830245481804e-05, accuracy 0.9074074074074074\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m [Client 56] fit, config: {'current_round': 83, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m Epoch 1: train loss 6.22487350483425e-05, accuracy 0.7962962962962963\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m [Client 97] fit, config: {'current_round': 83, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m Epoch 1: train loss 4.4407886889530346e-05, accuracy 0.8518518518518519\n",
      "Saving round 83 aggregated_parameters...\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38340)\u001b[0m [Client 15] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38340)\u001b[0m [Client 91] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38340)\u001b[0m [Client 96] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38340)\u001b[0m [Client 45] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38340)\u001b[0m [Client 51] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38337)\u001b[0m [Client 64] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38337)\u001b[0m [Client 43] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38340)\u001b[0m [Client 88] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38337)\u001b[0m [Client 58] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38338)\u001b[0m [Client 75] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38339)\u001b[0m [Client 6] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38340)\u001b[0m [Client 87] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38337)\u001b[0m [Client 93] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38341)\u001b[0m [Client 77] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38338)\u001b[0m [Client 11] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38339)\u001b[0m [Client 59] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38340)\u001b[0m [Client 19] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38334)\u001b[0m [Client 69] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38341)\u001b[0m [Client 76] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38336)\u001b[0m [Client 12] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38338)\u001b[0m [Client 67] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38339)\u001b[0m [Client 79] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38340)\u001b[0m [Client 4] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38337)\u001b[0m [Client 17] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38335)\u001b[0m [Client 22] evaluate, config: {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 12:25:12,018 | server.py:170 | evaluate_round received 0 results and 30 failures\n",
      "DEBUG flower 2023-02-01 12:25:12,019 | server.py:203 | fit_round: strategy sampled 30 clients (out of 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38338)\u001b[0m [Client 84] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38339)\u001b[0m [Client 30] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38340)\u001b[0m [Client 3] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38337)\u001b[0m [Client 44] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38335)\u001b[0m [Client 20] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m [Client 13] fit, config: {'current_round': 84, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m [Client 17] fit, config: {'current_round': 84, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m Epoch 1: train loss 8.369636634597555e-05, accuracy 0.7777777777777778\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m Epoch 1: train loss 5.1199214794905856e-05, accuracy 0.8518518518518519\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m [Client 75] fit, config: {'current_round': 84, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m Epoch 1: train loss 4.906288450001739e-05, accuracy 0.8888888888888888\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m [Client 8] fit, config: {'current_round': 84, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m Epoch 1: train loss 5.879378295503557e-05, accuracy 0.8148148148148148\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m [Client 99] fit, config: {'current_round': 84, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m [Client 6] fit, config: {'current_round': 84, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m Epoch 1: train loss 5.0711940275505185e-05, accuracy 0.8333333333333334\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m [Client 12] fit, config: {'current_round': 84, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m [Client 63] fit, config: {'current_round': 84, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m Epoch 1: train loss 5.078918911749497e-05, accuracy 0.8148148148148148\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m Epoch 1: train loss 4.878423715126701e-05, accuracy 0.8703703703703703\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m Epoch 1: train loss 3.7401841836981475e-05, accuracy 0.9074074074074074\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m [Client 89] fit, config: {'current_round': 84, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m Epoch 1: train loss 7.872673450037837e-05, accuracy 0.7962962962962963\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m [Client 38] fit, config: {'current_round': 84, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m Epoch 1: train loss 3.806831955444068e-05, accuracy 0.9259259259259259\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m [Client 64] fit, config: {'current_round': 84, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m Epoch 1: train loss 6.954040873097256e-05, accuracy 0.7777777777777778\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m [Client 52] fit, config: {'current_round': 84, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m Epoch 1: train loss 5.259062527329661e-05, accuracy 0.8518518518518519\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m [Client 79] fit, config: {'current_round': 84, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m [Client 97] fit, config: {'current_round': 84, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m Epoch 1: train loss 4.8242149205179885e-05, accuracy 0.8333333333333334\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m Epoch 1: train loss 4.71787279821001e-05, accuracy 0.8148148148148148\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m [Client 77] fit, config: {'current_round': 84, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m Epoch 1: train loss 5.127968324813992e-05, accuracy 0.8518518518518519\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m [Client 15] fit, config: {'current_round': 84, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m Epoch 1: train loss 3.706991992658004e-05, accuracy 0.8703703703703703\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m [Client 42] fit, config: {'current_round': 84, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m Epoch 1: train loss 7.532465679105371e-05, accuracy 0.7592592592592593\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m [Client 66] fit, config: {'current_round': 84, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m Epoch 1: train loss 3.771643969230354e-05, accuracy 0.8703703703703703\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m [Client 47] fit, config: {'current_round': 84, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m [Client 84] fit, config: {'current_round': 84, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m Epoch 1: train loss 6.546863005496562e-05, accuracy 0.7962962962962963\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m Epoch 1: train loss 6.534672138513997e-05, accuracy 0.8518518518518519\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m [Client 24] fit, config: {'current_round': 84, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m [Client 22] fit, config: {'current_round': 84, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m Epoch 1: train loss 4.1972860344685614e-05, accuracy 0.8703703703703703\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m Epoch 1: train loss 6.340938853099942e-05, accuracy 0.7777777777777778\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m [Client 10] fit, config: {'current_round': 84, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m Epoch 1: train loss 5.992232036078349e-05, accuracy 0.7777777777777778\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m [Client 60] fit, config: {'current_round': 84, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m [Client 82] fit, config: {'current_round': 84, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m [Client 50] fit, config: {'current_round': 84, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m Epoch 1: train loss 4.900730709778145e-05, accuracy 0.7962962962962963\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m Epoch 1: train loss 5.7259745517512783e-05, accuracy 0.7407407407407407\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m [Client 78] fit, config: {'current_round': 84, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m Epoch 1: train loss 8.61583321238868e-05, accuracy 0.7962962962962963\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 12:25:14,951 | server.py:216 | fit_round received 30 results and 0 failures\n",
      "DEBUG flower 2023-02-01 12:25:15,039 | server.py:157 | evaluate_round: strategy sampled 30 clients (out of 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m [Client 95] fit, config: {'current_round': 84, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m Epoch 1: train loss 4.657221143133938e-05, accuracy 0.8518518518518519\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m [Client 56] fit, config: {'current_round': 84, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m Epoch 1: train loss 6.894527177792042e-05, accuracy 0.7777777777777778\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m [Client 90] fit, config: {'current_round': 84, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m Epoch 1: train loss 5.841860911459662e-05, accuracy 0.7222222222222222\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m Epoch 1: train loss 4.148097650613636e-05, accuracy 0.9074074074074074\n",
      "Saving round 84 aggregated_parameters...\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38341)\u001b[0m [Client 58] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38341)\u001b[0m [Client 45] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38336)\u001b[0m [Client 38] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38339)\u001b[0m [Client 90] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38341)\u001b[0m [Client 56] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38341)\u001b[0m [Client 71] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38339)\u001b[0m [Client 8] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38341)\u001b[0m [Client 16] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38341)\u001b[0m [Client 89] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38336)\u001b[0m [Client 65] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38341)\u001b[0m [Client 19] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38339)\u001b[0m [Client 26] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38337)\u001b[0m [Client 87] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38336)\u001b[0m [Client 80] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38336)\u001b[0m [Client 17] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38336)\u001b[0m [Client 81] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38336)\u001b[0m [Client 32] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38339)\u001b[0m [Client 74] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38337)\u001b[0m [Client 24] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38336)\u001b[0m [Client 75] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38339)\u001b[0m [Client 35] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38336)\u001b[0m [Client 40] evaluate, config: {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 12:25:17,859 | server.py:170 | evaluate_round received 0 results and 30 failures\n",
      "DEBUG flower 2023-02-01 12:25:17,861 | server.py:203 | fit_round: strategy sampled 30 clients (out of 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38338)\u001b[0m [Client 54] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38340)\u001b[0m [Client 84] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38337)\u001b[0m [Client 15] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38334)\u001b[0m [Client 88] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38341)\u001b[0m [Client 85] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38336)\u001b[0m [Client 64] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38339)\u001b[0m [Client 9] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38335)\u001b[0m [Client 63] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m [Client 54] fit, config: {'current_round': 85, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m Epoch 1: train loss 5.545009844354354e-05, accuracy 0.8148148148148148\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m [Client 29] fit, config: {'current_round': 85, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m [Client 36] fit, config: {'current_round': 85, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m Epoch 1: train loss 5.4136246035341173e-05, accuracy 0.8148148148148148\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m [Client 81] fit, config: {'current_round': 85, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m [Client 2] fit, config: {'current_round': 85, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m Epoch 1: train loss 4.365637505543418e-05, accuracy 0.8518518518518519\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m [Client 87] fit, config: {'current_round': 85, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m Epoch 1: train loss 5.3564370318781585e-05, accuracy 0.8148148148148148\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m [Client 31] fit, config: {'current_round': 85, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m Epoch 1: train loss 5.016478826291859e-05, accuracy 0.8518518518518519\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m [Client 30] fit, config: {'current_round': 85, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m [Client 5] fit, config: {'current_round': 85, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m Epoch 1: train loss 5.463917113956995e-05, accuracy 0.7777777777777778\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m [Client 56] fit, config: {'current_round': 85, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m Epoch 1: train loss 7.447326788678765e-05, accuracy 0.7962962962962963\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m Epoch 1: train loss 4.2692929127952084e-05, accuracy 0.8888888888888888\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m [Client 97] fit, config: {'current_round': 85, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m Epoch 1: train loss 5.135196988703683e-05, accuracy 0.8148148148148148\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m Epoch 1: train loss 5.957691610092297e-05, accuracy 0.8333333333333334\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m Epoch 1: train loss 4.435648588696495e-05, accuracy 0.8518518518518519\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m [Client 70] fit, config: {'current_round': 85, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m Epoch 1: train loss 5.512957432074472e-05, accuracy 0.8148148148148148\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m [Client 68] fit, config: {'current_round': 85, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m Epoch 1: train loss 5.735785816796124e-05, accuracy 0.8148148148148148\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m [Client 77] fit, config: {'current_round': 85, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m Epoch 1: train loss 7.054889283608645e-05, accuracy 0.7222222222222222\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m [Client 23] fit, config: {'current_round': 85, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m Epoch 1: train loss 6.629863491980359e-05, accuracy 0.7037037037037037\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m [Client 91] fit, config: {'current_round': 85, 'local_epochs': 3}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 12:25:21,021 | server.py:216 | fit_round received 30 results and 0 failures\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m [Client 73] fit, config: {'current_round': 85, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m Epoch 1: train loss 5.4159299907041714e-05, accuracy 0.8518518518518519\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m [Client 72] fit, config: {'current_round': 85, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m Epoch 1: train loss 2.9182094294810668e-05, accuracy 0.9259259259259259\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m Epoch 1: train loss 4.546618220047094e-05, accuracy 0.8888888888888888\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m [Client 83] fit, config: {'current_round': 85, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m [Client 88] fit, config: {'current_round': 85, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m [Client 65] fit, config: {'current_round': 85, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m [Client 27] fit, config: {'current_round': 85, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m Epoch 1: train loss 3.8158450479386374e-05, accuracy 0.9074074074074074\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m [Client 32] fit, config: {'current_round': 85, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m Epoch 1: train loss 5.5134987633209676e-05, accuracy 0.8518518518518519\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m [Client 11] fit, config: {'current_round': 85, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m Epoch 1: train loss 6.393628427758813e-05, accuracy 0.7592592592592593\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m Epoch 1: train loss 4.17702722188551e-05, accuracy 0.8888888888888888\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m [Client 46] fit, config: {'current_round': 85, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m Epoch 1: train loss 5.445618080557324e-05, accuracy 0.7407407407407407\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m Epoch 1: train loss 6.471729284385219e-05, accuracy 0.8333333333333334\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m Epoch 1: train loss 6.339710671454668e-05, accuracy 0.8148148148148148\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m [Client 69] fit, config: {'current_round': 85, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m [Client 48] fit, config: {'current_round': 85, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m Epoch 1: train loss 5.287140447762795e-05, accuracy 0.8148148148148148\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m [Client 18] fit, config: {'current_round': 85, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m Epoch 1: train loss 5.608681385638192e-05, accuracy 0.7777777777777778\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 12:25:21,094 | server.py:157 | evaluate_round: strategy sampled 30 clients (out of 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m [Client 16] fit, config: {'current_round': 85, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m Epoch 1: train loss 5.7744204241316766e-05, accuracy 0.7962962962962963\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m Epoch 1: train loss 4.4357602746458724e-05, accuracy 0.8148148148148148\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m [Client 38] fit, config: {'current_round': 85, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m Epoch 1: train loss 4.460961645236239e-05, accuracy 0.8518518518518519\n",
      "Saving round 85 aggregated_parameters...\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38338)\u001b[0m [Client 76] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38339)\u001b[0m [Client 16] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38337)\u001b[0m [Client 41] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38334)\u001b[0m [Client 69] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38337)\u001b[0m [Client 72] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38334)\u001b[0m [Client 39] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38334)\u001b[0m [Client 79] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38338)\u001b[0m [Client 17] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38337)\u001b[0m [Client 25] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38337)\u001b[0m [Client 36] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38337)\u001b[0m [Client 63] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38334)\u001b[0m [Client 42] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38337)\u001b[0m [Client 12] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38334)\u001b[0m [Client 34] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38338)\u001b[0m [Client 28] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38339)\u001b[0m [Client 5] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38337)\u001b[0m [Client 92] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38338)\u001b[0m [Client 40] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38337)\u001b[0m [Client 70] evaluate, config: {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 12:25:24,157 | server.py:170 | evaluate_round received 0 results and 30 failures\n",
      "DEBUG flower 2023-02-01 12:25:24,158 | server.py:203 | fit_round: strategy sampled 30 clients (out of 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38338)\u001b[0m [Client 97] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38336)\u001b[0m [Client 15] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38337)\u001b[0m [Client 77] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38334)\u001b[0m [Client 14] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38341)\u001b[0m [Client 6] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38338)\u001b[0m [Client 62] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38336)\u001b[0m [Client 3] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38339)\u001b[0m [Client 93] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38340)\u001b[0m [Client 11] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38337)\u001b[0m [Client 26] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38335)\u001b[0m [Client 59] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m [Client 68] fit, config: {'current_round': 86, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m Epoch 1: train loss 6.616933387704194e-05, accuracy 0.8148148148148148\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m [Client 92] fit, config: {'current_round': 86, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m [Client 96] fit, config: {'current_round': 86, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m Epoch 1: train loss 6.239922367967665e-05, accuracy 0.8888888888888888\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m [Client 36] fit, config: {'current_round': 86, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m Epoch 1: train loss 3.4891821997007355e-05, accuracy 0.8888888888888888\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m [Client 55] fit, config: {'current_round': 86, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m Epoch 1: train loss 5.9243797295494005e-05, accuracy 0.7962962962962963\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m Epoch 1: train loss 4.6915392886148766e-05, accuracy 0.8518518518518519\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m [Client 17] fit, config: {'current_round': 86, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m Epoch 1: train loss 8.804969547782093e-05, accuracy 0.7592592592592593\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m [Client 16] fit, config: {'current_round': 86, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m Epoch 1: train loss 6.0783870139857754e-05, accuracy 0.8518518518518519\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m [Client 86] fit, config: {'current_round': 86, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m Epoch 1: train loss 5.8297264331486076e-05, accuracy 0.8333333333333334\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m [Client 58] fit, config: {'current_round': 86, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m [Client 4] fit, config: {'current_round': 86, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m Epoch 1: train loss 3.843879312626086e-05, accuracy 0.9259259259259259\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m [Client 98] fit, config: {'current_round': 86, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m [Client 62] fit, config: {'current_round': 86, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m Epoch 1: train loss 6.478289287770167e-05, accuracy 0.7962962962962963\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m [Client 87] fit, config: {'current_round': 86, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m Epoch 1: train loss 6.189535633893684e-05, accuracy 0.7592592592592593\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m [Client 65] fit, config: {'current_round': 86, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m [Client 85] fit, config: {'current_round': 86, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m [Client 23] fit, config: {'current_round': 86, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m Epoch 1: train loss 4.961543527315371e-05, accuracy 0.8703703703703703\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m Epoch 1: train loss 5.761282955063507e-05, accuracy 0.8518518518518519\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m Epoch 1: train loss 6.916037091286853e-05, accuracy 0.7407407407407407\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m [Client 32] fit, config: {'current_round': 86, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m Epoch 1: train loss 2.917926394729875e-05, accuracy 0.9259259259259259\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m [Client 77] fit, config: {'current_round': 86, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m Epoch 1: train loss 5.111338396091014e-05, accuracy 0.8333333333333334\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m [Client 67] fit, config: {'current_round': 86, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m Epoch 1: train loss 5.818846693728119e-05, accuracy 0.8333333333333334\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m Epoch 1: train loss 4.886500391876325e-05, accuracy 0.7962962962962963\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m [Client 76] fit, config: {'current_round': 86, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m Epoch 1: train loss 5.4241620091488585e-05, accuracy 0.8148148148148148\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m Epoch 1: train loss 5.492052878253162e-05, accuracy 0.8518518518518519\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m [Client 2] fit, config: {'current_round': 86, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m Epoch 1: train loss 3.791155540966429e-05, accuracy 0.8888888888888888\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m [Client 82] fit, config: {'current_round': 86, 'local_epochs': 3}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 12:25:26,938 | server.py:216 | fit_round received 30 results and 0 failures\n",
      "DEBUG flower 2023-02-01 12:25:27,000 | server.py:157 | evaluate_round: strategy sampled 30 clients (out of 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m Epoch 1: train loss 5.997936023049988e-05, accuracy 0.7592592592592593\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m [Client 80] fit, config: {'current_round': 86, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m [Client 10] fit, config: {'current_round': 86, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m Epoch 1: train loss 6.0257665609242395e-05, accuracy 0.7407407407407407\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m [Client 48] fit, config: {'current_round': 86, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m Epoch 1: train loss 3.729950913111679e-05, accuracy 0.9259259259259259\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m [Client 34] fit, config: {'current_round': 86, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m [Client 90] fit, config: {'current_round': 86, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m Epoch 1: train loss 5.58860701858066e-05, accuracy 0.7222222222222222\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m [Client 33] fit, config: {'current_round': 86, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m Epoch 1: train loss 6.730373570462689e-05, accuracy 0.8148148148148148\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m [Client 78] fit, config: {'current_round': 86, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m Epoch 1: train loss 4.496270412346348e-05, accuracy 0.8703703703703703\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m Epoch 1: train loss 4.069988790433854e-05, accuracy 0.9074074074074074\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m [Client 27] fit, config: {'current_round': 86, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m Epoch 1: train loss 6.563725764863193e-05, accuracy 0.8518518518518519\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m Epoch 1: train loss 7.978362555149943e-05, accuracy 0.7962962962962963\n",
      "Saving round 86 aggregated_parameters...\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38334)\u001b[0m [Client 83] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38341)\u001b[0m [Client 22] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38341)\u001b[0m [Client 47] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38334)\u001b[0m [Client 7] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38341)\u001b[0m [Client 41] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38341)\u001b[0m [Client 82] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38341)\u001b[0m [Client 69] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38341)\u001b[0m [Client 48] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38336)\u001b[0m [Client 45] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38334)\u001b[0m [Client 92] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38341)\u001b[0m [Client 49] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38338)\u001b[0m [Client 89] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38337)\u001b[0m [Client 85] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38334)\u001b[0m [Client 4] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38341)\u001b[0m [Client 67] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38337)\u001b[0m [Client 42] evaluate, config: {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 12:25:29,400 | server.py:170 | evaluate_round received 0 results and 30 failures\n",
      "DEBUG flower 2023-02-01 12:25:29,401 | server.py:203 | fit_round: strategy sampled 30 clients (out of 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38334)\u001b[0m [Client 78] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38341)\u001b[0m [Client 0] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38338)\u001b[0m [Client 11] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38340)\u001b[0m [Client 13] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38337)\u001b[0m [Client 8] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38334)\u001b[0m [Client 91] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38341)\u001b[0m [Client 12] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38336)\u001b[0m [Client 15] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38339)\u001b[0m [Client 29] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38340)\u001b[0m [Client 21] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38337)\u001b[0m [Client 75] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38335)\u001b[0m [Client 88] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38340)\u001b[0m [Client 86] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38335)\u001b[0m [Client 9] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m [Client 18] fit, config: {'current_round': 87, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m Epoch 1: train loss 5.709938341169618e-05, accuracy 0.7777777777777778\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m [Client 64] fit, config: {'current_round': 87, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m [Client 50] fit, config: {'current_round': 87, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m Epoch 1: train loss 6.726427818648517e-05, accuracy 0.8148148148148148\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m Epoch 1: train loss 5.371054430725053e-05, accuracy 0.8333333333333334\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m [Client 30] fit, config: {'current_round': 87, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m Epoch 1: train loss 7.35570429242216e-05, accuracy 0.7962962962962963\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m [Client 24] fit, config: {'current_round': 87, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m Epoch 1: train loss 5.1849849114660174e-05, accuracy 0.8333333333333334\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m [Client 14] fit, config: {'current_round': 87, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m Epoch 1: train loss 5.8470141084399074e-05, accuracy 0.7592592592592593\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m [Client 13] fit, config: {'current_round': 87, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m [Client 46] fit, config: {'current_round': 87, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m Epoch 1: train loss 5.3373169066617265e-05, accuracy 0.7222222222222222\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m Epoch 1: train loss 5.368434722186066e-05, accuracy 0.8333333333333334\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m [Client 6] fit, config: {'current_round': 87, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m Epoch 1: train loss 5.9644542488968e-05, accuracy 0.8148148148148148\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m [Client 33] fit, config: {'current_round': 87, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m Epoch 1: train loss 4.968318171449937e-05, accuracy 0.8148148148148148\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m [Client 29] fit, config: {'current_round': 87, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m Epoch 1: train loss 4.368042209534906e-05, accuracy 0.8518518518518519\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m [Client 68] fit, config: {'current_round': 87, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m Epoch 1: train loss 5.613981920760125e-05, accuracy 0.7962962962962963\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m [Client 73] fit, config: {'current_round': 87, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m Epoch 1: train loss 5.4107571486383677e-05, accuracy 0.8148148148148148\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m [Client 15] fit, config: {'current_round': 87, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m [Client 83] fit, config: {'current_round': 87, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m [Client 21] fit, config: {'current_round': 87, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m Epoch 1: train loss 5.3270719945430756e-05, accuracy 0.8148148148148148\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m [Client 52] fit, config: {'current_round': 87, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m Epoch 1: train loss 6.609878619201481e-05, accuracy 0.7592592592592593\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m [Client 10] fit, config: {'current_round': 87, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m [Client 27] fit, config: {'current_round': 87, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m Epoch 1: train loss 6.440644210670143e-05, accuracy 0.8333333333333334\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m [Client 40] fit, config: {'current_round': 87, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m [Client 49] fit, config: {'current_round': 87, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m Epoch 1: train loss 6.763728015357628e-05, accuracy 0.7407407407407407\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m Epoch 1: train loss 5.426385541795753e-05, accuracy 0.8518518518518519\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m Epoch 1: train loss 6.452117668231949e-05, accuracy 0.7592592592592593\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m Epoch 1: train loss 5.652469917549752e-05, accuracy 0.8148148148148148\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m Epoch 1: train loss 3.219353311578743e-05, accuracy 0.8518518518518519\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m [Client 56] fit, config: {'current_round': 87, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m Epoch 1: train loss 5.851601963513531e-05, accuracy 0.8333333333333334\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m [Client 55] fit, config: {'current_round': 87, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m [Client 44] fit, config: {'current_round': 87, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m [Client 76] fit, config: {'current_round': 87, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m Epoch 1: train loss 4.251428254065104e-05, accuracy 0.8703703703703703\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 12:25:32,066 | server.py:216 | fit_round received 30 results and 0 failures\n",
      "DEBUG flower 2023-02-01 12:25:32,124 | server.py:157 | evaluate_round: strategy sampled 30 clients (out of 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m [Client 90] fit, config: {'current_round': 87, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m Epoch 1: train loss 5.300990233081393e-05, accuracy 0.7962962962962963\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m [Client 93] fit, config: {'current_round': 87, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m Epoch 1: train loss 5.455612699734047e-05, accuracy 0.7592592592592593\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m [Client 53] fit, config: {'current_round': 87, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m [Client 39] fit, config: {'current_round': 87, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m Epoch 1: train loss 5.4627449571853504e-05, accuracy 0.8333333333333334\n",
      "Saving round 87 aggregated_parameters...\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m Epoch 1: train loss 5.222901017987169e-05, accuracy 0.7777777777777778\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m Epoch 1: train loss 5.579863136517815e-05, accuracy 0.7962962962962963\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m Epoch 1: train loss 7.857579475967214e-05, accuracy 0.7222222222222222\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m [Client 20] fit, config: {'current_round': 87, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m Epoch 1: train loss 5.419871740741655e-05, accuracy 0.7962962962962963\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38337)\u001b[0m [Client 70] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38338)\u001b[0m [Client 79] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38334)\u001b[0m [Client 74] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38339)\u001b[0m [Client 56] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38340)\u001b[0m [Client 93] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38337)\u001b[0m [Client 99] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38340)\u001b[0m [Client 20] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38337)\u001b[0m [Client 67] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38334)\u001b[0m [Client 2] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38339)\u001b[0m [Client 27] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38334)\u001b[0m [Client 33] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38339)\u001b[0m [Client 49] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38337)\u001b[0m [Client 39] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38334)\u001b[0m [Client 32] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38338)\u001b[0m [Client 7] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38339)\u001b[0m [Client 90] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38340)\u001b[0m [Client 81] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38337)\u001b[0m [Client 29] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38341)\u001b[0m [Client 96] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38341)\u001b[0m [Client 48] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38334)\u001b[0m [Client 19] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38341)\u001b[0m [Client 28] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38340)\u001b[0m [Client 68] evaluate, config: {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 12:25:34,839 | server.py:170 | evaluate_round received 0 results and 30 failures\n",
      "DEBUG flower 2023-02-01 12:25:34,841 | server.py:203 | fit_round: strategy sampled 30 clients (out of 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38336)\u001b[0m [Client 92] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38337)\u001b[0m [Client 25] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38334)\u001b[0m [Client 62] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38341)\u001b[0m [Client 0] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38338)\u001b[0m [Client 80] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38339)\u001b[0m [Client 83] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38340)\u001b[0m [Client 26] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m [Client 56] fit, config: {'current_round': 88, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m [Client 86] fit, config: {'current_round': 88, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m [Client 7] fit, config: {'current_round': 88, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m Epoch 1: train loss 5.1031958719249815e-05, accuracy 0.8148148148148148\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m Epoch 1: train loss 6.400512211257592e-05, accuracy 0.7962962962962963\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m Epoch 1: train loss 5.865309140062891e-05, accuracy 0.8148148148148148\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m [Client 46] fit, config: {'current_round': 88, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m Epoch 1: train loss 4.5689423131989315e-05, accuracy 0.8703703703703703\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m [Client 69] fit, config: {'current_round': 88, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m [Client 73] fit, config: {'current_round': 88, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m [Client 6] fit, config: {'current_round': 88, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m Epoch 1: train loss 4.86832250317093e-05, accuracy 0.8333333333333334\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m Epoch 1: train loss 5.99920931563247e-05, accuracy 0.7777777777777778\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m [Client 95] fit, config: {'current_round': 88, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m Epoch 1: train loss 4.8823116230778396e-05, accuracy 0.8703703703703703\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m [Client 16] fit, config: {'current_round': 88, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m Epoch 1: train loss 4.452990833669901e-05, accuracy 0.8703703703703703\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m Epoch 1: train loss 6.222844967851415e-05, accuracy 0.8333333333333334\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m [Client 91] fit, config: {'current_round': 88, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m [Client 96] fit, config: {'current_round': 88, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m Epoch 1: train loss 6.020333239575848e-05, accuracy 0.8888888888888888\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m [Client 89] fit, config: {'current_round': 88, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m [Client 80] fit, config: {'current_round': 88, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m Epoch 1: train loss 3.9491711504524574e-05, accuracy 0.9074074074074074\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m [Client 8] fit, config: {'current_round': 88, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m Epoch 1: train loss 5.6285316532012075e-05, accuracy 0.8333333333333334\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m Epoch 1: train loss 2.0361780116218142e-05, accuracy 0.9814814814814815\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m Epoch 1: train loss 7.787864888086915e-05, accuracy 0.7777777777777778\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m [Client 85] fit, config: {'current_round': 88, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m Epoch 1: train loss 2.8663911507464945e-05, accuracy 0.8888888888888888\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m [Client 81] fit, config: {'current_round': 88, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m Epoch 1: train loss 5.842019891133532e-05, accuracy 0.8333333333333334\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m [Client 57] fit, config: {'current_round': 88, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m [Client 11] fit, config: {'current_round': 88, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m Epoch 1: train loss 4.945712862536311e-05, accuracy 0.8333333333333334\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m Epoch 1: train loss 3.361349808983505e-05, accuracy 0.8518518518518519\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m [Client 12] fit, config: {'current_round': 88, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m [Client 35] fit, config: {'current_round': 88, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m [Client 84] fit, config: {'current_round': 88, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m Epoch 1: train loss 3.67925240425393e-05, accuracy 0.9074074074074074\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m Epoch 1: train loss 6.085988206905313e-05, accuracy 0.8148148148148148\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m [Client 79] fit, config: {'current_round': 88, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m Epoch 1: train loss 6.351606862153858e-05, accuracy 0.8333333333333334\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m [Client 25] fit, config: {'current_round': 88, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m [Client 1] fit, config: {'current_round': 88, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m Epoch 1: train loss 2.6628622435964644e-05, accuracy 0.9074074074074074\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 12:25:37,533 | server.py:216 | fit_round received 30 results and 0 failures\n",
      "DEBUG flower 2023-02-01 12:25:37,604 | server.py:157 | evaluate_round: strategy sampled 30 clients (out of 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m [Client 78] fit, config: {'current_round': 88, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m Epoch 1: train loss 4.547851131064817e-05, accuracy 0.8518518518518519\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m [Client 17] fit, config: {'current_round': 88, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m [Client 60] fit, config: {'current_round': 88, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m Epoch 1: train loss 4.708360575023107e-05, accuracy 0.8148148148148148\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m Epoch 1: train loss 4.1932606109185144e-05, accuracy 0.8703703703703703\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m [Client 98] fit, config: {'current_round': 88, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m Epoch 1: train loss 5.9899542975472286e-05, accuracy 0.7777777777777778\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m Epoch 1: train loss 7.893212750786915e-05, accuracy 0.8148148148148148\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m Epoch 1: train loss 4.0281654946738854e-05, accuracy 0.9074074074074074\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m [Client 55] fit, config: {'current_round': 88, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m Epoch 1: train loss 5.306622551870532e-05, accuracy 0.7777777777777778\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m [Client 0] fit, config: {'current_round': 88, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m Epoch 1: train loss 5.9189431340200827e-05, accuracy 0.8148148148148148\n",
      "Saving round 88 aggregated_parameters...\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38335)\u001b[0m [Client 21] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38339)\u001b[0m [Client 63] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38335)\u001b[0m [Client 88] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38339)\u001b[0m [Client 55] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38339)\u001b[0m [Client 73] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38339)\u001b[0m [Client 27] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38339)\u001b[0m [Client 26] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38335)\u001b[0m [Client 72] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38334)\u001b[0m [Client 79] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38339)\u001b[0m [Client 30] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38339)\u001b[0m [Client 99] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38335)\u001b[0m [Client 7] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38334)\u001b[0m [Client 66] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38338)\u001b[0m [Client 50] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38335)\u001b[0m [Client 87] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38334)\u001b[0m [Client 33] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38338)\u001b[0m [Client 91] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38338)\u001b[0m [Client 54] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38334)\u001b[0m [Client 44] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38338)\u001b[0m [Client 81] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38334)\u001b[0m [Client 35] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38338)\u001b[0m [Client 56] evaluate, config: {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 12:25:40,100 | server.py:170 | evaluate_round received 0 results and 30 failures\n",
      "DEBUG flower 2023-02-01 12:25:40,102 | server.py:203 | fit_round: strategy sampled 30 clients (out of 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38334)\u001b[0m [Client 29] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38338)\u001b[0m [Client 3] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38336)\u001b[0m [Client 53] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38339)\u001b[0m [Client 84] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38337)\u001b[0m [Client 24] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38341)\u001b[0m [Client 20] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38340)\u001b[0m [Client 19] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38335)\u001b[0m [Client 47] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m [Client 13] fit, config: {'current_round': 89, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m Epoch 1: train loss 5.4435698984889314e-05, accuracy 0.8333333333333334\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m [Client 22] fit, config: {'current_round': 89, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m [Client 53] fit, config: {'current_round': 89, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m Epoch 1: train loss 5.249339301371947e-05, accuracy 0.8518518518518519\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m Epoch 1: train loss 6.663714884780347e-05, accuracy 0.7407407407407407\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m [Client 61] fit, config: {'current_round': 89, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m Epoch 1: train loss 7.646994345122948e-05, accuracy 0.7222222222222222\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m [Client 6] fit, config: {'current_round': 89, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m Epoch 1: train loss 5.708550088456832e-05, accuracy 0.8148148148148148\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m [Client 51] fit, config: {'current_round': 89, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m Epoch 1: train loss 7.213844219222665e-05, accuracy 0.7777777777777778\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m [Client 84] fit, config: {'current_round': 89, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m Epoch 1: train loss 5.6889788538683206e-05, accuracy 0.8148148148148148\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m [Client 46] fit, config: {'current_round': 89, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m [Client 62] fit, config: {'current_round': 89, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m [Client 34] fit, config: {'current_round': 89, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m Epoch 1: train loss 6.167357787489891e-05, accuracy 0.8518518518518519\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m Epoch 1: train loss 5.53696918359492e-05, accuracy 0.7407407407407407\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m Epoch 1: train loss 4.302800880395807e-05, accuracy 0.8333333333333334\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m [Client 95] fit, config: {'current_round': 89, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m [Client 79] fit, config: {'current_round': 89, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m Epoch 1: train loss 5.325439997250214e-05, accuracy 0.8333333333333334\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m [Client 3] fit, config: {'current_round': 89, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m Epoch 1: train loss 6.30408976576291e-05, accuracy 0.7592592592592593\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m [Client 85] fit, config: {'current_round': 89, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m Epoch 1: train loss 3.37180208589416e-05, accuracy 0.8888888888888888\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m Epoch 1: train loss 2.6975649234373122e-05, accuracy 0.9444444444444444\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m [Client 83] fit, config: {'current_round': 89, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m Epoch 1: train loss 5.434405829873867e-05, accuracy 0.8518518518518519\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m [Client 33] fit, config: {'current_round': 89, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m Epoch 1: train loss 5.331135253072716e-05, accuracy 0.7962962962962963\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m [Client 90] fit, config: {'current_round': 89, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m Epoch 1: train loss 5.5558866733917966e-05, accuracy 0.8333333333333334\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m [Client 23] fit, config: {'current_round': 89, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m Epoch 1: train loss 6.456796108977869e-05, accuracy 0.7222222222222222\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m [Client 49] fit, config: {'current_round': 89, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m Epoch 1: train loss 7.018340693321079e-05, accuracy 0.7407407407407407\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m [Client 77] fit, config: {'current_round': 89, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m Epoch 1: train loss 7.570004527224228e-05, accuracy 0.6851851851851852\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m [Client 48] fit, config: {'current_round': 89, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m Epoch 1: train loss 5.300094926496968e-05, accuracy 0.8518518518518519\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m [Client 87] fit, config: {'current_round': 89, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m [Client 89] fit, config: {'current_round': 89, 'local_epochs': 3}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 12:25:43,173 | server.py:216 | fit_round received 30 results and 0 failures\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m [Client 47] fit, config: {'current_round': 89, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m [Client 29] fit, config: {'current_round': 89, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m Epoch 1: train loss 4.402305057737976e-05, accuracy 0.8148148148148148\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m Epoch 1: train loss 4.7947924031177536e-05, accuracy 0.8148148148148148\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m [Client 16] fit, config: {'current_round': 89, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m Epoch 1: train loss 5.712301572202705e-05, accuracy 0.8148148148148148\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m Epoch 1: train loss 6.420285353669897e-05, accuracy 0.8148148148148148\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m [Client 24] fit, config: {'current_round': 89, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m [Client 17] fit, config: {'current_round': 89, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m Epoch 1: train loss 7.029810512904078e-05, accuracy 0.8148148148148148\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m Epoch 1: train loss 5.647445868817158e-05, accuracy 0.7777777777777778\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m [Client 39] fit, config: {'current_round': 89, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m [Client 4] fit, config: {'current_round': 89, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m Epoch 1: train loss 3.499291779007763e-05, accuracy 0.8888888888888888\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 12:25:43,263 | server.py:157 | evaluate_round: strategy sampled 30 clients (out of 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving round 89 aggregated_parameters...\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m Epoch 1: train loss 5.143774251337163e-05, accuracy 0.7777777777777778\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m Epoch 1: train loss 7.715821993770078e-05, accuracy 0.7222222222222222\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38337)\u001b[0m [Client 18] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38337)\u001b[0m [Client 78] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38337)\u001b[0m [Client 72] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38338)\u001b[0m [Client 70] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38337)\u001b[0m [Client 26] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38337)\u001b[0m [Client 19] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38338)\u001b[0m [Client 15] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38339)\u001b[0m [Client 56] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38337)\u001b[0m [Client 53] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38339)\u001b[0m [Client 67] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38338)\u001b[0m [Client 42] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38338)\u001b[0m [Client 92] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38338)\u001b[0m [Client 20] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38339)\u001b[0m [Client 13] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38337)\u001b[0m [Client 74] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38338)\u001b[0m [Client 85] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38337)\u001b[0m [Client 45] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38338)\u001b[0m [Client 54] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38337)\u001b[0m [Client 97] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38337)\u001b[0m [Client 59] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38338)\u001b[0m [Client 64] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38337)\u001b[0m [Client 21] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38338)\u001b[0m [Client 9] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38339)\u001b[0m [Client 98] evaluate, config: {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 12:25:46,180 | server.py:170 | evaluate_round received 0 results and 30 failures\n",
      "DEBUG flower 2023-02-01 12:25:46,182 | server.py:203 | fit_round: strategy sampled 30 clients (out of 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38334)\u001b[0m [Client 3] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38341)\u001b[0m [Client 41] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38340)\u001b[0m [Client 89] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38337)\u001b[0m [Client 23] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38336)\u001b[0m [Client 93] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38335)\u001b[0m [Client 73] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m [Client 53] fit, config: {'current_round': 90, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m Epoch 1: train loss 5.726132440031506e-05, accuracy 0.7592592592592593\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m [Client 1] fit, config: {'current_round': 90, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m [Client 90] fit, config: {'current_round': 90, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m Epoch 1: train loss 5.1298724429216236e-05, accuracy 0.7592592592592593\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m Epoch 1: train loss 2.575133112259209e-05, accuracy 0.9259259259259259\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m [Client 44] fit, config: {'current_round': 90, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m Epoch 1: train loss 3.595947055146098e-05, accuracy 0.8703703703703703\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m [Client 2] fit, config: {'current_round': 90, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m [Client 23] fit, config: {'current_round': 90, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m Epoch 1: train loss 4.76913082820829e-05, accuracy 0.8333333333333334\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m [Client 52] fit, config: {'current_round': 90, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m Epoch 1: train loss 3.4542645153123885e-05, accuracy 0.8888888888888888\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m [Client 22] fit, config: {'current_round': 90, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m Epoch 1: train loss 5.950322884018533e-05, accuracy 0.7962962962962963\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m Epoch 1: train loss 4.803147749044001e-05, accuracy 0.8703703703703703\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m [Client 3] fit, config: {'current_round': 90, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m Epoch 1: train loss 5.126656833454035e-05, accuracy 0.8148148148148148\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m [Client 71] fit, config: {'current_round': 90, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m Epoch 1: train loss 3.927421130356379e-05, accuracy 0.8703703703703703\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m [Client 77] fit, config: {'current_round': 90, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m [Client 87] fit, config: {'current_round': 90, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m [Client 64] fit, config: {'current_round': 90, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m Epoch 1: train loss 4.5046959712635726e-05, accuracy 0.8703703703703703\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m [Client 26] fit, config: {'current_round': 90, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m Epoch 1: train loss 6.330919859465212e-05, accuracy 0.8148148148148148\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m Epoch 1: train loss 4.653768701246008e-05, accuracy 0.8333333333333334\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m Epoch 1: train loss 6.721226964145899e-05, accuracy 0.7592592592592593\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m [Client 54] fit, config: {'current_round': 90, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m Epoch 1: train loss 5.023276753490791e-05, accuracy 0.8148148148148148\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m [Client 29] fit, config: {'current_round': 90, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m [Client 84] fit, config: {'current_round': 90, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m [Client 59] fit, config: {'current_round': 90, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m [Client 33] fit, config: {'current_round': 90, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m Epoch 1: train loss 5.728585892939009e-05, accuracy 0.8518518518518519\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m [Client 85] fit, config: {'current_round': 90, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m Epoch 1: train loss 2.4751567252678797e-05, accuracy 0.9259259259259259\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m Epoch 1: train loss 3.797906538238749e-05, accuracy 0.8703703703703703\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m Epoch 1: train loss 6.16915785940364e-05, accuracy 0.8518518518518519\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m [Client 47] fit, config: {'current_round': 90, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m Epoch 1: train loss 6.469237996498123e-05, accuracy 0.8333333333333334\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m Epoch 1: train loss 6.336963997455314e-05, accuracy 0.8518518518518519\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m [Client 49] fit, config: {'current_round': 90, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m Epoch 1: train loss 4.161897595622577e-05, accuracy 0.9259259259259259\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m [Client 70] fit, config: {'current_round': 90, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m Epoch 1: train loss 5.534043884836137e-05, accuracy 0.7962962962962963\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m [Client 7] fit, config: {'current_round': 90, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m Epoch 1: train loss 4.950008224113844e-05, accuracy 0.8333333333333334\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m [Client 58] fit, config: {'current_round': 90, 'local_epochs': 3}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 12:25:49,335 | server.py:216 | fit_round received 30 results and 0 failures\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m [Client 16] fit, config: {'current_round': 90, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m Epoch 1: train loss 5.8770179748535156e-05, accuracy 0.8518518518518519\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m Epoch 1: train loss 6.639268394792452e-05, accuracy 0.7962962962962963\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m [Client 96] fit, config: {'current_round': 90, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m [Client 94] fit, config: {'current_round': 90, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m Epoch 1: train loss 4.576687206281349e-05, accuracy 0.8703703703703703\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m [Client 0] fit, config: {'current_round': 90, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m Epoch 1: train loss 5.838866127305664e-05, accuracy 0.8148148148148148\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m [Client 50] fit, config: {'current_round': 90, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m Epoch 1: train loss 5.858222357346676e-05, accuracy 0.8888888888888888\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 12:25:49,425 | server.py:157 | evaluate_round: strategy sampled 30 clients (out of 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m Epoch 1: train loss 8.560970309190452e-05, accuracy 0.7592592592592593\n",
      "Saving round 90 aggregated_parameters...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(raylet)\u001b[0m Spilled 262353 MiB, 8594 objects, write throughput 1020 MiB/s.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38336)\u001b[0m [Client 39] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38339)\u001b[0m [Client 21] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38334)\u001b[0m [Client 29] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38334)\u001b[0m [Client 76] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38336)\u001b[0m [Client 67] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38334)\u001b[0m [Client 72] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38334)\u001b[0m [Client 93] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38336)\u001b[0m [Client 4] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38339)\u001b[0m [Client 88] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38340)\u001b[0m [Client 75] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38337)\u001b[0m [Client 6] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38337)\u001b[0m [Client 17] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38340)\u001b[0m [Client 91] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38340)\u001b[0m [Client 22] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38337)\u001b[0m [Client 18] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38339)\u001b[0m [Client 83] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38340)\u001b[0m [Client 87] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38337)\u001b[0m [Client 70] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38334)\u001b[0m [Client 34] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38337)\u001b[0m [Client 53] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38334)\u001b[0m [Client 94] evaluate, config: {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 12:25:52,445 | server.py:170 | evaluate_round received 0 results and 30 failures\n",
      "DEBUG flower 2023-02-01 12:25:52,446 | server.py:203 | fit_round: strategy sampled 30 clients (out of 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38334)\u001b[0m [Client 69] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38341)\u001b[0m [Client 96] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38336)\u001b[0m [Client 80] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38339)\u001b[0m [Client 20] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38340)\u001b[0m [Client 61] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38337)\u001b[0m [Client 14] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38334)\u001b[0m [Client 33] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38338)\u001b[0m [Client 97] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38335)\u001b[0m [Client 71] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m [Client 81] fit, config: {'current_round': 91, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m [Client 78] fit, config: {'current_round': 91, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m Epoch 1: train loss 5.086031524115242e-05, accuracy 0.8333333333333334\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m Epoch 1: train loss 3.27041998389177e-05, accuracy 0.9074074074074074\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m [Client 70] fit, config: {'current_round': 91, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m Epoch 1: train loss 5.313947258400731e-05, accuracy 0.8333333333333334\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m [Client 72] fit, config: {'current_round': 91, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m [Client 43] fit, config: {'current_round': 91, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m [Client 26] fit, config: {'current_round': 91, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m Epoch 1: train loss 6.180591299198568e-05, accuracy 0.8148148148148148\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m [Client 45] fit, config: {'current_round': 91, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m Epoch 1: train loss 4.192739652353339e-05, accuracy 0.8888888888888888\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m Epoch 1: train loss 4.259641355019994e-05, accuracy 0.9074074074074074\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m [Client 75] fit, config: {'current_round': 91, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m [Client 91] fit, config: {'current_round': 91, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m Epoch 1: train loss 5.9726484323618934e-05, accuracy 0.8333333333333334\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m [Client 77] fit, config: {'current_round': 91, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m Epoch 1: train loss 6.591723649762571e-05, accuracy 0.7222222222222222\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m Epoch 1: train loss 2.7390906325308606e-05, accuracy 0.9259259259259259\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m Epoch 1: train loss 7.255695527419448e-05, accuracy 0.7037037037037037\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m [Client 61] fit, config: {'current_round': 91, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m Epoch 1: train loss 7.420025212923065e-05, accuracy 0.7222222222222222\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m [Client 94] fit, config: {'current_round': 91, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m Epoch 1: train loss 4.3702868424588814e-05, accuracy 0.8518518518518519\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m [Client 50] fit, config: {'current_round': 91, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m Epoch 1: train loss 6.66902560624294e-05, accuracy 0.8148148148148148\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m [Client 41] fit, config: {'current_round': 91, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m [Client 88] fit, config: {'current_round': 91, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m Epoch 1: train loss 7.707862823735923e-05, accuracy 0.7222222222222222\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m [Client 2] fit, config: {'current_round': 91, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m [Client 66] fit, config: {'current_round': 91, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m Epoch 1: train loss 3.519458186929114e-05, accuracy 0.9074074074074074\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 12:25:55,888 | server.py:216 | fit_round received 30 results and 0 failures\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m Epoch 1: train loss 5.064818833488971e-05, accuracy 0.8333333333333334\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m [Client 35] fit, config: {'current_round': 91, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m [Client 17] fit, config: {'current_round': 91, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m [Client 40] fit, config: {'current_round': 91, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m Epoch 1: train loss 3.077852670685388e-05, accuracy 0.8888888888888888\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m [Client 22] fit, config: {'current_round': 91, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m Epoch 1: train loss 6.429196218959987e-05, accuracy 0.7592592592592593\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m [Client 96] fit, config: {'current_round': 91, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m Epoch 1: train loss 3.8237067201407626e-05, accuracy 0.8703703703703703\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m Epoch 1: train loss 6.248808495001867e-05, accuracy 0.7962962962962963\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m [Client 21] fit, config: {'current_round': 91, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m Epoch 1: train loss 5.190469164517708e-05, accuracy 0.8148148148148148\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m Epoch 1: train loss 4.0081671613734215e-05, accuracy 0.8703703703703703\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m Epoch 1: train loss 6.800991832278669e-05, accuracy 0.8518518518518519\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m [Client 57] fit, config: {'current_round': 91, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m Epoch 1: train loss 2.8099730116082355e-05, accuracy 0.9074074074074074\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m [Client 95] fit, config: {'current_round': 91, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m [Client 20] fit, config: {'current_round': 91, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m [Client 82] fit, config: {'current_round': 91, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m Epoch 1: train loss 6.339846731862053e-05, accuracy 0.7222222222222222\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m [Client 90] fit, config: {'current_round': 91, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m Epoch 1: train loss 5.2878789574606344e-05, accuracy 0.8148148148148148\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m Epoch 1: train loss 2.677369957382325e-05, accuracy 0.9444444444444444\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m [Client 55] fit, config: {'current_round': 91, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m Epoch 1: train loss 5.373493331717327e-05, accuracy 0.7962962962962963\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m [Client 65] fit, config: {'current_round': 91, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m Epoch 1: train loss 3.947145523852669e-05, accuracy 0.9074074074074074\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m Epoch 1: train loss 5.3539977670880035e-05, accuracy 0.7962962962962963\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 12:25:55,942 | server.py:157 | evaluate_round: strategy sampled 30 clients (out of 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving round 91 aggregated_parameters...\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38336)\u001b[0m [Client 84] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38341)\u001b[0m [Client 95] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38336)\u001b[0m [Client 94] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38341)\u001b[0m [Client 28] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38341)\u001b[0m [Client 77] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38336)\u001b[0m [Client 80] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38339)\u001b[0m [Client 22] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38334)\u001b[0m [Client 30] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38341)\u001b[0m [Client 52] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38336)\u001b[0m [Client 71] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38340)\u001b[0m [Client 99] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38338)\u001b[0m [Client 51] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38339)\u001b[0m [Client 46] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38340)\u001b[0m [Client 1] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38340)\u001b[0m [Client 23] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38338)\u001b[0m [Client 81] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38338)\u001b[0m [Client 85] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38338)\u001b[0m [Client 59] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38338)\u001b[0m [Client 60] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38339)\u001b[0m [Client 93] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38340)\u001b[0m [Client 27] evaluate, config: {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 12:25:58,516 | server.py:170 | evaluate_round received 0 results and 30 failures\n",
      "DEBUG flower 2023-02-01 12:25:58,518 | server.py:203 | fit_round: strategy sampled 30 clients (out of 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38336)\u001b[0m [Client 19] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38340)\u001b[0m [Client 6] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38335)\u001b[0m [Client 7] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38334)\u001b[0m [Client 42] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38341)\u001b[0m [Client 72] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38338)\u001b[0m [Client 50] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38339)\u001b[0m [Client 73] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38337)\u001b[0m [Client 26] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38335)\u001b[0m [Client 57] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m [Client 78] fit, config: {'current_round': 92, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m Epoch 1: train loss 3.8844769733259454e-05, accuracy 0.9074074074074074\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m [Client 26] fit, config: {'current_round': 92, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m Epoch 1: train loss 4.647275636671111e-05, accuracy 0.8518518518518519\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m [Client 27] fit, config: {'current_round': 92, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m Epoch 1: train loss 6.271949678193778e-05, accuracy 0.8333333333333334\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m [Client 46] fit, config: {'current_round': 92, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m [Client 67] fit, config: {'current_round': 92, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m Epoch 1: train loss 5.6568544096080586e-05, accuracy 0.8703703703703703\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m Epoch 1: train loss 4.3069172534160316e-05, accuracy 0.8703703703703703\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m [Client 49] fit, config: {'current_round': 92, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m Epoch 1: train loss 4.2425723222550005e-05, accuracy 0.9259259259259259\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m [Client 25] fit, config: {'current_round': 92, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m [Client 52] fit, config: {'current_round': 92, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m [Client 45] fit, config: {'current_round': 92, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m Epoch 1: train loss 4.71268649562262e-05, accuracy 0.8703703703703703\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m Epoch 1: train loss 3.97781259380281e-05, accuracy 0.9259259259259259\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m Epoch 1: train loss 4.827306111110374e-05, accuracy 0.8333333333333334\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m [Client 82] fit, config: {'current_round': 92, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m Epoch 1: train loss 5.788414637208916e-05, accuracy 0.7962962962962963\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m [Client 95] fit, config: {'current_round': 92, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m Epoch 1: train loss 4.346578134573065e-05, accuracy 0.8703703703703703\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m [Client 99] fit, config: {'current_round': 92, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m [Client 9] fit, config: {'current_round': 92, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m Epoch 1: train loss 4.672332579502836e-05, accuracy 0.8518518518518519\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m [Client 98] fit, config: {'current_round': 92, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m Epoch 1: train loss 5.881797187612392e-05, accuracy 0.7777777777777778\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m [Client 64] fit, config: {'current_round': 92, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m Epoch 1: train loss 5.338337359717116e-05, accuracy 0.8888888888888888\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m [Client 11] fit, config: {'current_round': 92, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m [Client 3] fit, config: {'current_round': 92, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m Epoch 1: train loss 5.1941602578153834e-05, accuracy 0.7962962962962963\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m [Client 15] fit, config: {'current_round': 92, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m Epoch 1: train loss 3.579682743293233e-05, accuracy 0.8703703703703703\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m [Client 74] fit, config: {'current_round': 92, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m [Client 59] fit, config: {'current_round': 92, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m Epoch 1: train loss 4.8282941861543804e-05, accuracy 0.8333333333333334\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m [Client 91] fit, config: {'current_round': 92, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m [Client 18] fit, config: {'current_round': 92, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m Epoch 1: train loss 5.0839607865782455e-05, accuracy 0.8333333333333334\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m [Client 96] fit, config: {'current_round': 92, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m Epoch 1: train loss 5.795919423690066e-05, accuracy 0.8888888888888888\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m Epoch 1: train loss 7.003634527791291e-05, accuracy 0.7592592592592593\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m Epoch 1: train loss 5.088250691187568e-05, accuracy 0.8333333333333334\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m Epoch 1: train loss 6.262445822358131e-05, accuracy 0.8518518518518519\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m Epoch 1: train loss 2.0811263311770745e-05, accuracy 0.9444444444444444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 12:26:01,391 | server.py:216 | fit_round received 30 results and 0 failures\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m [Client 97] fit, config: {'current_round': 92, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m Epoch 1: train loss 4.676021490013227e-05, accuracy 0.8148148148148148\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m [Client 50] fit, config: {'current_round': 92, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m [Client 47] fit, config: {'current_round': 92, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m Epoch 1: train loss 6.44588508293964e-05, accuracy 0.8148148148148148\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m Epoch 1: train loss 8.346737013198435e-05, accuracy 0.7777777777777778\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m [Client 75] fit, config: {'current_round': 92, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m Epoch 1: train loss 4.316387639846653e-05, accuracy 0.8888888888888888\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m [Client 37] fit, config: {'current_round': 92, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m Epoch 1: train loss 4.4924810936208814e-05, accuracy 0.8703703703703703\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m [Client 71] fit, config: {'current_round': 92, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m [Client 93] fit, config: {'current_round': 92, 'local_epochs': 3}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 12:26:01,515 | server.py:157 | evaluate_round: strategy sampled 30 clients (out of 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m Epoch 1: train loss 3.988748721894808e-05, accuracy 0.9074074074074074\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m Epoch 1: train loss 3.9615122659597546e-05, accuracy 0.8888888888888888\n",
      "Saving round 92 aggregated_parameters...\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38334)\u001b[0m [Client 38] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38337)\u001b[0m [Client 63] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38337)\u001b[0m [Client 55] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38334)\u001b[0m [Client 67] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38337)\u001b[0m [Client 34] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38334)\u001b[0m [Client 78] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38337)\u001b[0m [Client 84] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38334)\u001b[0m [Client 73] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38339)\u001b[0m [Client 44] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38340)\u001b[0m [Client 98] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38337)\u001b[0m [Client 29] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38339)\u001b[0m [Client 85] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38340)\u001b[0m [Client 11] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38339)\u001b[0m [Client 48] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38340)\u001b[0m [Client 53] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38334)\u001b[0m [Client 30] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38338)\u001b[0m [Client 88] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38337)\u001b[0m [Client 54] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38334)\u001b[0m [Client 66] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38334)\u001b[0m [Client 21] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38337)\u001b[0m [Client 62] evaluate, config: {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 12:26:04,036 | server.py:170 | evaluate_round received 0 results and 30 failures\n",
      "DEBUG flower 2023-02-01 12:26:04,037 | server.py:203 | fit_round: strategy sampled 30 clients (out of 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38334)\u001b[0m [Client 75] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38341)\u001b[0m [Client 86] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38336)\u001b[0m [Client 23] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38339)\u001b[0m [Client 56] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38340)\u001b[0m [Client 79] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38337)\u001b[0m [Client 35] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38335)\u001b[0m [Client 91] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38338)\u001b[0m [Client 64] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38340)\u001b[0m [Client 81] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m [Client 46] fit, config: {'current_round': 93, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m Epoch 1: train loss 5.139696440892294e-05, accuracy 0.7407407407407407\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m [Client 74] fit, config: {'current_round': 93, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m Epoch 1: train loss 4.9819962441688403e-05, accuracy 0.8148148148148148\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m [Client 65] fit, config: {'current_round': 93, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m Epoch 1: train loss 3.669948273454793e-05, accuracy 0.9074074074074074\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m [Client 56] fit, config: {'current_round': 93, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m Epoch 1: train loss 5.4853684559930116e-05, accuracy 0.8148148148148148\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m [Client 87] fit, config: {'current_round': 93, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m Epoch 1: train loss 4.662945502786897e-05, accuracy 0.8333333333333334\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m [Client 96] fit, config: {'current_round': 93, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m [Client 44] fit, config: {'current_round': 93, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m Epoch 1: train loss 5.222899198997766e-05, accuracy 0.7962962962962963\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m Epoch 1: train loss 6.171253335196525e-05, accuracy 0.8148148148148148\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m [Client 31] fit, config: {'current_round': 93, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m Epoch 1: train loss 4.498587077250704e-05, accuracy 0.8148148148148148\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m [Client 32] fit, config: {'current_round': 93, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m Epoch 1: train loss 5.647316720569506e-05, accuracy 0.8518518518518519\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m [Client 99] fit, config: {'current_round': 93, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m Epoch 1: train loss 6.22189327259548e-05, accuracy 0.7777777777777778\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m [Client 63] fit, config: {'current_round': 93, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m [Client 50] fit, config: {'current_round': 93, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m Epoch 1: train loss 6.499529990833253e-05, accuracy 0.7962962962962963\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m Epoch 1: train loss 4.090731454198249e-05, accuracy 0.9074074074074074\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m [Client 52] fit, config: {'current_round': 93, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m Epoch 1: train loss 6.105267675593495e-05, accuracy 0.7592592592592593\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m [Client 59] fit, config: {'current_round': 93, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m [Client 84] fit, config: {'current_round': 93, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m Epoch 1: train loss 5.2531464461935684e-05, accuracy 0.8148148148148148\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m [Client 82] fit, config: {'current_round': 93, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m [Client 36] fit, config: {'current_round': 93, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m Epoch 1: train loss 6.89471053192392e-05, accuracy 0.7962962962962963\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m [Client 98] fit, config: {'current_round': 93, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m Epoch 1: train loss 5.533980220207013e-05, accuracy 0.7962962962962963\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m Epoch 1: train loss 4.890160926152021e-05, accuracy 0.8148148148148148\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m [Client 53] fit, config: {'current_round': 93, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m Epoch 1: train loss 4.92640319862403e-05, accuracy 0.8703703703703703\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m [Client 77] fit, config: {'current_round': 93, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m Epoch 1: train loss 6.957073492230847e-05, accuracy 0.7407407407407407\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m [Client 14] fit, config: {'current_round': 93, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m Epoch 1: train loss 5.7574070524424314e-05, accuracy 0.7777777777777778\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m Epoch 1: train loss 5.1381473895162344e-05, accuracy 0.8148148148148148\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m [Client 70] fit, config: {'current_round': 93, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m [Client 26] fit, config: {'current_round': 93, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m Epoch 1: train loss 5.8110766985919327e-05, accuracy 0.7962962962962963\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m Epoch 1: train loss 5.166960181668401e-05, accuracy 0.8148148148148148\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m [Client 71] fit, config: {'current_round': 93, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m Epoch 1: train loss 4.392266055219807e-05, accuracy 0.8703703703703703\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 12:26:06,266 | server.py:216 | fit_round received 30 results and 0 failures\n",
      "DEBUG flower 2023-02-01 12:26:06,318 | server.py:157 | evaluate_round: strategy sampled 30 clients (out of 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m [Client 45] fit, config: {'current_round': 93, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m Epoch 1: train loss 4.009724216302857e-05, accuracy 0.9074074074074074\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m [Client 41] fit, config: {'current_round': 93, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m [Client 94] fit, config: {'current_round': 93, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m Epoch 1: train loss 4.075614924659021e-05, accuracy 0.8333333333333334\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m [Client 80] fit, config: {'current_round': 93, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m Epoch 1: train loss 3.140930493827909e-05, accuracy 0.9259259259259259\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m [Client 10] fit, config: {'current_round': 93, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m Epoch 1: train loss 5.708922617486678e-05, accuracy 0.8148148148148148\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m [Client 97] fit, config: {'current_round': 93, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m Epoch 1: train loss 4.074438038514927e-05, accuracy 0.8148148148148148\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m Epoch 1: train loss 7.51090919948183e-05, accuracy 0.7592592592592593\n",
      "Saving round 93 aggregated_parameters...\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38341)\u001b[0m [Client 38] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38338)\u001b[0m [Client 43] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38340)\u001b[0m [Client 79] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38341)\u001b[0m [Client 39] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38338)\u001b[0m [Client 76] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38334)\u001b[0m [Client 86] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38338)\u001b[0m [Client 41] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38336)\u001b[0m [Client 97] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38339)\u001b[0m [Client 23] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38337)\u001b[0m [Client 68] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38334)\u001b[0m [Client 30] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38341)\u001b[0m [Client 99] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38338)\u001b[0m [Client 51] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38336)\u001b[0m [Client 59] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38339)\u001b[0m [Client 69] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38340)\u001b[0m [Client 95] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38335)\u001b[0m [Client 73] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38334)\u001b[0m [Client 70] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38338)\u001b[0m [Client 61] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38336)\u001b[0m [Client 81] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38339)\u001b[0m [Client 87] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38340)\u001b[0m [Client 29] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38335)\u001b[0m [Client 54] evaluate, config: {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 12:26:08,403 | server.py:170 | evaluate_round received 0 results and 30 failures\n",
      "DEBUG flower 2023-02-01 12:26:08,404 | server.py:203 | fit_round: strategy sampled 30 clients (out of 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38341)\u001b[0m [Client 27] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38338)\u001b[0m [Client 22] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38336)\u001b[0m [Client 80] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38339)\u001b[0m [Client 7] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38337)\u001b[0m [Client 45] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38335)\u001b[0m [Client 44] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38336)\u001b[0m [Client 85] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m [Client 29] fit, config: {'current_round': 94, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m Epoch 1: train loss 3.782285057241097e-05, accuracy 0.8888888888888888\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m [Client 45] fit, config: {'current_round': 94, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m [Client 11] fit, config: {'current_round': 94, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m Epoch 1: train loss 4.584865746437572e-05, accuracy 0.8518518518518519\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m Epoch 1: train loss 4.6198438212741166e-05, accuracy 0.8518518518518519\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m [Client 62] fit, config: {'current_round': 94, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m Epoch 1: train loss 5.683851850335486e-05, accuracy 0.8518518518518519\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m [Client 48] fit, config: {'current_round': 94, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m Epoch 1: train loss 3.511596150929108e-05, accuracy 0.9074074074074074\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m [Client 61] fit, config: {'current_round': 94, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m Epoch 1: train loss 5.131436410010792e-05, accuracy 0.8703703703703703\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m [Client 2] fit, config: {'current_round': 94, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m Epoch 1: train loss 3.392558573978022e-05, accuracy 0.9074074074074074\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m [Client 35] fit, config: {'current_round': 94, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m Epoch 1: train loss 5.806117769679986e-05, accuracy 0.7962962962962963\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m [Client 25] fit, config: {'current_round': 94, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m Epoch 1: train loss 3.9255290175788105e-05, accuracy 0.9074074074074074\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m [Client 27] fit, config: {'current_round': 94, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m [Client 59] fit, config: {'current_round': 94, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m Epoch 1: train loss 6.296801439020783e-05, accuracy 0.8518518518518519\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m Epoch 1: train loss 6.342456617858261e-05, accuracy 0.8333333333333334\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m [Client 95] fit, config: {'current_round': 94, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m [Client 98] fit, config: {'current_round': 94, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m Epoch 1: train loss 5.890564352739602e-05, accuracy 0.7777777777777778\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m [Client 56] fit, config: {'current_round': 94, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m [Client 85] fit, config: {'current_round': 94, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m [Client 38] fit, config: {'current_round': 94, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m Epoch 1: train loss 3.438282146817073e-05, accuracy 0.9259259259259259\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m [Client 49] fit, config: {'current_round': 94, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m Epoch 1: train loss 4.1288141801487654e-05, accuracy 0.9259259259259259\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m [Client 26] fit, config: {'current_round': 94, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m Epoch 1: train loss 4.697675467468798e-05, accuracy 0.8518518518518519\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m Epoch 1: train loss 4.2476985981920734e-05, accuracy 0.8888888888888888\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m [Client 65] fit, config: {'current_round': 94, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m Epoch 1: train loss 4.856996383750811e-05, accuracy 0.8703703703703703\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m Epoch 1: train loss 6.552733248099685e-05, accuracy 0.7962962962962963\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m Epoch 1: train loss 2.519142253731843e-05, accuracy 0.9259259259259259\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m [Client 32] fit, config: {'current_round': 94, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m Epoch 1: train loss 5.102939758216962e-05, accuracy 0.8333333333333334\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m [Client 23] fit, config: {'current_round': 94, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m [Client 63] fit, config: {'current_round': 94, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m Epoch 1: train loss 4.662275387090631e-05, accuracy 0.8518518518518519\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 12:26:10,762 | server.py:216 | fit_round received 30 results and 0 failures\n",
      "DEBUG flower 2023-02-01 12:26:10,820 | server.py:157 | evaluate_round: strategy sampled 30 clients (out of 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m Epoch 1: train loss 4.7946450649760664e-05, accuracy 0.8333333333333334\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m [Client 89] fit, config: {'current_round': 94, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m [Client 0] fit, config: {'current_round': 94, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m Epoch 1: train loss 5.858433723915368e-05, accuracy 0.8148148148148148\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m [Client 54] fit, config: {'current_round': 94, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m [Client 94] fit, config: {'current_round': 94, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m [Client 42] fit, config: {'current_round': 94, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m [Client 81] fit, config: {'current_round': 94, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m [Client 37] fit, config: {'current_round': 94, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m Epoch 1: train loss 4.3787767936009914e-05, accuracy 0.8518518518518519\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m Epoch 1: train loss 4.572846955852583e-05, accuracy 0.8888888888888888\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m Epoch 1: train loss 7.04898702679202e-05, accuracy 0.7592592592592593\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m Epoch 1: train loss 7.912423461675644e-05, accuracy 0.7777777777777778\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m Epoch 1: train loss 5.908585080760531e-05, accuracy 0.8703703703703703\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m [Client 57] fit, config: {'current_round': 94, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m Epoch 1: train loss 3.130914774374105e-05, accuracy 0.8888888888888888\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m Epoch 1: train loss 5.150998185854405e-05, accuracy 0.8148148148148148\n",
      "Saving round 94 aggregated_parameters...\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38334)\u001b[0m [Client 22] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38334)\u001b[0m [Client 62] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38334)\u001b[0m [Client 91] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38337)\u001b[0m [Client 71] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38334)\u001b[0m [Client 11] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38336)\u001b[0m [Client 88] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38337)\u001b[0m [Client 82] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38341)\u001b[0m [Client 99] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38341)\u001b[0m [Client 20] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38334)\u001b[0m [Client 60] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38341)\u001b[0m [Client 79] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38336)\u001b[0m [Client 42] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38336)\u001b[0m [Client 1] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38334)\u001b[0m [Client 33] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38336)\u001b[0m [Client 21] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38334)\u001b[0m [Client 57] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38336)\u001b[0m [Client 53] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38334)\u001b[0m [Client 32] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38341)\u001b[0m [Client 16] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38336)\u001b[0m [Client 47] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38338)\u001b[0m [Client 6] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38338)\u001b[0m [Client 40] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38336)\u001b[0m [Client 26] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38337)\u001b[0m [Client 94] evaluate, config: {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 12:26:13,037 | server.py:170 | evaluate_round received 0 results and 30 failures\n",
      "DEBUG flower 2023-02-01 12:26:13,039 | server.py:203 | fit_round: strategy sampled 30 clients (out of 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38334)\u001b[0m [Client 36] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38341)\u001b[0m [Client 24] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38338)\u001b[0m [Client 38] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38336)\u001b[0m [Client 78] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38339)\u001b[0m [Client 84] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38337)\u001b[0m [Client 90] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m [Client 53] fit, config: {'current_round': 95, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m [Client 55] fit, config: {'current_round': 95, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m Epoch 1: train loss 5.2514213166432455e-05, accuracy 0.7962962962962963\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m Epoch 1: train loss 5.0693215598585084e-05, accuracy 0.8518518518518519\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m [Client 13] fit, config: {'current_round': 95, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m Epoch 1: train loss 4.814446219825186e-05, accuracy 0.8333333333333334\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m [Client 51] fit, config: {'current_round': 95, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m Epoch 1: train loss 6.731284520355985e-05, accuracy 0.7777777777777778\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m [Client 63] fit, config: {'current_round': 95, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m [Client 79] fit, config: {'current_round': 95, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m [Client 38] fit, config: {'current_round': 95, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m Epoch 1: train loss 4.029909541714005e-05, accuracy 0.9074074074074074\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m [Client 22] fit, config: {'current_round': 95, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m Epoch 1: train loss 6.132808630354702e-05, accuracy 0.7777777777777778\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m [Client 21] fit, config: {'current_round': 95, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m [Client 84] fit, config: {'current_round': 95, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m [Client 99] fit, config: {'current_round': 95, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m Epoch 1: train loss 6.358383689075708e-05, accuracy 0.7592592592592593\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m [Client 98] fit, config: {'current_round': 95, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m Epoch 1: train loss 5.177128332434222e-05, accuracy 0.8148148148148148\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m Epoch 1: train loss 5.0133236072724685e-05, accuracy 0.8333333333333334\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m Epoch 1: train loss 3.957752778660506e-05, accuracy 0.8888888888888888\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m [Client 85] fit, config: {'current_round': 95, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m Epoch 1: train loss 2.9681810701731592e-05, accuracy 0.9074074074074074\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m Epoch 1: train loss 4.966963388142176e-05, accuracy 0.8148148148148148\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m Epoch 1: train loss 5.074448563391343e-05, accuracy 0.8333333333333334\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m [Client 14] fit, config: {'current_round': 95, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m Epoch 1: train loss 5.5200485803652555e-05, accuracy 0.7592592592592593\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m [Client 71] fit, config: {'current_round': 95, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m Epoch 1: train loss 4.41236152255442e-05, accuracy 0.8518518518518519\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 12:26:15,449 | server.py:216 | fit_round received 30 results and 0 failures\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m [Client 27] fit, config: {'current_round': 95, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m Epoch 1: train loss 5.728985706809908e-05, accuracy 0.8518518518518519\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m [Client 49] fit, config: {'current_round': 95, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m [Client 40] fit, config: {'current_round': 95, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m Epoch 1: train loss 2.826788113452494e-05, accuracy 0.8703703703703703\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m Epoch 1: train loss 6.121924525359645e-05, accuracy 0.7777777777777778\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m [Client 7] fit, config: {'current_round': 95, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m Epoch 1: train loss 5.8814912335947156e-05, accuracy 0.8333333333333334\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m [Client 17] fit, config: {'current_round': 95, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m [Client 23] fit, config: {'current_round': 95, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m [Client 74] fit, config: {'current_round': 95, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m [Client 18] fit, config: {'current_round': 95, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m Epoch 1: train loss 6.741715333191678e-05, accuracy 0.8518518518518519\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m [Client 91] fit, config: {'current_round': 95, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m [Client 42] fit, config: {'current_round': 95, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m Epoch 1: train loss 7.374923006864265e-05, accuracy 0.7407407407407407\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m [Client 29] fit, config: {'current_round': 95, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m Epoch 1: train loss 4.0700793761061504e-05, accuracy 0.8703703703703703\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m Epoch 1: train loss 5.6173659686464816e-05, accuracy 0.7407407407407407\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m Epoch 1: train loss 5.114705709274858e-05, accuracy 0.8148148148148148\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m Epoch 1: train loss 5.613841858576052e-05, accuracy 0.8148148148148148\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m Epoch 1: train loss 2.5044217181857675e-05, accuracy 0.9259259259259259\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m [Client 95] fit, config: {'current_round': 95, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m [Client 54] fit, config: {'current_round': 95, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m [Client 5] fit, config: {'current_round': 95, 'local_epochs': 3}\n",
      "Saving round 95 aggregated_parameters...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 12:26:15,500 | server.py:157 | evaluate_round: strategy sampled 30 clients (out of 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m [Client 60] fit, config: {'current_round': 95, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m Epoch 1: train loss 3.327216472825967e-05, accuracy 0.9074074074074074\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m Epoch 1: train loss 2.5935200028470717e-05, accuracy 0.9444444444444444\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m Epoch 1: train loss 4.7998422814998776e-05, accuracy 0.8518518518518519\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m Epoch 1: train loss 3.716127685038373e-05, accuracy 0.9074074074074074\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38340)\u001b[0m [Client 78] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38337)\u001b[0m [Client 3] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38341)\u001b[0m [Client 85] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38341)\u001b[0m [Client 6] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38340)\u001b[0m [Client 68] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38341)\u001b[0m [Client 97] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38340)\u001b[0m [Client 99] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38337)\u001b[0m [Client 71] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38340)\u001b[0m [Client 73] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38337)\u001b[0m [Client 66] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38337)\u001b[0m [Client 89] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38337)\u001b[0m [Client 39] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38340)\u001b[0m [Client 40] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38340)\u001b[0m [Client 16] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38337)\u001b[0m [Client 61] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38340)\u001b[0m [Client 37] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38337)\u001b[0m [Client 75] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38337)\u001b[0m [Client 58] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38337)\u001b[0m [Client 20] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38337)\u001b[0m [Client 48] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38341)\u001b[0m [Client 18] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38337)\u001b[0m [Client 8] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38341)\u001b[0m [Client 26] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38338)\u001b[0m [Client 5] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38336)\u001b[0m [Client 84] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38337)\u001b[0m [Client 33] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38335)\u001b[0m [Client 92] evaluate, config: {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 12:26:18,081 | server.py:170 | evaluate_round received 0 results and 30 failures\n",
      "DEBUG flower 2023-02-01 12:26:18,082 | server.py:203 | fit_round: strategy sampled 30 clients (out of 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38339)\u001b[0m [Client 43] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38340)\u001b[0m [Client 41] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38334)\u001b[0m [Client 91] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m [Client 88] fit, config: {'current_round': 96, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m Epoch 1: train loss 3.8750400563003495e-05, accuracy 0.8703703703703703\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m [Client 65] fit, config: {'current_round': 96, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m Epoch 1: train loss 4.461538264877163e-05, accuracy 0.8888888888888888\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m [Client 9] fit, config: {'current_round': 96, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m Epoch 1: train loss 5.3377534641185775e-05, accuracy 0.8703703703703703\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m [Client 7] fit, config: {'current_round': 96, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m Epoch 1: train loss 4.487966725719161e-05, accuracy 0.8148148148148148\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m [Client 70] fit, config: {'current_round': 96, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m [Client 50] fit, config: {'current_round': 96, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m Epoch 1: train loss 8.365801477339119e-05, accuracy 0.7962962962962963\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m [Client 55] fit, config: {'current_round': 96, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m Epoch 1: train loss 5.2798379329033196e-05, accuracy 0.7777777777777778\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m [Client 43] fit, config: {'current_round': 96, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m Epoch 1: train loss 6.721523823216558e-05, accuracy 0.8703703703703703\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m Epoch 1: train loss 5.297934330883436e-05, accuracy 0.8148148148148148\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m [Client 66] fit, config: {'current_round': 96, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m Epoch 1: train loss 3.282228499301709e-05, accuracy 0.9074074074074074\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m [Client 10] fit, config: {'current_round': 96, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m Epoch 1: train loss 5.5605978559469804e-05, accuracy 0.7777777777777778\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m [Client 87] fit, config: {'current_round': 96, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m [Client 2] fit, config: {'current_round': 96, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m Epoch 1: train loss 3.515477874316275e-05, accuracy 0.8888888888888888\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m [Client 15] fit, config: {'current_round': 96, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m Epoch 1: train loss 6.347276939777657e-05, accuracy 0.7777777777777778\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m [Client 39] fit, config: {'current_round': 96, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m Epoch 1: train loss 5.9743470046669245e-05, accuracy 0.8703703703703703\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m [Client 76] fit, config: {'current_round': 96, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m Epoch 1: train loss 3.182669388479553e-05, accuracy 0.8703703703703703\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m [Client 74] fit, config: {'current_round': 96, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m Epoch 1: train loss 4.670997441280633e-05, accuracy 0.8148148148148148\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m [Client 62] fit, config: {'current_round': 96, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m [Client 34] fit, config: {'current_round': 96, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m Epoch 1: train loss 7.204819848993793e-05, accuracy 0.8148148148148148\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m Epoch 1: train loss 4.800018359674141e-05, accuracy 0.8333333333333334\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m Epoch 1: train loss 5.5764990975148976e-05, accuracy 0.8518518518518519\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m [Client 68] fit, config: {'current_round': 96, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m [Client 19] fit, config: {'current_round': 96, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m Epoch 1: train loss 4.3295513023622334e-05, accuracy 0.8333333333333334\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m Epoch 1: train loss 5.98772348894272e-05, accuracy 0.8518518518518519\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m [Client 27] fit, config: {'current_round': 96, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m Epoch 1: train loss 6.099102392909117e-05, accuracy 0.8518518518518519\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m [Client 45] fit, config: {'current_round': 96, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m Epoch 1: train loss 4.409880057210103e-05, accuracy 0.8703703703703703\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 12:26:20,416 | server.py:216 | fit_round received 30 results and 0 failures\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m [Client 46] fit, config: {'current_round': 96, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m [Client 47] fit, config: {'current_round': 96, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m [Client 22] fit, config: {'current_round': 96, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m Epoch 1: train loss 4.408580207382329e-05, accuracy 0.8888888888888888\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m [Client 20] fit, config: {'current_round': 96, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m Epoch 1: train loss 3.717184154083952e-05, accuracy 0.8703703703703703\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m [Client 93] fit, config: {'current_round': 96, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m Epoch 1: train loss 3.78199401893653e-05, accuracy 0.8888888888888888\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m [Client 61] fit, config: {'current_round': 96, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m Epoch 1: train loss 5.3016799938632175e-05, accuracy 0.8888888888888888\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m Epoch 1: train loss 6.245743861654773e-05, accuracy 0.8703703703703703\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 12:26:20,472 | server.py:157 | evaluate_round: strategy sampled 30 clients (out of 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m Epoch 1: train loss 5.8600813645171e-05, accuracy 0.8148148148148148\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m [Client 6] fit, config: {'current_round': 96, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m Epoch 1: train loss 4.4217351387487724e-05, accuracy 0.8703703703703703\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m [Client 63] fit, config: {'current_round': 96, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m Epoch 1: train loss 4.365825225249864e-05, accuracy 0.8518518518518519\n",
      "Saving round 96 aggregated_parameters...\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38338)\u001b[0m [Client 14] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38338)\u001b[0m [Client 48] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38338)\u001b[0m [Client 31] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38338)\u001b[0m [Client 57] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38338)\u001b[0m [Client 54] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38338)\u001b[0m [Client 78] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38335)\u001b[0m [Client 99] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38338)\u001b[0m [Client 7] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38338)\u001b[0m [Client 62] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38335)\u001b[0m [Client 32] evaluate, config: {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 12:26:22,719 | server.py:170 | evaluate_round received 0 results and 30 failures\n",
      "DEBUG flower 2023-02-01 12:26:22,721 | server.py:203 | fit_round: strategy sampled 30 clients (out of 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38338)\u001b[0m [Client 10] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38335)\u001b[0m [Client 51] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38334)\u001b[0m [Client 80] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38334)\u001b[0m [Client 69] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38334)\u001b[0m [Client 0] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38335)\u001b[0m [Client 18] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38335)\u001b[0m [Client 30] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38334)\u001b[0m [Client 29] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38335)\u001b[0m [Client 96] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38338)\u001b[0m [Client 11] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38338)\u001b[0m [Client 42] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38338)\u001b[0m [Client 81] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38334)\u001b[0m [Client 97] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38341)\u001b[0m [Client 41] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38338)\u001b[0m [Client 50] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38337)\u001b[0m [Client 64] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38335)\u001b[0m [Client 28] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38336)\u001b[0m [Client 36] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38339)\u001b[0m [Client 89] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38340)\u001b[0m [Client 84] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m [Client 81] fit, config: {'current_round': 97, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m Epoch 1: train loss 4.6707005822099745e-05, accuracy 0.8518518518518519\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m [Client 62] fit, config: {'current_round': 97, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m Epoch 1: train loss 3.80033852707129e-05, accuracy 0.8888888888888888\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m [Client 13] fit, config: {'current_round': 97, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m Epoch 1: train loss 4.9657992349239066e-05, accuracy 0.8333333333333334\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m [Client 63] fit, config: {'current_round': 97, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m Epoch 1: train loss 4.1318988223792985e-05, accuracy 0.8888888888888888\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m [Client 96] fit, config: {'current_round': 97, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m Epoch 1: train loss 5.854707342223264e-05, accuracy 0.8333333333333334\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m [Client 58] fit, config: {'current_round': 97, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m [Client 67] fit, config: {'current_round': 97, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m Epoch 1: train loss 5.589749707723968e-05, accuracy 0.7962962962962963\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m Epoch 1: train loss 4.842519774683751e-05, accuracy 0.8703703703703703\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m [Client 66] fit, config: {'current_round': 97, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m Epoch 1: train loss 3.359161564731039e-05, accuracy 0.8888888888888888\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m [Client 80] fit, config: {'current_round': 97, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m Epoch 1: train loss 3.444156391196884e-05, accuracy 0.8703703703703703\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m [Client 87] fit, config: {'current_round': 97, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m Epoch 1: train loss 4.7062399971764535e-05, accuracy 0.8518518518518519\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m [Client 85] fit, config: {'current_round': 97, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m Epoch 1: train loss 2.971299909404479e-05, accuracy 0.9074074074074074\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m [Client 61] fit, config: {'current_round': 97, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m [Client 53] fit, config: {'current_round': 97, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m [Client 95] fit, config: {'current_round': 97, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m Epoch 1: train loss 2.394640978309326e-05, accuracy 0.9444444444444444\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m [Client 77] fit, config: {'current_round': 97, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m Epoch 1: train loss 6.552008562721312e-05, accuracy 0.7407407407407407\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m [Client 27] fit, config: {'current_round': 97, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m Epoch 1: train loss 5.722611604142003e-05, accuracy 0.8518518518518519\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m Epoch 1: train loss 6.925623893039301e-05, accuracy 0.7777777777777778\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m Epoch 1: train loss 5.10819154442288e-05, accuracy 0.8518518518518519\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m [Client 74] fit, config: {'current_round': 97, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m Epoch 1: train loss 5.1777620683424175e-05, accuracy 0.7962962962962963\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m [Client 64] fit, config: {'current_round': 97, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m Epoch 1: train loss 4.861357592744753e-05, accuracy 0.8148148148148148\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m [Client 83] fit, config: {'current_round': 97, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m [Client 40] fit, config: {'current_round': 97, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m Epoch 1: train loss 2.7736929041566327e-05, accuracy 0.8703703703703703\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m [Client 3] fit, config: {'current_round': 97, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m Epoch 1: train loss 5.691215847036801e-05, accuracy 0.8148148148148148\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m Epoch 1: train loss 4.869955955655314e-05, accuracy 0.8518518518518519\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m [Client 69] fit, config: {'current_round': 97, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m [Client 70] fit, config: {'current_round': 97, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m Epoch 1: train loss 5.00538335472811e-05, accuracy 0.8518518518518519\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m [Client 12] fit, config: {'current_round': 97, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m [Client 21] fit, config: {'current_round': 97, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m [Client 23] fit, config: {'current_round': 97, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m Epoch 1: train loss 5.741806671721861e-05, accuracy 0.7407407407407407\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 12:26:25,243 | server.py:216 | fit_round received 30 results and 0 failures\n",
      "DEBUG flower 2023-02-01 12:26:25,298 | server.py:157 | evaluate_round: strategy sampled 30 clients (out of 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m [Client 35] fit, config: {'current_round': 97, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m Epoch 1: train loss 3.5599343391368166e-05, accuracy 0.8703703703703703\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m [Client 18] fit, config: {'current_round': 97, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m Epoch 1: train loss 5.106086246087216e-05, accuracy 0.8148148148148148\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m [Client 47] fit, config: {'current_round': 97, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m Epoch 1: train loss 6.040394873707555e-05, accuracy 0.8148148148148148\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m Epoch 1: train loss 3.832550282822922e-05, accuracy 0.8703703703703703\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m Epoch 1: train loss 4.424936560099013e-05, accuracy 0.8518518518518519\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m Epoch 1: train loss 4.875442027696408e-05, accuracy 0.8333333333333334\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m [Client 59] fit, config: {'current_round': 97, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m Epoch 1: train loss 6.467843195423484e-05, accuracy 0.8333333333333334\n",
      "Saving round 97 aggregated_parameters...\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38334)\u001b[0m [Client 9] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38338)\u001b[0m [Client 72] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38335)\u001b[0m [Client 63] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38338)\u001b[0m [Client 79] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38338)\u001b[0m [Client 16] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38338)\u001b[0m [Client 35] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38334)\u001b[0m [Client 32] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38341)\u001b[0m [Client 65] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38335)\u001b[0m [Client 77] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38335)\u001b[0m [Client 17] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38335)\u001b[0m [Client 5] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38335)\u001b[0m [Client 50] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38335)\u001b[0m [Client 33] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38334)\u001b[0m [Client 25] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38341)\u001b[0m [Client 4] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38338)\u001b[0m [Client 60] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38337)\u001b[0m [Client 98] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38335)\u001b[0m [Client 97] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38340)\u001b[0m [Client 45] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38337)\u001b[0m [Client 92] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38337)\u001b[0m [Client 84] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38337)\u001b[0m [Client 95] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38340)\u001b[0m [Client 93] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38341)\u001b[0m [Client 52] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38340)\u001b[0m [Client 86] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38337)\u001b[0m [Client 61] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38337)\u001b[0m [Client 43] evaluate, config: {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 12:26:27,558 | server.py:170 | evaluate_round received 0 results and 30 failures\n",
      "DEBUG flower 2023-02-01 12:26:27,559 | server.py:203 | fit_round: strategy sampled 30 clients (out of 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38334)\u001b[0m [Client 44] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38338)\u001b[0m [Client 46] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38335)\u001b[0m [Client 78] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m [Client 89] fit, config: {'current_round': 98, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m Epoch 1: train loss 6.900777225382626e-05, accuracy 0.8333333333333334\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m [Client 93] fit, config: {'current_round': 98, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m Epoch 1: train loss 3.4419306757627055e-05, accuracy 0.9074074074074074\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m [Client 11] fit, config: {'current_round': 98, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m Epoch 1: train loss 3.991075573139824e-05, accuracy 0.8888888888888888\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m [Client 6] fit, config: {'current_round': 98, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m Epoch 1: train loss 4.237275425111875e-05, accuracy 0.8888888888888888\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m [Client 97] fit, config: {'current_round': 98, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m [Client 71] fit, config: {'current_round': 98, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m Epoch 1: train loss 3.539200042723678e-05, accuracy 0.8888888888888888\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m [Client 45] fit, config: {'current_round': 98, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m Epoch 1: train loss 4.143418118474074e-05, accuracy 0.8888888888888888\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m [Client 20] fit, config: {'current_round': 98, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m [Client 3] fit, config: {'current_round': 98, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m Epoch 1: train loss 4.739010546472855e-05, accuracy 0.8518518518518519\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m Epoch 1: train loss 3.8979716919129714e-05, accuracy 0.8703703703703703\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m [Client 83] fit, config: {'current_round': 98, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m Epoch 1: train loss 4.657684257836081e-05, accuracy 0.8148148148148148\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m Epoch 1: train loss 3.331611878820695e-05, accuracy 0.8888888888888888\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m [Client 41] fit, config: {'current_round': 98, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m Epoch 1: train loss 5.934140790486708e-05, accuracy 0.8333333333333334\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m [Client 74] fit, config: {'current_round': 98, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m Epoch 1: train loss 4.123037797398865e-05, accuracy 0.8333333333333334\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m [Client 62] fit, config: {'current_round': 98, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m Epoch 1: train loss 4.849981996812858e-05, accuracy 0.8703703703703703\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m [Client 68] fit, config: {'current_round': 98, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m Epoch 1: train loss 5.709690958610736e-05, accuracy 0.8518518518518519\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m [Client 42] fit, config: {'current_round': 98, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m [Client 76] fit, config: {'current_round': 98, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m [Client 48] fit, config: {'current_round': 98, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m Epoch 1: train loss 3.679702422232367e-05, accuracy 0.9074074074074074\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m [Client 31] fit, config: {'current_round': 98, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m Epoch 1: train loss 3.656684930319898e-05, accuracy 0.8888888888888888\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m [Client 85] fit, config: {'current_round': 98, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m Epoch 1: train loss 2.1317764549166895e-05, accuracy 0.9444444444444444\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m [Client 84] fit, config: {'current_round': 98, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m Epoch 1: train loss 5.806731496704742e-05, accuracy 0.7962962962962963\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m Epoch 1: train loss 6.51408699923195e-05, accuracy 0.7962962962962963\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m Epoch 1: train loss 4.650422852137126e-05, accuracy 0.8148148148148148\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m [Client 57] fit, config: {'current_round': 98, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m Epoch 1: train loss 3.003209894814063e-05, accuracy 0.8703703703703703\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m [Client 32] fit, config: {'current_round': 98, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m Epoch 1: train loss 5.14424973516725e-05, accuracy 0.8888888888888888\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m [Client 23] fit, config: {'current_round': 98, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m [Client 69] fit, config: {'current_round': 98, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m Epoch 1: train loss 4.255032035871409e-05, accuracy 0.8333333333333334\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m [Client 18] fit, config: {'current_round': 98, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m Epoch 1: train loss 5.1088612963212654e-05, accuracy 0.8148148148148148\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m Epoch 1: train loss 4.600846295943484e-05, accuracy 0.8148148148148148\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m [Client 44] fit, config: {'current_round': 98, 'local_epochs': 3}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 12:26:29,813 | server.py:216 | fit_round received 30 results and 0 failures\n",
      "DEBUG flower 2023-02-01 12:26:29,893 | server.py:157 | evaluate_round: strategy sampled 30 clients (out of 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m [Client 66] fit, config: {'current_round': 98, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m Epoch 1: train loss 3.2047199056250975e-05, accuracy 0.9259259259259259\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m [Client 46] fit, config: {'current_round': 98, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m Epoch 1: train loss 4.337373684393242e-05, accuracy 0.8888888888888888\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m [Client 53] fit, config: {'current_round': 98, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m Epoch 1: train loss 5.5128832173068076e-05, accuracy 0.7592592592592593\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m Epoch 1: train loss 3.8509238947881386e-05, accuracy 0.8703703703703703\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m [Client 43] fit, config: {'current_round': 98, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m Epoch 1: train loss 6.211839354364201e-05, accuracy 0.8888888888888888\n",
      "Saving round 98 aggregated_parameters...\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38340)\u001b[0m [Client 60] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38336)\u001b[0m [Client 40] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38340)\u001b[0m [Client 90] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38336)\u001b[0m [Client 89] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38340)\u001b[0m [Client 13] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38340)\u001b[0m [Client 4] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38337)\u001b[0m [Client 53] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38335)\u001b[0m [Client 21] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38334)\u001b[0m [Client 20] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38336)\u001b[0m [Client 18] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38334)\u001b[0m [Client 38] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38336)\u001b[0m [Client 44] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38336)\u001b[0m [Client 97] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38334)\u001b[0m [Client 8] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38336)\u001b[0m [Client 2] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38340)\u001b[0m [Client 32] evaluate, config: {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 12:26:32,701 | server.py:170 | evaluate_round received 0 results and 30 failures\n",
      "DEBUG flower 2023-02-01 12:26:32,703 | server.py:203 | fit_round: strategy sampled 30 clients (out of 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38337)\u001b[0m [Client 26] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38334)\u001b[0m [Client 77] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38341)\u001b[0m [Client 99] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38338)\u001b[0m [Client 84] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38336)\u001b[0m [Client 15] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38340)\u001b[0m [Client 24] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38337)\u001b[0m [Client 35] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38338)\u001b[0m [Client 52] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38335)\u001b[0m [Client 80] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38338)\u001b[0m [Client 7] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38336)\u001b[0m [Client 6] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38340)\u001b[0m [Client 31] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38337)\u001b[0m [Client 82] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38335)\u001b[0m [Client 72] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m [Client 32] fit, config: {'current_round': 99, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m Epoch 1: train loss 5.882202458451502e-05, accuracy 0.8148148148148148\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m [Client 17] fit, config: {'current_round': 99, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m Epoch 1: train loss 6.310300523182377e-05, accuracy 0.8518518518518519\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m [Client 26] fit, config: {'current_round': 99, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m Epoch 1: train loss 5.682682240149006e-05, accuracy 0.8518518518518519\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m [Client 30] fit, config: {'current_round': 99, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m Epoch 1: train loss 6.964895874261856e-05, accuracy 0.7962962962962963\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m [Client 72] fit, config: {'current_round': 99, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m Epoch 1: train loss 3.722812107298523e-05, accuracy 0.9074074074074074\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m [Client 0] fit, config: {'current_round': 99, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m Epoch 1: train loss 5.1777846238110214e-05, accuracy 0.8518518518518519\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m [Client 66] fit, config: {'current_round': 99, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m Epoch 1: train loss 3.322822885820642e-05, accuracy 0.8888888888888888\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m [Client 28] fit, config: {'current_round': 99, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m [Client 41] fit, config: {'current_round': 99, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m [Client 53] fit, config: {'current_round': 99, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m Epoch 1: train loss 5.195936682866886e-05, accuracy 0.8333333333333334\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m Epoch 1: train loss 5.813191455672495e-05, accuracy 0.8703703703703703\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m [Client 59] fit, config: {'current_round': 99, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m Epoch 1: train loss 6.828836922068149e-05, accuracy 0.7407407407407407\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m [Client 50] fit, config: {'current_round': 99, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m Epoch 1: train loss 6.44269966869615e-05, accuracy 0.7962962962962963\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m [Client 75] fit, config: {'current_round': 99, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m Epoch 1: train loss 5.8360510593047366e-05, accuracy 0.7777777777777778\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m [Client 80] fit, config: {'current_round': 99, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m Epoch 1: train loss 3.700560409924947e-05, accuracy 0.8518518518518519\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m [Client 94] fit, config: {'current_round': 99, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m Epoch 1: train loss 4.191473635728471e-05, accuracy 0.8518518518518519\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m Epoch 1: train loss 6.406668398994952e-05, accuracy 0.8148148148148148\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m [Client 22] fit, config: {'current_round': 99, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m Epoch 1: train loss 5.928744576522149e-05, accuracy 0.7777777777777778\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m [Client 93] fit, config: {'current_round': 99, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m Epoch 1: train loss 4.91242426505778e-05, accuracy 0.7962962962962963\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m [Client 61] fit, config: {'current_round': 99, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m Epoch 1: train loss 6.751721230102703e-05, accuracy 0.8518518518518519\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m [Client 14] fit, config: {'current_round': 99, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m [Client 45] fit, config: {'current_round': 99, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m Epoch 1: train loss 4.049255949212238e-05, accuracy 0.9074074074074074\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m [Client 48] fit, config: {'current_round': 99, 'local_epochs': 3}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 12:26:35,695 | server.py:216 | fit_round received 30 results and 0 failures\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m [Client 54] fit, config: {'current_round': 99, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m [Client 42] fit, config: {'current_round': 99, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m Epoch 1: train loss 5.2184499509166926e-05, accuracy 0.7777777777777778\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m [Client 31] fit, config: {'current_round': 99, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m [Client 76] fit, config: {'current_round': 99, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m Epoch 1: train loss 4.3956973968306556e-05, accuracy 0.8148148148148148\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m [Client 78] fit, config: {'current_round': 99, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m Epoch 1: train loss 5.0818867748603225e-05, accuracy 0.8518518518518519\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m [Client 57] fit, config: {'current_round': 99, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m Epoch 1: train loss 2.3276403226191178e-05, accuracy 0.9259259259259259\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m Epoch 1: train loss 4.4282671296969056e-05, accuracy 0.8703703703703703\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m Epoch 1: train loss 2.6640143914846703e-05, accuracy 0.9074074074074074\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m Epoch 1: train loss 7.301491859834641e-05, accuracy 0.7222222222222222\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m Epoch 1: train loss 4.003230787930079e-05, accuracy 0.8888888888888888\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m [Client 18] fit, config: {'current_round': 99, 'local_epochs': 3}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 12:26:35,828 | server.py:157 | evaluate_round: strategy sampled 30 clients (out of 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m [Client 7] fit, config: {'current_round': 99, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m Epoch 1: train loss 6.223967648111284e-05, accuracy 0.8148148148148148\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m Epoch 1: train loss 4.957689088769257e-05, accuracy 0.8148148148148148\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m [Client 44] fit, config: {'current_round': 99, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m Epoch 1: train loss 4.55025838164147e-05, accuracy 0.8148148148148148\n",
      "Saving round 99 aggregated_parameters...\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38334)\u001b[0m [Client 35] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38334)\u001b[0m [Client 67] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38334)\u001b[0m [Client 50] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38341)\u001b[0m [Client 7] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38335)\u001b[0m [Client 83] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38334)\u001b[0m [Client 80] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38334)\u001b[0m [Client 79] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38341)\u001b[0m [Client 8] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38340)\u001b[0m [Client 51] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38335)\u001b[0m [Client 60] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38334)\u001b[0m [Client 98] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38338)\u001b[0m [Client 82] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38339)\u001b[0m [Client 93] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38340)\u001b[0m [Client 70] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38339)\u001b[0m [Client 31] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38340)\u001b[0m [Client 32] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38339)\u001b[0m [Client 36] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38334)\u001b[0m [Client 30] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38338)\u001b[0m [Client 88] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38339)\u001b[0m [Client 69] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38340)\u001b[0m [Client 14] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38339)\u001b[0m [Client 38] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38340)\u001b[0m [Client 6] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38335)\u001b[0m [Client 57] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38338)\u001b[0m [Client 62] evaluate, config: {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 12:26:38,763 | server.py:170 | evaluate_round received 0 results and 30 failures\n",
      "DEBUG flower 2023-02-01 12:26:38,766 | server.py:203 | fit_round: strategy sampled 30 clients (out of 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38334)\u001b[0m [Client 74] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38341)\u001b[0m [Client 58] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38339)\u001b[0m [Client 26] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38340)\u001b[0m [Client 13] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38335)\u001b[0m [Client 72] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m [Client 38] fit, config: {'current_round': 100, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m Epoch 1: train loss 3.2083225960377604e-05, accuracy 0.9259259259259259\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m [Client 8] fit, config: {'current_round': 100, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m Epoch 1: train loss 5.041626718593761e-05, accuracy 0.8333333333333334\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m [Client 56] fit, config: {'current_round': 100, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m [Client 3] fit, config: {'current_round': 100, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m Epoch 1: train loss 4.85879645566456e-05, accuracy 0.8518518518518519\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m Epoch 1: train loss 5.900952237425372e-05, accuracy 0.7962962962962963\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m [Client 61] fit, config: {'current_round': 100, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m Epoch 1: train loss 5.2724564739037305e-05, accuracy 0.8703703703703703\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m [Client 64] fit, config: {'current_round': 100, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m Epoch 1: train loss 5.964583033346571e-05, accuracy 0.7962962962962963\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m [Client 95] fit, config: {'current_round': 100, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m [Client 17] fit, config: {'current_round': 100, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m [Client 18] fit, config: {'current_round': 100, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m [Client 81] fit, config: {'current_round': 100, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m Epoch 1: train loss 5.2617073379224166e-05, accuracy 0.8333333333333334\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m [Client 72] fit, config: {'current_round': 100, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m Epoch 1: train loss 3.4746055462164804e-05, accuracy 0.8888888888888888\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m Epoch 1: train loss 7.462120993295684e-05, accuracy 0.7962962962962963\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m Epoch 1: train loss 4.773551700054668e-05, accuracy 0.8518518518518519\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m [Client 16] fit, config: {'current_round': 100, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m [Client 88] fit, config: {'current_round': 100, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m Epoch 1: train loss 3.9119906432460994e-05, accuracy 0.8518518518518519\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m [Client 42] fit, config: {'current_round': 100, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m Epoch 1: train loss 5.9665511798812076e-05, accuracy 0.7962962962962963\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m Epoch 1: train loss 5.910093750571832e-05, accuracy 0.8148148148148148\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m Epoch 1: train loss 3.4581622458063066e-05, accuracy 0.9074074074074074\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m [Client 66] fit, config: {'current_round': 100, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m Epoch 1: train loss 3.0313145543914288e-05, accuracy 0.9074074074074074\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m [Client 79] fit, config: {'current_round': 100, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m Epoch 1: train loss 3.697034117067233e-05, accuracy 0.8703703703703703\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m [Client 77] fit, config: {'current_round': 100, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m Epoch 1: train loss 4.475799505598843e-05, accuracy 0.8333333333333334\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m [Client 48] fit, config: {'current_round': 100, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m Epoch 1: train loss 3.7602025258820504e-05, accuracy 0.9259259259259259\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m [Client 68] fit, config: {'current_round': 100, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m [Client 62] fit, config: {'current_round': 100, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m [Client 31] fit, config: {'current_round': 100, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m Epoch 1: train loss 3.666267002699897e-05, accuracy 0.8703703703703703\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m Epoch 1: train loss 5.7640867453301325e-05, accuracy 0.8518518518518519\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m Epoch 1: train loss 5.295954906614497e-05, accuracy 0.8518518518518519\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m [Client 91] fit, config: {'current_round': 100, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m [Client 54] fit, config: {'current_round': 100, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m [Client 60] fit, config: {'current_round': 100, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m [Client 7] fit, config: {'current_round': 100, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m [Client 78] fit, config: {'current_round': 100, 'local_epochs': 3}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 12:26:42,377 | server.py:216 | fit_round received 30 results and 0 failures\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m Epoch 1: train loss 4.457337490748614e-05, accuracy 0.8703703703703703\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m [Client 12] fit, config: {'current_round': 100, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38340)\u001b[0m Epoch 1: train loss 3.266211206209846e-05, accuracy 0.9074074074074074\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m [Client 22] fit, config: {'current_round': 100, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38335)\u001b[0m Epoch 1: train loss 3.222980740247294e-05, accuracy 0.9259259259259259\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38334)\u001b[0m Epoch 1: train loss 4.227798854117282e-05, accuracy 0.8333333333333334\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38339)\u001b[0m Epoch 1: train loss 4.2512649088166654e-05, accuracy 0.8333333333333334\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38341)\u001b[0m Epoch 1: train loss 1.6986305126920342e-05, accuracy 0.9629629629629629\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m [Client 93] fit, config: {'current_round': 100, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38338)\u001b[0m Epoch 1: train loss 3.470247975201346e-05, accuracy 0.8888888888888888\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m [Client 23] fit, config: {'current_round': 100, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=38337)\u001b[0m Epoch 1: train loss 5.6429420510539785e-05, accuracy 0.7777777777777778\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 12:26:42,482 | server.py:157 | evaluate_round: strategy sampled 30 clients (out of 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_fit pid=38336)\u001b[0m Epoch 1: train loss 5.224292181083001e-05, accuracy 0.8333333333333334\n",
      "Saving round 100 aggregated_parameters...\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38338)\u001b[0m [Client 95] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38336)\u001b[0m [Client 36] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38341)\u001b[0m [Client 69] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38337)\u001b[0m [Client 66] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38341)\u001b[0m [Client 78] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38341)\u001b[0m [Client 90] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38337)\u001b[0m [Client 31] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38337)\u001b[0m [Client 7] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38337)\u001b[0m [Client 96] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38336)\u001b[0m [Client 40] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38335)\u001b[0m [Client 64] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38334)\u001b[0m [Client 37] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38341)\u001b[0m [Client 71] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38338)\u001b[0m [Client 15] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38339)\u001b[0m [Client 33] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38335)\u001b[0m [Client 56] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38336)\u001b[0m [Client 52] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38336)\u001b[0m [Client 38] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38339)\u001b[0m [Client 3] evaluate, config: {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 12:26:46,159 | server.py:170 | evaluate_round received 0 results and 30 failures\n",
      "INFO flower 2023-02-01 12:26:46,161 | server.py:138 | FL finished in 483.76801455500026\n",
      "INFO flower 2023-02-01 12:26:46,163 | app.py:178 | app_fit: losses_distributed []\n",
      "INFO flower 2023-02-01 12:26:46,165 | app.py:179 | app_fit: metrics_distributed {}\n",
      "INFO flower 2023-02-01 12:26:46,166 | app.py:180 | app_fit: losses_centralized []\n",
      "INFO flower 2023-02-01 12:26:46,167 | app.py:181 | app_fit: metrics_centralized {}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38339)\u001b[0m [Client 63] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38334)\u001b[0m [Client 68] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38341)\u001b[0m [Client 49] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38338)\u001b[0m [Client 27] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38336)\u001b[0m [Client 30] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38340)\u001b[0m [Client 85] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38337)\u001b[0m [Client 76] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38337)\u001b[0m [Client 19] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38335)\u001b[0m [Client 45] evaluate, config: {}\n"
     ]
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38341)\u001b[0m [Client 99] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=38339)\u001b[0m [Client 46] evaluate, config: {}\n"
     ]
    }
   ],
   "source": [
    "def fit_config(rnd: int):\n",
    "    config = {\n",
    "        \"current_round\": rnd,\n",
    "        \"local_epochs\": LOCAL_EPOCH,\n",
    "    }\n",
    "    return config\n",
    "\n",
    "##################################################################################\n",
    "\n",
    "class SaveModelStrategy(fl.server.strategy.FedAvg):\n",
    "    def aggregate_fit(\n",
    "        self,\n",
    "        rnd: int,\n",
    "        results: List[Tuple[fl.server.client_proxy.ClientProxy, fl.common.FitRes]],\n",
    "        failures: List[BaseException],\n",
    "    ) -> Optional[fl.common.Weights]:\n",
    "        \n",
    "        # Aggregate model weights using weighted average and store checkpoint\n",
    "        aggregated_parameters_tuple = super().aggregate_fit(rnd, results, failures)\n",
    "        aggregated_parameters, _ = aggregated_parameters_tuple\n",
    "        # log_dict['aggregated_parameters']=aggregated_parameters\n",
    "        \n",
    "        if aggregated_parameters is not None:\n",
    "            print(f\"Saving round {rnd} aggregated_parameters...\")\n",
    "            # Convert `Parameters` to `List[np.ndarray]`\n",
    "            aggregated_weights: List[np.ndarray] = fl.common.parameters_to_weights(aggregated_parameters)\n",
    "            \n",
    "            # Convert `List[np.ndarray]` to PyTorch`state_dict`\n",
    "            params_dict = zip(Net().state_dict().keys(), aggregated_weights)\n",
    "            state_dict = OrderedDict({k: torch.tensor(v) for k, v in params_dict})\n",
    "            \n",
    "            net = Net().to(DEVICE)\n",
    "            net.load_state_dict(state_dict, strict=True)\n",
    "            \n",
    "            # torch.save(Net().state_dict(), PATH_TO_EXPERIMENT + f\"model_round_{rnd}.pth\")\n",
    "            torch.save(net.state_dict(), os.getcwd() + '/' + str(rnd) + '.pth')\n",
    "            \n",
    "        return aggregated_parameters_tuple \n",
    "\n",
    "\n",
    "##################################################################################\n",
    "    \n",
    "# Create strategy and run server\n",
    "strategy = SaveModelStrategy(\n",
    "    \n",
    "    # fl.server.strategy.FedAvg(  # .FedAdagrad(    (As an alternative).\n",
    "    fraction_fit=0.3,  # Train on 30% of clients (each round)\n",
    "    fraction_eval=0.3,  # Evaluate on 30% of clients (each round)\n",
    "    min_fit_clients=3,\n",
    "    min_eval_clients=3,\n",
    "    min_available_clients=NUM_DEVICES,\n",
    "    \n",
    "    initial_parameters=fl.common.weights_to_parameters(get_parameters(Net())),\n",
    "    \n",
    "    on_fit_config_fn=fit_config,\n",
    "    # To evaluate aggregated model parameters on the server-side, open evaluate function above and run below:\n",
    "    # eval_fn=evaluate,  # Pass the evaluation function\n",
    "    # (same arguments as FedAvg here)\n",
    ")\n",
    "    \n",
    "\"\"\"    \n",
    "strategy = fl.server.strategy.FedAvg(  # .FedAdagrad(    (As an alternative).\n",
    "    fraction_fit=0.3,  # Train on 30% of clients (each round)\n",
    "    fraction_eval=0.3,  # Evaluate on 30% of clients (each round)\n",
    "    min_fit_clients=3,\n",
    "    min_eval_clients=3,\n",
    "    min_available_clients=NUM_DEVICES,\n",
    "    \n",
    "    initial_parameters=fl.common.weights_to_parameters(get_parameters(Net())),\n",
    "    \n",
    "    on_fit_config_fn=fit_config,\n",
    "    # To evaluate aggregated model parameters on the server-side, open evaluate function above and run below:\n",
    "    # eval_fn=evaluate,  # Pass the evaluation function\n",
    ")\n",
    "\"\"\"\n",
    "\n",
    "fl.simulation.start_simulation(\n",
    "    client_fn=client_fn,\n",
    "    num_clients=NUM_DEVICES,\n",
    "    num_rounds=NUM_ROUNDS,\n",
    "    strategy=strategy,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec28e947-d5d0-4105-beef-afccffee134c",
   "metadata": {},
   "source": [
    "***\n",
    "# Result Analysis:\n",
    "***\n",
    "## Helper Function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "078e9167-7429-4899-a21f-4b42a2251d38",
   "metadata": {},
   "outputs": [],
   "source": [
    "def take_global_model():\n",
    "    \n",
    "    GM = Net().to(device=DEVICE)\n",
    "    \n",
    "    PATH = os.getcwd() + '/' + str(NUM_ROUNDS) + '.pth'\n",
    "    state_dict = torch.load(PATH)\n",
    "    \n",
    "    GM.load_state_dict(state_dict)\n",
    "    \n",
    "    return GM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1f255a23-04b3-4863-923b-ffd66f5d3048",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GM loss and acc: 0.007147507399320603 0.8569\n"
     ]
    }
   ],
   "source": [
    "GM = take_global_model()\n",
    "GM_loss, GM_acc = test_model(GM, testloader)\n",
    "print('GM loss and acc:', GM_loss, GM_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a021e87-a9b1-45f9-b382-9e1287d7c1c0",
   "metadata": {},
   "source": [
    "***\n",
    "## Pruning Functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "37632487-3fbc-46aa-ac90-7361e2d4fd4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def take_sparsity(model):\n",
    "    \n",
    "    \n",
    "    conv1 = 100. * float(torch.sum(model.conv1.weight == 0)) / float(model.conv1.weight.nelement())\n",
    "    conv2 = 100. * float(torch.sum(model.conv2.weight == 0)) / float(model.conv2.weight.nelement())\n",
    "    \n",
    "    fc1 = 100. * float(torch.sum(model.fc1.weight == 0)) / float(model.fc1.weight.nelement())\n",
    "    fc2 = 100. * float(torch.sum(model.fc2.weight == 0)) / float(model.fc2.weight.nelement())\n",
    "    fc3 = 100. * float(torch.sum(model.fc3.weight == 0)) / float(model.fc3.weight.nelement())\n",
    "\n",
    "    global_sparsity = float(conv1 + conv2 + fc1 + fc2 + fc3) / 5.0\n",
    "    \n",
    "    print(\"Sparsity in conv1.weight: {:.2f}%\".format(conv1))\n",
    "    print(\"Sparsity in conv2.weight: {:.2f}%\".format(conv2))\n",
    "    \n",
    "    print(\"Sparsity in fc1.weight: {:.2f}%\".format(fc1))\n",
    "    print(\"Sparsity in fc2.weight: {:.2f}%\".format(fc2))\n",
    "    print(\"Sparsity in fc3.weight: {:.2f}%\".format(fc3))\n",
    "\n",
    "    print(\"Global sparsity: {:.2f}%\".format(global_sparsity))\n",
    "    \n",
    "    \n",
    "    return [conv1, conv2, fc1, fc2, fc3, global_sparsity]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3d1005d5-e255-4a86-8325-c504d1cd981b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def prune_model(model, threshold=0.5):\n",
    "    \n",
    "    # Search about prune.remove(layername, \"weight\")\n",
    "    \n",
    "    model = model.eval()\n",
    "\n",
    "    parameters_to_prune = (\n",
    "        (model.conv1, 'weight'),\n",
    "        (model.conv2, 'weight'),\n",
    "        (model.fc1, 'weight'),\n",
    "        (model.fc2, 'weight'),\n",
    "        (model.fc3, 'weight'),\n",
    "    )\n",
    "    \n",
    "    \n",
    "    prune.global_unstructured(parameters_to_prune,\n",
    "                              pruning_method=prune.L1Unstructured,\n",
    "                              amount=threshold,)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "301a29dd-3cba-4885-8f1b-9f9b5a9b3ae8",
   "metadata": {},
   "source": [
    "***\n",
    "## Results after Pruning:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9048b92a-66ca-468b-87fa-6e08e6db2c65",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " *******************************************************\n",
      "\n",
      " Threshold is: 0.1 \n",
      "\n",
      "Sparsity in conv1.weight: 2.67%\n",
      "Sparsity in conv2.weight: 6.92%\n",
      "Sparsity in fc1.weight: 11.13%\n",
      "Sparsity in fc2.weight: 5.98%\n",
      "Sparsity in fc3.weight: 3.57%\n",
      "Global sparsity: 6.05%\n",
      "\n",
      " Pruned GM1 loss and acc: [0.007107287827134132, 0.8585]\n",
      "\n",
      " *******************************************************\n",
      "\n",
      " Threshold is: 0.2 \n",
      "\n",
      "Sparsity in conv1.weight: 6.67%\n",
      "Sparsity in conv2.weight: 13.25%\n",
      "Sparsity in fc1.weight: 22.30%\n",
      "Sparsity in fc2.weight: 11.86%\n",
      "Sparsity in fc3.weight: 7.86%\n",
      "Global sparsity: 12.39%\n",
      "\n",
      " Pruned GM1 loss and acc: [0.007510668306052685, 0.8499]\n",
      "\n",
      " *******************************************************\n",
      "\n",
      " Threshold is: 0.3 \n",
      "\n",
      "Sparsity in conv1.weight: 10.00%\n",
      "Sparsity in conv2.weight: 19.29%\n",
      "Sparsity in fc1.weight: 33.42%\n",
      "Sparsity in fc2.weight: 17.98%\n",
      "Sparsity in fc3.weight: 12.86%\n",
      "Global sparsity: 18.71%\n",
      "\n",
      " Pruned GM1 loss and acc: [0.007789574541151523, 0.8397]\n",
      "\n",
      " *******************************************************\n",
      "\n",
      " Threshold is: 0.4 \n",
      "\n",
      "Sparsity in conv1.weight: 10.67%\n",
      "Sparsity in conv2.weight: 26.17%\n",
      "Sparsity in fc1.weight: 44.56%\n",
      "Sparsity in fc2.weight: 23.83%\n",
      "Sparsity in fc3.weight: 18.10%\n",
      "Global sparsity: 24.66%\n",
      "\n",
      " Pruned GM1 loss and acc: [0.008231264588236809, 0.831]\n",
      "\n",
      " *******************************************************\n",
      "\n",
      " Threshold is: 0.5 \n",
      "\n",
      "Sparsity in conv1.weight: 14.00%\n",
      "Sparsity in conv2.weight: 32.67%\n",
      "Sparsity in fc1.weight: 55.67%\n",
      "Sparsity in fc2.weight: 29.91%\n",
      "Sparsity in fc3.weight: 23.21%\n",
      "Global sparsity: 31.09%\n",
      "\n",
      " Pruned GM1 loss and acc: [0.008402083124220371, 0.8301]\n",
      "\n",
      " *******************************************************\n",
      "\n",
      " Threshold is: 0.6 \n",
      "\n",
      "Sparsity in conv1.weight: 17.33%\n",
      "Sparsity in conv2.weight: 39.33%\n",
      "Sparsity in fc1.weight: 66.65%\n",
      "Sparsity in fc2.weight: 36.55%\n",
      "Sparsity in fc3.weight: 27.98%\n",
      "Global sparsity: 37.57%\n",
      "\n",
      " Pruned GM1 loss and acc: [0.00819697802811861, 0.8422]\n",
      "\n",
      " *******************************************************\n",
      "\n",
      " Threshold is: 0.7 \n",
      "\n",
      "Sparsity in conv1.weight: 19.33%\n",
      "Sparsity in conv2.weight: 44.67%\n",
      "Sparsity in fc1.weight: 77.60%\n",
      "Sparsity in fc2.weight: 43.72%\n",
      "Sparsity in fc3.weight: 32.74%\n",
      "Global sparsity: 43.61%\n",
      "\n",
      " Pruned GM1 loss and acc: [0.008464288817346096, 0.8472]\n",
      "\n",
      " *******************************************************\n",
      "\n",
      " Threshold is: 0.8 \n",
      "\n",
      "Sparsity in conv1.weight: 22.67%\n",
      "Sparsity in conv2.weight: 52.88%\n",
      "Sparsity in fc1.weight: 88.34%\n",
      "Sparsity in fc2.weight: 50.99%\n",
      "Sparsity in fc3.weight: 39.05%\n",
      "Global sparsity: 50.79%\n",
      "\n",
      " Pruned GM1 loss and acc: [0.011098796090483665, 0.838]\n",
      "\n",
      " *******************************************************\n",
      "\n",
      " Threshold is: 0.9 \n",
      "\n",
      "Sparsity in conv1.weight: 24.00%\n",
      "Sparsity in conv2.weight: 65.12%\n",
      "Sparsity in fc1.weight: 97.40%\n",
      "Sparsity in fc2.weight: 65.10%\n",
      "Sparsity in fc3.weight: 49.05%\n",
      "Global sparsity: 60.13%\n",
      "\n",
      " Pruned GM1 loss and acc: [0.02676420772075653, 0.6169]\n",
      "\n",
      " *******************************************************\n",
      "\n",
      " Threshold is: 1.0 \n",
      "\n",
      "Sparsity in conv1.weight: 100.00%\n",
      "Sparsity in conv2.weight: 100.00%\n",
      "Sparsity in fc1.weight: 100.00%\n",
      "Sparsity in fc2.weight: 100.00%\n",
      "Sparsity in fc3.weight: 100.00%\n",
      "Global sparsity: 100.00%\n",
      "\n",
      " Pruned GM1 loss and acc: [0.03616348149776459, 0.1028]\n"
     ]
    }
   ],
   "source": [
    "threshold_arr = []\n",
    "sparsity_arr = []\n",
    "loss_and_acc_arr = []\n",
    "\n",
    "for t in range(1, 11):\n",
    "    \n",
    "    T = t/10\n",
    "    threshold_arr.append(T)\n",
    "    \n",
    "    print('\\n *******************************************************')\n",
    "    print('\\n Threshold is:', T, '\\n')\n",
    "    \n",
    "    GM1 = take_global_model()\n",
    "\n",
    "    temp_pruned_GM = prune_model(GM1, threshold=T) \n",
    "    sparsity_arr.append(take_sparsity(temp_pruned_GM))\n",
    "    \n",
    "    performance = test_model(temp_pruned_GM, testloader)\n",
    "    loss_and_acc_arr.append(performance)\n",
    "\n",
    "    print('\\n Pruned GM1 loss and acc:', performance)\n",
    "    \n",
    "sparsity_arr = np.array(sparsity_arr)\n",
    "\n",
    "loss_and_acc_arr = np.array(loss_and_acc_arr)\n",
    "loss_arr = loss_and_acc_arr[:,0]\n",
    "acc_arr = loss_and_acc_arr[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "507b0eb2-ab2d-43f2-a354-ed5e1c37bd5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Threshold</th>\n",
       "      <th>SFL Accuracy</th>\n",
       "      <th>GPFL Accuracy</th>\n",
       "      <th>SFL Loss</th>\n",
       "      <th>GPFL Loss</th>\n",
       "      <th>Participation</th>\n",
       "      <th>Global Sparsity</th>\n",
       "      <th>Conv1</th>\n",
       "      <th>Conv2</th>\n",
       "      <th>FC1</th>\n",
       "      <th>FC2</th>\n",
       "      <th>FC3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>GM</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1721</td>\n",
       "      <td>0.1721</td>\n",
       "      <td>0.036158</td>\n",
       "      <td>0.036158</td>\n",
       "      <td>100</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SM1</th>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0970</td>\n",
       "      <td>0.8585</td>\n",
       "      <td>0.036210</td>\n",
       "      <td>0.007107</td>\n",
       "      <td>200</td>\n",
       "      <td>6.054048</td>\n",
       "      <td>2.666667</td>\n",
       "      <td>6.916667</td>\n",
       "      <td>11.133333</td>\n",
       "      <td>5.982143</td>\n",
       "      <td>3.571429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SM2</th>\n",
       "      <td>0.2</td>\n",
       "      <td>0.1633</td>\n",
       "      <td>0.8499</td>\n",
       "      <td>0.036131</td>\n",
       "      <td>0.007511</td>\n",
       "      <td>300</td>\n",
       "      <td>12.386210</td>\n",
       "      <td>6.666667</td>\n",
       "      <td>13.250000</td>\n",
       "      <td>22.302083</td>\n",
       "      <td>11.855159</td>\n",
       "      <td>7.857143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SM3</th>\n",
       "      <td>0.3</td>\n",
       "      <td>0.0889</td>\n",
       "      <td>0.8397</td>\n",
       "      <td>0.036183</td>\n",
       "      <td>0.007790</td>\n",
       "      <td>400</td>\n",
       "      <td>18.709583</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>19.291667</td>\n",
       "      <td>33.422917</td>\n",
       "      <td>17.976190</td>\n",
       "      <td>12.857143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SM4</th>\n",
       "      <td>0.4</td>\n",
       "      <td>0.0849</td>\n",
       "      <td>0.8310</td>\n",
       "      <td>0.036248</td>\n",
       "      <td>0.008231</td>\n",
       "      <td>500</td>\n",
       "      <td>24.664087</td>\n",
       "      <td>10.666667</td>\n",
       "      <td>26.166667</td>\n",
       "      <td>44.562500</td>\n",
       "      <td>23.829365</td>\n",
       "      <td>18.095238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SM5</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.1593</td>\n",
       "      <td>0.8301</td>\n",
       "      <td>0.036198</td>\n",
       "      <td>0.008402</td>\n",
       "      <td>600</td>\n",
       "      <td>31.091667</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>32.666667</td>\n",
       "      <td>55.666667</td>\n",
       "      <td>29.910714</td>\n",
       "      <td>23.214286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SM6</th>\n",
       "      <td>0.6</td>\n",
       "      <td>0.1043</td>\n",
       "      <td>0.8422</td>\n",
       "      <td>0.036183</td>\n",
       "      <td>0.008197</td>\n",
       "      <td>700</td>\n",
       "      <td>37.568512</td>\n",
       "      <td>17.333333</td>\n",
       "      <td>39.333333</td>\n",
       "      <td>66.652083</td>\n",
       "      <td>36.547619</td>\n",
       "      <td>27.976190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SM7</th>\n",
       "      <td>0.7</td>\n",
       "      <td>0.0549</td>\n",
       "      <td>0.8472</td>\n",
       "      <td>0.036219</td>\n",
       "      <td>0.008464</td>\n",
       "      <td>800</td>\n",
       "      <td>43.610833</td>\n",
       "      <td>19.333333</td>\n",
       "      <td>44.666667</td>\n",
       "      <td>77.595833</td>\n",
       "      <td>43.720238</td>\n",
       "      <td>32.738095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SM8</th>\n",
       "      <td>0.8</td>\n",
       "      <td>0.0616</td>\n",
       "      <td>0.8380</td>\n",
       "      <td>0.036171</td>\n",
       "      <td>0.011099</td>\n",
       "      <td>900</td>\n",
       "      <td>50.785020</td>\n",
       "      <td>22.666667</td>\n",
       "      <td>52.875000</td>\n",
       "      <td>88.343750</td>\n",
       "      <td>50.992063</td>\n",
       "      <td>39.047619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SM9</th>\n",
       "      <td>0.9</td>\n",
       "      <td>0.0980</td>\n",
       "      <td>0.6169</td>\n",
       "      <td>0.036176</td>\n",
       "      <td>0.026764</td>\n",
       "      <td>1000</td>\n",
       "      <td>60.133532</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>65.125000</td>\n",
       "      <td>97.395833</td>\n",
       "      <td>65.099206</td>\n",
       "      <td>49.047619</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Threshold  SFL Accuracy  GPFL Accuracy  SFL Loss  GPFL Loss  \\\n",
       "GM         0.0        0.1721         0.1721  0.036158   0.036158   \n",
       "SM1        0.1        0.0970         0.8585  0.036210   0.007107   \n",
       "SM2        0.2        0.1633         0.8499  0.036131   0.007511   \n",
       "SM3        0.3        0.0889         0.8397  0.036183   0.007790   \n",
       "SM4        0.4        0.0849         0.8310  0.036248   0.008231   \n",
       "SM5        0.5        0.1593         0.8301  0.036198   0.008402   \n",
       "SM6        0.6        0.1043         0.8422  0.036183   0.008197   \n",
       "SM7        0.7        0.0549         0.8472  0.036219   0.008464   \n",
       "SM8        0.8        0.0616         0.8380  0.036171   0.011099   \n",
       "SM9        0.9        0.0980         0.6169  0.036176   0.026764   \n",
       "\n",
       "     Participation  Global Sparsity      Conv1      Conv2        FC1  \\\n",
       "GM             100         0.000000   0.000000   0.000000   0.000000   \n",
       "SM1            200         6.054048   2.666667   6.916667  11.133333   \n",
       "SM2            300        12.386210   6.666667  13.250000  22.302083   \n",
       "SM3            400        18.709583  10.000000  19.291667  33.422917   \n",
       "SM4            500        24.664087  10.666667  26.166667  44.562500   \n",
       "SM5            600        31.091667  14.000000  32.666667  55.666667   \n",
       "SM6            700        37.568512  17.333333  39.333333  66.652083   \n",
       "SM7            800        43.610833  19.333333  44.666667  77.595833   \n",
       "SM8            900        50.785020  22.666667  52.875000  88.343750   \n",
       "SM9           1000        60.133532  24.000000  65.125000  97.395833   \n",
       "\n",
       "           FC2        FC3  \n",
       "GM    0.000000   0.000000  \n",
       "SM1   5.982143   3.571429  \n",
       "SM2  11.855159   7.857143  \n",
       "SM3  17.976190  12.857143  \n",
       "SM4  23.829365  18.095238  \n",
       "SM5  29.910714  23.214286  \n",
       "SM6  36.547619  27.976190  \n",
       "SM7  43.720238  32.738095  \n",
       "SM8  50.992063  39.047619  \n",
       "SM9  65.099206  49.047619  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(data=sparsity_arr, columns=['Conv1', 'Conv2', 'FC1', 'FC2', 'FC3', 'Global Sparsity'])\n",
    "df[\"GPFL Accuracy\"] = acc_arr\n",
    "df[\"GPFL Loss\"] = loss_arr\n",
    "df[\"Threshold\"] = threshold_arr\n",
    "df = df[['Threshold', 'GPFL Accuracy', 'GPFL Loss', 'Global Sparsity', \n",
    "         'Conv1', 'Conv2', 'FC1', 'FC2', 'FC3']]\n",
    "df.loc[-1] = [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0] \n",
    "df.index = df.index + 1  \n",
    "df.sort_index(inplace=True) \n",
    "df['Participation'] = [x*100 for x in range(1, 11)] + [1000]\n",
    "df = df[:-1]\n",
    "# Add SFL Results:\n",
    "arr = [[], []]\n",
    "sfl_smodels = []\n",
    "for t in range(0, 10):\n",
    "\n",
    "    T = t/10\n",
    "    \n",
    "    sfl_smodel = Net()\n",
    "    sfl_smodels.append(sfl_smodel)\n",
    "    \n",
    "    S_FL_GM = sfl_smodel.to(device=DEVICE)\n",
    "    SM = prune_model(S_FL_GM, threshold=T)\n",
    "    l, a = test_model(SM, testloader)\n",
    "    \n",
    "    arr[0].append(l)\n",
    "    arr[1].append(a)\n",
    "\n",
    "df['SFL Loss'] = arr[0]\n",
    "df['SFL Accuracy'] = arr[1]\n",
    "\n",
    "\n",
    "df.loc[0, 'GPFL Accuracy'] = df.loc[0, 'SFL Accuracy']\n",
    "df.loc[0, 'GPFL Loss'] = df.loc[0, 'SFL Loss']\n",
    "\n",
    "df = df[['Threshold', 'SFL Accuracy', 'GPFL Accuracy', 'SFL Loss', 'GPFL Loss', 'Participation', \n",
    "         'Global Sparsity', 'Conv1', 'Conv2', 'FC1', 'FC2','FC3']]\n",
    "\n",
    "df = df.rename(index={0: 'GM', 1: 'SM1', 2: 'SM2', 3: 'SM3', 4: 'SM4', 5: 'SM5', 6: 'SM6', 7: 'SM7',\n",
    "                      8: 'SM8', 9: 'SM9'})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3d51ba3d-fc15-41fd-860e-c1c3294305a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Threshold</th>\n",
       "      <th>SFL Accuracy</th>\n",
       "      <th>GPFL Accuracy</th>\n",
       "      <th>SFL Loss</th>\n",
       "      <th>GPFL Loss</th>\n",
       "      <th>Participation</th>\n",
       "      <th>Global Sparsity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>GM</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1721</td>\n",
       "      <td>0.1721</td>\n",
       "      <td>0.036158</td>\n",
       "      <td>0.036158</td>\n",
       "      <td>100</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SM1</th>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0970</td>\n",
       "      <td>0.8585</td>\n",
       "      <td>0.036210</td>\n",
       "      <td>0.007107</td>\n",
       "      <td>200</td>\n",
       "      <td>6.054048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SM2</th>\n",
       "      <td>0.2</td>\n",
       "      <td>0.1633</td>\n",
       "      <td>0.8499</td>\n",
       "      <td>0.036131</td>\n",
       "      <td>0.007511</td>\n",
       "      <td>300</td>\n",
       "      <td>12.386210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SM3</th>\n",
       "      <td>0.3</td>\n",
       "      <td>0.0889</td>\n",
       "      <td>0.8397</td>\n",
       "      <td>0.036183</td>\n",
       "      <td>0.007790</td>\n",
       "      <td>400</td>\n",
       "      <td>18.709583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SM4</th>\n",
       "      <td>0.4</td>\n",
       "      <td>0.0849</td>\n",
       "      <td>0.8310</td>\n",
       "      <td>0.036248</td>\n",
       "      <td>0.008231</td>\n",
       "      <td>500</td>\n",
       "      <td>24.664087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SM5</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.1593</td>\n",
       "      <td>0.8301</td>\n",
       "      <td>0.036198</td>\n",
       "      <td>0.008402</td>\n",
       "      <td>600</td>\n",
       "      <td>31.091667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SM6</th>\n",
       "      <td>0.6</td>\n",
       "      <td>0.1043</td>\n",
       "      <td>0.8422</td>\n",
       "      <td>0.036183</td>\n",
       "      <td>0.008197</td>\n",
       "      <td>700</td>\n",
       "      <td>37.568512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SM7</th>\n",
       "      <td>0.7</td>\n",
       "      <td>0.0549</td>\n",
       "      <td>0.8472</td>\n",
       "      <td>0.036219</td>\n",
       "      <td>0.008464</td>\n",
       "      <td>800</td>\n",
       "      <td>43.610833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SM8</th>\n",
       "      <td>0.8</td>\n",
       "      <td>0.0616</td>\n",
       "      <td>0.8380</td>\n",
       "      <td>0.036171</td>\n",
       "      <td>0.011099</td>\n",
       "      <td>900</td>\n",
       "      <td>50.785020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SM9</th>\n",
       "      <td>0.9</td>\n",
       "      <td>0.0980</td>\n",
       "      <td>0.6169</td>\n",
       "      <td>0.036176</td>\n",
       "      <td>0.026764</td>\n",
       "      <td>1000</td>\n",
       "      <td>60.133532</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Threshold  SFL Accuracy  GPFL Accuracy  SFL Loss  GPFL Loss  \\\n",
       "GM         0.0        0.1721         0.1721  0.036158   0.036158   \n",
       "SM1        0.1        0.0970         0.8585  0.036210   0.007107   \n",
       "SM2        0.2        0.1633         0.8499  0.036131   0.007511   \n",
       "SM3        0.3        0.0889         0.8397  0.036183   0.007790   \n",
       "SM4        0.4        0.0849         0.8310  0.036248   0.008231   \n",
       "SM5        0.5        0.1593         0.8301  0.036198   0.008402   \n",
       "SM6        0.6        0.1043         0.8422  0.036183   0.008197   \n",
       "SM7        0.7        0.0549         0.8472  0.036219   0.008464   \n",
       "SM8        0.8        0.0616         0.8380  0.036171   0.011099   \n",
       "SM9        0.9        0.0980         0.6169  0.036176   0.026764   \n",
       "\n",
       "     Participation  Global Sparsity  \n",
       "GM             100         0.000000  \n",
       "SM1            200         6.054048  \n",
       "SM2            300        12.386210  \n",
       "SM3            400        18.709583  \n",
       "SM4            500        24.664087  \n",
       "SM5            600        31.091667  \n",
       "SM6            700        37.568512  \n",
       "SM7            800        43.610833  \n",
       "SM8            900        50.785020  \n",
       "SM9           1000        60.133532  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final = df[['Threshold', 'SFL Accuracy', 'GPFL Accuracy', 'SFL Loss', 'GPFL Loss', \n",
    "               'Participation', 'Global Sparsity']]\n",
    "df_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "49b8af25-ea5f-4970-baf6-eed81e11e36b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lrrrrrrr}\n",
      " & Threshold & SFL Accuracy & GPFL Accuracy & SFL Loss & GPFL Loss & Participation & Global Sparsity \\\\\n",
      "GM & 0.000000 & 0.172100 & 0.172100 & 0.036158 & 0.036158 & 100 & 0.000000 \\\\\n",
      "SM1 & 0.100000 & 0.097000 & 0.858500 & 0.036210 & 0.007107 & 200 & 6.054048 \\\\\n",
      "SM2 & 0.200000 & 0.163300 & 0.849900 & 0.036131 & 0.007511 & 300 & 12.386210 \\\\\n",
      "SM3 & 0.300000 & 0.088900 & 0.839700 & 0.036183 & 0.007790 & 400 & 18.709583 \\\\\n",
      "SM4 & 0.400000 & 0.084900 & 0.831000 & 0.036248 & 0.008231 & 500 & 24.664087 \\\\\n",
      "SM5 & 0.500000 & 0.159300 & 0.830100 & 0.036198 & 0.008402 & 600 & 31.091667 \\\\\n",
      "SM6 & 0.600000 & 0.104300 & 0.842200 & 0.036183 & 0.008197 & 700 & 37.568512 \\\\\n",
      "SM7 & 0.700000 & 0.054900 & 0.847200 & 0.036219 & 0.008464 & 800 & 43.610833 \\\\\n",
      "SM8 & 0.800000 & 0.061600 & 0.838000 & 0.036171 & 0.011099 & 900 & 50.785020 \\\\\n",
      "SM9 & 0.900000 & 0.098000 & 0.616900 & 0.036176 & 0.026764 & \\cellcolor{red} \\bfseries 1000 & 60.133532 \\\\\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "s = df_final.style.highlight_max(axis=None, props='cellcolor:{red}; bfseries: ;')\n",
    "\n",
    "print(s.to_latex()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "095b0a5d-d760-4e7f-a509-b7de8f381dfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "table_latex_version = {'table_latex_version': s.to_latex()}\n",
    "\n",
    "with open('table_latex_version.txt', 'w') as f:\n",
    "    f.write(json.dumps(table_latex_version))\n",
    "\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8341bd9-4c62-405c-af96-ce2fb62203dc",
   "metadata": {
    "tags": []
   },
   "source": [
    "***\n",
    "# Pruning Result with S-FL Visualisation:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71822bb8-1f47-465d-a1b4-7f0d108dd90e",
   "metadata": {},
   "source": [
    "***\n",
    "### Initial Accuracy & Participation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e3c45fd5-4fbb-4f01-9d5e-a8d05c737bcd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# create figure and axis objects with subplots()\n",
    "fig, ax = plt.subplots()\n",
    "plt.grid()\n",
    "\n",
    "# Our Algo. Acc.\n",
    "ax.plot(df['Threshold'].values, \n",
    "        df['GPFL Accuracy'].values, \n",
    "        color=\"green\", \n",
    "        label='Accuracy of GPFL', \n",
    "        marker=\"o\")\n",
    "\n",
    "# S-FL Acc.\n",
    "ax.plot(df['Threshold'].values, \n",
    "        df['SFL Accuracy'].values, \n",
    "        color=\"red\", \n",
    "        label='S-FL Accuracy',\n",
    "        marker=\"o\")\n",
    "\n",
    "plt.legend(framealpha=1, frameon=True, bbox_to_anchor=(0.38, 1.2));\n",
    "\n",
    "# set x-axis label\n",
    "ax.set_xlabel(\"Threshold Values\", fontweight='bold', fontsize=14)\n",
    "# set y-axis label\n",
    "ax.set_ylabel(\"Accuracy of Models\", color=\"black\", fontweight='bold', fontsize=14)\n",
    "\n",
    "# twin object for two different y-axis on the sample plot\n",
    "ax2=ax.twinx()\n",
    "# make a plot with different y-axis using second axis object\n",
    "ax2.plot(df['Threshold'].values, \n",
    "         df['Participation'].values, \n",
    "         color=\"blue\", \n",
    "         label='Participation', \n",
    "         marker=\"x\")\n",
    "\n",
    "ax2.set_ylabel(\"Number of Participated Devices\", color=\"black\", fontweight='bold', fontsize=14)\n",
    "# ax2.legend(loc='upper left', frameon=False)\n",
    "\n",
    "#plt.legend(lines[:2], ['first', 'second']);\n",
    "# plt.title(\"Initial Accuracy values of Standard Federated Learning\", fontweight=\"bold\")\n",
    "plt.legend(framealpha=1, frameon=True, bbox_to_anchor=(1.015, 1.15));\n",
    "plt.show()\n",
    "\n",
    "# save the plot as a file\n",
    "fig.savefig('Accuracy&Participation vs Threshold with S-FL.jpg', \n",
    "            format='jpeg', dpi=100, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8413aee5-465a-4f20-9212-dd1c9ed34e96",
   "metadata": {},
   "source": [
    "### Initial Accuracy & Model Sparsity:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "75eed462-ba81-4d8b-b6d3-b7066d77bc87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# create figure and axis objects with subplots()\n",
    "fig, ax = plt.subplots()\n",
    "plt.grid()\n",
    "# make a plot\n",
    "ax.plot(df['Threshold'].values, \n",
    "        df['GPFL Accuracy'].values, \n",
    "        label='Accuracy of GPFL', \n",
    "        color=\"green\", \n",
    "        marker=\"o\")\n",
    "\n",
    "ax.plot(df['Threshold'].values, \n",
    "        df['SFL Accuracy'].values, \n",
    "        label='S-FL Accuracy', \n",
    "        color=\"red\", \n",
    "        marker=\"o\")\n",
    "\n",
    "plt.legend(framealpha=1, frameon=True, bbox_to_anchor=(0.38, 1.2));\n",
    "\n",
    "# set x-axis label\n",
    "ax.set_xlabel(\"Threshold Values\", fontweight='bold', fontsize = 14)\n",
    "# set y-axis label\n",
    "ax.set_ylabel(\"Accuracy of Models\", color=\"black\", fontweight='bold', fontsize=14)\n",
    "\n",
    "# twin object for two different y-axis on the sample plot\n",
    "ax2=ax.twinx()\n",
    "# make a plot with different y-axis using second axis object\n",
    "ax2.plot(df['Threshold'].values, \n",
    "         df['Global Sparsity'].values, \n",
    "         label='Global Sparsity', \n",
    "         color=\"orange\", \n",
    "         marker=\"x\")\n",
    "\n",
    "ax2.set_ylabel(\"Global Sparsity\", color=\"black\", fontweight='bold', fontsize=14)\n",
    "\n",
    "plt.legend(framealpha=1, frameon=True, bbox_to_anchor=(1.015, 1.15));\n",
    "plt.show()\n",
    "# save the plot as a file\n",
    "fig.savefig('Accuracy&Global_Sparsity vs Threshold with S-FL.jpg', \n",
    "            format='jpeg', dpi=100, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b3b4a06-04ff-4eb6-86f3-7c64a96a94c0",
   "metadata": {},
   "source": [
    "***\n",
    "### Initial Loss & Partcipation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5af61e8c-93f3-4365-bf25-cd926113242a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# create figure and axis objects with subplots()\n",
    "fig, ax = plt.subplots()\n",
    "plt.grid()\n",
    "# make a plot\n",
    "ax.plot(df['Threshold'].values, \n",
    "        df['GPFL Loss'].values, \n",
    "        color=\"green\", \n",
    "        label='Loss of GPFL', \n",
    "        marker=\"o\")\n",
    "\n",
    "ax.plot(df['Threshold'].values, \n",
    "        df['SFL Loss'].values, \n",
    "        color=\"red\", \n",
    "        label='S-FL Loss', \n",
    "        marker=\"o\")\n",
    "\n",
    "plt.legend(framealpha=1, frameon=True, bbox_to_anchor=(0.31, 1.2));\n",
    "\n",
    "# set x-axis label\n",
    "ax.set_xlabel(\"Threshold Values\", fontweight='bold', fontsize = 14)\n",
    "# set y-axis label\n",
    "ax.set_ylabel(\"Loss\", color=\"black\", fontweight='bold', fontsize=14)\n",
    "\n",
    "# twin object for two different y-axis on the sample plot\n",
    "ax2=ax.twinx()\n",
    "# make a plot with different y-axis using second axis object\n",
    "ax2.plot(df['Threshold'].values, \n",
    "         df['Participation'].values, \n",
    "         label='Participation', \n",
    "         color=\"blue\", \n",
    "         marker=\"x\")\n",
    "ax2.set_ylabel(\"Number of Participated Devices\", fontweight='bold', color=\"black\", fontsize=14)\n",
    "\n",
    "plt.legend(framealpha=1, frameon=True, bbox_to_anchor=(1.015, 1.15));\n",
    "plt.show()\n",
    "# save the plot as a file\n",
    "fig.savefig('Loss&Participation vs Threshold with S-FL.jpg', \n",
    "            format='jpeg', dpi=100, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b71c0b48-2915-42cc-a6d4-b853e12937cc",
   "metadata": {},
   "source": [
    "### Loss & Model Sparsity:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d83de388-7347-4a8e-80d7-50ccacaa5144",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAoEAAAH4CAYAAAA1ljcsAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjYuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/P9b71AAAACXBIWXMAAA9hAAAPYQGoP6dpAACw0UlEQVR4nOzdd3hUZdrA4d+ZVNILkIQACZ0AITSB0JESwIYgKLBSZNFdpUhcFnGRuor6KQKCIi5FVxFFkUWlGENVIEDo0kINhCQQAqSRNnO+P44zEJJA+kwyz+01lzllzvscziR58lZFVVUVIYQQQghhVXTmDkAIIYQQQlQ8SQKFEEIIIayQJIFCCCGEEFZIkkAhhBBCCCskSaAQQgghhBWSJFAIIYQQwgpJEiiEEEIIYYVszR2ANcvNzSU7O9vcYQgLY29vj62tfGsKIYQoX/KbxgxUVSU2NpakpCRzhyIsVPXq1albty6Kopg7FCGEEFWUJIFmYEwA/f39cXFxQaeTVnmhMRgMpKWlERcXB0BAQICZIxJCCFFVSRJYwXJzc00JoK+vr7nDERbIxcUFgLi4OPz9/aVpWAghRLmQKqgKZuwDaPxFL0RBjJ8P6TMqhBCivEgSaCbSBCweRD4fQgghypv8phFCCCGEsEKSBAohhBBCWCFJAisxvUHP9ovb+frY12y/uB29QW/ukCzKrFmz8PHxQVEU1q9fb+5whBBCCIsiSWAlte7kOgIXBtLz854MXzecnp/3JHBhIOtOriu3MkePHs3AgQPL7fpl6eTJk8yePZtPP/2U+Ph4+vfvX+i533//PY8++iienp5Uq1aNJk2a8MILL3Do0CHTOatWrUJRFBRFQafTUbt2bcaMGcO1a9dM5xiP3/vq0qVLnuOSjAohhLAUkgRWQutOruOZb5/hSsqVPPvjUuJ45ttnyjURrCzOnTsHwFNPPYWvry8ODg4Fnjd16lSeffZZWrVqxYYNGzh9+jSrV6+mfv36TJs2Lc+5bm5uxMfHc+XKFT777DM2bdrE888/n+eclStXEh8fb3pt2LChfG5QCCGEKCVJAi2AqqqkZ6cX6ZWSmcLETRNRUfNf5899kzZNIiUzpUjXU9X81ympHTt20L59exwcHPDz8+P1118nNzfXdPy7774jODiYatWq4e3tTe/evUlPTwdg+/bttG/fHmdnZzw8POjcuTOXLl0qtKxjx47x6KOPmq714osvkpaWBmjNwE888QSgjbItbNWNvXv38t577zF//nzmz59P165dqVu3Lm3btmX69Ols2rQpz/mKouDr60utWrXo378/EydO5Ndff+XOnTumczw8PPD19TW9vLy8SvaPKYQQQpQzmYXWAmTkZOAyr2zmDVRRuZJ6Bfd33Yt0ftq0NJztnUtdblxcHAMGDGD06NF88cUXnDp1inHjxuHo6MisWbOIj49n2LBhvPfeezz99NOkpqaya9cuVFUlNzeXgQMHMm7cOL7++muys7PZt29foclbeno6YWFhhIaGsn//fq5du8Zf//pXxo8fz6pVq/jHP/5BYGAgY8aMIT4+vtCYv/76a1xcXHj55ZcLPP6wJduqVauGwWDIk+gKIYQQlYUkgaJMfPzxx9SpU4fFixejKApNmzbl6tWrTJ06lRkzZhAfH09ubi6DBg0yLYUWHBwMQHJyMrdv3+bxxx+nQYMGAAQFBRVa1urVq8nMzOSLL77A2VlLYBcvXswTTzzBu+++i4+PDx4eHgAPXJXlzJkz1K9fP8+KHPPnz2fGjBmm7bi4ONzd8yfUMTExLF26lHbt2uHq6mraP2zYMGxsbEzbX375ZaXpRymEEMK6SBJoAZzsnEibllakc3de2smA1QMeet7G4RvpFtCtSGWXhZMnTxIaGpqn9qxz586kpaVx5coVQkJC6NWrF8HBwYSFhdG3b1+eeeYZPD098fLyYvTo0YSFhdGnTx969+7N0KFD8fPzK7SskJAQUwJoLMtgMHD69Gl8fHxKfB8vvPACTz75JFFRUfzlL3/J01x++/ZtXFxcMBgMZGZm0qVLF/7zn//kef+HH35I7969TduF3YMQQghhbtIn0AIoioKzvXORXn0b9KW2W20UCm6qVFCo41aHvg36Ful6D2vyLCs2NjZERESwadMmmjVrxkcffUSTJk24cOECoA2o2LNnD506deKbb76hcePG7N27t1xjatSoEefPnycnJ8e0z8PDg4YNG+Lv75/vfFdXVw4fPszx48dJT09n586dNG7cOM85vr6+NGzY0PS6N1EVQgghLIkkgZWMjc6Ghf0WAuRLBI3bC/otwEZnk++95SkoKIg9e/bkqTn7/fffcXV1pXbt2lp8ikLnzp2ZPXs2hw4dwt7enh9++MF0fuvWrZk2bRq7d++mRYsWrF69utCyjhw5YhpUYixLp9PRpEmTIsc8bNgw0tLS+Pjjj4t0vk6no2HDhtSvX59q1aoVuRwhhBDCEklzcCU0KGgQ3w39jkmbJ+WZJqa2W20W9FvAoKBB5Vb27du3OXz4cJ593t7evPzyyyxYsIAJEyYwfvx4Tp8+zcyZMwkPD0en0xEVFUVkZCR9+/alZs2aREVFcf36dYKCgrhw4QLLli3jySefpFatWpw+fZqYmBhGjhxZYAwjRoxg5syZjBo1ilmzZnH9+nUmTJjA888/X6ym4NDQUF577TVee+01Ll26xKBBg6hTpw7x8fEsX77cNCdgWbpw4UK+f79GjRpJjaEQQoiKp4oKlZ6erh44cEBNT08v9bVy9bnqtgvb1NVHV6vbLmxTc/W5ZRBh4UaNGqUC+V5jx45VVVVVt2/frj7yyCOqvb296uvrq06dOlXNyclRVVVVT5w4oYaFhak1atRQHRwc1MaNG6sfffSRqqqqmpCQoA4cOFD18/NT7e3t1YCAAHXGjBmqXq8vNJajR4+qPXv2VB0dHVUvLy913Lhxampqqun4Dz/8oBb14/3NN9+oPXr0UN3d3VU7Ozu1du3a6vDhw9W9e/eazlm5cqXq7u7+wOsA6g8//PDA4wW9du3ale/csvycCCGEEAVRVLUMJ4oTD5WRkcHJkycJCgrCyalsBmWIqkc+J0LcpdfrycrKMncYooqytbXFzs6uwvrIWxJpDhZCCGGxUlJSOHv2bJlObC/E/VxcXAgMDCx0damqSpJAIYQQFkmv13P27FlcXV3x8/Mr8z66QqiqSlZWFnFxcZw4cYKQkBCr+pxJEiiEEMIiZWVloaoqfn5+uLiUzapKQtzP2dkZe3t7Tp8+TVZWllXN/mA96a4QQohKyZpqZoR5GD9j1tbtQL6zhBBCCCGskCSBQgghhBBWSJJAIYQQwkwURWH9+vVFPn/06NEMHDiwVGVevHgRRVHyTVxfWfTo0YNXX33V3GFUCZIECiGEqJqOzoJjcws+dmyudrycJCQkMGnSJBo2bIijoyM+Pj507tyZTz75hIyMjHIrt6xcuHCB4cOHU6tWLRwdHalduzZPPfUUp06dMndorFu3jrlz7z7XwMBAFixYYL6AKjEZHSyEEKJqUmzg2Azt6+A37+4/NlfbHzynXIo9f/48nTt3xsPDg7fffpvg4GAcHBw4duwYy5Ytw9/fnyeffLJcyi4LOTk59OnThyZNmrBu3Tr8/Py4cuUKmzZt4tatW+VadnZ2Nvb29g88x8vLq1xjsCZSE1iZ6fWwfTt8/bX2f73e3BEJIUT5UVXITS/6Kygcmk/XEr4jb2r7jrypbTefrh0v6rWKMWr05ZdfxtbWlgMHDjB06FCCgoKoX78+Tz31FD///DNPPPFEoe89duwYjz76KNWqVcPb25sXX3yRtLS0fOfNnj2bGjVq4Obmxt/+9jeys7NNxzZv3kyXLl3w8PDA29ubxx9/nHPnzhU5/j/++INz587x8ccf07FjRwICAujcuTP//ve/6dixI3C3SXnNmjV06tQJR0dHWrRowY4dO0zX0ev1jB07lnr16lGtWjWaNGnCwoUL85RlbN5+6623qFWrFk2aNAHg448/plGjRqZa1Geeecb0nnubg3v06MGlS5eYPHkyiqKgKArp6em4ubnx3Xff5Slr/fr1ODs7k5qaWuR/i6pOagIrq3XrYNIkuHLl7r7atWHhQhg0qFyKvH79OjNmzODnn38mMTERT09PQkJCmDFjBp07dy70fQUtxdO5c2d+++030/EffvihyP1cAgMDefXVV6VPiBDWRp8B35ZwvsA//q29Ctt+mKFpYOv80NNu3LjBL7/8wttvv42zc8HnF7Y8WXp6OmFhYYSGhrJ//36uXbvGX//6V8aPH8+qVatM50VGRuLo6Mj27du5ePEiY8aMwdvbm7feest0nfDwcFq2bElaWhozZszg6aef5vDhw0WabqdGjRrodDq+++47Xn31VWxsbAo9d8qUKSxYsIBmzZoxf/58nnjiCS5cuIC3tzcGg4HatWuzdu1avL292b17Ny+++CJ+fn4MHTo0z/24ubkREREBwIEDB5g4cSL//e9/6dSpE8nJyezatavA8tetW0dISAgvvvgi48aNA7R5/5577jlWrlyZJ3k0bru6uj7038BaSBJYGa1bB888k/8v07g4bf9335VLIjh48GCys7P5/PPPqV+/PomJiURGRnLjxo2HvnflypX069fPtP2w6n4hhKiMjEvcGWu0jKpXr05mZiYAr7zyCu+++26+965evZrMzEy++OILUwK5ePFinnjiCd599118fHwA7efnihUrcHJyonnz5syZM4cpU6Ywd+5cdDodgwcPznPdFStWUKNGDU6cOEGLFi0eeg/+/v4sWrSIf/7zn8yePZt27drRs2dPRowYQf369fOcO378eFN5n3zyCZs3b2b58uX885//xM7OjtmzZ5vOrVevHnv27OHbb7/NkwQ6Ozvzn//8x/R7Yd26dTg7O/P444/j6upKQEAArVu3LjBWLy8vbGxscHV1xdfX17T/r3/9K506dSI+Ph4/Pz+uXbvGxo0b+fXXXx96/9ZEkkBLoKpQ1I7Cej1MnFhw04SqgqJoNYS9e8MD/nozcXLS3vMQt27dYteuXWzfvp3u3bsDEBAQQPv27YsUtoeHR55v0PL0ySef8P7773P58mXq1avH9OnTef755wFtItDZs2ezYsUKEhMT8fb25plnnmHRokWA1gTx4YcfcvnyZdzd3enatWu+JgUhhJnYOGk1csX1xztarZ/OHgzZWlNw89eLX3Yp7Nu3D4PBwIgRI8jKyirwnJMnTxISEpKnBrFz584YDAZOnz5tSgJDQkJwcrobT2hoKGlpaVy+fJmAgABiYmKYMWMGUVFRJCUlYTAYAIiNjS1SEghaojpy5Ei2b9/O3r17Wbt2LW+//TYbNmygT58+eco2srW1pV27dpw8edK0b8mSJaxYsYLY2Fju3LlDdnY2rVq1ylNWcHBwnoqBPn36EBAQQP369enXrx/9+vXj6aefznPPD9O+fXuaN2/O559/zuuvv86XX35JQEAA3bp1K/I1rIH0CbQEGRng4lK0l7u7VuNXGFXVmojd3Yt2vSImny4uLri4uLB+/fpCf4BZgh9++IFJkybx2muvcfz4cV566SXGjBnDtm3bAPj+++/58MMP+fTTT4mJiWH9+vUEBwcDd5sg5syZw+nTp9m8ebP8wBDCkiiK1iRbnNfJ+VoCGDwHnsvS/v/Hv7X9xblOEf5YBmjYsCGKonD69Ok8++vXr0/Dhg0rZEmyJ554guTkZD777DOioqKIiooCyNNvsChcXV154okneOuttzhy5Ahdu3bl3/8uehP6mjVr+Mc//sHYsWP55ZdfOHz4MGPGjMkXx/3N5q6urhw8eJCvv/4aPz8/ZsyYQUhISLEHpfz1r381NaOvXLmSMWPGFNoUb60kCRRFYmtry6pVq/j888/x8PCgc+fOvPHGGxw9erRI7x82bJgpkTQmk+Xh/fffZ/To0bz88ss0btyY8PBwBg0axPvvvw9ofwn7+vrSu3dv6tatS/v27U39SGJjY01NEMbmh4kTJ5ZLnEKICnDvKGDj6ODgN7XtYzMKnz6mFLy9venTpw+LFy8mPT29WO8NCgriyJEjed73+++/o9Pp8jQvHzlyhDt37pi29+7di4uLC3Xq1OHGjRucPn2a6dOn06tXL4KCgrh582ap70tRFJo2bZrvnvbu3Wv6Ojc3l+joaIKCgkyxd+rUiZdffpnWrVvTsGHDIg9QsbW1pXfv3rz33nscPXqUixcvsnXr1gLPtbe3R1/AwMi//OUvXLp0iUWLFnHixAlGjRpV1Nu1GpIEWgInJ0hLK9pr48aiXXPjxqJdrxjV64MHD+bq1ats2LCBfv36sX37dtq0aWP6S+tvf/tbnkTvXh9++CGHDx82ve5tTihLJ0+ezDdIpXPnzqbmiSFDhnDnzh3q16/PuHHj+OGHH8jNzQXyNkE8//zzfPXVV5ViPi8hRCFUfd4E0MiYCKrlM6PCxx9/TG5uLu3ateObb77h5MmTnD59mi+//JJTp04VOtBixIgRODo6MmrUKI4fP862bduYMGECzz//vKkpGLQavbFjx3LixAk2btzIzJkzGT9+PDqdDk9PT7y9vVm2bBlnz55l69athIeHFyv+w4cP89RTT/Hdd99x4sQJzp49y/Lly1mxYgVPPfVUnnOXLFnCDz/8wKlTp3jllVe4efMmL7zwAgCNGjXiwIEDbNmyhTNnzvDmm2+yf//+h5b/008/sWjRIg4fPsylS5f44osvMBgM+fpZGgUGBrJz507i4uJISkoy7ff09GTQoEFMmTKFvn37Urt27WL9O1gFVVSo9PR09cCBA2p6enrJLpCbq6q1a6uqoqiq1vib96UoqlqnjnZeBRg7dqxat25dVVVVNTExUY2JiTG9jAD1hx9+KPQaDzt+v4CAAPXDDz8s8Jinp6e6atWqPPsWLFig1qtXz7SdkZGhbtiwQZ0wYYLq6+urhoaGqtnZ2aqqqmpOTo4aERGhTpkyRa1fv77asGFD9ebNm0WOrayU+nMiRBVQmb8Prl69qo4fP16tV6+eamdnp7q4uKjt27dX/+///i/P/dz/8+/o0aNqz549VUdHR9XLy0sdN26cmpqaajo+atQo9amnnlJnzJihent7qy4uLuq4cePUzMxM0zkRERFqUFCQ6uDgoLZs2VLdvn17nnIuXLigAuqhQ4cKjP369evqxIkT1RYtWqguLi6qq6urGhwcrL7//vuqXq/Pc43Vq1er7du3V+3t7dVmzZqpW7duNV0nMzNTHT16tOru7q56eHiof//739XXX39dDQkJyXc/99q1a5favXt31dPTU61WrZrasmVL9ZtvvjEd7969uzpp0iTT9p49e9SWLVuqDg4O6v1pTWRkpAqo3377bYH3alSZP2ulIUlgBSuTD9r332vJ3v2JoHHf99+XXcAP8cEHH6je3t4PPKcik8BOnTqp48aNy7NvyJAh6mOPPVbg+adOnVIBNTo6Ot+xtLQ01dbWVv2+Av89jaz1B5IQ95LvA8v1sETSUnzxxReqt7e3mpWV9cDzrPWzJqODK6NBg7RpYAqaJ3DBgnKZHubGjRsMGTKEF154gZYtW+Lq6sqBAwd477338jUPlMSFCxfyrWPZqFGjQufZiouLy3d+QEAAU6ZMYejQobRu3ZrevXvz448/sm7dOtO0AKtWrUKv19OhQwecnJz48ssvqVatGgEBAfz000+cP3+ebt264enpycaNGx/YBCGEEMIyZWRkEB8fzzvvvMNLL70k05IVxtxZqLUp0782cnNVdds2VV29Wvt/OTYBZ2Zmqq+//rrapk0b1d3dXXVyclKbNGmiTp8+Xc3IyHjgeylCTWBBr127dhV4fkBAQIHn//e//1VVVVU//vhjtX79+qqdnZ3auHFj9YsvvjC994cfflA7dOigurm5qc7OzmrHjh3VX3/9VVXVhzdBVCRr/atUiHvJ94HlsvSawJkzZ6q2trbqo48+mqc5vTDW+llTVLUYa+GIUsvIyODkyZMEBQUVa84jYV3kcyKEfB+IimOtnzUZHSyEEEIIYYUkCRRCCGHRpMFKlDfjqirWRpJAIYQQFsnWVhu7aMmrFImqIS1NW47Q2gaQyOhgM7HWvzpE0cjnQwiws7PDxcWFuLg47O3t0emk3kKULYPBQFpaGnFxcVSvXt30h4e1sK67tQDGvzLS0tLyraohhJG1/lUqxL0URSEwMJATJ07kW4tXiLJUvXp16tata+4wKpwkgRXM1taW6tWrExcXB4CLi4v8dStMrP2vUiHu5+DgQEhICFlZWdI3UJQLe3t7q/1ZK1PEmIGqqsTGxuZZ41CIexn/KlUUxdyhCCGEqKIkCTSj3NxcsrOzzR2GsDDW/FepEEKIiiNJoBBCCCGEFZLOaEIIIYQQVkiSQCGEEEIIKyRJoBBCCCGEFZIkUAghhBDCCkkSKIQQQghhhSQJFEIIIYSwQpIECiGEEEJYIUkChRBCCCGskCSBQgghhBBWSJJAIYQQQggrJEmgEEIIIYQVkiRQCCGEEMIKSRIohBBCCGGFJAkUQgghhLBCkgQKIYQQQlghSQKFEEIIIayQJIFCCCGEEFbI1twBVCW5ubkcOnQIHx8fdDrJr4UQQojKwGAwkJiYSOvWrbG1tZ7UyHrutAIcOnSI9u3bmzsMIYQQQpTAvn37eOSRR8wdRoWRJLAM+fj4ANqHyM/Pr8yum5ubS2RkJL169bKqv1AsmTwTyyLPw7LI87As8jweLj4+nvbt25t+j1sL+TSUIWMTsJ+fH7Vr1y6z6+bk5FC9enX8/f2xs7Mrs+uKkpNnYlnkeVgWeR6WRZ5H0VlbVy7rulshhBBCCAFIEiiEEEIIYZUkCRRCCCGEsEKSBAohhBBCWCFJAoUQQgghrJAkgUIIIYQQVkiSQCGEEEIIKyRJoBBCCCGEFZIkUAghhBDCCsmKIaJi6PWwaxfEx4OfH3TtCjY25o5KVAV6PcqOHfjv3Ini7Aw9e1bOz5Z8j1gWeR7CCkhNoIXT52Rz9NtFpG5axtFvF6HPyTZ3SMW3bh0EBmq/nIcP1/4fGKjtr4zuTTp27NB+WVRGej1s3w5ff639vzLex5+fLds+fWg3fz62ffpUzs9WVfoeqQrfH/I8LMfRWXBsbsE/r47N1Y6LklNFmbl8+bIKqJcvXy6T6+1ZOEWNc7dRVTC94txt1D0Lp5TJ9SvE99+rqqLkuQcVtH2Koh2vTL7/XlVr1857L7Vry32YQ1X5bFWV+1BV+VxZmqrwPI7OUdWvUNVRbnnvY5Sbtv/onDIppiS/v69cuaKOGDFC9fLyUh0dHdUWLVqo+/fvNx03GAzqm2++qfr6+qqOjo5qr1691DNnzpRJvGVFksAyVJZJ4J6FU1Q9qPr7fhAZ91WKRDA3N/8PoPt/qNapo51XGVSVXw6V8T4MBlXNyVHVO3dUNTVVVZOSVLVWrQd/tvz9VfXGDe38jAxVzcrSPmsGg7nv5q6q9D1SGT9X95PnYXm+/15Vn0ZL+IagqkGo6sA/t5+mzO6juL+/k5OT1YCAAHX06NFqVFSUev78eXXLli3q2bNnTee88847qru7u7p+/Xr1yJEj6pNPPqnWq1dPvXPnTpnEXBYUVVVV89ZFVh1XrlyhTp06XL58mdq1a5f4OvqcbBJrOOF7W19ge70BuO6mo/qeo9goOq1avLBXbm75HX/Ye69cgV9/ffgNP/YYBASArS3Y2Wmviv7a1hYU5QEPRa81B125UvBxRYHateHCheL3GzIYiv5vWtJnYXzl5MDLL0NycuHxeHjAlClaXMbr5ubefd2/Xdb7CjrHYCjev+nD6HTaczL+vySvsnhvYiL8/PPD4x02TPseUZS7n1Pj1/e/zHFMVeGNN+DmzcLvwcMDZs3SvjZ+5g2Gor2Kem5pr5mcDEePPvx5tGkD1asX73NRkfsBXngBkpIKv4eaNWHNGu1997o3Jbg/PSjJsdJcQ6+/ex/PAE8DKqAAa4H/leLn7n2K+/v79ddf5/fff2fXrl0FHldVlVq1avHaa6/xj3/8A4Dbt2/j4+PDqlWreO6550oVb1mRJLAMlVUSeHjNAloNm1yGkYkiMSaDBSWK2dlw9erDr+HvDw4OxUvMhBBCFM4O+AfQ4s/tXGDUPce3bYMePUpVhPH394kTJ/D39zftd3BwwMHBId/5zZo1IywsjCtXrrBjxw78/f15+eWXGTduHADnz5+nQYMGHDp0iFatWpne1717d1q1asXChQtLFW9ZkdHBFijj0rkinZfrYIetk4uWrDys5sEc51y8CEuXPvxGXnhB+2suJ0dLnHJySvd1Uc4t8B/0z1qnzMyiP6z7xcWV/L2FKe6//4NeN27A6dMPL7N7d2jU6G5ibHwZYyjuvpK+r7B9v/0GYWEPv48tW6Bz57sJ9721rg97Fefckp5/9iysWPHw+3jmGe17xNioB4U1WJbN8eJe4/JlOHjw4ffRsaNWo67T5a2NLcqrqOeW5ponT8Ls2Q+/jzfegCZNHv78C/tMFPXckr7/+nWtduxhatUCN7f8rSD3bhf1WFlc4/7t5GSIvQCTyJsA2gIDgfV/7ouPp6w0a9Ysz/bMmTOZZazBvsf58+f55JNPCA8P54033mD//v1MnDgRe3t7Ro0aRUJCAgA+Pj553ufj42M6ZgkkCbRATgENinTe8VXv0eq5V8s3mNLQ6+Gnn7TEqKAKZ2MT6rJlFTv1gqpqPzCLk1RGRcHEiQ+/9qJF0K5d2SVu9zfVlNb27dpIx4eZNavUf1mXq169tM/Owz5bvXpV7GeruPR6+OWXh9/HmjWWfR9F/VzNm2fZnyu9HpYvf/jzmDOnajyPr76y7OexLRL+1xta/7m9HfgMLQEc8ue+9WhT+JSRgmoCC2IwGGjXrh1vv/02AK1bt+b48eMsXbqUUaNGFfgeSyRJoAUKHvwyV93/8cA+gfEeNgQPfrmiQyseGxtYuFCrxVCUvD9UjX/tLVhQ8T9MFeVukuXoWLT3tG0L77338F8OL79s2b8cunYtWvLUtWvFx1YclvrZKq6qch/yubIsVeF5GPRgvwLa/7m9Ey0BhLs1gEMAd7cyvQ9XV1fc3Nweep6fn1++WsOgoCC+//57AHx9fQFITEzE754kNTExMU/zsLnJPIEWyMbOntg54YCW8N3LuH15djg2dvYVGleJDBoE332n9ZW7V+3a2v5Bg8wTV3EZfzlA4c0XleGXQ1W5D6g6n62qcB/yubIslf15qCrs/ztcWg0o8Duw7L77+J8C3wH9+5nlPjp37szp+7rWnDlzhoCAAADq1auHr68vkZGRpuMpKSlERUURGhpaobE+kFnHJlcxFTFP4BWPSjZPoFFurqpu26aqq1dr/68MUywUpKB5t+rUqTzTLRhVlftQVVXNzVVzIiLU/eHhak5EROX9bFWF75Eq9rmS52EGBoOq7p+oTQGzWqeqF9dUyH0U9/f3vn37VFtbW/Wtt95SY2Ji1K+++kp1cnJSv/zyS9M577zzjurh4aH+73//U48ePao+9dRTMkVMVVZWo4Pvpc/J5vC3H7F4/b+44JzFu7N/p0NApzK5tighvZ7cbds4vGkTrfr3x1aWKTO7nJwcNm7cyIABA7CzszN3ONatqnx/VBWV7XkcfgNOzNO+7rgK6v/Zv66cf16V5Pf3Tz/9xLRp04iJiaFevXqEh4ebRgeDNk3MzJkzWbZsGbdu3aJLly58/PHHNG7cuMziLi3pE2jhbOzsaTl0IvvjV/JH+h+cS7lIByQJNCsbG9Tu3YlLTyeke3fL/oH6IDY2lt0pXFROVeX7o6qoTM/j+Ft3E8BHPr6bAIJF/rx6/PHHefzxxws9rigKc+bMYc6cORUYVfFIn8BKopZjLQBOJxVheg8hhBCiMjn1IRydrn3d+n1o9HfzxmMlJAmsJPwdtE7KZ5LPmDkSIYQQogzFLIWD2mBIgudA0GvmjceKSBJYSdRy0GoCz9yQJFAIIUQVcf4LbSQwQLOp0GK6eeOxMhabBC5ZsoTAwEAcHR3p0KED+/bte+D5a9eupWnTpjg6OhIcHMzGjRvzHJ81axZNmzbF2dkZT09PevfuTVRUVJ5zAgMDURQlz+udd94p83sriXuTQBnLI4QQotKLXQtRY7SvG0+AkHkPXsNdlDmLTAK/+eYbwsPDmTlzJgcPHiQkJISwsDCuXbtW4Pm7d+9m2LBhjB07lkOHDjFw4EAGDhzI8ePHTec0btyYxYsXc+zYMX777TcCAwPp27cv169fz3OtOXPmEB8fb3pNmDChXO+1qHzsfbBRbEjLTiM+reyWyBFCCCEq3JUf4ffhoBqgwVhou0ASQDOwyNHB8+fPZ9y4cYwZo/2FsHTpUn7++WdWrFjB66+/nu/8hQsX0q9fP6ZMmQLA3LlziYiIYPHixSz9c+3a4cOH5ytj+fLlHD16lF69epn2u7q6mmb6fpisrCyysrJM26mpqQDk5uaSU9j6tCWQk5ODnc6OQPdAzt06x4nEE9RwrFFm1xfFZ3y+ZfmcRcnJ87As8jwsi6U9DyXxV2x+ewZFzcVQ9zn0rRdDrh7Qmy2m3Nxcs5VtThaXBGZnZxMdHc20adNM+3Q6Hb1792bPnj0FvmfPnj2Eh4fn2RcWFsb69esLLWPZsmW4u7sTEhKS59g777zD3LlzqVu3LsOHD2fy5MnY2hb8zzRv3jxmF7DYeGRkJNWrV3/QbZaIh8EDgHU71pFePb3Mry+KLyIiwtwhiHvI87As8jwsiyU8D2/9H3TMnI1CNldtOnIgaQjqpi3mDoukpCRzh2AWFpcEJiUlodfr8fHxybPfx8eHU6dOFfiehISEAs9PSEjIs++nn37iueeeIyMjAz8/PyIiIvIkaxMnTqRNmzZ4eXmxe/dupk2bRnx8PPPnzy+w3GnTpuVJPuPi4mjWrBm9evXKswB1aeXk5BAREUFoo1Cio6NxqOXAgN4Dyuz6oviMz6RPnz4yObEFkOdhWeR5WBZLeR5K8n5sdsxDIRuDbz9qdP6O/jrLWP40Li7O3CGYhcUlgeWpZ8+eHD58mKSkJD777DOGDh1KVFQUNWvWBMiT0LVs2RJ7e3teeukl5s2bh4ODQ77rOTg45NmfkpICgK2tbbl8ozWt0RSAs7fOyg9WC2FnZyfPwoLI87As8jwsi1mfx83DsPMxyE0Dn57ouq1DZ1vNPLEUoLAWv6rO4gaGVK9eHRsbGxITE/PsT0xMLLSvnq+vb5HOd3Z2pmHDhnTs2JHly5dja2vL8uXLC42lQ4cO5ObmcvHixZLdTBlr5NUIkGlihBBCVCK3T8LWPpBzC6p3gm4bwIISQGtmcUmgvb09bdu2JTIy0rTPYDAQGRlJaGhoge8JDQ3Ncz5ofR8KO//e6947sON+hw8fRqfTmWoKzc2YBJ6/eZ4cvWV08BVCCCEKlXoWtvaCrCTwags9NoKdi7mjEn+yyPrP8PBwRo0aRbt27Wjfvj0LFiwgPT3dNFp45MiR+Pv7M2+etsbgpEmT6N69Ox988AGPPfYYa9as4cCBAyxbtgyA9PR03nrrLZ588kn8/PxISkpiyZIlxMXFMWTIEEAbXBIVFUXPnj1xdXVlz549TJ48mb/85S94enqa5x/iPv6u/jjZOZGRk8GFWxdo7G05i1ALIYQQeaTHQmQvuBMP7i2g5xawdzd3VOIeFpkEPvvss1y/fp0ZM2aQkJBAq1at2Lx5s2nwR2xsLDrd3UrMTp06sXr1aqZPn84bb7xBo0aNWL9+PS1atADAxsaGU6dO8fnnn5OUlIS3tzePPPIIu3btonnz5oDWv2/NmjXMmjWLrKws6tWrx+TJk/ONOjYnRVFo7N2YwwmHOXPjjCSBQgghLNOdeC0BzIgF18bwaAQ4eJs7KnEfi0wCAcaPH8/48eMLPLZ9+/Z8+4YMGWKq1bufo6Mj69ate2B5bdq0Ye/evcWOs6LdmwQKIYQQFifzOmztDWlnwTkQekVCtaLNvysqlsX1CRQP1sS7CQCnk06bORIhhBDiPtk3YVtfuH0CqvlrCaBTbXNHJQohSWAlY2wCPpMsNYFCCCEsSE4qbOuvTQfjWFNLAF3qmzsq8QCSBFYypiRQmoOFEEJYitwM2PE43IgCey/oGQFuTcwdlXgISQIrGWMSeDX1KqlZqWaORgghhNXTZ8HOp+HaTrBz00YBe7Y0d1SiCCQJrGQ8HD2o6azNWxiTHGPmaIQQQlg1Qw78NhQSfgEbJ20eQO925o5KFJEkgZWQNAkLIYQwO4Medj8PcRtA5wDdf4Qanc0dlSgGSQIrocZekgQKIYQwI9UA+/4Ksd+Azg66rgPfR80dlSgmSQIroSbV/5wm5oZMEyOEEKKCqSocmADnV4FiA52+Bv8B5o5KlIAkgZWQNAcLIYQwC1WFw/+EmI8BBTp+DnUHmzsqUUKSBFZC9yaBqqqaORohhBBW49hsOPm+9nX7T6HeCPPGI0pFksBKqIFnA3SKjpSsFBLTE80djhBCCGtw4l04Plv7uu1CaDjOvPGIUpMksBJysHUg0CMQkCZhIYQQFeD0R3D4de3rkHnQZKJ54xFlQpLASkr6BQohhKgQ55ZD9J9JX/Pp0Px188YjyowkgZWUTBMjhBCi3F1cDVF/Nvs2DYeWc8wbjyhTkgRWUjJNjBBCiHJ1+QfYMxJQoeHfoPX7oCjmjkqUIUkCKylpDhZCCFFurm6C358FVQ/1RsEjSyQBrIIkCaykjEngueRz5BpyzRyNEEKIKiNxG+wapK0LXHcodPgPKJIuVEXyVCup2m61qWZbjRxDDhdvXTR3OEIIIaqC67thxxOgzwT/J6DTl6CzNXdUopxIElhJ6RQdjbwbAdIkLIQQogwkR8P2/pCbDr59oMu32rrAosqSJLASk36BQgghysSt47C1L+SkQI2u0G092DiaOypRziQJrMSM08ScTpIRwkIIIUoo5Qxs7Q3ZyeDdHnr8BLZO5o5KVABJAisx4zQxZ5KlJlAIIUQJpF2Arb0gMxE8QqDnZrBzM3dUooJIEliJSXOwEEKIEsu4ApG9tP+7BcGjv4C9p7mjEhVIksBKzJgEXkm5Qnp2upmjEUIIUWncSdSagNMvgEsDePRXcKxp7qhEBZMksBLzquZFdafqAMQkx5g5GiGEEJVC1g3Y1gdSToNTHegVCU61zB2VMANJAis5aRIWQghRZNm3YVs/uHUMqvlBr63gHGDuqISZSBJYyUkSKIQQIp+js+DY3Lz7ctNhx2OQfABsqmlNwK4NzRGdsBAyDXglZ5om5oZMEyOEEOJPig0cm6F93fR1dGoWNr8Pguu/a/vqjQb3ZmYLT1gGSQIrOdM0MVITKIQQwij4Te3/x2ag02fzSNYmdBnR2r4GL0L7j80Xm7AYkgRWcvc2B6uqiqIoZo5ICCGERQh+EwxZ2Pzxb3yN++q/AB0+NWdUwoJIn8BKroFnAxQUbmXeIikjydzhCCGEsBQpMXDlB9OmqthCx+VmDEhYGkkCK7lqdtUI8NBGdkm/QCGEEABc3QRbHoHbJwAwYIOi5uYfLCJKZNasWSiKkufVtGlT0/HMzExeeeUVvL29cXFxYfDgwSQmJpox4oJJElgFyAhhIYQQAKgq/PE2bH8Mcm4DoG8czo/O36NvPlMbLCKJYJlo3rw58fHxptdvv/1mOjZ58mR+/PFH1q5dy44dO7h69SqDBg0yY7QFkz6BVUBjr8b8cu4XSQKFEMKa5aTC3tFwed3dfS1mYAiaDnEbMTT7Fza6e0YNGwePiBKxtbXF19c33/7bt2+zfPlyVq9ezaOPPgrAypUrCQoKYu/evXTs2LGiQy2UJIFVgLEmUJqDhRDCSqWehZ1Pac2/OjvwDQPv9lqil5Nz9zxj4qfqzROnhUtNTSUlJcW07eDggIODQ4HnxsTEUKtWLRwdHQkNDWXevHnUrVuX6OhocnJy6N27t+ncpk2bUrduXfbs2SNJoChbMk2MEEJYsaub4PfhkHNLWwWky/dQI7Tw86UGsFDNmuWdO3HmzJnMmjUr33kdOnRg1apVNGnShPj4eGbPnk3Xrl05fvw4CQkJ2Nvb4+Hhkec9Pj4+JCQklGP0xSdJYBVgrAk8m3wWvUGvVfcLIYSo2lQVTsyDI9MBFaqHQpfvZB3gUjhx4gT+/v6m7cJqAfv372/6umXLlnTo0IGAgAC+/fZbqlWrVu5xlhUZGFIF1HGrg4ONA9n6bGJvx5o7HCGEEOUtJw1+GwJH/gWo0PBF6LVNEsBScnV1xc3NzfQqLAm8n4eHB40bN+bs2bP4+vqSnZ3NrVu38pyTmJhYYB9Cc5IksAqw0dnQyLsRIP0ChRCiyks9C790hMvfa/3/2n+qvWyKlrCIspeWlsa5c+fw8/Ojbdu22NnZERkZaTp++vRpYmNjCQ19QDO9GUgSWEXINDFCCGEFrm6CzY/A7T+0/n+9dmi1gKJC/eMf/2DHjh1cvHiR3bt38/TTT2NjY8OwYcNwd3dn7NixhIeHs23bNqKjoxkzZgyhoaEWNSgEpE9gldHYS5JAIYSosqT/n0W5cuUKw4YN48aNG9SoUYMuXbqwd+9eatSoAcCHH36ITqdj8ODBZGVlERYWxscfW956zZIEVhEyTYwQQlRROWl/zv/3vbbd8EVou0iaf81ozZo1Dzzu6OjIkiVLWLJkSQVFVDKSBFYRMk2MEEJUQalnYedArflXZwftFkvzrygzkgRWEcaawNjbsdzJuUM1u8ozRF0IIUQBijv/nxDFJANDqgjvat54OnoCEJMcY+ZohBBClFie9X9vaf3/wg5IAijKnCSBVYSiKNIkLIQQlZ3M/ycqkMUmgUuWLCEwMBBHR0c6dOjAvn37Hnj+2rVradq0KY6OjgQHB7Nx48Y8x2fNmkXTpk1xdnbG09OT3r17ExUVleec5ORkRowYgZubGx4eHowdO5a0tLQyv7fyItPECCFEJSbz/4kKZpFJ4DfffEN4eDgzZ87k4MGDhISEEBYWxrVr1wo8f/fu3QwbNoyxY8dy6NAhBg4cyMCBAzl+/LjpnMaNG7N48WKOHTvGb7/9RmBgIH379uX69eumc0aMGMEff/xBREQEP/30Ezt37uTFFytPB1yZJkYIISopmf9PmIFFJoHz589n3LhxjBkzhmbNmrF06VKcnJxYsWJFgecvXLiQfv36MWXKFIKCgpg7dy5t2rRh8eLFpnOGDx9O7969qV+/Ps2bN2f+/PmkpKRw9OhRAE6ePMnmzZv5z3/+Q4cOHejSpQsfffQRa9as4erVqxVy36Ul08QIIUQlI/3/hBlZ3Ojg7OxsoqOjmTZtmmmfTqejd+/e7Nmzp8D37Nmzh/Dw8Dz7wsLCWL9+faFlLFu2DHd3d0JCQkzX8PDwoF27dqbzevfujU6nIyoqiqeffjrfdbKyssjKyjJtp6amApCbm0tOTk7RbrgIjNd62DXre9QHtJrAsixf5FfUZyIqhjwPyyLPo4hy07DZNxZd3A8A6Ov/FUOrD7XmXzP8DrFmubm55g7BLCwuCUxKSkKv1+Pj45Nnv4+PD6dOnSrwPQkJCQWen5CQkGffTz/9xHPPPUdGRgZ+fn5ERERQvXp10zVq1qyZ53xbW1u8vLzyXcdo3rx5zJ49O9/+yMhI03XLUkRExAOPZxm0hDT5TjJrNqzBzdatzGMQeT3smYiKJc/DssjzKJyzIZ72mfNwU2MxYMtR+3FcSgyDLZEPf3MJyfMoXFJSkrlDMAuLSwLLU8+ePTl8+DBJSUl89tlnDB06lKioqHzJX1FNmzYtTw1kXFwczZo1o1evXvj7+5dV2OTk5BAREUGfPn2ws7N74Ll1LtbhcsplAtoEEFpbmhPKS3GeiSh/8jwsizyPB1PiN2MTNQ1FvYXq6Ieh0zc09+5I83IqT57Hw8XFxZk7BLOwuCSwevXq2NjYkJiYmGd/YmIivr6+Bb7H19e3SOc7OzvTsGFDGjZsSMeOHWnUqBHLly9n2rRp+Pr65ht4kpubS3JycqHlOjg44OBwd9RWSkoKoNUglsc3mp2d3UOv26R6Ey6nXOb87fN0q9etzGMQeRXlmYiKI8/DssjzuE8B6/8qXb7DtoKmf5HnUThbW4tLhyqExQ0Msbe3p23btkRG3q0SNxgMREZGEhpacM1WaGhonvNBq/Yu7Px7r2vs0xcaGsqtW7eIjo42Hd+6dSsGg4EOHTqU9HYqnIwQFkIICyTz/wkLZJGpb3h4OKNGjaJdu3a0b9+eBQsWkJ6ezpgxYwAYOXIk/v7+zJs3D4BJkybRvXt3PvjgAx577DHWrFnDgQMHWLZsGQDp6em89dZbPPnkk/j5+ZGUlMSSJUuIi4tjyJAhAAQFBdGvXz/GjRvH0qVLycnJYfz48Tz33HPUqlV5vkllrkAhhLAwsv6vsFAWmQQ+++yzXL9+nRkzZpCQkECrVq3YvHmzafBHbGwsOt3dSsxOnTqxevVqpk+fzhtvvEGjRo1Yv349LVq0AMDGxoZTp07x+eefk5SUhLe3N4888gi7du2iefO7vTC++uorxo8fT69evdDpdAwePJhFixZV7M2XknHVEJkmRgghLMDVzfD7MFn/V1gki0wCAcaPH8/48eMLPLZ9+/Z8+4YMGWKq1bufo6Mj69ate2iZXl5erF69ulhxWhpjTWDMjRgMqgGdYnEt/kIIUfWpKpx4527zb/VQ6PKdNP8KiyIZQhUT4B6Anc6OLH0Wl29fNnc4QghhfXLS4LehcOQNpP+fsGSSBFYxNjobGno1BKRJWAghKlzqWfglFC5/J+v/CosnSWAVZOwXKINDhBCiAl3d/Of6v8dl/V9RKVhsn0BRcjJNjBBCVCDp/ycqKUkCqyCZJkYIISpIThrsHaM1/4JW89d2kTT/ikpBksAqSKaJEUKICpB6FnY+rTX/yvx/ohKSJLAKMtYEXrp1iczcTBxtHc0ckRBCVDH3zv/n6Atdv4cancwdlRDFIgNDqqAaTjVwd3BHReVc8jlzhyOEEFWHqsIf82D7AC0B9O4I/aIlARRlLjs7u9zLkCSwClIUxVQbKE3CQghRRu6f/6/BOOi9XQaAiHJRq1YtJk6cyMGDB8utDEkCqyiZJkYIIUrg6Cw4Njf//tSzsKFB3vn/OiyTASCi3CQnJ7NkyRIeeeQRWrVqxaJFi7hx40aZliFJYBUl08QIIUQJKDZwbEbeRPDqZvg5GLKuga0L9NouA0BEhVFVlWPHjjF58mT8/f0ZMmQIGzduxGAwlPraMjCkipJpYoQQogSC39T+f2wGoGq1fkfe0PZVqw1hUdL8KyrERx99xNq1a/ntt99MCV92djbr1q1j3bp1+Pr6MnLkSMaMGUPjxo1LVIbUBFZRMk2MEEKUUPCbEPQ6HJt5NwH0bAtPnpUEUFSYV155he3btxMXF8dHH31Et27d0Ol0qKqKqqrEx8fz3nvvERQUROfOnVmzZk2xy5AksIoyrh+clJFE8p1kM0cjhBCVyOX1cGHF3W3FFvofkP5/wix8fHxMCeGVK1eYN28ejo6OKIpiSgj37t3LiBEj6NKlCzdv3izytSUJrKJc7F3wd/UHIOZGjJmjEUKISiD7Jux+HnY9DZnXtH2KHai5BQ8WEaIC7d+/n5kzZ/L222+TlZUFaLOBAKZkcM+ePfzrX/8q8jUlCazCZJoYIYQoorif4efmcPFLQPvFSosZMCwbgufkHywiRAW4ffs2ixcvplWrVnTs2JH//Oc/pKWlmZI+Pz8/5syZw9dff039+vVRVZUNGzYU+foyMKQKa+LdhG0Xt8ngECGEKEz2bTg4Gc6v1LYdvCHrhpb4GQeJ5Bkscs+2EOXoL3/5Cz/88AOZmZmAVttn1KlTJyZMmMDgwYOxtdVSOUVReO6550hISChyGZIEVmEyQlgIIR4g/heIGgsZVwAFmk4GnSPYOOZP9Izbqr7CwxTWafXq1aZ+fwAODg4MGzaMCRMm0Lp163zn+/j4AHmTxYeRJLAKk+ZgIYQoQE4qHJoCZz/Vtl0aQMdVULPLg98nNYCigqmqSu3atfn73//OuHHjqF69eqHntmrVim3bthXr+pIEVmHGaWJibsRgUA3oFOkCKoSwconbYO8LkH5R2248AVrNA1tns4YlxP26devGhAkTGDhwIDY2Ng89393dne7duxerDMkKqrBAj0Bsdbbcyb1DXEqcucMRQgjzyU2HAxMg8lEtAXQOhF5bod0iSQCFRZozZw41atQoVh+/4pIksAqz1dnSwLMBIP0ChRBW7NpvsDEEzizWthu+BAOOgk9P88YlxAP06NGDnj178s033xR4/KOPPsLNzQ13d/cSlyFJYBUn/QKFEFYr9w4cfA1+7QZp58CpNvTcAu2Xgp2ruaMTolSys7NJS0sjLS2txNeQJLCKa+Kt9QuUmkAhhFVJioLNreHUfECF+i/AgOPg19fckQlRJi5fvlzqa8jAkCpOpokRQlgVfRYcmwUn3wPVANX8oP1n4P+YuSMT4qEeffTRfPs++eQTfvrppzz7MjIyiI6OBsDR0bHE5UkSWMVJc7AQwmokR8OeUXD7D2078C/awA97T/PGJUpNb9CzK3YX8anx+Ln60bVuV2x0Dx8xW9ls377dtBQcaFPEnD9/nvPnz+c7V1VVFEWhWbNmJS5PksAqzjhNzMVbF8nKzcLBVhZAF0JUMfps+OPf8Mfb2mTOjjXhkU+hzkBzRybKwLqT65i0eRJXUq6Y9tV2q83CfgsZFDTIjJGVj/sne37Q5M+KojB16tQSlyVJYBXn4+yDq70rqdmpnL95nqAaQeYOSQghys7NI1rt360j2nbdZ6HdYnAsfFJdUXmsO7mOZ759BpW8iVBcShzPfPsM3w39rkolgiNHjjTVBH7++ecoikLbtm1p3rx5nvPs7Ozw9/dn4MCBhISElLg8SQKrOEVRaOzdmOj4aM7cOCNJoBCiajDkwB/vwPE5oOZqa/4+8gnUHWLuyEQZ0Rv0TNo8KV8CCKCioqDw6uZXearJU1WmaXjVqlWmrz///HMAnnvuOcLDw8ulPEkCrYAxCZR+gUKIKuHWH7B3lNYHEKD2QHhkKVTzMWtYomztit2Vpwn4fioql1Musyt2Fz0Ce1RcYBVk5cqVADzyyCPlVoZMEWMFZJoYIUSVYNDDiXdhcxstAbT3hNAvoes6SQCroPjU+DI9r7y88847KIrCq6++atqXmZnJK6+8gre3Ny4uLgwePJjExMRiXXfUqFGMGjWqVAM/HkZqAq2ATBMjhKj0Uk7DntFwY6+2XesxaL8MnGqZNSxRfvxc/cr0vPKwf/9+Pv30U1q2bJln/+TJk/n5559Zu3Yt7u7ujB8/nkGDBvH7778Xei3j9DB///vfGTJkSIHTxRREURQiIyNLFL8kgVZApokRQlRaBj2cWQRH3gB9Jti5QduFUG8U3DOVhqh6utbtSm232sSlxBXYL1BBobZbbbrW7VpmZaamppKSkmLadnBwwMGh4Fk10tLSGDFiBJ999hn//ve/Tftv377N8uXLWb16tSmRW7lyJUFBQezdu5eOHTsWeD3j9DCPP/54nu0HMU4TU1LSHGwFjEngtfRr3Mq8Zd5ghBCiqFLPQmQPOBiuJYC+fbVVP+qPlgTQCtjobFjYb2GBxxS057+g34IyHRTSrFkz3N3dTa958+YVeu4rr7zCY489Ru/evfPsj46OJicnJ8/+pk2bUrduXfbs2VOseFRVfeCrtKQm0Aq4Orji5+JHfFo8MTdieMS//DqZCiFEqakGOPMxHJ4K+gywdYE286HBXyX5szKDggbx30H/5S/r/pJnf2232izot6DMp4c5ceIE/v7+pu3CagHXrFnDwYMH2b9/f75jCQkJ2Nvb4+HhkWe/j48PCQkJhZZtnB6mRYsWebbLkySBVqKxd2Pi0+I5c+OMJIFCCMuVdhGiXoDEbdq2T0/osAJcAs0ZlTAjN3s3APxc/Pig7wflumKIq6srbm5uDzzn8uXLTJo0iYiIiFIt2Xa/e6eHKWi7PEhzsJUwjhCWfoFCCIukqnB2GWwM1hJAGydo+xE8+qskgFZuy7ktAAxsOpBhwcPoEdjDrPMCRkdHc+3aNdq0aYOtrS22trbs2LGDRYsWYWtri4+PD9nZ2dy6dSvP+xITE/H19TVP0IWQJNBKyAhhIYTFSr8M28Jg30uQmwY1usCAI9BkPCjya8raGZPAsAZhZo5E06tXL44dO8bhw4dNr3bt2jFixAjT13Z2dnlG7J4+fZrY2FhCQ0OLXE5qaipnzpzhzJkzZGZmAloiOWbMGEJCQujevTs//vhjqe5FmoOthCSBQgiLo6pwfhUcfBVyUsDGEULehsYToYqsACFK5/zN85xNPoutzpae9XqaOxxAazI29tszcnZ2xtvb27R/7NixhIeH4+XlhZubGxMmTCA0NLTQkcEFmT9/PnPmzEGn0xEXF4ejoyN9+vThjz/+ALRBI7t372bHjh106tSpRPciSaCVuDcJLO2QciGEKLWMq1rN39WftG3vjhC6CtyamDUsYVm2nNVqATvV6YSbw4P76lmSDz/8EJ1Ox+DBg8nKyiIsLIyPP/64WNeIiopCVVVat25NzZo12bdvH8ePH0dRFNPIYL1ez6JFiyQJFA9W37M+NooN6TnpXE29ir+b/8PfJIQQZU1V4eJqiJ4A2TdBZw8t50LT16T2T+RjaU3Bhdm+fXuebUdHR5YsWcKSJUtKfM2TJ0+iKAqtWrUCME007enpyfTp05k3bx7Xr19n7969JS5DOltYCTsbO+p71gekSVgIYSZ3EmHXYNjzFy0B9GoL/Q5Cs39KAijyydHnsPXCVsDyk8DykJSUBEDdunUBrV8hwNNPP82rr77KyJEjAYq9HN29JAm0ItIvUAhhNpe+hY3N4coPoLPTav/67gGP5uaOTFioPVf2kJqdSg2nGrT2a23ucCpcdnY2ALm5uQCcOXMGRVFo0kTrMuHl5QWATlfyVE6ag61IE+8m/Bzzs0wTI4Qoe0dngWIDwW/m3Z+ZpK36cVvrzI5HCIR+Dp4hFRygqGyM/QH7NOiDzgpHideoUYP4+HjWrl1Ls2bNTKuNGJNAYw1gjRo1SlyG9f2rWjGpCRRClBvFBo7NgGNz7+6K+x9sCPwzAVSgxZsQtk8SQFEklaU/YHlp3749qqpy6tQphg0bRlZWFjY2NqZBIBcuXACgXr16JS5DagKtiCSBQohyY6wBPDYDXU4abTKjsN29Q9vnUAN6btL6AApRBNfTr3Mw/iAAfRv0NXM05jF58mR+/PFH9Hq9ad/w4cPx9vbmzp07REZGoihKseYevJ8kgVbEmASev3mebH029jb2Zo5ICFGlBL8JaeexOfUedYz7anSFRyPApuA1WIUoSMT5CFRUQnxC8HWxrFU2KkrXrl3ZvHkzn332GZmZmXTt2pVXX30V0Jaue/755wEYPHhwicuw2ObgJUuWEBgYiKOjIx06dGDfvn0PPH/t2rU0bdoUR0dHgoOD2bhxo+lYTk4OU6dOJTg4GGdnZ2rVqsXIkSO5evVqnmsEBgaiKEqe1zvvvFMu92cOtVxr4WznjF7Vc+HmBXOHI4SoSgw5cHgaXPjctEtV7KDPTkkARbFZe1NwdnY2R48epUaNGsyZM4f169fz2muvYWOjjaJv3Lgxn3zyCZ988glt25a8ht0ik8BvvvmG8PBwZs6cycGDBwkJCSEsLIxr164VeP7u3bsZNmwYY8eO5dChQwwcOJCBAwdy/PhxADIyMjh48CBvvvkmBw8eZN26dZw+fZonn3wy37XmzJlDfHy86TVhwoRyvdeKpCiKNAkLIcpe6jn4pTOceAf4cxJbbFHUnDx9BIUoClVV+eXcLwCENbTOJNA4P2Dr1q2ZO7f8vocsMgmcP38+48aNY8yYMTRr1oylS5fi5OTEihUrCjx/4cKF9OvXjylTphAUFMTcuXNp06YNixcvBsDd3Z2IiAiGDh1KkyZN6NixI4sXLyY6OprY2Ng813J1dcXX19f0cnZ2Lvf7rUjGJFBGCAshysSF/8KmVpC8H3SOAOibz+Qn5+/QN5+Zb7CIEA9zNPEoCWkJONk50blOZ3OHYxZ2dnamKWCaNm1abuVYXJ/A7OxsoqOjmTZtmmmfTqejd+/epuHR99uzZw/h4eF59oWFhbF+/fpCy7l9+zaKouDh4ZFn/zvvvMPcuXOpW7cuw4cPZ/LkydjaFvzPlJWVRVZWlmk7NTUV0Ob0ycnJedBtFovxWmVxzYaeDQE4df1UmcZobcrymYjSk+dhBjkp2BycgC72awAMTnXRZcSibz6TrEb/hIsRZDX6Jw6AzbEZ6A16DM3+Zd6YrVRl+/7YeEbrztUjoAc6VVchcRvn4rMkXbp04ccff+Ts2bPlVobFJYFJSUno9Xp8fHzy7Pfx8eHUqVMFvichIaHA8xMSEgo8PzMzk6lTpzJs2DDc3O6uRThx4kTatGmDl5cXu3fvZtq0acTHxzN//vwCrzNv3jxmz56db39kZCTVq1d/4H2WRERERKmvkZGcAcDemL15+k2KkimLZyLKjjyPiuGpP0PbrA9wVhMxoOO03bMo2XpUu86cudgaLmrPQXserWlsNwzlzClOX5SfOeZUWb4/vj6r/WFR606tCvs9ZVydw5K89dZbREZGsnr1agYPHszjjz9e5mVYXBJY3nJychg6dCiqqvLJJ5/kOXZvbWLLli2xt7fnpZdeYt68eTg45O/YPG3atDzviYuLo1mzZvTq1Qt//7JbmzcnJ4eIiAj69OmDnZ1dqa5V82pNPlz1IclKMgMGDCijCK1PWT4TUXryPCqIqkd36n10f8xGUXNRnQIwdPiChtXvTlHRkIKeh/azpoF5orZ6len7Iy07jVNHtQqfVx9/1dSFqbzFxcVVSDnF8cEHH9C4cWMOHTrEU089RYsWLWjatGm+bmqKorB8+fISlWFxSWD16tWxsbHJtxZeYmIivr4FDxP39fUt0vnGBPDSpUts3bo1Ty1gQTp06EBubi4XL140zdB9LwcHhzzJYUpKCgC2trbl8o1mZ2dX6us282kGQHxaPHcMd3BzePC/gXiwsngmouzI8yhHGXGw53lI3KZt130Wpf1SbO09Cn2LPA/LUhmex+8XfifHkEOgRyDNfJqhKEqFlFtYty9zWrVqlWmmElVVOXbsmGnAq5GqqqVKAi1uYIi9vT1t27YlMjLStM9gMBAZGVnohIihoaF5zget2vve840JYExMDL/++ive3t4PjeXw4cPodDpq1qxZwruxPO6O7vg4a03nMTdizByNEKJSuPI/2NhSSwBtnaHDCuj8NTwgARSiJIxLxYU1CKuwBNDSqaqa5+t7X6VleakvWrPsqFGjaNeuHe3bt2fBggWkp6czZswYAEaOHIm/vz/z5s0DYNKkSXTv3p0PPviAxx57jDVr1nDgwAGWLVsGaAngM888w8GDB/npp5/Q6/Wm/oJeXl7Y29uzZ88eoqKi6NmzJ66uruzZs4fJkyfzl7/8BU9PT/P8Q5STxt6NSUxP5MyNM7StJTP4CyEKkXsHDv0DYj7Wtj3baMmfW8U00QnrY+3zA96rW7du5Z4IW2QS+Oyzz3L9+nVmzJhBQkICrVq1YvPmzabBH7Gxseh0dysxO3XqxOrVq5k+fTpvvPEGjRo1Yv369bRo0QLQ2vo3bNgAQKtWrfKUtW3bNnr06IGDgwNr1qxh1qxZZGVlUa9ePSZPnpxv1HFV0Ni7Mbtid8k0MUKIwt06Dr8/9+e6v0DT1yDkLZn4WZSbCzcvEJMcg41iw6P1HjV3OGa3ffv2ci/DIpNAgPHjxzN+/PgCjxX0DzNkyBCGDBlS4PmBgYEPrTZt06YNe/fuLXaclVETb61/o0wYLYTIR1W1mr+Dr4EhCxx9oOPnUEtqZkT5MtYChtYJxd3R3czRWAeLTQJF+ZFVQ4QQBcpMgqixEKe1nODXH0JXgWPV6RctLJc0BRdOr9eTlJSUZ27ie9WtW7dE15Uk0ArdmwQaRxYJIaxcwlZt9O+dq6Czh1bvQZOJID8fRAXI0ecQeV4b4ClJ4F1//PEHU6dOZevWrYUmgIqilHiya0kCrVB9z/roFB2p2akkpCXg5+pn7pCEEOZiyIGjM+DEu4AKbk2g8xrwbGXuyIQV2XtlL6nZqXhX86aNXxtzh2MRLl26ROfOnUlNTS2TkcAFsbgpYkT5c7B1oJ5HPUCahIWwaqnnIKILnHgHUKHBOOgXLQmgqHDGpuA+Dfpgo7MxczSW4f333yclJcWUABrnDDQqi1Y8SQKtlPQLFMLKXfgSNrWGG/vAzgO6rIUOy7R5AIWoYNIfML+tW7eiKAoBAQGMGTPGlAz+/PPPjBw5ElVVGT16NFu3bi1xGZIEWiljEijTxAhhZXJSYPfzWv+/3FSo0RUGHIG6z5g7MmGlkjKSiL4aDUDfBn3NHI3liI2NBeDpp5+mWbNmpv39+/dn1apV9OnTh88//5zbt2+XuAxJAq2UTBMjhBVKitJq/y5+CYoOgmdDr23gXLKRhUKUhYhzEaioBNcMppZrLXOHYzGys7MB8PHxybOs3Z07dwDo2rUrqqqaFs4oCUkCrZQ0BwthRQx6+GOe1v8v7Tw41YXeOyF4Bkj/K2Fm0hRcMONqZdnZ2bi5uZn2//TTTwDs3r0bgGPHjpW4DEkCrZQxCTx38xy5hpINLRdCVAIZcbCtDxx5A9RcqDtUa/6t0dnckQmBqqr8cu4XAMIaShJ4L+MqaTdv3qRRo0am/cOGDcPb25stW7Tk2c7OrsRlSBJopfzd/KlmW41cQy4Xbl4wdzhCiPJwZQNsCoHEbWDjBB2Wa9O/2HuYOzIhADh27RjxafFUs61Gl7pdzB2ORQkJCUFVVU6ePEnHjh3x9vYGwGAwcPPmTdM8v7179y5xGZIEWimdopMmYSGqqtw7sP8V2PkUZN0Az9bQ/yA0eEEmfxYWZctZrTarR2APHG0dzRyNZRk0aBCDBw+mTp062NrasmDBgnzTwvj5+fH++++XuIxSTRYdHx9vaovu0KED7u7unDx5kpdffpmDBw/i4eHB1KlTefnll0tTjCgnjb0bcyTxCGdunOExHjN3OEKIsnDrOPw+DG4f17abvgYhb4GNg3njEqIA0h+wcAMHDmTgwIGm7REjRhAUFMR3333HjRs3aNKkCWPGjDH1HSyJUiWBH330Ee+++y42NjZcv34dg8HAgAEDiI2NRVVVUlNTmTBhAoGBgQwYMKA0RYlyINPECFGFqCrEfAKHXgN9Jjj6QMfPoZb8chWWKT07nV2xuwDpD1hUbdq0oU2bsltRpVRJYFRUFKqq0rFjR9zd3dmxYweXLl3KU12pqipLly6VJNACyTQxQlQRmUkQNRbiNmjbfv2h40qo5mPeuIR4gB2XdpCtz6aue13T7yORX2pqKmvXriU6Oppbt27h4eFBu3bteOaZZ3B1dS3VtUuVBJ49exZFUWjRogWgJYUAtWrV4qOPPiI8PJyLFy9y8ODBUgUpyof0CRSiCkjcBrv/Aneugs4eWr0LTSZq8wAKYcGM/QHDGoSVyRJoVdH333/Piy++yK1bt/Ide+211/j0008ZMmRIia9fqp8S169fB6B27doAnD6tNSs++eSTDBw4kGHDhuU5T1gWYxIYlxpHWnaamaMRQhSLIQcOvwGRvbQE0K0J9N0LTV+VBFBUCtIf8MEiIyN59tlnTSOB73fr1i2GDx/Or7/+WuIySvWTwmAwAJCeng7AqVOnUBSFxo215MLZWVuD0t7evjTFiHLiWc2TGk41AIi5EWPmaIQQRZZ6Tpv4+cQ8QIUGf4V+0eDV2tyRCVEkl25d4vSN09goNvSq38vc4VikWbNmYTAYTLWktra2ptVDjNPD6PV65syZU+IySpUE+vn5AfDll1/y3nvvsW/fPgCaNm0KaKOHAWrWrFmaYkQ5kiZhISqZC19qS7/d2Ad2HtBlLXT4DGydzR2ZEEVmrAXsULsDHo4e5g3GQh08eBBFUXBwcOCrr77izp07XL16lTt37vDll1+aKthK0+WuVElg586dUVWVK1euMG3aNPR6PQ4ODnTq1AmAmJgYFEWhYcOGpSlGlCNJAoWoJHJSYPfzsOd5yE2FGl20lT/qPmPuyIQoNmkKfjhHR23exLFjxzJs2DB0Oi1l0+l0DB8+nLFjx+Y5ryRKlQS+/vrrODk5oaqqqb16woQJuLq6cvv2bbZv3w5gSgqF5ZFpYoSoBJL2abV/F7/U+vsFz4Ze28C5rrkjE6LYcg25RJ6PBCQJfJAePXoAFDoC2Li/V6+SN6eXanRwixYt2L9/P59//jmZmZl07dqVwYMHA9pad7Nnzwbg6aefLk0xohzJNDFCWDDVACfeg6Nvauv+OtWFTl9BTVleS1ReUVeiuJ11G69qXrSr1c7c4Vist99+m8jISP773//y97//nTp16piOxcbG8t///hdvb2/eeeedEpdRqiQQICgoqMAAAgMDmTp1amkvL8rZvc3Bxo6mQogKdHQWKDYQ/Gbe/RlXtcEf6X+u7V13CLT/FOxLvjqAEJbA2BTcu35vbHQ2Zo7Gcr377rs0atSI6OhoGjVqRNeuXalZsybXrl1j165d5OTk0LFjR+bOnZvnfYqisHz58iKVUeoksCA7duwwLRtXFpMZivLTwKsBCgq3s25zLf0aPi4yuawQFUqxgWMztK+NieCVDfD7c6C/A4odtF8K9cfIur+iSpD+gEWzatUqFEVBURSys7PZunWr6Zix0mbv3r3s3bs33/4KSQK/+eYbFi5ciKIorF69moCAAF577TUWLFhgOuftt99m7969eHt7l6YoUU4cbR0J9Ajkwq0LnLlxRpJAISqaMfE7NkOb+y87GWKWaPscfaH3dm0OQCGqgBsZN9gftx+Avg36mjmaysE45uL+uQILmjuwuEqVBG7cuJG9e/fi5+dHQEAAV69eZeHChXmCO3/+PB988AFvv/12qYMV5aOxd2NTEtg1oKu5wxHC+gS/CZmJ8Mc9zTrVO0GvrWDjYL64hChjv57/FRWV5jWaU9uttrnDsWjdunUr9y5apUoCo6OjURSF7t27A9rs1saJDVu2bMnRo0cB2LRpkySBFqyxd2O2nNsig0OEMAdVhTNL4Nx/7u5TbKHv7+aLSYhyIk3BRWecYaU8lWqKmISEBAACAgIAOHbsGAD9+/fn8OHDDB06FFVVOX/+fCnDFOVJpokRwkwyr8OOJyF6AhiytH06e20k8LG5D36vEJWMqqp3k8CGkgRaglIlgbdv3wbA3d0duDs5dJs2bQBo1aoVAJmZmaUpRpQzmSZGCDOI/wU2toSrP2mDQ0Cb/++5LAieo/URlERQVCF/XP+Dq6lXcbR1pGtd6XpUErdu3WL//v3ExJTNUq+lSgJdXFwAOHToELm5uezfr3X2bNSoEQApKSkAeHrKlAaWzFgTeDb5LHqD3szRCFHF6bPg4GuwLQwyE8ChBqh6LfELvmeUsCSCoorZclarBewe0J1qdtXMHE3pfPLJJ7Rs2RI3Nzfc3NwIDQ1l06ZNpuOZmZm88soreHt74+LiwuDBg0lMTHzodePi4tiwYQMbNmwgNjbWtP/OnTu88MILeHt707FjR5o2bUqjRo3YsWNHqe6jVElgUFAQqqry3XffUaNGDa5evQpgqgk0bhvXGBaWqY57HRxtHckx5HDx1kVzhyNE1XX7JPzSEU7N17YbvQINxv2ZAN43T6AxEVTlDzNRNVSl/oC1a9fmnXfeITo6mgMHDvDoo4/y1FNP8ccffwAwefJkfvzxR9auXcuOHTu4evUqgwYNeuh1ly9fztNPP83TTz/NnTt3TPunTZvGqlWrTCu0qarKuXPnGDBgQKm63JVqYMjQoUNN89MYm4abNWtG8+bNAdi1axeKotC2bdvSFCPKmU7R0cirEceuHePMjTM08Gpg7pCEqFpUFc4ug4OTtbn/HKpDhxVQ+4kHv+/+xFCISiojJ4Odl3YClt0fMDU11dSKCeDg4ICDQ/4R+k88kfd796233uKTTz5h79691K5dm+XLl7N69WoeffRRAFauXElQUBB79+6lY8eOhZZ/+PBhVFWlSZMmNGmiddVKS0tj2bJlppHC904Nk5mZycKFC00zsxRXqWoCJ0yYwMiRI02LGjdv3pzVq1cDcOTIEeLi4rC3t6drV2n7t3T3rhwihChDmUmw62nY/zctAfTtAwOOPjwBFKIK2XlpJ1n6LGq71SaoepC5wylUs2bNcHd3N73mzZv30Pfo9XrWrFlDeno6oaGhREdHk5OTQ+/evU3nNG3alLp167Jnz54HXuvUqVMoikKnTp1M+7Zu3ZpnbMWcOXOYP38+9vb2puMlVaqaQBsbG1atWsWSJUvIycnBw8PDdCwkJEQGhFQikgQKUQ4SImHPSLhzFXR2EPIONH0VlFL9/S1EpWPsDxjWIMyilyc9ceIE/v7+pu2CagGNjh07RmhoKJmZmbi4uPDDDz/QrFkzDh8+jL29fZ6cCMDHx8c0q0phbty4AUD9+vVN+6Kiokxf9+jRg+nTpwPaeIz//ve/XLp0qcj3d78yWTbO2dm5LC4jzEimiRGiDOmz4eibcPL/AFVb8aPT1+DV2tyRCWEWlaU/oKurK25ubkU6t0mTJhw+fJjbt2/z3XffMWrUqFIP1Lh16xZAnkT54MGDpq/Dwu7++xmbi7OyskpcXpn8Obpr1y4GDRqEn58fjo6O+Pn5MXjwYHbt2lUWlxcVQKaJEaKMpJyBiE5w8j1AhYYvQr9oSQCF1bp8+zInk06iU3T0rt/74W+oJOzt7WnYsCFt27Zl3rx5hISEsHDhQnx9fcnOzjYldEaJiYn4+vo+8JrGmscTJ04AkJ2dnacJ+d7+hNnZ2QB4eXmV+B5KnQR++OGH9OzZk//9738kJiaSnZ1NYmIi69evp2fPnnnWERaWy1gTeDnlMhk5GWaORohKSFXh3ArY1BqSo8HeC7qug/afgq20lgjrZawFbO/fHs9qVXfKOIPBQFZWFm3btsXOzo7IyEjTsdOnTxMbG0toaOgDr9GwYUNUVWXt2rXMnTuXMWPGmAaq2NnZ0b59e9O5xrkCa9asWeKYS9UcvH//fqZMmWJaKu5+BoOBKVOm0LlzZx555JHSFCXKmbeTN17VvEi+k0zMjRhCfEPMHZIQlUf2TYh6ES5/p2379ITQL8BJ1kYVorI0BRfHtGnT6N+/P3Xr1iU1NZXVq1ezfft2tmzZgru7O2PHjiU8PBwvLy/c3NyYMGECoaGhDxwZDDBgwAAOHz5Mbm4us2bNMu1XFIUBAwbg6Oho2rdjxw4URaFx48Ylvo9S1QQuWrTIlAA6OzszZMgQxo8fz5AhQ0z9BA0GAx999FFpihEVRJqEhSiBazthY4iWACq20Ood6BkhCaAQQK4hl1/P/wpUrSTw2rVrjBw5kiZNmtCrVy/279/Pli1b6NOnD6C1kj7++OMMHjyYbt264evry7p16x563ddeew1/f/8808CA1vR8b1JonHsQME1DUxKlqgn87bffAG3t4KioKGrUqGE6du3aNTp06MClS5ekb2Al0di7MXuu7JEkUIiiMOTAsVnwxzxABZeG0Hk1eEurhxBG++P2cyvzFh6OHjziX3W+N5YvX/7A446OjixZsoQlS5YU67qenp78/vvv/POf/yQiIoLc3FzatGnDe++9R8uWLU3nff/99wQEBADkmYqmuEqVBCYkJKAoCsOGDcuTAILWRj18+HDmzZv30CHRwjKYpolJliRQiAdKPQe7h8ONfdp2/Reg7UKwczFvXEJYGGNTcO/6vbHVlcmEJFVe3bp1WbNmzQPPWbRoEYsWLSp1WaV6Ira2tmRnZ+eZXftexv22tvLgKwPTNDFJMk2MEAVSVbjwXzjwCuSmgZ07tF8GAUPNHZkQFqkq9gesSkrVJ7BevXqoqsrKlSv55Zdf8hzbsmULK1asQFEU6tWrV6ogRcUw9gk8feN0vv4IQli97NuwewTsHaUlgDW6ait/SAIoRIFu3rnJvjittlySQMtUqiq6sLAwjh8/zp07d+jfvz81atTAx8eHxMRErl+/jqqqKIpCv379yipeUY4aejUE4FbmLW7cuUF1p+pmjkgIC3H9dy0BTL8Eig0Ez4Jm00BnY+7IhLBYv57/FYNqIKh6EHXc65g7HFGAUtUETp48GU9Pbc4fVVW5du0ax48f59q1a6aaJA8PDyZPnlz6SEW5q2ZXjbrudQFpEhYCAEMuHJ0Fv3bTEkDnetDnN2gxXRJAIR5CmoItX6mSwFq1avHDDz/kma363mZEb29v1q9fj5+fX2mKERVIpokR4k9pF+HX7nB8NqgGCHweBhyG6g+e50sIoeUCpiSwoSSBlqrUIza6devG2bNnWbVqFXv27CE5ORkvLy86derE6NGji7wGn7AMjb0bE3E+QpJAYd0ufg37/wY5KWDnBo98AoHDzR2VEJXGyaSTXEm5goONA90Cupk7HFGIMhm26+7uzqRJk5g0aVKe/QMHDuTo0aMoisK5c+fKoihRzkwjhG9Ic7CwQjmpcGA8XPhC267eCTp9CS4yuE2I4thyVqsF7BbQDSc7JzNHIwpT6rWDHyQuLo6LFy9y8eLFYr93yZIlBAYG4ujoSIcOHdi3b98Dz1+7di1NmzbF0dGR4OBgNm7caDqWk5PD1KlTCQ4OxtnZmVq1ajFy5EjTbNtGycnJjBgxAjc3Nzw8PBg7dixpaWnFjr0yM80VKDWBwtokRcGmVloCqOigxUzovUMSQCFKQPoDVg4WOYHfN998Q3h4OEuXLqVDhw4sWLCAsLAwTp8+XeBCybt372bYsGHMmzePxx9/nNWrVzNw4EAOHjxIixYtyMjI4ODBg7z55puEhIRw8+ZNJk2axJNPPsmBAwdM1xkxYgTx8fFERESQk5PDmDFjePHFF1m9enVF3r5ZGfsEnk0+i96gx0Y6v4uqzqCHE+/AsZmg6sE5AEK/hJpdzB2ZEJXSnZw77Li0A5D+gMWxc+fOEr+3W7eSNblbZBI4f/58xo0bx5gxYwBYunQpP//8MytWrOD111/Pd/7ChQvp168fU6ZMAWDu3LlERESwePFili5diru7OxEREXnes3jxYtq3b09sbCx169bl5MmTbN68mf3799OuXTsAPvroIwYMGMD7779PrVq18pWblZVFVlaWaTs1NRWA3NxccnJyyuYfA0zXKstrFsbPyQ97G3uy9Fmcv3GeQI/Aci+zMqrIZyIersTPIyMWm6gx6JK0pS0NdYaib7MY7D1Anm2JyfeHZano57Ht/DYyczPxd/WnsUfjSvE5yM3NNXcI9OjRA0VRiv0+RVFKHL/FJYHZ2dlER0czbdo00z6dTkfv3r3Zs2dPge/Zs2cP4eHhefaFhYWxfv36Qsu5ffs2iqLg4eFhuoaHh4cpAQRtPT6dTkdUVBRPP/10vmvMmzeP2bNn59sfGRlJ9eplP8fe/YlsefGx8+Gy/jJfbf6K1m6tK6TMyqqinokomuI8j1q5vxOS9TE60snFkaP2L3H5Rg/4dXf5BWhl5PvDslTU81gRtwKApnZN2bRpU4WUWVpJSUnmDsGkqIs1KIpS6oUdLC4JTEpKQq/X4+Pjk2e/j48Pp06dKvA9CQkJBZ5f2JrFmZmZTJ06lWHDhplGLyckJORrara1tcXLy6vQ60ybNi1P8hkXF0ezZs3o1asX/v7+D77RYsjJySEiIoI+ffpgZ2dXZtctzMqMlVw+cxmPBh4MeGRAuZdXGVX0MxEPVqznkZuGzaFwdBdXAWDwbIfa8QuCXRoSXP6hWgX5/rAsFf083lj2BgBjuo1hQLPK8TskLi7O3CEARU8Ai3tuYYqdBH7xxRdFPvfGjRvFvXy5y8nJYejQoaiqyieffFKqazk4OODg4GDavnet5PL4RrOzs6uQb+CmNZryvzP/49ytc/ID/CEq6pmIonno87hxAHYPh9QYQIHm09AFz0Knk2dYHuT7w7JUxPO4knKFE0knUFDo16hfpXn+trbmrxO7cOFChZdZ7LsePXp0idqsi6p69erY2NiQmJiYZ39iYiK+vr4FvsfX17dI5xsTwEuXLrF169Y8cxj6+vpy7dq1POfn5uaSnJxcaLlVlUwTI6oc1QAn34cj/wI1F5xqa4M/fLqbOzIhqpRfzv0CwCP+j+Dt5G3maCqXgICACi+zxFPEqKr60FdJ2Nvb07ZtWyIjI037DAYDkZGRhIaGFvie0NDQPOeD1vfh3vONCWBMTAy//vor3t7e+a5x69YtoqOjTfu2bt2KwWCgQ4cOJbqXykpWDRFVSkYcbO0Dh6dqCWCdZ6D/EUkAhSgHMjVM5VKi+s+iJnglTQTDw8MZNWoU7dq1o3379ixYsID09HTTaOGRI0fi7+/PvHnzAJg0aRLdu3fngw8+4LHHHmPNmjUcOHCAZcuWAVoC+Mwzz3Dw4EF++ukn9Hq9qZ+fl5cX9vb2BAUF0a9fP8aNG8fSpUvJyclh/PjxPPfccwWODK7KjDWBsbdjuZNzh2p21cwckRAldHk9RI2F7GSwcYJ2i6D+C1COrRlCWCu9QU/EOW3wiSSBZUNVVb7//nu2bNnClStX8sxIYqQoSr6KsKIqdhK4bdu2EhVUHM8++yzXr19nxowZJCQk0KpVKzZv3mwa/BEbG4tOd7cSs1OnTqxevZrp06fzxhtv0KhRI9avX0+LFi0ArcPnhg0bAGjVqlW+++nRowcAX331FePHj6dXr17odDoGDx7MokWLyv1+LU11p+p4OHpwK/MW526eo0XNFuYOSYjiyU2Hg+FwVvtDEM820Hk1uDUxb1xCVGEHrh7gZuZN3B3c6VDbulrQykNubi6PPfYYv/76a6HnqKpaqi56xU4Cu3evmCaU8ePHM378+AKPbd++Pd++IUOGMGTIkALPDwwMLFKtpJeXl1VNDF0YRVFo7N2YfXH7OJ10WpJAYZmOzgLFBoLfzLs/+RBs6wtZf075EPRPaDkXbOwrOkIhrIqxKbhX/V7Y6sw/0KKyW7p0KREREQVOBVNWYzPKddk4UXlJv0Bh8RQbODYDjs3VtlUDujMLYEs7LQG0dYFHI6D1u5IAClEBpD9g2fr2228BsLGxMbVsKorCkCFDTHMR9+3bl5EjR5a4DEnVRYFMawgnSxIoLJSxBvDYDHRZtwjN2orNkcPaPrem0HsXOJb9pO1CiPxuZd4i6koUIElgWTlx4gSKojB06FBat25tWhXtm2++4fr167Rr147jx4/zn//8p8RlSE2gKJBpmpgkmSZGWLDgN6Hus9icmU9N/WFtn/8T8NgJSQCFqECR5yPRq3qaeDchwKPipzqpioxzDzdt2jRP86/BYKBGjRo8//zzXL16lalTp5a4DEkCRYGkOVhYvMxr8NtQiP3GtEtV7KD7Bhn9K0QFk6bgsufs7Axok3w7OTmZ9p85o/1ezsjIAEq3HKAkgaJADb0aAnDjzg1uZFjeyi/Cyl36Fn5uDrFrAS3h02OLoubc7SMohKgQqqreTQIbShJYVozzGd+8eTPPUrTPPfcckydP5tNPPwXu1hiWhPQJFAVytnemtlttrqRcISY5RmZ+F5bhTiIceAUuf69tO/pAZiL65jP56WJrHg88hM2xGdqx+0cNCyHKxekbp4m9HYu9jT3dA2QS9rLSpEkTLly4wNWrV+nYsSM6nQ5VVTl27BjHjh0zTQ/TrFmzEpchNYGiUNIvUFgMVYWLa2Bjcy0BVGyhZg/ITITgORia/QtA+3/wnLyjhoUQ5WrLWa0WsGvdrjjbO5s5mqqjTZs2qKrKnj17TH0AC5ru7l//+leJy5AkUBRK+gUKi3AnAXYNht3DIOsGeIRA2D6o2V1L+O6v8Qt+U9uv6s0TrxBWRvoDlo9Zs2aRmprKkSNHAPjkk0+YOHEiPj4+2Nra0qJFC1avXs3gwYNLXIY0B4tCyTQxwqxUFS59DQcmaMu+KbbQYjo0m6bN++fVuvD3SlOwEBUiMzeT7Re3A9IfsKzZ2NiYBocAODo6smDBAhYsWFBmZUgSKAolzcHCbO7Ew/6/w5X/adueraDjKvAMMWdUQoj7/Bb7G3dy7+Dn4kdwzWBzh1NlZWZmcuzYMW7duoWHhwfBwcE4OjqW+rqSBIpCGZuDY5JjMKgGdIr0HhDlTFXh4lcQPRGyb4LODpq/Cc1f174WQlgUY3/Avg36ltlSZuKuGzduMHXqVL766iuys7NN++3t7RkxYgTvvPOOafWQkpAkUBQqwCMAO50dmbmZXEm5Ql33uuYOSVRlGVdh/98g7kdt27MNdFwJni3NG5cQolDSH7D8XLt2jc6dO3P+/Pl8A0KysrJYuXIl27dv5/fff8fHx6dEZUjVjiiUrc6WBl4NAGkSFuVIVeH8F9q8f3E/ajV+Lf8NYXslARTCgl1Nvcqxa8dQUOjToI+5w6lypk2bxrlz5wo9rqoqFy5c4I033ihxGZIEigcyDQ6REcKiPGRchR1Pwt5RkHMLvNpCv4PQ4l/S/CuEhfvl3C8AtK3VlupOskxjWfvpp59MTex9+/bl888/Z/PmzXz++ef07dsX0BLBH3/8scRlSHOweCCZJkaUC1WFC19A9Kta8qezh+BZEDQFdPJjSYjKQJqCy1daWhoAvXr1YvPmzXmOPf/88/Tp04fIyEjS09NLXIbUBIoHkmliRJnLiIMdj8Pe0X/W/j2i1f41nyYJoBCVhN6gJ+KctmatJIHlIygoCIDOnTsXeLxLly55zisJSQLFA8k0MaLMqCqcW6n1/bu6Uav9a/UO9N0NHs3NHZ0QohgOxh/kxp0buNq70rF2R3OHUyVNmTIFVVX57bffCjy+c+dOFEXh1VdfLXEZ8me3eCBjc/DFWxfJys3CwdbBzBGJSin9Mux7EeL/bNLw7gAdV4B7yde8FEKYj7EpuFf9XtjZSP/dsrBz5848235+fjz22GNs3LiRAQMGMGLECGrWrMm1a9f48ssv2b59Oz169KBu3ZLP3CFJoHigms41cXNwIyUrhXM3z9GshvzSFsWgqnB+BRwMh5wU0DlAy7nQNBx0NuaOTghRQtIfsOz16NGjwLkWVVVly5YtbNmyJd/+7du3s2PHDnJzc0tUpjQHiwdSFEWahEXJpMfCtn4Q9VctAfTuCP0PQ7MpkgAKUYndzrzNnst7AEkCy4OqqqYXkCcxvHe+QEVR8pxXEpIEioeSaWJEsagqnP0Mfm4BCb+AjSO0fh/6/AbuTc0dnRCilLZe2Ipe1dPIqxH1POuZO5wq5f6E7t6E0Hjs/u3SkOZg8VAyTYwosvRLWs1fwq/advVOWt8/tybmjUsIUWakKbh8XLhwocLLlCRQPJRMEyMeSlXh7DI49A/ITdNq/0LehsYTpelXiCpEVdW7SWBDSQLLUkBAQIWXKUmgeCjpEygeKO0iRI2FxK3ado0u0GEFuDUya1hCiLIXkxzDxVsXsdPZ0SOwh7nDsRo3b95k37593Lx5E09PT9q3b4+np2eprytJoHgoYxJ4PeM6N+/cxLNa6T94ogpQDXD2Uzg0BXLTwaYahMyDJhNAke7GQlRFW85qtYBd6nbBxd7FzNFUfRkZGUycOJEvvvgCvV5v2m9jY8OoUaNYuHAhTk5OJb6+/KQWD+Vi70It11qA9legEKRdgK29Yf/LWgJYoysMOApNJ0kCKEQVZmwK7tewn5kjqfr0ej39+vVj5cqV5Obm5hkQkpuby4oVK+jfvz8Gg6HEZchPa1Ek0iQsAK3278wS2BgMidvAxgnaLoLe28G1obmjE0KUo6zcLLZd3AbIoJB58+bxyCOP4OrqSs2aNRk4cCCnT+f9/ZiZmckrr7yCt7c3Li4uDB48mMTExCKXsXLlykJXCwFMq4msXLmyxPchSaAoksZeMk2M1Us9B5GPwoHxWu1fze5a7Z80/wphFX6//DsZORn4uvjS0qelucMxqx07dvDKK6+wd+9eIiIiyMnJoW/fvqSnp5vOmTx5Mj/++CNr165lx44dXL16lUGDBhW5jNWrV5u+Hjp0KD///DMHDhzg559/ZsiQIaZjX331VYnvQ/oEiiJpUv3PaWJkhLD1Mdb+HX4d9Blg6wyt3oVGf5fkTwgrYuwP2LdB3wJXtqgKUlNTSUlJMW07ODjg4JB/udTNmzfn2V61ahU1a9YkOjqabt26cfv2bZYvX87q1at59NFHAa1mLygoiL1799Kx48PXWz569CiKohAWFsaaNWvyHOvfvz8pKSls2bKFo0ePluRWAakJFEUkE0ZbqdSz8GsPiJ6oJYA+PbXav8avSAIohJWxhvkBmzVrhru7u+k1b968Ir3v9u3bAHh5eQEQHR1NTk4OvXv3Np3TtGlT6taty549e4p0TWMyWljCaNyfmppapOsVRGoCRZHcmwQaVAM6SQCqNtUApz+CI9NAf0er/Wv9f9DwJUn+hLBCCWkJHEk8goJCn/p9zB1OuTlx4gT+/v6m7YJqAe9nMBh49dVX6dy5My1atAAgISEBe3t7PDw88pzr4+NDQkJCkWJxd3cnOTm50KTRuN/Nza1I1yuIJIGiSOp51MNWZ0tGTgZXU69S2622uUMS5SUlBqJegOt/dkj2eRQ6LAeXQLOGJYQwn1/O/QJAG7821HCuYeZoyo+rq2uxk6pXXnmF48ePP3AQR0mEhISwdetWfvnlF4YPH87IkSPx8fEhMTGRzz//nF9++QVFUQgJCSlxGZIEiiKxs7Gjvmd9ztw4w5kbZyQJrMyOzgLFBoLfzLvfoIcdj0NCBKh6sHXR1vxt+CJU0f4/QoiisYam4JIYP348P/30Ezt37qR27bu/F319fcnOzubWrVt5agMTExPx9fUt0rWHDx/O1q3aJPzffPMN33zzTYHnjRgxosTxS7uOKDKZJqaKUGzg2Aw4NvfuvpTTsKEexG/WEkDf3vDYcWj0kiSAQlg5g2ow1QTKUnEaVVUZP348P/zwA1u3bqVevXp5jrdt2xY7OzsiIyNN+06fPk1sbCyhoaFFKmP06NF07doVVVVNZRpfRt26dWPUqFElvg+pCRRF1sS7CT/xkwwOqeyMNYDHZmh9/+xctJG/ai7o7KHdYmjwV0n+hBAAHIo/RFJGEq72roTWLloCU9W98sorrF69mv/973+4urqa+vm5u7tTrVo13N3dGTt2LOHh4Xh5eeHm5saECRMIDQ0t0shgAJ1Ox6ZNm5gwYUK+FUN0Oh2jR49m4cKF6HQlr8+TJFAUmWlwiEwTU/kFvwlZN+D4rLv7XBpAr63gXNdsYQkhLI+xKfjReo9iZ2Nn5mgswyeffAJAjx498uxfuXIlo0ePBuDDDz9Ep9MxePBgsrKyCAsL4+OPPy5WOU5OTixfvpz/+7//Y9++fSQnJ+Pl5UX79u1NI5FLQ5JAUWQyTUwVoapw7jPtZaTYwhMxUvsnhMhH+gPmd2+TbGEcHR1ZsmQJS5YsKXV5Xl5e9OtX9kv1SRIoisyYBF64eYFsfTb2NvZmjkgUW+Z1iPorxG24u09nD4ZsOP7v/INFhBBWLSUrhd2XdwPSH7C8xcbGlvi9deuWrAVHkkBRZH4ufrjYu5CWncb5m+dpWr2puUMSxXF1E+wdA5mJ2uAQVQ/BsyH4z0Eix2Zo50kiKIT407YL28g15NLQqyH1PeubO5wqLTAwsEQrsSiKQm5ubonKlNHBosgURZEm4coo9w4cmADbB2gJoEONPxPAOVoCCFriFzwn/6hhIYRVk6bginfvKOCivkpKagJFsTT2bszB+IPaNDFNzB2NeKjkQ7B7BKSc1LabTAIbZ7BxzF/jZ9xW9QghBEgSWNFKk9CVhCSBoliaeGuZn9QEWjiDHk59AEengyEHHH2h4yqo9ZAf5NIULIT409nks5y/eR47nR096/U0dzhV3rZt2yq8TEkCRbHINDGVQHos7BkF17Zr27WfhvbLwLG6WcMSQlQuW85qtYCd63bGxd7FzNFUfd27d6/wMiUJFMUiq4ZYuItrYP/fIOc22DpD24VQ/wWZ+kUIUWzSFFz1SRIoisWYBCamJ3I78zbuju5mjkgAkH0bDrwCF7/Str07QKcvwbWheeMSQlRK2fpstl3UmiclCaxY165dA6BatWq4uroC8MILLxR4bvXq1XnvvfdKXJYkgaJY3Bzc8HXxJSEtgZjkGNrVamfukMS1nbD7eciIBUUHzd+EFv8CnczsL4Qomd2Xd5OWnUZN55qE+IaYOxyr8dtvv5mahT/++GNeeuklAFatWlXo9DEjRowgJKRkz8gip4hZsmQJgYGBODo60qFDB/bt2/fA89euXUvTpk1xdHQkODiYjRs35jm+bt06+vbti7e3N4qicPjw4XzX6NGjB4qi5Hn97W9/K8vbqjJkmhgLoc+Gw2/Arz20BNClPvT+DVrOkgRQCFEqxv6AfRv0RadYZKpQJW3YsAFVVXF0dOT555/Pd/ze0cPGrzds2JDvvKKyuCf7zTffEB4ezsyZMzl48CAhISGEhYWZqkfvt3v3boYNG8bYsWM5dOgQAwcOZODAgRw/ftx0Tnp6Ol26dOHdd999YNnjxo0jPj7e9CpNFWtV1thL+gWa3e1TENEJTswDVKg/BvofhhqyuLsQovSkP6B5REVFoSgKXbp0wcnJKd9xJycnvLy88PLyws5O+2P/999/L3F5FpcEzp8/n3HjxjFmzBiaNWvG0qVLcXJyYsWKFQWev3DhQvr168eUKVMICgpi7ty5tGnThsWLF5vOef7555kxYwa9e/d+YNlOTk74+vqaXm5ubmV6b1VFk+p/ThMjI4QrnqpCzFLY3AaSo8HeC7p8Bx1XgJ2ruaMTQlQBiWmJHEo4BGg1gaLixMTEANCqVasCj8+ZM4fr169z/fp1Ro4ciaqqnD5d8goZi+oTmJ2dTXR0NNOmTTPt0+l09O7dmz179hT4nj179hAeHp5nX1hYGOvXry92+V999RVffvklvr6+PPHEE7z55psFZuJGWVlZZGVlmbZTU1MByM3NJScnp9jlF8Z4rbK8ZmnUd9eWDjqddNpiYqpoZnkmmdewOfAiunitu4OhZi/07f8D1fzBSp+DkaV9j1g7eR6WpbjPY1PMJgBa+bTC097TKp5jSZddK2vJyckAeHl55Tt2/0TS9erVA+D69eslLs+iksCkpCT0ej0+Pj559vv4+HDq1KkC35OQkFDg+QkJCcUqe/jw4QQEBFCrVi2OHj3K1KlTOX36NOvWrSv0PfPmzWP27Nn59kdGRlK9etnPyRYREVHm1yyJ+Mx4AE5eO8nPP/9corUOq4qKeiY+uftplbUYO26jx44T9s9zPu1x2HYEOFIhMVQGlvI9IjTyPCxLUZ/HqkurAGigNsjXx76qSkpKMncIAKbfp2lpaXn2nzyprfpUs2ZN076y+GPLopJAc3rxxRdNXwcHB+Pn50evXr04d+4cDRo0KPA906ZNy1MLGRcXR7NmzejVqxf+/v5lFltOTg4RERH06dPH1AfAnLL12Uw6PYlMQyatu7Wmlmstc4dU4SrsmeRmoDs6FZtznwKgurfA0OFzmroH07T8Sq10LO17xNrJ87AsxXkeBtXAiwu134d/6/M3ugdU/ATG5hAXF2fuEACtBjAhIYG9e/fm2d+kSf51WqOjowHw9PQscXkWlQRWr14dGxsbEhMT8+xPTEzE19e3wPf4+voW6/yi6tChAwBnz54tNAl0cHDAwcHBtJ2SkgKAra1tufzgs7Ozs4gfqHZ2dtTzrMfZ5LNcSLlAgFeAuUMym3J9JsnRf677+2d/jyaTUVq9jZ2NY/mUVwVYyveI0MjzsCxFeR6H4g9xLeMaLvYudKvXDTsb63h+traWkQ61aNGC+Ph4tm3bRlRUlCkXud+RI0fYtGkTiqIUmCAWlUUNDLG3t6dt27ZERkaa9hkMBiIjIwkNLXjUY2hoaJ7zQavyLuz8ojJOI+Pn51eq61RVMk1MOTLo4Y95sKWjlgBWqwWPRkDb+SAJoBCiHBlHBfcM7Im9jb2Zo7E+xgGsBoOBJ554gh9++CHfOT/++CMDBgxAr9fneU9JWEbqe4/w8HBGjRpFu3btaN++PQsWLCA9PZ0xY8YAMHLkSPz9/Zk3bx4AkyZNonv37nzwwQc89thjrFmzhgMHDrBs2TLTNZOTk4mNjeXq1asAppE0xlHA586dY/Xq1QwYMABvb2+OHj3K5MmT6datGy1btqzgf4HKobFXYzayUaaJKWvpl7SJn6/v0rbrDIb2n4KDt3njEkJYBZkaxrzGjh3LnDlzyMjIICkpiWeeeQZPT08aNWqEoijExMSQnJxsGiTi4OCQpztbcVlcEvjss89y/fp1ZsyYQUJCAq1atWLz5s2mwR+xsbHodHcrMDt16sTq1auZPn06b7zxBo0aNWL9+vW0aNHCdM6GDRtMSSTAc889B8DMmTOZNWsW9vb2/Prrr6aEs06dOgwePJjp06dX0F1XPjJNTDm48BUceBlyUsDWBdp9BPVGybq/QogKkZadxu+x2pxzYQ0lCTQHLy8vPvjgA/72t7+hKAqqqpKcnGxaNMOY/BkHkLz33nv5BscWh8UlgQDjx49n/PjxBR7bvn17vn1DhgxhyJAhhV5v9OjRjB49utDjderUYceOHcUN06pJc3AZyr4F+1+GS19r29VDtXV/XeqbNSwhhHXZdmEbOYYc6nvWp6GXrDtuLi+++CK3b9/mjTfeQK/X55mBw5gY6nQ65s6dW2iuVFQW1SdQVB7GJPD8zfPk6Kv+HFLlJnE7bGypJYCKDQTPgd47JQEUQlQ4aQq2HFOmTOHYsWO89NJLNGzYkGrVqlGtWjUaNmzI3/72N44cOcLrr79e6nIssiZQWL5arrVwsnMiIyeDC7cumJJCUUT6bDj6Jpz8P0AFl4Za7V/1gkeCCSFEeZMk0LI0bdqUTz75pFzLkJpAUSI6RSdNwiV1+yT80gFOvgeo0OCv0P+QJIBCCLM5f/M8Z5PPYquzpWe9nuYOR1QQSQJFiUkSWEyqCmeWaOv+3jysjfjt+gN0+AzsXMwdnRDCim05q9UCdqrTCTcHNzNHIyqKNAeLEmvspSWBMk1MEdxJgL0vQLy2Jid+YdBxJVSTeSiFEOYnTcHWSZJAUWIyTUwRXdkAUWMhKwl0DtD6/6DxK6BIRbwQwvxy9DlsvbAVkCTQ2kgSKEpMmoMfIjcdDobD2T8nLvcIgU5fgUdz88YlhBD32HNlD6nZqdRwqkFrv9bmDkdUIEkCRYkZk8CrqVdJzUrF1cHVzBFZkBv7tXV/U2MABYJeg5b/BhuHh75VCCEqkrE/YJ8GfdBJC4VVkactSszD0YOazjUBiEmOMXM0FsKgh+NvwS+dtATQqTY8+qvWBCwJoBDCAkl/QOslSaAoFWkSvkfaBYjsDkeng5oLdYfCgKPg+6i5IxNCiAJdT7/OwfiDAPRt0NfM0YiKJkmgKBXjCGGrTgJVFc5/ARtD4PrvYOsKoV9A5zVg72nu6IQQolAR5yNQUQnxCcHXxdfc4YgKJn0CRakYawJP37CCaWKOzvpzabc37+7LToaoiRD7rbZdowuE/hdcAs0QoBBCFI80BVs3SQJFqZimibGGmkDFBo7N0L5u+jrV9Uex/eUVuBOn7fPtBT22gM7GfDEKIUQRGVSDaVBIWENJAq2RJIGiVO7tE6iqKoqimDmicmSsATw2A5urm+icuefusYYvQful5olLCCFK4GjiURLTE3Gyc6Jznc7mDkeYgfQJFKXSwLMBOkVHSlYKiemJ5g6n/NUZBI4+6G7ckwA2ny4JoBCi0jHWAvYM7ImDrcxeYI0kCRSl4mDrQKBHIFDFm4RVFU4vgs1tITMR1bhbZw8hc80amhBClIT0BxSSBIpSq/LTxNyJh+39IXoSGLLApREKoMcWxZANxyQJFEJULmnZafwW+xsg/QGtmSSBotSM08ScTqqCI4Qvr4eNwRC/BWwcodZjkBaDvvlMfnL+Dn3zmdpgEUkEhRCVyPaL28kx5BDoEUgjr0bmDkeYiQwMEaVmqglMrkI1gTlpcHAynPuPtu3ZSpv+5cxiCJ6DoenrcHEjhmb/wkZ3z6jhe6ePEUIIC2UaFdwgrGoP6BMPJEmgKLUqN01M0j5t3d+0s2jr/k6BlnPgj3kQPEdL9HJy7p5vTPxUvVnCFUKI4pL+gAIkCRRlwFgTeC75HLmGXGx1lfRjZciFE+/AsVlaQudUW1v5w6endrzlrMLfKzWAQohK4sLNC8Qkx2Cj2PBoPVnW0ppV0t/WwpLUdqtNNdtq3Mm9w8VbF2no1dDcIRVf2gXY87y27BtA3Weh/Sey7JsQosox1gKG1gnF3dHdzNEIc5KBIaLUdIqORt5ax+JK1yRc6Lq/X0sCKISokqQpWBhJEijKRKWcJib7Jvz+HOwdBbmp2sCPAUeh3vMgHaWFEFVQjj6HyPORgCSBQpJAUUYq3TQxCVthY0uI/RYUW2j5b+i1HVwCzRyYEEKUn71X9pKanYp3NW/a+LUxdziV1s6dO3niiSeoVasWiqKwfv36PMdVVWXGjBn4+flRrVo1evfuTUxMjHmCfQBJAkWZqDTTxOiz4NAU2NobMq6AayPouxta/At0NuaOTgghypWxKbhPgz7a9FaiRNLT0wkJCWHJkiUFHn/vvfdYtGgRS5cuJSoqCmdnZ8LCwsjMzKzgSB9MBoaIMlEppom5fUKb+uXmYW274YvQZj7YOps1LCGEqCjSH7Bs9O/fn/79+xd4TFVVFixYwPTp03nqqacA+OKLL/Dx8WH9+vU899xzFRnqA0lNoCgTxprAKylXSM9ON3M091FVOL1YW/f35mFwqA7d1kP7TyUBFEJYjaSMJKKvRgPQt0FfM0djmVJTU0lJSTG9srKyin2NCxcukJCQQO/evU373N3d6dChA3v27CnLcEtNkkBRJryqeeFdzRuAmGQL6vdwJwG2D4DoCaDPBL9+MOAY1H7K3JEJIUSF+vXCr6ioBNcMppZrLXOHY5GaNWuGu7u76TVv3rxiXyMhIQEAHx+fPPt9fHxMxyyFNAeLMtOkehN2X97NmRtnaOXbytzhwJUNEDUWspK0dX9b/R80fkVG/gohrFLE+QhAmoIf5MSJE/j7+5u2HRwczBhN+ZOaQFFmLGaamNx02PcS7HxKSwA9QiDsADQZLwmgEMIqqarKrxd+BSCsoSSBhXF1dcXNzc30KkkS6OvrC0BiYmKe/YmJiaZjlkKSQFFmTNPE3DDjNDE39sOm1nB2Gdq6v/+AsCjwaG6+mIQQwswuZV4iPi2earbV6FK3i7nDqdLq1auHr68vkZGRpn0pKSlERUURGhpqxsjyk+ZgUWbMWhNo0N+z7m8uVPPXVv7wlXUxhRDiUOohAHoE9sDR1tHM0VR+aWlpnD171rR94cIFDh8+jJeXF3Xr1uXVV1/l3//+N40aNaJevXq8+eab1KpVi4EDB5ov6AJIEijKzL3TxKiqilJRTa9pF/9c9/c3bbvuUHjkE3DwqpjyhRDCQukNenZc2sHWG1sB6FO/j5kjqhoOHDhAz549Tdvh4eEAjBo1ilWrVvHPf/6T9PR0XnzxRW7dukWXLl3YvHkzjo6WlYBLEijKTAPPBigo3Mq8RVJGEjWca5RvgaoKF7+CA69AToq27m+7xbLsmxBCAOtOrmPS5klcSbli2vfe7+8R4BHAoKBBZoys8uvRoweqqhZ6XFEU5syZw5w5cyowquKTPoGizFSzq0Zd97pABfQLzL4Jvw/TagBzUqB6JxhwBOqPlARQCGH11p1cxzPfPpMnAQRITE/kmW+fYd3JdWaKTFgSSQJFmaqQlUMSt8PGEIj9BhQbaDkXeu8Al3rlV6YQQlQSeoOeSZsnoZK/psq479XNr6I36Cs6NGFhJAkUZco4QrhckkB9NhyaCpGPQsZlcGkIfXZDi+mgk54NQggBsCt2V74awHupqFxOucyu2F0VGJWwRPKbU5Qp4wjhMm8Ovn0Sdg+/u+5vg79Cmw/BzqVsyxFCiEouPjW+TM8TVZckgaJMlfk0MaoKMR/DoX9oy745eEP7/0CdgWVzfSGEqEIycjLYGLOxSOf6ufqVczTC0kkSKMqUsU/g2eSz6A16bHQ2Jb/YnUSIegGu/vkDzS8MOq6EavKDSwgh7vfj6R+ZuHkiF29dfOB5Cgq13WrTtW7XiglMWCzpEyjKVB23OjjYOJCtz+bS7Uslv9CVH2FjsJYA6hyg7ULosVESQCGEuM+Fmxd48usneXLNk1y8dZE6bnX4Z6d/ovz5372M2wv6LSjdH+miSpAkUJQpG50NDb0aAiVsEs5Nh31/g51PQtZ18GgJ/Q5Ak4mgyMdVCCGMsnKz+PfOf9Ps42b8eOZHbHW2TO08lZOvnOTdPu/y3dDv8Hfzz/Oe2m61+W7odzJPoACkOViUgybVm/DH9T84c+MM/Rr2K/obbxyA3SMg9c/kselrEPIW2BR/AW8hhKjKfjn3C+M3jicmOQaAnoE9WTJgCUE1gkznDAoaxFNNnmLb+W1s+m0T/bv0p2f9nlIDKEwkCRRlrtjTxBj0cPJdODrznnV/PwffXuUYpRBCVD5XUq4QviWctSfWAuDr4sv8vvN5rsVzBS7VaaOzoXvA/7d353FRlfsfwD+zMDPsqwyLCGqyqLjh1XCJVFy7pklqmgbmtbqi1+RaroFbUpam1zCvpqW2uGVWKl6VX6gpWJqkKaIFaiIgm+zCLM/vj5EjBwaYQWCGme/79TovOc95znO+M4/kt+ec5zkhKLtahhDvEEoACQ8lgaTZ6bVMTOktIOkVIPfRelVeLwL9/kvv/SWEkBoUKgU2nt+I5YnLUaYog1AgxNx+c7Hi2RWwl9kbOjzSRlESSJod760hl5dr3uoR+E7dimdeBDJ/ANRVgNjm0Xt/6bVvhBBS0+nbpzH7yGxczb0KABjgNQCbx2xGT7eeBo6MtHVG+aR9XFwcfHx8IJPJ0L9/f/z8888N1t+/fz/8/f0hk8kQGBiIo0f5ayQdPHgQI0aMgLOzMwQCAVJSUuq08fDhQ0RGRsLZ2Rk2NjYICwtDTk5Oc34ss1E9Enin6A4UTA1ciQaurHpcoeoBcKQH8Nc3mgTQJfjRe3/DKQEkhJBHckpz8Mq3ryDk8xBczb0KFysXbH9+O87MOEMJIGkWRpcE7t27F1FRUYiJicGvv/6Knj17YuTIkbh//77W+ufOncOUKVMwc+ZMXLp0CePHj8f48ePx+++/c3XKysowaNAgvP/++/Ved/78+fjhhx+wf/9+nDp1Cvfu3cOECTR7qimcLZ3hKHMEAKS6vQgErnycCOacAr7zBoquABAAgSuA0NOATSfDBk0IIUZCpVbh458/ht/Hfth9eTcEEOD1oNeRNicNr/Z+FUJaKYE0E6O7Hbx+/XrMmjULM2bMAABs2bIFR44cwY4dO7Bo0aI69Tdu3IhRo0bhrbfeAgCsWrUKJ06cwMcff4wtW7YAAKZPnw4AuHXrltZrFhUVYfv27fjqq68wdOhQAMBnn32GgIAAJCcn4+mnn27uj2nSBAIBfJ19cT7zPG7k30CPwHc0Ez6uRD+uJHHUrPvnQt8tIYRUS76bjNlHZuNS9iUAQJB7ED557hP8zfNvBo6MmCKjSgKrqqpw8eJFLF68mCsTCoUIDQ1FUlKS1nOSkpIQFRXFKxs5ciQOHTqk83UvXrwIhUKB0NBQrszf3x8dOnRAUlJSvUlgZWUlKisruf2SkhIAgFKphEKh0Pn6jaluqznbbGldnLrgfOZ5pN5PhdI5CaLb+7glSxmEUD73p+Y5wDb0mWpqi31iyqg/jAv1h/7yy/OxLHEZtqdsBwA4yBywKmQV/tH7HxAJRU/0XVJ/NE6pVBo6BIMwqiQwLy8PKpUKcrmcVy6Xy3H9+nWt52RnZ2utn52drfN1s7OzIZFI4ODgoFc7sbGxWLFiRZ3yhIQEuLi46Hx9XZ04caLZ22wpLJdBIgA6/rEdwnvLIYAaAKCGCEKo8MfhSNyQTDZwlE+uLfWJOaD+MC7UH41TMzUSChKw694ulKg0AwlDHIcg3CMcDjkO+N+x/zXbtag/6peXl2foEAzCqJLAtmbx4sW8UcjMzEx07doVw4YNg6enZwNn6kehUODEiRMYPnw4LCwsmq3dliT59Rrevgb0kD5+dZzK7y2oe7wLdu1dBFxdAV9fX6i7LjVglE3XFvvElFF/GBfqD92k5KRg7rG5OJ95HgDQrV03bBq5CYM6DGrW61B/NC4zM9PQIRiEUSWBLi4uEIlEdWbl5uTkwM3NTes5bm5uetWvr42qqio8ePCANxrYWDtSqRRS6eO3WRQXFwMAxGJxi/yiWVhYGP8vsFoBXI3FqPRVEEiBMjVgLQQQuBKiwHcgAoCeywGhCKIr0ZqFS7UtH9NGtIk+MSPUH8aF+kO7oodFeOfHdxD3SxzUTA0biQ1WPLsCc/vNhYWo5b4v6o/6icVGlQ61GqOaYiSRSBAUFISEhASuTK1WIyEhAcHBwVrPCQ4O5tUHNEPe9dXXJigoCBYWFrx20tLScOfOHb3aMXsPrgLHg4ErMRAwJb4pBTYXAeX+i+omeoHvaGYNM5VhYiWEkFbGGMMXl7+A38d+2PTzJqiZGpO7Tcb1yOuICo5q0QSQEG2MLvWNiopCeHg4+vbti379+mHDhg0oKyvjZgu/8sor8PT0RGxsLABg3rx5CAkJwbp16/Dcc89hz549uHDhArZu3cq1WVBQgDt37uDevXsANAkeoBkBdHNzg729PWbOnImoqCg4OTnBzs4Oc+fORXBwMM0M1oVaBVz/ELgcrVn3T+II9P0Y879diL+K72Jgu7EYoO28NjwCSAgh+rh6/yoij0bi1O1TAAA/Zz98POZjhHYKbeRMQlqO0SWBkydPRm5uLqKjo5GdnY1evXrh2LFj3OSPO3fuQCh8PIA5YMAAfPXVV1i2bBmWLFmCLl264NChQ+jevTtX5/vvv+eSSAB46aWXAAAxMTFYvnw5AOCjjz6CUChEWFgYKisrMXLkSGzevLkVPnEbV5wGJEUA+cmafY/ngH5bASsP+DrvwF/Fd3Ej/wYGeGlNAwkhxKSVVpVi5amV+Cj5IyjVSliKLbHsmWX4d/C/IRVLG2+AkBZkdEkgAMyZMwdz5szReiwxMbFO2cSJEzFx4sR624uIiEBERESD15TJZIiLi0NcXJw+oZovpgbSNgK/LQFUDwELOyBoI9Dx8Vs//Jz9kJCRoHl9HCGEmBHGGL5J/Qbz/zcfd4vvAgDG+Y3DhlEb4OPgY9jgCHnEKJNAYuRK/gSSZwC5ZzT7biOA/p8C1l68atWvj6MkkBBiTm7m38Sc+Dk4/udxAEBHh474z+j/4O++fzdwZITwURJIdMfUwM0twKW3AFU5ILYGeq8DnnpN6zt/q5PAtPy01o6UEEJaXYWiArE/xeL9s++jSlUFiUiChQMXYvGgxbC0sDR0eITUQUkg0U3ZbSB5JpDzaAa167PA0zsAm471nuLn4gdA83/Faqam910SQkzW4RuH8a/4fyHjQQYAYGTnkdg0ehO6OHcxcGSE1I+SQNIwxoA/twO/RgHKEkBkCfR6H/CNBBpJ6rztvWEhtEClqhJ/Ff0FbwfvVgqaEEJax60Ht/DmsTfxXdp3AABPW09sGLUBYQFhEGi5Q0KIMaEkkNSvPBM4PwvIitfsuwwAnv4csNPt/2xFQhGecnoKqXmpSMtPoySQEGIyKpWVWJe0DqtPr0aFsgJioRjzn56P6JBo2EhsDB0eITqhJJDUxRhw6wvgwr8AxQNAKAV6rgb85gNCkV5N+Tr7IjUvFTfyb2BE5xEtEy8hhDQzlVqFM3fOIKskC+627hjcYbDmDUcATqafROTRSG7SW4h3COLGxKGbazdDhkyI3igJJHwV2cAvbwB3Nbc24PQ3IHgnYB/QpOb8nDXPBdIMYUIa1lDSQVrXwdSDmHdsHre0CwC0t2uP6GeikZCRgL1X9wIA5NZyrBuxDlMDp9KtX9ImURJIHru9F7gQCVTmA0ILIHA5EPA2IGz6XxNaJoaQxtWXdGwctRETAiYYMDLzczD1IF7c9yIYGK/8bvFdvHb4NQCAUCBE5N8isXLISjjIHAwQJSHNg5JAAjzMAy7MBu7s1+w79gKe3gk49njipmmZGNLSVGoVTt0+hdOFp2F92xpDOg1pUyNo9SUdmcWZeHHfizgw6UCbSgTbcn+o1CrMOzavTl/UJBFJcHbGWfT17NuKkRHSMigJNHd/HQJ+eR14eB8QiIBuSzWbSNIszVcvE3P7wW08VD6ETCxrlnYJAeqOoK2/vb5NjaA1lHQwMAggwJvH3sQ4v3FtIpEy9v5QMzWKK4vx4OEDFD0swoOHD7itqLIIl7Iu8UZjtalSVaFUUdpKERPSsigJNFdVhZqJH7e+0Ozbd9M8++cU1KyXaWfVDvZSexRVFuHPgj/pwWnSbFpzBE2hUqBcUd7krUxRprW8oKIAueW59V6XgeGv4r/Q/ZPu8LD1gI3ERrNZ2MBWavt4v4HNVqKpJxFJWvS5tdboD4VKgaLKIq0JXM19bWVFD4tQXFnc4CifrrJKsp64DUKMASWB5ijzKPDzLKDinmatv4C3Nc//iZr/ZeYCgQC+zr745d4vSMtPoySQNIvGRtAA4I3DbwAMqFRV1puE6bop1IrW/og81/Ou43re9SdqQywUN5wwNiGxlIllEAgEOo9ojuw8EqVVpY0maw8qH9Qte/gAZYqyJ/oOqsnEMthL7eEgc+A2e5k9yqvKcfjm4UbPd7d1b5Y4CDE0SgLNSVWRZtHn9B2afTs/zbp/Lk+36GWrk0CaHEL0VVpVinsl9+psKdkpjd62yy3PRdj+sGaNRwABrCXWsLKwangTW+lULzU3FW8ceaPR67475F10dOyI0qpSlFaVoqSqhPu5sa1CWQEAUKqVXFLVXIQCIWwkNrAQWiC/Ir/eetUjmjaxzbN+no3ERmsS5yCttV/z+KP69jL7eh9LUalV8Nnog8ziTK0JrQACtLdrj8EdBjfL5yDE0CgJNBfZJ4HkV4HyvwAIAL83gZ7vAuKWf58lLRNjnAy5JEmFogJZpVlaE7yaW0lVyRNdp4tTF3Sw79B40lZjs7aoP3lr7luqA70GYvWZ1Y0mHQsHLWxy36jUKp0TRl0TzOoRuepn7PQhgAD2MvsnSuLET7BiQUNEQhE2jtqIF/e9CAEEvD4RQNPvG0ZtaBPPZxKiC0oCTZ2iFEh5G7j5iWbfppNm9M+19f5PlmYIG5+WWpKkSlWF7NLsRpO7woeFOrdpK7GFh60Ht3naeqJMUYa4X+IaPXfr2K141ufZJn+eltYaSYdIKNIkXTL7J463mpqpUa4o1ySNlSVIvJXILZ/SkB+m/IAxXcYY9XvEJwRMwIFJB7T+fmwYtcEoJrgQ0lwoCTRl908DyTOA0nTNfpfZmvf+WrTuK41orUDj0pQH+JVqJe6X3W80uWtokkNtMrEMnraevASv9uZu4w5bqW2dc1VqFb5L+84kbtu1xaSj+jawjcQGbjZu6OTYCStPr2y0P0Y/NdqoE8BqEwImYJzfOFq8m5g8SgJNkbIc+G0pkLYRAAOsOgBP7wDchhkknC7OmncN55XnoaCiAE6WTgaJo7mY6jpo1WUzvpuBY38c443o5ZTlQM3UOl3DQmjRYGJXvdlL7Zt8a9XUbtu19aTD1PoD0HwmYx5FJqQ5UBJoanKTgOQIoOTRqFvnfwB91gEWdgYLyUZiA09bT2SWZOJm/k30b9/fYLE8KWNcB61KVcU98F9YUaj582Gh1rL0wvRGJ1QUVxZj26/b6pQLBUK42bhxt2TrS+6cLJ1aZbSnLY6gNaStJx2m1h+EmANKAk2F6iFwOQa4/iHA1IClB9D/U8BjtKEjA6C5JZxZkom0/LQ2mwS21DpoaqZGSWVJg8kb78+KGnUeFqJcUd5cH5EzwX8CRnQewUvuXK1djW4kp3oE7cf0HxH/UzxGDxrdpkZmTQ31ByFtCyWBpiD/ApAcDhRd0+x3fAUI2gBIHA0aVk2+zr748daPbfa5QF3WQZsbPxd+zn7cGwlqJ228BK/GsaLKIp1vtTbETmoHR5kjHGQOcLR05GZVcmUyR2SVZCH2bGyjbc3tP7fNjEqJhCKEeIeg7GoZQrxDKOEwMOoPQtoOSgLbMlUV8Psq4FoswFSATA70+y/QfpyhI6ujrS0TU6GoQE5ZDnJKc5Bdmo1Tt081eBuVgeFeyT10/6R7k68pFUm55I2XzD1aNkPrsRrLZ+jyj61KrcLuK7tNYkIFIYSQJ0NJYFtV+BuQFA48+E2z32Ey0PdjQOZi2Ljq0dmxMwAg+W4yEm8lGuShd4VKgftl95FTpknsskuzuSQvu4y/X1RZ1KRrWFtYQ24j1zoKV+8I3aOy1nivsik+wE8IIaRpKAk0VpeXAwIREPgOv1ytBH4cCeQkAlADUmfgb58AHSa2fow6Oph6EJFHIwEAfxX/hSE7hzTbZAo1UyO/PP9xUlcjwau9n1eep1fbUpEUbjZucLNxg1goxtm/zjZ6zuGph43+Nio9wE8IIU8uLi4OH3zwAbKzs9GzZ09s2rQJ/fr1M3RYeqEk0FgJRMCVaM3P/os0fxZfA06P0bzzFwDav6BJAC3lholRB02ZTMEYQ1FlEX+krp4k737ZfaiYSud4RAIR5DZyyK3lXIJXvdUus5PacUuYmNrrpNr6kiSEEGJIe/fuRVRUFLZs2YL+/ftjw4YNGDlyJNLS0uDq6mro8HRGSaCxqh4BvBINoUqJp6puQ3z8C82zf0KZZuavz1SgGV9h1dx0XZMu/mY87pff5yV9lapKva7lYuVSbzJXs8zZyrlJy5eY4m3Utr4kCSGEGMr69esxa9YszJgxAwCwZcsWHDlyBDt27MCiRYsMHJ3uKAk0ZoHvAEwF0e8r0K26zLYLMCwRsPIwXFw6OnPnjE5r0n166VOtx+yl9pDb1EjorN34+4+2dlbtYCGyaImPwEO3UQkhxLSVlJSguPjx+7ClUimkUimvTlVVFS5evIjFixdzZUKhEKGhoUhKSmq1WJsDJYHGrsdysKurIWAqMIEYgr+nGfXoX01ZJVk61QsLCMPwTsN5CZ7cWg5LC8sWjlB/tA4aIYSYrq5du/L2Y2JisHz5cl5ZXl4eVCoV5HL+o1hyuRzXr19v6RCbFSWBxu7KKgiYCmqIIWRK4PfVdSeLGCl3W3ed6s3pN6dN3ZakddAIIcQ0Xbt2DZ6entx+7VFAU0NJoDG7sgq4Eg1VtxgcvtUbf/e5BFH1ZJE2kAgO7jAY7e3am8xkCkIIIabN1tYWdnYNv2bVxcUFIpEIOTk5vPKcnBy4ubm1ZHjNruVf8Ema5lECiMCVUHddCgCaPwNXasqvrDJwgI2rnkwBPJ48Ua2tTqYghBBi3iQSCYKCgpCQkMCVqdVqJCQkIDg42ICR6Y+SQGPFVJqEr/aIX+A7mnI9lkUxpOrJFJ52nrzy9nbtm/yuXUIIIcSQoqKisG3bNuzcuROpqan45z//ibKyMm62cFtBt4ONVY/l9R9rA7eCa6I16QghhJiSyZMnIzc3F9HR0cjOzkavXr1w7NixOpNFjB0lgaRV0Jp0hBBCTMmcOXMwZ84cQ4fxROh2MCGEEEKIGaIkkBBCCCHEDFESSAghhBBihigJJIQQQggxQ5QEEkIIIYSYIUoCCSGEEELMECWBhBBCCCFmiJJAQgghhBAzREkgIYQQQogZojeGNCO1Wg0AyMrKatZ2lUol8vLykJmZCbGYuswYUJ8YF+oP40L9YVyoPxpX/e929b/j5oL+NjSjnJwcAEC/fv0MHAkhhBBC9JWTk4MOHToYOoxWI2CMMUMHYSqUSiUuXboEuVwOobD57rSXlJSga9euuHbtGmxtbZutXdJ01CfGhfrDuFB/GBfqj8ap1Wrk5OSgd+/eZjVaSklgG1BcXAx7e3sUFRXBzs7O0OEQUJ8YG+oP40L9YVyoP0h9aGIIIYQQQogZoiSQEEIIIcQMURLYBkilUsTExEAqlRo6FPII9Ylxof4wLtQfxoX6g9SHngkkhBBCCDFDNBJICCGEEGKGKAkkhBBCCDFDlAQSQgghhJghSgIJIYQQQswQJYFGIi4uDj4+PpDJZOjfvz9+/vnnBuvv378f/v7+kMlkCAwMxNGjR1spUvOgT39s27YNgwcPhqOjIxwdHREaGtpo/xH96fs7Um3Pnj0QCAQYP358ywZoZvTtjwcPHiAyMhLu7u6QSqXw9fWl/241I337Y8OGDfDz84OlpSW8vLwwf/58PHz4sJWiJUaDEYPbs2cPk0gkbMeOHezq1ats1qxZzMHBgeXk5Gitf/bsWSYSidjatWvZtWvX2LJly5iFhQW7cuVKK0dumvTtj6lTp7K4uDh26dIllpqayiIiIpi9vT27e/duK0duuvTtk2oZGRnM09OTDR48mI0bN651gjUD+vZHZWUl69u3LxszZgz76aefWEZGBktMTGQpKSmtHLlp0rc/vvzySyaVStmXX37JMjIy2P/+9z/m7u7O5s+f38qRE0OjJNAI9OvXj0VGRnL7KpWKeXh4sNjYWK31J02axJ577jleWf/+/dnrr7/eonGaC337ozalUslsbW3Zzp07WypEs9OUPlEqlWzAgAHs008/ZeHh4ZQENiN9++OTTz5hnTp1YlVVVa0VolnRtz8iIyPZ0KFDeWVRUVFs4MCBLRonMT50O9jAqqqqcPHiRYSGhnJlQqEQoaGhSEpK0npOUlISrz4AjBw5st76RHdN6Y/aysvLoVAo4OTk1FJhmpWm9snKlSvh6uqKmTNntkaYZqMp/fH9998jODgYkZGRkMvl6N69O9asWQOVStVaYZuspvTHgAEDcPHiRe6WcXp6Oo4ePYoxY8a0SszEeIgNHYC5y8vLg0qlglwu55XL5XJcv35d6znZ2dla62dnZ7dYnOaiKf1R28KFC+Hh4VEnUSdN05Q++emnn7B9+3akpKS0QoTmpSn9kZ6ejv/7v//Dyy+/jKNHj+KPP/7A7NmzoVAoEBMT0xphm6ym9MfUqVORl5eHQYMGgTEGpVKJN954A0uWLGmNkIkRoZFAQprRe++9hz179uDbb7+FTCYzdDhmqaSkBNOnT8e2bdvg4uJi6HAIALVaDVdXV2zduhVBQUGYPHkyli5dii1bthg6NLOUmJiINWvWYPPmzfj1119x8OBBHDlyBKtWrTJ0aKSV0Uiggbm4uEAkEiEnJ4dXnpOTAzc3N63nuLm56VWf6K4p/VHtww8/xHvvvYeTJ0+iR48eLRmmWdG3T/7880/cunULY8eO5crUajUAQCwWIy0tDZ07d27ZoE1YU35H3N3dYWFhAZFIxJUFBAQgOzsbVVVVkEgkLRqzKWtKf7zzzjuYPn06/vGPfwAAAgMDUVZWhtdeew1Lly6FUEjjQ+aCetrAJBIJgoKCkJCQwJWp1WokJCQgODhY6znBwcG8+gBw4sSJeusT3TWlPwBg7dq1WLVqFY4dO4a+ffu2RqhmQ98+8ff3x5UrV5CSksJtzz//PIYMGYKUlBR4eXm1Zvgmpym/IwMHDsQff/zBJeMAcOPGDbi7u1MC+ISa0h/l5eV1Er3qBJ0x1nLBEuNj6JkpRDO9XyqVss8//5xdu3aNvfbaa8zBwYFlZ2czxhibPn06W7RoEVf/7NmzTCwWsw8//JClpqaymJgYWiKmGenbH++99x6TSCTswIEDLCsri9tKSkoM9RFMjr59UhvNDm5e+vbHnTt3mK2tLZszZw5LS0tjhw8fZq6urmz16tWG+ggmRd/+iImJYba2tuzrr79m6enp7Pjx46xz585s0qRJhvoIxEAoCTQSmzZtYh06dGASiYT169ePJScnc8dCQkJYeHg4r/6+ffuYr68vk0gkrFu3buzIkSOtHLFp06c/vL29GYA6W0xMTOsHbsL0/R2piZLA5qdvf5w7d47179+fSaVS1qlTJ/buu+8ypVLZylGbLn36Q6FQsOXLl7POnTszmUzGvLy82OzZs1lhYWHrB04MSsAYjf0SQgghhJgbeiaQEEIIIcQMURJICCGEEGKGKAkkhBBCCDFDlAQSQgghhJghSgIJIYQQQswQJYGEEEIIIWaIkkBCCCGEEDNESSAhhBBCiBmiJJAQMyIQCLjt888/N3Q4eouIiODif/bZZ1v0WomJibzv69atWzqd9/nnn/POM0Y+Pj5cfMuXLzd0OIQQA6EkkJA2puY/4LpuiYmJhg6b1GPPnj28vtq3b1+9dVesWMGr+9tvv7VipIQQU0NJICGEGND48ePh4ODA7e/evbveul988QX3c69evdCzZ8+WDI0QYuLEhg6AEKKfpUuXoqioiNsvLCzEmjVruP3hw4djxIgRvHM6d+7cYvEUFxfDzs6uxdo3dTKZDJMnT8Z///tfAMCxY8eQm5uLdu3a8eqdO3cOf/zxB7cfERHRmmESQkwQjQQS0sbMmjULCxYs4LZZs2bxjg8YMIB3fMGCBfDy8tLa1unTpzFs2DDY2trC1tYWo0ePxtWrV3l1bt26VefW8vbt29GnTx9YWlrimWee4dX/4YcfMG7cOLi7u0MikcDR0RFDhw7Fl19+CcZYnRjOnDmDF154AZ6enpBIJLCxsYGPjw9Gjx6N5cuX8xLe2vLy8jB79mx4eHhAKpUiICAA27Zt01q3oqICH330EQYOHAhHR0dIJBLI5XKMGTOmwVuw9bl9+zamTJkCJycnWFtb45lnnsHJkyf1bgcAZsyYwf2sVCrx9ddf16lTc4TQwsICL7/8MgBgx44dmDRpEgICAuDi4gILCwvY2dmhV69eWLhwIfLy8nSOo7HnGRt7pvTMmTN46aWX0KFDB0ilUtjZ2SE4OBhxcXFQKBR16l+5cgXTpk2Dj48PpFIpLC0t0aFDBwwdOhSLFy9GZmamzrETQpqAEULatIyMDAaA22JiYuqtW7Pe8OHDmVAo5JUBYM7Ozuz+/fv1tj948GDefs+ePRljjKlUKjZ9+vQ67dXcJk6cyJRKJdf2yZMnmUgkavCc1NRUrn54eDhX7ufnx3x8fLSes337dt7nzsrKYt26dWvwOmFhYUyhUHDn/Pjjj7zjGRkZvO/Ezc2tThsCgYCNGTOGV6argIAA7py+ffvyjlVWVjInJyfu+AsvvMAdCwoKavBzeXp6sszMTF573t7eWv++fPbZZw3GXvPYZ599xju2ZMmSBuMYPHgwKy0t5epfvXqVWVlZNXhOfHy8zt8fIUR/dDuYEDN14sQJ+Pv7Y8KECUhJScHRo0cBAPn5+di+fTsWLVqk9bwzZ87A29sbYWFhsLKywv379wEAa9eu5UarBAIBwsLC0LNnT2RkZGD37t1QKBTYv38/evXqhSVLlgAAtm7dCpVKBQDw9/fHxIkTIRaLcefOHaSkpODXX3+tN/60tDTIZDL885//hKWlJT755BNUVFRwsbz66qtc3Zdffpk3wvniiy+ia9euOHHiBJKSkgAA33zzDdasWYPo6OhGv7s5c+YgOzub2x87dix69+6N+Ph47nvUV3h4OPedX7hwAampqQgICAAAHD58GAUFBVzdmreCXV1dMXbsWHTu3BlOTk4QiUTIzMzE3r17kZ+fj8zMTKxevRqbN29uUly62LNnD++RhJEjR2LgwIHIycnBzp07UVpaijNnzmD+/PnYunUrAGDnzp0oLy8HALRv3x7Tpk2DtbU17t69i99//x3JycktFi8h5BFDZ6GEkCfT1JFALy8vVlxczB3r3bs3d2zChAn1tt+xY0dWWFjIa1elUjEXFxeuTnR0NO/42rVreSONKpWKMcbY888/z5V//fXXdeLNyspiZWVl3H7NkUAA7NChQ9yxDRs28I5Vf7ZLly7xyt9++23uHKVSyYKDg7ljTk5OXGz1jQTeu3ePCQQCrnzatGlce1VVVXVGHHWVmZnJGxVdvHgxd2z8+PFcuaurK2/EkjHGysrK2MmTJ9nWrVvZ+vXr2QcffMDGjRvHndOpUyde/eYeCaz5d+eVV17hnbNv3z7umFgsZvn5+Ywxxv71r39x5bGxsXWuVVBQwAoKCnT+/ggh+qNnAgkxU9OnT4etrS237+vry/1cWFhY73mRkZG82ayAZlSu5rNnK1eu5D0/9vbbb3PH8vPzcePGDQDA4MGDufKIiAgMGTIEr7/+OtavX4/z589DLpfDyspKaxweHh4YN24ct+/n58c7Xv0Zqkf6qoWHh3M/i0QiTJs2jdsvKChAWlpavZ8dAC5evMh7trH62TxA86zepEmTGjy/Ph4eHrwJPdXPUBYUFPBGF6dNmwax+PFNnPXr10MulyM0NBSvvfYaoqKi8NZbb+G7777j6ty9e7dJMemivLwcKSkp3P6uXbt4fV/z+1Aqlfj5558B8Pt+2bJlGDBgAF599VW8//77SExMhJ2dHRwdHVssbkIIzQ4mxGz5+Pjw9qVSKfezWq2u9zx/f/86ZTVvVeoiNzcX/v7+ePPNN3H58mV89dVXqKysRGJiIm9Nw+7du+P48eNwd3fXK/6an6F2bHK5vMH9hhJgAHjw4AFv39XVtcH29BEREYH4+HgAwJ07d5CYmIjU1FRUVVXx6lQ7dOgQ/v3vfzfabs3z9cEY4yaIVFZWaq1TWFiodcJPfXJzcwFobskvWLAAmzZtQmVlJZKSkngJu7e3N44cOYJu3bo1KXZCSOMoCSTETFlYWPD2dX27hbW1dZ0yJycn3n54eDi6d+9ebxvVCZxYLMauXbuwbt06nDt3DmlpaUhLS8O3336LwsJC/P7771i0aBF27tzZ5Phrx5aTkwNnZ2fefk2NjT7VHgWtfiayvvb0MW7cODg6OnKJ6O7du5Gamsod79OnDwIDA7n9vXv3cj/b2Njg4MGDGDx4MGQyGTZv3ozIyEi9ri8U8m8OVVRUcCOxN2/e1HpO7e/j+eef543y1danTx/u5w8++ADLli3DuXPncP36ddy4cQPff/897t27h9u3b2P27Nk4deqUXp+BEKI7SgIJIU/Mz88Pzs7OyM/PB6BJHhYsWFCn3v3793H27FluyZq0tDR4eXmhXbt2vFu73bt3R1RUFAA0ODlEFwMGDODt79y5E++//z4AQKVS8RZgdnJyqnNbubY+ffpAIBBwo19ffvklRo0aBQBQKBRNWm6mmlQqxZQpU7hJHHv27OEmuwD8pWQAcN83AHTq1AnDhw8HoBkFPXDggN7Xr53QJScnY+jQoVCr1YiNjdV6jrW1NXr16sXdEs7Pz8e8efPqJOlFRUWIj4/nRvYyMjLg6OgIBwcHjB49GqNHjwYAjBgxAhMmTADw5H1PCGkYJYGEkCcmFAoRFRWFpUuXAgD27duH9PR0DB8+HLa2tsjOzsaFCxdw/vx5DBo0CC+88AIA4KOPPsLu3bsxbNgwdOzYEXK5HAUFBdi1axfXdu3ERF89e/bEsGHDkJCQAEAzczg9PR3dunXD8ePHebcg582bV2c0rDYPDw+MHj2ae07viy++QHFxMXr16oX4+Pg66yzqKyIigksCayaAEokEU6dO5dX18/PDiRMnAACXL1/GlClTEBAQgPj4+CbNrg0KCuIluBMmTMCIESOQlpaGy5cv13veW2+9xT0befbsWfTo0QNjx46Fo6Mj8vPzcenSJfz0009wd3fHSy+9BEAzihkTE4Nnn30WXbp0gbu7O8rKynhrJD5p3xNCGmHIWSmEkCfX1NnBtdd5qznzNiQkpN72f/zxR61t67JOYO22X3/99QbrCoVC9u233zYaI2MNr+uXlZXFunbt2uC19FknMD09nbm6utb7+WruN4W2NQ3DwsLq1Lt58yaztbWtU1csFrOXX3653jjqmx3MGGPTpk3T+rlqr39Y++/P4sWLG+17b29vrn5sbGyj9f/zn/806fsjhOiGZgcTQpqFUCjErl27cOTIEYSFhaF9+/aQSCSQSqXw9vbG2LFjsWHDBt5Iz8yZM7Fw4UI888wz8PLygkwmg0QigZeXFyZOnIhTp05h/PjxTxybm5sbfvnlF6xbtw7BwcGwt7eHWCxGu3btMGrUKOzZswcHDhzgzbptSMeOHZGcnIxJkybBwcEBlpaWCA4Oxg8//NAsr3PT1oa2sqeeegqnT5/GiBEjYGVlBRsbG4SEhCAhIQGhoaFNuvann36KBQsWcG9w8fX1xdq1a3mzjbVZs2YNzp49i2nTpqFjx46QSqWwsLCAp6cnRowYgTVr1nCjsYDmncnR0dEIDQ2Fj48PrKysIBaL4e7ujueeew7ff/895s6d26TPQAjRjYAxPaZ1EUIIIYQQk0AjgYQQQgghZoiSQEIIIYQQM0RJICGEEEKIGaIkkBBCCCHEDFESSAghhBBihigJJIQQQggxQ5QEEkIIIYSYIUoCCSGEEELMECWBhBBCCCFmiJJAQgghhBAzREkgIYQQQogZoiSQEEIIIcQM/T8lsh3DpEUoiAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-02-01 12:31:41,560 E 38235 38235] (raylet) node_manager.cc:3097: 1 Workers (tasks / actors) killed due to memory pressure (OOM), 0 Workers crashed due to other reasons at node (ID: 7e8848a3d8041b6df27e0004bdf18a201f5eea8aa0b92c438a1b7202, IP: 137.43.23.126) over the last time period. To see more information about the Workers killed on this node, use `ray logs raylet.out -ip 137.43.23.126`\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m Refer to the documentation on how to address the out of memory issue: https://docs.ray.io/en/latest/ray-core/scheduling/ray-oom-prevention.html. Consider provisioning more memory on this node or reducing task parallelism by requesting more CPUs per task. To adjust the kill threshold, set the environment variable `RAY_memory_usage_threshold` when starting Ray. To disable worker killing, set the environment variable `RAY_memory_monitor_refresh_ms` to zero.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-02-01 12:32:41,561 E 38235 38235] (raylet) node_manager.cc:3097: 1 Workers (tasks / actors) killed due to memory pressure (OOM), 0 Workers crashed due to other reasons at node (ID: 7e8848a3d8041b6df27e0004bdf18a201f5eea8aa0b92c438a1b7202, IP: 137.43.23.126) over the last time period. To see more information about the Workers killed on this node, use `ray logs raylet.out -ip 137.43.23.126`\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m Refer to the documentation on how to address the out of memory issue: https://docs.ray.io/en/latest/ray-core/scheduling/ray-oom-prevention.html. Consider provisioning more memory on this node or reducing task parallelism by requesting more CPUs per task. To adjust the kill threshold, set the environment variable `RAY_memory_usage_threshold` when starting Ray. To disable worker killing, set the environment variable `RAY_memory_monitor_refresh_ms` to zero.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-02-01 12:33:41,562 E 38235 38235] (raylet) node_manager.cc:3097: 1 Workers (tasks / actors) killed due to memory pressure (OOM), 0 Workers crashed due to other reasons at node (ID: 7e8848a3d8041b6df27e0004bdf18a201f5eea8aa0b92c438a1b7202, IP: 137.43.23.126) over the last time period. To see more information about the Workers killed on this node, use `ray logs raylet.out -ip 137.43.23.126`\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m Refer to the documentation on how to address the out of memory issue: https://docs.ray.io/en/latest/ray-core/scheduling/ray-oom-prevention.html. Consider provisioning more memory on this node or reducing task parallelism by requesting more CPUs per task. To adjust the kill threshold, set the environment variable `RAY_memory_usage_threshold` when starting Ray. To disable worker killing, set the environment variable `RAY_memory_monitor_refresh_ms` to zero.\n"
     ]
    }
   ],
   "source": [
    "# create figure and axis objects with subplots()\n",
    "fig, ax = plt.subplots()\n",
    "plt.grid()\n",
    "# make a plot\n",
    "ax.plot(df['Threshold'].values, \n",
    "        df['GPFL Loss'].values, \n",
    "        color=\"green\", \n",
    "        label='Loss of GPFL', \n",
    "        marker=\"o\")\n",
    "\n",
    "ax.plot(df['Threshold'].values, \n",
    "        df['SFL Loss'], \n",
    "        color=\"red\", \n",
    "        label='S-FL Loss',\n",
    "        marker=\"o\")\n",
    "\n",
    "plt.legend(framealpha=1, frameon=True, bbox_to_anchor=(0.31, 1.2));\n",
    "\n",
    "# set x-axis label\n",
    "ax.set_xlabel(\"Threshold Values\", fontweight='bold', fontsize = 14)\n",
    "# set y-axis label\n",
    "ax.set_ylabel(\"Loss\", color=\"black\", fontweight='bold', fontsize=14)\n",
    "\n",
    "# twin object for two different y-axis on the sample plot\n",
    "ax2=ax.twinx()\n",
    "# make a plot with different y-axis using second axis object\n",
    "ax2.plot(df['Threshold'].values, \n",
    "         df['Global Sparsity'].values, \n",
    "         label='Global Sparsity', \n",
    "         color=\"orange\", \n",
    "         marker=\"x\")\n",
    "ax2.set_ylabel(\"Global Sparsity\",color=\"black\", fontweight='bold', fontsize=14)\n",
    "\n",
    "plt.legend(framealpha=1, frameon=True, bbox_to_anchor=(1.015, 1.15));\n",
    "plt.show()\n",
    "# save the plot as a file\n",
    "fig.savefig('Loss&Global_Sparsity vs Threshold with S-FL.jpg', \n",
    "            format='jpeg', dpi=100, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80f572ef-7973-4e3b-abb2-87225ad378c2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d956bd0e-cede-4321-9737-3269561fd563",
   "metadata": {},
   "outputs": [],
   "source": [
    "import this"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab6322f2-2326-4e12-ad4d-d93c5e4195dc",
   "metadata": {
    "tags": []
   },
   "source": [
    "# What is this code doing?\n",
    "\n",
    "* Divides dataset to 10 category in simulation.\n",
    "\n",
    "* Trains GM.\n",
    "\n",
    "* Prunes GM & Show Results.\n",
    "\n",
    "* Shows participation & global sparsity results.\n",
    "\n",
    "* Use standart Federated Learning as baseline.\n",
    "\n",
    "***\n",
    "### Core contributions:\n",
    "\n",
    "* Pruning increase model sparsification significantly while still preserve a good performance. \n",
    "\n",
    "* Thus, to use in Federated Learning system, a group of talented devices in terms of hardware can train a dense model and then gradually rise sparsification threshold of model to assign them as proper initial global model for model contrainted devices. \n",
    "\n",
    "* As a result, those assigned proper models own tuned parameters from previous training, which act as transfer learning and increase model generality (1). Moreover, number of devices participate to Federated Learning system is increased by using a trainable model (2).\n",
    "\n",
    "* Beside, our model works with quantisation method as well, by representing 32 float bits with smaller integer bits. Thus, reduce training time and communication overhead.\n",
    "\n",
    "* Furthermore, since each device trains their proper model, syncronisation during training is also rises."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4658837d-e2c6-4693-a488-651412c21567",
   "metadata": {},
   "source": [
    "***\n",
    "# Install Necessary Libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b630a16-e062-401e-8d5a-079c1be0543b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -U flwr[\"simulation\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13547627-a2d8-4b63-bb1a-7dcb3602c186",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -U flwr==0.19.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bde9371e-369b-4a1a-a90e-8fed66b4e1b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install torch==1.13.1 torchvision==0.14.1 numpy==1.24.1 pandas==1.5.3 matplotlib==3.6.3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51703fc2-8ae8-4a24-b6c6-fba7121e65e3",
   "metadata": {},
   "source": [
    "***\n",
    "## 1- Importing Libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "59fcc7f0-1a62-4dbb-8e76-929e67be4236",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on cpu\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torchvision.datasets import CIFAR10\n",
    "import torchvision.models as models\n",
    "import torchvision\n",
    "\n",
    "import torch.nn.utils.prune as prune\n",
    "\n",
    "\n",
    "import flwr as fl\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from collections import OrderedDict\n",
    "from typing import Dict, List, Optional, Tuple\n",
    "import json\n",
    "import os\n",
    "\n",
    "DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Training on {DEVICE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "40197165-b7be-4702-ae74-79312022098e",
   "metadata": {},
   "outputs": [],
   "source": [
    "(fl.__version__, torch.__version__, torchvision.__version__, np.__version__, pd.__version__,\n",
    "json.__version__, matplotlib.__version__)\n",
    "\n",
    "library_versions = {\"flwr\": fl.__version__, \"torch\": torch.__version__, \n",
    "                    \"torchvision\": torchvision.__version__, \"numpy\": np.__version__, \n",
    "                    \"pandas\": pd.__version__, \"json\": json.__version__, \n",
    "                    \"matplotlib\": matplotlib.__version__}\n",
    "\n",
    "with open('library_versions.txt', 'w') as f:\n",
    "    f.write(json.dumps(library_versions))\n",
    "\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4c8301b-fe3c-41e1-8128-7e8058dc47f4",
   "metadata": {},
   "source": [
    "***\n",
    "## 2- Initilisation/Hyperparameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "589ffaf0-468a-4b82-a827-03013b9fdd85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total number of devices (For D1 devices):\n",
    "NUM_DEVICES = 100\n",
    "\n",
    "# Model aggregation (Training round):\n",
    "NUM_ROUNDS = 100\n",
    "\n",
    "# On device local updates:\n",
    "LOCAL_EPOCH = 3\n",
    "\n",
    "# You may need to decrease it since total image per device is 60.\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "# D1, D2, D3, ... , D10:\n",
    "NUM_DEVICE_TYPE = 10\n",
    "\n",
    "hyperparameters = {'NUM_DEVICES': NUM_DEVICES,\n",
    "                   'NUM_ROUNDS': NUM_ROUNDS,\n",
    "                   'NUM_DEVICE_TYPE': NUM_DEVICE_TYPE,\n",
    "                   'BATCH_SIZE': BATCH_SIZE,\n",
    "                   'LOCAL_EPOCH': LOCAL_EPOCH}\n",
    "\n",
    "with open('hyperparameters.txt', 'w') as f:\n",
    "    f.write(json.dumps(hyperparameters))\n",
    "\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "181048bd-67d0-417b-87a2-10bd8517bb60",
   "metadata": {},
   "source": [
    "***\n",
    "## 3- Load Datasets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c85638ba-9a0c-4df3-a874-77fbc5607a79",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_datasets(num_clients: int):\n",
    "    \n",
    "    \n",
    "    # ######################## Test Dataset Preparetion #########################\n",
    "    testset = torchvision.datasets.FashionMNIST(\"./data\", \n",
    "                                         train = False, \n",
    "                                         transform = transforms.Compose([transforms.Resize((32,32)),\n",
    "                                                                         transforms.ToTensor(),\n",
    "                                                                         transforms.Normalize(mean = (0.1325,), \n",
    "                                                                                              std = (0.3105,))]),\n",
    "                                         download=True)\n",
    "    \n",
    "    testloader = DataLoader(testset, batch_size=BATCH_SIZE)\n",
    "    \n",
    "    \n",
    "    # #################### Train and Val Datasets Preparetion ####################\n",
    "    trainset = torchvision.datasets.FashionMNIST(\"./data\", \n",
    "                                          train = True, \n",
    "                                          transform = transforms.Compose([transforms.Resize((32,32)),\n",
    "                                                                          transforms.ToTensor(),\n",
    "                                                                          transforms.Normalize(mean = (0.1307,), \n",
    "                                                                                               std = (0.3081,))]),\n",
    "                                          download=True)\n",
    "    \n",
    "    plan = num_clients * NUM_DEVICE_TYPE\n",
    "    partition_size = len(trainset) // plan\n",
    "    lengths = [partition_size] * plan\n",
    "    # plan = num_clients * 2\n",
    "    # partition_size = len(trainset) // plan\n",
    "    # lengths = [partition_size] * plan\n",
    "    # partition_size = len(trainset) // num_clients\n",
    "    # lengths = [partition_size] * num_clients\n",
    "    \n",
    "    datasets = random_split(trainset, lengths, torch.Generator().manual_seed(42))\n",
    "\n",
    "    \n",
    "    trainloaders_1, valloaders_1 = [], []\n",
    "    trainloaders_2, valloaders_2 = [], []\n",
    "    trainloaders_3, valloaders_3 = [], []\n",
    "    trainloaders_4, valloaders_4 = [], []\n",
    "    trainloaders_5, valloaders_5 = [], []\n",
    "    trainloaders_6, valloaders_6 = [], []\n",
    "    trainloaders_7, valloaders_7 = [], []\n",
    "    trainloaders_8, valloaders_8 = [], []\n",
    "    trainloaders_9, valloaders_9 = [], []\n",
    "    trainloaders_10, valloaders_10 = [], []\n",
    "\n",
    "    \n",
    "    # The amount of data should be shared per device class (D1, D2, ... , D10):\n",
    "    amount = (len(datasets) // NUM_DEVICE_TYPE)\n",
    "    \n",
    "    # Sharing dataset to devices:\n",
    "    for i, ds in enumerate(datasets):\n",
    "        len_val = len(ds) // 10  \n",
    "        len_train = len(ds) - len_val\n",
    "        lengths = [len_train, len_val]\n",
    "\n",
    "        ds_train, ds_val = random_split(ds, lengths, torch.Generator().manual_seed(42))\n",
    "\n",
    "        # D1 devices:\n",
    "        if (amount*0 <= i) and (i < amount*1):\n",
    "            trainloaders_1.append(DataLoader(ds_train, batch_size=BATCH_SIZE, shuffle=True))\n",
    "            valloaders_1.append(DataLoader(ds_val, batch_size=BATCH_SIZE))\n",
    "\n",
    "        # D2 devices:\n",
    "        elif (amount*1 <= i) and (i < amount*2):\n",
    "            trainloaders_2.append(DataLoader(ds_train, batch_size=BATCH_SIZE, shuffle=True))\n",
    "            valloaders_2.append(DataLoader(ds_val, batch_size=BATCH_SIZE))\n",
    "\n",
    "        # D3 devices:\n",
    "        elif (amount*2 <= i) and (i < amount*3):\n",
    "            trainloaders_3.append(DataLoader(ds_train, batch_size=BATCH_SIZE, shuffle=True))\n",
    "            valloaders_3.append(DataLoader(ds_val, batch_size=BATCH_SIZE))\n",
    "\n",
    "        # D4 devices:    \n",
    "        elif (amount*3 <= i) and (i < amount*4):\n",
    "            trainloaders_4.append(DataLoader(ds_train, batch_size=BATCH_SIZE, shuffle=True))\n",
    "            valloaders_4.append(DataLoader(ds_val, batch_size=BATCH_SIZE))\n",
    "\n",
    "        # D5 devices:\n",
    "        elif (amount*4 <= i) and (i < amount*5):\n",
    "            trainloaders_5.append(DataLoader(ds_train, batch_size=BATCH_SIZE, shuffle=True))\n",
    "            valloaders_5.append(DataLoader(ds_val, batch_size=BATCH_SIZE))\n",
    "\n",
    "        # D6 devices:\n",
    "        elif (amount*5 <= i) and (i < amount*6):\n",
    "            trainloaders_6.append(DataLoader(ds_train, batch_size=BATCH_SIZE, shuffle=True))\n",
    "            valloaders_6.append(DataLoader(ds_val, batch_size=BATCH_SIZE))\n",
    "\n",
    "        # D7 devices:\n",
    "        elif (amount*6 <= i) and (i < amount*7):\n",
    "            trainloaders_7.append(DataLoader(ds_train, batch_size=BATCH_SIZE, shuffle=True))\n",
    "            valloaders_7.append(DataLoader(ds_val, batch_size=BATCH_SIZE))\n",
    "\n",
    "        # D8 devices:    \n",
    "        elif (amount*7 <= i) and (i < amount*8):\n",
    "            trainloaders_8.append(DataLoader(ds_train, batch_size=BATCH_SIZE, shuffle=True))\n",
    "            valloaders_8.append(DataLoader(ds_val, batch_size=BATCH_SIZE))\n",
    "\n",
    "        # D9 devices:   \n",
    "        elif (amount*8 <= i) and (i < amount*9):\n",
    "            trainloaders_9.append(DataLoader(ds_train, batch_size=BATCH_SIZE, shuffle=True))\n",
    "            valloaders_9.append(DataLoader(ds_val, batch_size=BATCH_SIZE))\n",
    "\n",
    "        # D10 devices:\n",
    "        elif (amount*9 <= i) and (i < amount*10):\n",
    "            trainloaders_10.append(DataLoader(ds_train, batch_size=BATCH_SIZE, shuffle=True))\n",
    "            valloaders_10.append(DataLoader(ds_val, batch_size=BATCH_SIZE))\n",
    "\n",
    "            \n",
    "    return (trainloaders_1, valloaders_1, trainloaders_2, valloaders_2, \n",
    "            trainloaders_3, valloaders_3, trainloaders_4, valloaders_4, \n",
    "            trainloaders_5, valloaders_5, trainloaders_6, valloaders_6, \n",
    "            trainloaders_7, valloaders_7, trainloaders_8, valloaders_8, \n",
    "            trainloaders_9, valloaders_9, trainloaders_10, valloaders_10,\n",
    "            testloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "85a63e33-6ee5-46c1-851e-5568847f92e5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to ./data/FashionMNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/FashionMNIST/raw/train-images-idx3-ubyte.gz to ./data/FashionMNIST/raw\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to ./data/FashionMNIST/raw/train-labels-idx1-ubyte.gz\n",
      "Extracting ./data/FashionMNIST/raw/train-labels-idx1-ubyte.gz to ./data/FashionMNIST/raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "6.7%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to ./data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n",
      "100.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz to ./data/FashionMNIST/raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to ./data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz\n",
      "Extracting ./data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/FashionMNIST/raw\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trainloaders_1, valloaders_1, trainloaders_2, valloaders_2, trainloaders_3, valloaders_3, trainloaders_4, valloaders_4, trainloaders_5, valloaders_5, trainloaders_6, valloaders_6, trainloaders_7, valloaders_7, trainloaders_8, valloaders_8, trainloaders_9, valloaders_9, trainloaders_10, valloaders_10, testloader = load_datasets(NUM_DEVICES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b381314b-4065-4097-8d30-f9836c030f06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# D1 devices are choosed to train:\n",
    "trainloaders = trainloaders_1\n",
    "valloaders = valloaders_1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcd3093f-d3ed-4c5b-b0dc-70aae2a00d71",
   "metadata": {},
   "source": [
    "***\n",
    "## 4- Flower Client to Simulate Devices:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "709858c8-73f7-4496-9735-fcd194b5b979",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FlowerClient(fl.client.NumPyClient):\n",
    "    def __init__(self, cid, net, trainloader, valloader):\n",
    "        self.cid = cid\n",
    "        self.net = net\n",
    "        self.trainloader = trainloader\n",
    "        self.valloader = valloader\n",
    "\n",
    "    def get_parameters(self):\n",
    "        print(f\"[Client {self.cid}] get_parameters\")\n",
    "        \n",
    "        return get_parameters(self.net)\n",
    "    \n",
    "    # Fit Function A:\n",
    "    # Configuration from client-side\n",
    "    # To make client-side execution (trainig, evaluation).\n",
    "    def fit(self, parameters, config):\n",
    "        print(f\"[Client {self.cid}] fit, config: {config}\")\n",
    "        set_parameters(self.net, parameters)\n",
    "        train(self.net, self.trainloader, epochs=1)\n",
    "        \n",
    "        return get_parameters(self.net), len(self.trainloader), {}\n",
    "    \n",
    "    \"\"\"\n",
    "    # Fit Function B:\n",
    "    # To make configuration values from the server to the clients using a dictionary.\n",
    "    def fit(self, parameters, config):\n",
    "        # Read values from config\n",
    "        current_round = config[\"current_round\"]\n",
    "        local_epochs = config[\"local_epochs\"]\n",
    "\n",
    "        # Use values provided by the config\n",
    "        print(f\"[Client {self.cid}, round {current_round}] fit, config: {config}\")\n",
    "        set_parameters(self.net, parameters)\n",
    "        train(self.net, self.trainloader, epochs=local_epochs)\n",
    "        return get_parameters(self.net), len(self.trainloader), {}\n",
    "    \"\"\"\n",
    "\n",
    "    # This function is included for case of client side (federated) evaluation is required to use.\n",
    "    def evaluate(self, parameters, config):\n",
    "        print(f\"[Client {self.cid}] evaluate, config: {config}\")\n",
    "        set_parameters(self.net, parameters)\n",
    "        loss, accuracy = test(self.net, self.valloader)\n",
    "        \n",
    "        return float(loss), len(self.valloader), {\"accuracy\": float(accuracy)}\n",
    "    \n",
    "\n",
    "def client_fn(cid) -> FlowerClient:\n",
    "    net = Net().to(DEVICE)\n",
    "    trainloader = trainloaders[int(cid)]\n",
    "    valloader = valloaders[int(cid)]\n",
    "    \n",
    "    return FlowerClient(cid, net, trainloader, valloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37d808e4-ddcc-4a5f-b9be-67e33c651527",
   "metadata": {},
   "source": [
    "***\n",
    "## 5- Model Preparetion:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "72628d2a-eeff-469a-b265-d701b6f71c42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LeNet:\n",
    "class Net(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        # 1 input image channel, 6 output channels, 5x5 square convolution\n",
    "        # kernel\n",
    "        self.conv1 = nn.Conv2d(1, 6, 5)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        # an affine operation: y = Wx + b\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)  # 5*5 from image dimension\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Max pooling over a (2, 2) window\n",
    "        x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2))\n",
    "        # If the size is a square, you can specify with a single number\n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)), 2)\n",
    "        x = torch.flatten(x, 1) # flatten all dimensions except the batch dimension\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d1124124-3d73-45a4-a0fb-7352579d6f4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_parameters(net) -> List[np.ndarray]:\n",
    "    return [val.cpu().numpy() for _, val in net.state_dict().items()]\n",
    "\n",
    "def set_parameters(net, parameters: List[np.ndarray]):\n",
    "    params_dict = zip(net.state_dict().keys(), parameters)\n",
    "    state_dict = OrderedDict({k: torch.tensor(v) for k, v in params_dict})\n",
    "    net.load_state_dict(state_dict, strict=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfab70d1-c956-4154-b902-17c0946bf0d5",
   "metadata": {},
   "source": [
    "***\n",
    "## 6- Train & Test Functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "94d1355a-e5b8-4943-9bdc-246b1ab3d8f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(net, trainloader, epochs: int):\n",
    "    \"\"\"Train the network on the training set.\"\"\"\n",
    "    \n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(net.parameters())\n",
    "    net.train()\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        correct, total, epoch_loss = 0, 0, 0.0\n",
    "        \n",
    "        for images, labels in trainloader:\n",
    "            images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = net(images)\n",
    "            loss = criterion(net(images), labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            # Metrics\n",
    "            epoch_loss += loss\n",
    "            total += labels.size(0)\n",
    "            correct += (torch.max(outputs.data, 1)[1] == labels).sum().item()\n",
    "        \n",
    "        epoch_loss /= len(testloader.dataset)\n",
    "        epoch_acc = correct / total\n",
    "        print(f\"Epoch {epoch+1}: train loss {epoch_loss}, accuracy {epoch_acc}\")\n",
    "\n",
    "\n",
    "        \n",
    "def test_model(net, testloader):\n",
    "    \"\"\"Evaluate the network on the entire test set.\"\"\"\n",
    "    \n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    correct, total, loss = 0, 0, 0.0\n",
    "    net.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, labels in testloader:\n",
    "            images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
    "            outputs = net(images)\n",
    "            loss += criterion(outputs, labels).item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    \n",
    "    loss /= len(testloader.dataset)\n",
    "    accuracy = correct / total\n",
    "    \n",
    "    \n",
    "    return [loss, accuracy]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b961cbad-4370-4e79-b714-c03965d3123f",
   "metadata": {},
   "source": [
    "***\n",
    "## 7- System Running (Training):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b20d4303-6db1-493f-8a99-31fc1169ea5c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-01 12:54:19,856\tINFO worker.py:1529 -- Started a local Ray instance. View the dashboard at \u001b[1m\u001b[32m127.0.0.1:8265 \u001b[39m\u001b[22m\n",
      "INFO flower 2023-02-01 12:54:20,688 | app.py:155 | Ray initialized with resources: {'memory': 17059693364.0, 'CPU': 8.0, 'object_store_memory': 8529846681.0, 'node:137.43.23.126': 1.0}\n",
      "INFO flower 2023-02-01 12:54:20,689 | app.py:171 | Starting Flower simulation running: Config(num_rounds=100, round_timeout=None)\n",
      "INFO flower 2023-02-01 12:54:20,692 | server.py:84 | Initializing global parameters\n",
      "INFO flower 2023-02-01 12:54:20,693 | server.py:252 | Using initial parameters provided by strategy\n",
      "INFO flower 2023-02-01 12:54:20,694 | server.py:86 | Evaluating initial parameters\n",
      "INFO flower 2023-02-01 12:54:20,694 | server.py:99 | FL starting\n",
      "DEBUG flower 2023-02-01 12:54:20,695 | server.py:203 | fit_round: strategy sampled 30 clients (out of 100)\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m /usr/local/lib/python3.10/dist-packages/ray/dashboard/agent.py:51: DeprecationWarning: There is no current event loop\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m   aiogrpc.init_grpc_aio()\n",
      "2023-02-01 12:54:21,289\tWARNING __init__.py:182 -- DeprecationWarning: `ray.worker.get` is a private attribute and access will be removed in a future Ray version.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m [Client 38] fit, config: {'current_round': 1, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m [Client 3] fit, config: {'current_round': 1, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m [Client 42] fit, config: {'current_round': 1, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m [Client 7] fit, config: {'current_round': 1, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m [Client 13] fit, config: {'current_round': 1, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m [Client 14] fit, config: {'current_round': 1, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m Epoch 1: train loss 0.0002292536519235, accuracy 0.12962962962962962\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m Epoch 1: train loss 0.0002312331198481843, accuracy 0.037037037037037035\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m [Client 33] fit, config: {'current_round': 1, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m Epoch 1: train loss 0.00023117303499020636, accuracy 0.037037037037037035\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m [Client 44] fit, config: {'current_round': 1, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m Epoch 1: train loss 0.00023297850566450506, accuracy 0.07407407407407407\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m [Client 60] fit, config: {'current_round': 1, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m Epoch 1: train loss 0.00023150241759140044, accuracy 0.07407407407407407\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m Epoch 1: train loss 0.00023117306409403682, accuracy 0.07407407407407407\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m [Client 28] fit, config: {'current_round': 1, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m [Client 45] fit, config: {'current_round': 1, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m Epoch 1: train loss 0.0002289861731696874, accuracy 0.09259259259259259\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m [Client 77] fit, config: {'current_round': 1, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m Epoch 1: train loss 0.00022888582316227257, accuracy 0.1111111111111111\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m Epoch 1: train loss 0.0002314983867108822, accuracy 0.018518518518518517\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m Epoch 1: train loss 0.00023039989173412323, accuracy 0.07407407407407407\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m Epoch 1: train loss 0.00022924001677893102, accuracy 0.18518518518518517\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m Epoch 1: train loss 0.00023039996449369937, accuracy 0.1111111111111111\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m [Client 93] fit, config: {'current_round': 1, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m Epoch 1: train loss 0.00022892828565090895, accuracy 0.1111111111111111\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 12:54:23,562 | server.py:216 | fit_round received 30 results and 0 failures\n",
      "WARNING flower 2023-02-01 12:54:23,596 | fedavg.py:237 | No fit_metrics_aggregation_fn provided\n",
      "DEBUG flower 2023-02-01 12:54:23,601 | server.py:157 | evaluate_round: strategy sampled 30 clients (out of 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m [Client 84] fit, config: {'current_round': 1, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m [Client 23] fit, config: {'current_round': 1, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m [Client 5] fit, config: {'current_round': 1, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m Epoch 1: train loss 0.0002323653461644426, accuracy 0.09259259259259259\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m [Client 59] fit, config: {'current_round': 1, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m Epoch 1: train loss 0.00023138120013754815, accuracy 0.09259259259259259\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m [Client 11] fit, config: {'current_round': 1, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m Epoch 1: train loss 0.0002304420922882855, accuracy 0.12962962962962962\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m [Client 66] fit, config: {'current_round': 1, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m Epoch 1: train loss 0.0002303030778421089, accuracy 0.12962962962962962\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m [Client 21] fit, config: {'current_round': 1, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m Epoch 1: train loss 0.0002303712535649538, accuracy 0.09259259259259259\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m Epoch 1: train loss 0.00023211653751786798, accuracy 0.037037037037037035\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m [Client 19] fit, config: {'current_round': 1, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m Epoch 1: train loss 0.00023117291857488453, accuracy 0.09259259259259259\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m [Client 39] fit, config: {'current_round': 1, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m [Client 32] fit, config: {'current_round': 1, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m Epoch 1: train loss 0.00023074366617947817, accuracy 0.07407407407407407\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m [Client 61] fit, config: {'current_round': 1, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m Epoch 1: train loss 0.0002328325208509341, accuracy 0.05555555555555555\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m Epoch 1: train loss 0.00023217263515107334, accuracy 0.1111111111111111\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m Epoch 1: train loss 0.00022822391474619508, accuracy 0.16666666666666666\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m [Client 22] fit, config: {'current_round': 1, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m Epoch 1: train loss 0.00022959646594244987, accuracy 0.09259259259259259\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m [Client 65] fit, config: {'current_round': 1, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m Epoch 1: train loss 0.00023057369980961084, accuracy 0.07407407407407407\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m [Client 71] fit, config: {'current_round': 1, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m Epoch 1: train loss 0.00022848592197988182, accuracy 0.18518518518518517\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m [Client 52] fit, config: {'current_round': 1, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m Epoch 1: train loss 0.00022893557616043836, accuracy 0.07407407407407407\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m [Client 64] fit, config: {'current_round': 1, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m Epoch 1: train loss 0.00022991666628513485, accuracy 0.12962962962962962\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m [Client 87] fit, config: {'current_round': 1, 'local_epochs': 3}\n",
      "Saving round 1 aggregated_parameters...\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m Epoch 1: train loss 0.00022991893638391048, accuracy 0.1111111111111111\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98094)\u001b[0m [Client 1] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98092)\u001b[0m [Client 72] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98094)\u001b[0m [Client 62] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98092)\u001b[0m [Client 28] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98094)\u001b[0m [Client 15] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98094)\u001b[0m [Client 64] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98092)\u001b[0m [Client 67] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98092)\u001b[0m [Client 54] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98092)\u001b[0m [Client 36] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98091)\u001b[0m [Client 90] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98093)\u001b[0m [Client 31] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98094)\u001b[0m [Client 59] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98091)\u001b[0m [Client 45] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98093)\u001b[0m [Client 20] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98091)\u001b[0m [Client 93] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98093)\u001b[0m [Client 34] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98094)\u001b[0m [Client 73] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98094)\u001b[0m [Client 92] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98094)\u001b[0m [Client 52] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98091)\u001b[0m [Client 74] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98090)\u001b[0m [Client 91] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98093)\u001b[0m [Client 71] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98089)\u001b[0m [Client 33] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98094)\u001b[0m [Client 13] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98092)\u001b[0m [Client 85] evaluate, config: {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 12:54:25,156 | server.py:170 | evaluate_round received 0 results and 30 failures\n",
      "DEBUG flower 2023-02-01 12:54:25,156 | server.py:203 | fit_round: strategy sampled 30 clients (out of 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98091)\u001b[0m [Client 35] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98090)\u001b[0m [Client 6] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98088)\u001b[0m [Client 96] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98095)\u001b[0m [Client 89] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98093)\u001b[0m [Client 30] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m [Client 15] fit, config: {'current_round': 2, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m [Client 44] fit, config: {'current_round': 2, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m Epoch 1: train loss 0.00022923613141756505, accuracy 0.09259259259259259\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m Epoch 1: train loss 0.00023049060837365687, accuracy 0.037037037037037035\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m [Client 12] fit, config: {'current_round': 2, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m Epoch 1: train loss 0.00023019230866339058, accuracy 0.05555555555555555\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m [Client 23] fit, config: {'current_round': 2, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m [Client 69] fit, config: {'current_round': 2, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m Epoch 1: train loss 0.00022981385700404644, accuracy 0.09259259259259259\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m Epoch 1: train loss 0.0002307886170456186, accuracy 0.037037037037037035\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m [Client 16] fit, config: {'current_round': 2, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m Epoch 1: train loss 0.00023034846526570618, accuracy 0.14814814814814814\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m [Client 40] fit, config: {'current_round': 2, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m Epoch 1: train loss 0.00022823836479801685, accuracy 0.14814814814814814\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m [Client 19] fit, config: {'current_round': 2, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m Epoch 1: train loss 0.0002298841718584299, accuracy 0.09259259259259259\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m [Client 42] fit, config: {'current_round': 2, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m Epoch 1: train loss 0.00023000557848718017, accuracy 0.037037037037037035\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m [Client 33] fit, config: {'current_round': 2, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m Epoch 1: train loss 0.00023011089069768786, accuracy 0.018518518518518517\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m [Client 54] fit, config: {'current_round': 2, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m Epoch 1: train loss 0.0002301024942426011, accuracy 0.09259259259259259\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m [Client 97] fit, config: {'current_round': 2, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m Epoch 1: train loss 0.00022907962556928396, accuracy 0.09259259259259259\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m [Client 27] fit, config: {'current_round': 2, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m Epoch 1: train loss 0.00022743680165149271, accuracy 0.18518518518518517\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m [Client 57] fit, config: {'current_round': 2, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m Epoch 1: train loss 0.00022811422240920365, accuracy 0.14814814814814814\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m [Client 14] fit, config: {'current_round': 2, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m Epoch 1: train loss 0.00022985598479863256, accuracy 0.07407407407407407\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m [Client 98] fit, config: {'current_round': 2, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m Epoch 1: train loss 0.00022842161706648767, accuracy 0.1111111111111111\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m [Client 85] fit, config: {'current_round': 2, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m Epoch 1: train loss 0.0002293184952577576, accuracy 0.09259259259259259\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m [Client 76] fit, config: {'current_round': 2, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m Epoch 1: train loss 0.00022914441069588065, accuracy 0.07407407407407407\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m [Client 79] fit, config: {'current_round': 2, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m Epoch 1: train loss 0.00022967610857449472, accuracy 0.07407407407407407\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m [Client 22] fit, config: {'current_round': 2, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m Epoch 1: train loss 0.00022857873409520835, accuracy 0.1111111111111111\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m [Client 3] fit, config: {'current_round': 2, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m Epoch 1: train loss 0.00023000288638286293, accuracy 0.037037037037037035\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m [Client 56] fit, config: {'current_round': 2, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m Epoch 1: train loss 0.00022981985239312053, accuracy 0.09259259259259259\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m [Client 21] fit, config: {'current_round': 2, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m Epoch 1: train loss 0.00023100755061022937, accuracy 0.1111111111111111\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 12:54:26,722 | server.py:216 | fit_round received 30 results and 0 failures\n",
      "DEBUG flower 2023-02-01 12:54:26,755 | server.py:157 | evaluate_round: strategy sampled 30 clients (out of 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m [Client 0] fit, config: {'current_round': 2, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m Epoch 1: train loss 0.00022979898494668305, accuracy 0.05555555555555555\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m [Client 61] fit, config: {'current_round': 2, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m Epoch 1: train loss 0.00023144076112657785, accuracy 0.05555555555555555\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m [Client 84] fit, config: {'current_round': 2, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m Epoch 1: train loss 0.00022913921566214412, accuracy 0.09259259259259259\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m [Client 41] fit, config: {'current_round': 2, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m Epoch 1: train loss 0.00022856189752928913, accuracy 0.2222222222222222\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m [Client 4] fit, config: {'current_round': 2, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m Epoch 1: train loss 0.0002290702541358769, accuracy 0.07407407407407407\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m [Client 64] fit, config: {'current_round': 2, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m [Client 26] fit, config: {'current_round': 2, 'local_epochs': 3}\n",
      "Saving round 2 aggregated_parameters...\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m Epoch 1: train loss 0.00022876978619024158, accuracy 0.12962962962962962\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m Epoch 1: train loss 0.0002291119162691757, accuracy 0.07407407407407407\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98094)\u001b[0m [Client 66] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98092)\u001b[0m [Client 62] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98092)\u001b[0m [Client 38] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98092)\u001b[0m [Client 24] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98094)\u001b[0m [Client 88] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98094)\u001b[0m [Client 90] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98090)\u001b[0m [Client 79] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98088)\u001b[0m [Client 16] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98094)\u001b[0m [Client 9] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98092)\u001b[0m [Client 47] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98090)\u001b[0m [Client 32] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98090)\u001b[0m [Client 23] evaluate, config: {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 12:54:28,243 | server.py:170 | evaluate_round received 0 results and 30 failures\n",
      "DEBUG flower 2023-02-01 12:54:28,244 | server.py:203 | fit_round: strategy sampled 30 clients (out of 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98091)\u001b[0m [Client 95] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98090)\u001b[0m [Client 64] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98088)\u001b[0m [Client 39] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98088)\u001b[0m [Client 94] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98095)\u001b[0m [Client 28] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98093)\u001b[0m [Client 57] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98089)\u001b[0m [Client 48] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98094)\u001b[0m [Client 76] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98092)\u001b[0m [Client 61] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98094)\u001b[0m [Client 34] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98091)\u001b[0m [Client 92] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98088)\u001b[0m [Client 46] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98095)\u001b[0m [Client 70] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98093)\u001b[0m [Client 6] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98089)\u001b[0m [Client 3] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98094)\u001b[0m [Client 51] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98090)\u001b[0m [Client 98] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98092)\u001b[0m [Client 63] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m [Client 50] fit, config: {'current_round': 3, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m Epoch 1: train loss 0.00022930276463739574, accuracy 0.2037037037037037\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m [Client 46] fit, config: {'current_round': 3, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m Epoch 1: train loss 0.00022655153588857502, accuracy 0.14814814814814814\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m [Client 51] fit, config: {'current_round': 3, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m Epoch 1: train loss 0.00022887279919814318, accuracy 0.09259259259259259\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m [Client 98] fit, config: {'current_round': 3, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m [Client 2] fit, config: {'current_round': 3, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m Epoch 1: train loss 0.0002264825307065621, accuracy 0.2222222222222222\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m [Client 67] fit, config: {'current_round': 3, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m Epoch 1: train loss 0.0002279323380207643, accuracy 0.2037037037037037\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m [Client 45] fit, config: {'current_round': 3, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m Epoch 1: train loss 0.0002271198754897341, accuracy 0.09259259259259259\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m [Client 3] fit, config: {'current_round': 3, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m Epoch 1: train loss 0.0002286816161358729, accuracy 0.07407407407407407\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m [Client 5] fit, config: {'current_round': 3, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m Epoch 1: train loss 0.00022948042897041887, accuracy 0.14814814814814814\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m [Client 35] fit, config: {'current_round': 3, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m Epoch 1: train loss 0.000226528340135701, accuracy 0.14814814814814814\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m Epoch 1: train loss 0.00022655136126559228, accuracy 0.2222222222222222\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m [Client 30] fit, config: {'current_round': 3, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m Epoch 1: train loss 0.0002280147309647873, accuracy 0.16666666666666666\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m [Client 25] fit, config: {'current_round': 3, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m Epoch 1: train loss 0.00022854442067909986, accuracy 0.18518518518518517\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m [Client 4] fit, config: {'current_round': 3, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m Epoch 1: train loss 0.00022786438057664782, accuracy 0.18518518518518517\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m [Client 9] fit, config: {'current_round': 3, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m Epoch 1: train loss 0.0002283500216435641, accuracy 0.05555555555555555\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m [Client 91] fit, config: {'current_round': 3, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m Epoch 1: train loss 0.00022716622333973646, accuracy 0.16666666666666666\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m [Client 65] fit, config: {'current_round': 3, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m [Client 38] fit, config: {'current_round': 3, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m Epoch 1: train loss 0.000227261713007465, accuracy 0.16666666666666666\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m [Client 22] fit, config: {'current_round': 3, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m Epoch 1: train loss 0.00022746137983631343, accuracy 0.14814814814814814\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m [Client 44] fit, config: {'current_round': 3, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m Epoch 1: train loss 0.000228008721023798, accuracy 0.14814814814814814\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m [Client 17] fit, config: {'current_round': 3, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m Epoch 1: train loss 0.00022706494200974703, accuracy 0.2222222222222222\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m [Client 92] fit, config: {'current_round': 3, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m [Client 27] fit, config: {'current_round': 3, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m Epoch 1: train loss 0.00022633634216617793, accuracy 0.2222222222222222\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 12:54:29,754 | server.py:216 | fit_round received 30 results and 0 failures\n",
      "DEBUG flower 2023-02-01 12:54:29,790 | server.py:157 | evaluate_round: strategy sampled 30 clients (out of 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m Epoch 1: train loss 0.00022840338351670653, accuracy 0.16666666666666666\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m [Client 93] fit, config: {'current_round': 3, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m Epoch 1: train loss 0.00022673550120089203, accuracy 0.12962962962962962\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m Epoch 1: train loss 0.00022791240189690143, accuracy 0.14814814814814814\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m [Client 56] fit, config: {'current_round': 3, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m Epoch 1: train loss 0.00022849335800856352, accuracy 0.1111111111111111\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m [Client 79] fit, config: {'current_round': 3, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m Epoch 1: train loss 0.0002281718043377623, accuracy 0.18518518518518517\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m [Client 8] fit, config: {'current_round': 3, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m Epoch 1: train loss 0.000228632619837299, accuracy 0.07407407407407407\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m [Client 36] fit, config: {'current_round': 3, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m Epoch 1: train loss 0.00022896261361893266, accuracy 0.12962962962962962\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m [Client 23] fit, config: {'current_round': 3, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m Epoch 1: train loss 0.0002293740981258452, accuracy 0.1111111111111111\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m [Client 88] fit, config: {'current_round': 3, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m Epoch 1: train loss 0.00022721465211361647, accuracy 0.12962962962962962\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m [Client 13] fit, config: {'current_round': 3, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m Epoch 1: train loss 0.00022941891802474856, accuracy 0.07407407407407407\n",
      "Saving round 3 aggregated_parameters...\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98090)\u001b[0m [Client 96] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98090)\u001b[0m [Client 79] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98090)\u001b[0m [Client 22] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98091)\u001b[0m [Client 18] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98090)\u001b[0m [Client 89] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98090)\u001b[0m [Client 98] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98089)\u001b[0m [Client 34] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98091)\u001b[0m [Client 86] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98089)\u001b[0m [Client 65] evaluate, config: {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 12:54:31,271 | server.py:170 | evaluate_round received 0 results and 30 failures\n",
      "DEBUG flower 2023-02-01 12:54:31,271 | server.py:203 | fit_round: strategy sampled 30 clients (out of 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98091)\u001b[0m [Client 8] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98089)\u001b[0m [Client 21] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98091)\u001b[0m [Client 76] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98091)\u001b[0m [Client 80] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98091)\u001b[0m [Client 66] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98091)\u001b[0m [Client 2] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98090)\u001b[0m [Client 52] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98089)\u001b[0m [Client 38] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98089)\u001b[0m [Client 10] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98089)\u001b[0m [Client 71] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98091)\u001b[0m [Client 7] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98091)\u001b[0m [Client 67] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98090)\u001b[0m [Client 37] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98088)\u001b[0m [Client 6] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98095)\u001b[0m [Client 19] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98093)\u001b[0m [Client 27] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98089)\u001b[0m [Client 26] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98089)\u001b[0m [Client 1] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98094)\u001b[0m [Client 77] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98094)\u001b[0m [Client 90] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98092)\u001b[0m [Client 12] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m [Client 42] fit, config: {'current_round': 4, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m Epoch 1: train loss 0.0002272474957862869, accuracy 0.16666666666666666\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m [Client 40] fit, config: {'current_round': 4, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m [Client 20] fit, config: {'current_round': 4, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m Epoch 1: train loss 0.00022569840075448155, accuracy 0.2037037037037037\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m Epoch 1: train loss 0.00022525408712681383, accuracy 0.18518518518518517\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m [Client 18] fit, config: {'current_round': 4, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m Epoch 1: train loss 0.00022656972578261048, accuracy 0.16666666666666666\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m [Client 6] fit, config: {'current_round': 4, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m Epoch 1: train loss 0.0002259909815620631, accuracy 0.25925925925925924\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m [Client 76] fit, config: {'current_round': 4, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m Epoch 1: train loss 0.00022592837922275066, accuracy 0.2222222222222222\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m [Client 67] fit, config: {'current_round': 4, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m Epoch 1: train loss 0.00022677850211039186, accuracy 0.2037037037037037\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m [Client 44] fit, config: {'current_round': 4, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m Epoch 1: train loss 0.00022654068015981466, accuracy 0.18518518518518517\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m [Client 54] fit, config: {'current_round': 4, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m Epoch 1: train loss 0.00022728228941559792, accuracy 0.16666666666666666\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m [Client 4] fit, config: {'current_round': 4, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m Epoch 1: train loss 0.00022642972180619836, accuracy 0.24074074074074073\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m [Client 84] fit, config: {'current_round': 4, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m Epoch 1: train loss 0.00022635106870438904, accuracy 0.16666666666666666\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m [Client 24] fit, config: {'current_round': 4, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m [Client 73] fit, config: {'current_round': 4, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m Epoch 1: train loss 0.0002259423054056242, accuracy 0.2222222222222222\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m Epoch 1: train loss 0.00022707435709889978, accuracy 0.2037037037037037\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m [Client 81] fit, config: {'current_round': 4, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m Epoch 1: train loss 0.00022646023717243224, accuracy 0.16666666666666666\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m [Client 51] fit, config: {'current_round': 4, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m Epoch 1: train loss 0.00022706142044626176, accuracy 0.1111111111111111\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 12:54:33,006 | server.py:216 | fit_round received 30 results and 0 failures\n",
      "DEBUG flower 2023-02-01 12:54:33,043 | server.py:157 | evaluate_round: strategy sampled 30 clients (out of 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m [Client 7] fit, config: {'current_round': 4, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m Epoch 1: train loss 0.00022855093993712217, accuracy 0.14814814814814814\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m [Client 61] fit, config: {'current_round': 4, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m Epoch 1: train loss 0.0002287122479174286, accuracy 0.16666666666666666\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m [Client 77] fit, config: {'current_round': 4, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m Epoch 1: train loss 0.00022514407464768738, accuracy 0.18518518518518517\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m [Client 9] fit, config: {'current_round': 4, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m [Client 43] fit, config: {'current_round': 4, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m [Client 97] fit, config: {'current_round': 4, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m Epoch 1: train loss 0.00022676736989524215, accuracy 0.2222222222222222\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m [Client 64] fit, config: {'current_round': 4, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m Epoch 1: train loss 0.00022691028425469995, accuracy 0.05555555555555555\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m Epoch 1: train loss 0.00022633511980529875, accuracy 0.18518518518518517\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m [Client 14] fit, config: {'current_round': 4, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m Epoch 1: train loss 0.0002268875832669437, accuracy 0.2037037037037037\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m Epoch 1: train loss 0.00022623148106504232, accuracy 0.14814814814814814\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m [Client 89] fit, config: {'current_round': 4, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m Epoch 1: train loss 0.0002272294950671494, accuracy 0.2037037037037037\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m [Client 62] fit, config: {'current_round': 4, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m Epoch 1: train loss 0.00022594410984311253, accuracy 0.12962962962962962\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m [Client 29] fit, config: {'current_round': 4, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m Epoch 1: train loss 0.00022625068959314376, accuracy 0.2777777777777778\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m [Client 30] fit, config: {'current_round': 4, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m Epoch 1: train loss 0.00022665369033347815, accuracy 0.2037037037037037\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m [Client 70] fit, config: {'current_round': 4, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m Epoch 1: train loss 0.00022691223421134055, accuracy 0.2222222222222222\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m [Client 36] fit, config: {'current_round': 4, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m Epoch 1: train loss 0.00022770505165681243, accuracy 0.12962962962962962\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m [Client 90] fit, config: {'current_round': 4, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m Epoch 1: train loss 0.00022555727628059685, accuracy 0.2037037037037037\n",
      "Saving round 4 aggregated_parameters...\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98090)\u001b[0m [Client 39] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98088)\u001b[0m [Client 57] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98092)\u001b[0m [Client 17] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98088)\u001b[0m [Client 6] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98095)\u001b[0m [Client 72] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98088)\u001b[0m [Client 63] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98088)\u001b[0m [Client 71] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98095)\u001b[0m [Client 62] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98088)\u001b[0m [Client 99] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98090)\u001b[0m [Client 59] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98089)\u001b[0m [Client 96] evaluate, config: {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 12:54:35,104 | server.py:170 | evaluate_round received 0 results and 30 failures\n",
      "DEBUG flower 2023-02-01 12:54:35,106 | server.py:203 | fit_round: strategy sampled 30 clients (out of 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98090)\u001b[0m [Client 1] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98095)\u001b[0m [Client 89] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98093)\u001b[0m [Client 86] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98089)\u001b[0m [Client 48] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98090)\u001b[0m [Client 88] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98091)\u001b[0m [Client 13] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98088)\u001b[0m [Client 68] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98095)\u001b[0m [Client 67] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98094)\u001b[0m [Client 7] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98092)\u001b[0m [Client 82] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98088)\u001b[0m [Client 21] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98095)\u001b[0m [Client 30] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98095)\u001b[0m [Client 42] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98092)\u001b[0m [Client 87] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98091)\u001b[0m [Client 28] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98090)\u001b[0m [Client 54] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98093)\u001b[0m [Client 76] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98089)\u001b[0m [Client 69] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98094)\u001b[0m [Client 47] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m [Client 16] fit, config: {'current_round': 5, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m Epoch 1: train loss 0.00022581429220736027, accuracy 0.2222222222222222\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m [Client 85] fit, config: {'current_round': 5, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m [Client 19] fit, config: {'current_round': 5, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m Epoch 1: train loss 0.000225627634790726, accuracy 0.25925925925925924\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m [Client 66] fit, config: {'current_round': 5, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m [Client 82] fit, config: {'current_round': 5, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m Epoch 1: train loss 0.00022437794541474432, accuracy 0.24074074074074073\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m Epoch 1: train loss 0.0002244639181299135, accuracy 0.2777777777777778\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m Epoch 1: train loss 0.00022494993754662573, accuracy 0.16666666666666666\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m [Client 84] fit, config: {'current_round': 5, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m Epoch 1: train loss 0.00022424761846195906, accuracy 0.2962962962962963\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m [Client 70] fit, config: {'current_round': 5, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m Epoch 1: train loss 0.00022512578289024532, accuracy 0.2777777777777778\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m [Client 53] fit, config: {'current_round': 5, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m Epoch 1: train loss 0.00022439859458245337, accuracy 0.18518518518518517\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m [Client 0] fit, config: {'current_round': 5, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m Epoch 1: train loss 0.00022488825197797269, accuracy 0.24074074074074073\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m [Client 1] fit, config: {'current_round': 5, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m Epoch 1: train loss 0.00022391231323126704, accuracy 0.2962962962962963\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m [Client 89] fit, config: {'current_round': 5, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m Epoch 1: train loss 0.00022528276895172894, accuracy 0.18518518518518517\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m [Client 63] fit, config: {'current_round': 5, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m Epoch 1: train loss 0.00022277687094174325, accuracy 0.3888888888888889\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m [Client 10] fit, config: {'current_round': 5, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m Epoch 1: train loss 0.00022628002625424415, accuracy 0.18518518518518517\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m [Client 39] fit, config: {'current_round': 5, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m Epoch 1: train loss 0.00022223329870030284, accuracy 0.25925925925925924\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m [Client 3] fit, config: {'current_round': 5, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m Epoch 1: train loss 0.00022531340073328465, accuracy 0.18518518518518517\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m [Client 45] fit, config: {'current_round': 5, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m Epoch 1: train loss 0.00022239642567001283, accuracy 0.2777777777777778\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m [Client 72] fit, config: {'current_round': 5, 'local_epochs': 3}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(raylet)\u001b[0m Spilled 2602 MiB, 81 objects, write throughput 939 MiB/s. Set RAY_verbose_spill_logs=0 to disable this message.\n",
      "DEBUG flower 2023-02-01 12:54:37,063 | server.py:216 | fit_round received 30 results and 0 failures\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m [Client 50] fit, config: {'current_round': 5, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m Epoch 1: train loss 0.0002261541085317731, accuracy 0.12962962962962962\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m [Client 74] fit, config: {'current_round': 5, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m Epoch 1: train loss 0.00022354364045895636, accuracy 0.37037037037037035\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m [Client 21] fit, config: {'current_round': 5, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m [Client 60] fit, config: {'current_round': 5, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m Epoch 1: train loss 0.00022511194401886314, accuracy 0.2037037037037037\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m Epoch 1: train loss 0.00022490911942441016, accuracy 0.25925925925925924\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m [Client 48] fit, config: {'current_round': 5, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m Epoch 1: train loss 0.000222538918023929, accuracy 0.24074074074074073\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m Epoch 1: train loss 0.00022731810167897493, accuracy 0.14814814814814814\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m [Client 96] fit, config: {'current_round': 5, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m Epoch 1: train loss 0.00022308154439087957, accuracy 0.3888888888888889\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m [Client 37] fit, config: {'current_round': 5, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m Epoch 1: train loss 0.00022425720817409456, accuracy 0.24074074074074073\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m [Client 38] fit, config: {'current_round': 5, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m Epoch 1: train loss 0.0002237974840682, accuracy 0.2222222222222222\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m [Client 62] fit, config: {'current_round': 5, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m Epoch 1: train loss 0.0002241642214357853, accuracy 0.3148148148148148\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m [Client 87] fit, config: {'current_round': 5, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m Epoch 1: train loss 0.0002248448581667617, accuracy 0.2037037037037037\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 12:54:37,111 | server.py:157 | evaluate_round: strategy sampled 30 clients (out of 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m [Client 58] fit, config: {'current_round': 5, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m Epoch 1: train loss 0.00022553594317287207, accuracy 0.25925925925925924\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m [Client 97] fit, config: {'current_round': 5, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m Epoch 1: train loss 0.00022495172743219882, accuracy 0.25925925925925924\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m [Client 17] fit, config: {'current_round': 5, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m Epoch 1: train loss 0.00022340173018164933, accuracy 0.2962962962962963\n",
      "Saving round 5 aggregated_parameters...\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98091)\u001b[0m [Client 65] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98091)\u001b[0m [Client 48] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98090)\u001b[0m [Client 26] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98093)\u001b[0m [Client 49] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98090)\u001b[0m [Client 13] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98093)\u001b[0m [Client 0] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98091)\u001b[0m [Client 64] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98091)\u001b[0m [Client 83] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98090)\u001b[0m [Client 60] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98090)\u001b[0m [Client 1] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98093)\u001b[0m [Client 59] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98089)\u001b[0m [Client 76] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98089)\u001b[0m [Client 84] evaluate, config: {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 12:54:39,074 | server.py:170 | evaluate_round received 0 results and 30 failures\n",
      "DEBUG flower 2023-02-01 12:54:39,076 | server.py:203 | fit_round: strategy sampled 30 clients (out of 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98089)\u001b[0m [Client 52] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98090)\u001b[0m [Client 40] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98095)\u001b[0m [Client 4] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98093)\u001b[0m [Client 66] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98091)\u001b[0m [Client 58] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98095)\u001b[0m [Client 80] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98089)\u001b[0m [Client 87] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98094)\u001b[0m [Client 62] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98091)\u001b[0m [Client 61] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98090)\u001b[0m [Client 10] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98088)\u001b[0m [Client 74] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98092)\u001b[0m [Client 67] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98090)\u001b[0m [Client 31] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98092)\u001b[0m [Client 35] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98091)\u001b[0m [Client 70] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98088)\u001b[0m [Client 17] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98095)\u001b[0m [Client 14] evaluate, config: {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(raylet)\u001b[0m Spilled 4247 MiB, 128 objects, write throughput 1076 MiB/s.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m [Client 36] fit, config: {'current_round': 6, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m Epoch 1: train loss 0.00022426007490139455, accuracy 0.2037037037037037\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m [Client 4] fit, config: {'current_round': 6, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m Epoch 1: train loss 0.00022221190738491714, accuracy 0.35185185185185186\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m [Client 71] fit, config: {'current_round': 6, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m Epoch 1: train loss 0.00022152159363031387, accuracy 0.3333333333333333\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m [Client 47] fit, config: {'current_round': 6, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m Epoch 1: train loss 0.00022102540242485702, accuracy 0.4074074074074074\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m [Client 84] fit, config: {'current_round': 6, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m Epoch 1: train loss 0.00022151449229568243, accuracy 0.3888888888888889\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m [Client 31] fit, config: {'current_round': 6, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m Epoch 1: train loss 0.00022254977375268936, accuracy 0.37037037037037035\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m [Client 26] fit, config: {'current_round': 6, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m Epoch 1: train loss 0.0002225589705631137, accuracy 0.35185185185185186\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m [Client 70] fit, config: {'current_round': 6, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m Epoch 1: train loss 0.0002228080265922472, accuracy 0.3148148148148148\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m [Client 97] fit, config: {'current_round': 6, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m Epoch 1: train loss 0.0002227443183073774, accuracy 0.2962962962962963\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m [Client 48] fit, config: {'current_round': 6, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m Epoch 1: train loss 0.00022010336397215724, accuracy 0.3333333333333333\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m [Client 87] fit, config: {'current_round': 6, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m Epoch 1: train loss 0.00022246594016905874, accuracy 0.3148148148148148\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m [Client 22] fit, config: {'current_round': 6, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m Epoch 1: train loss 0.0002216946886619553, accuracy 0.35185185185185186\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m [Client 16] fit, config: {'current_round': 6, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m [Client 56] fit, config: {'current_round': 6, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m [Client 40] fit, config: {'current_round': 6, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m [Client 92] fit, config: {'current_round': 6, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m Epoch 1: train loss 0.00022127476404421031, accuracy 0.4074074074074074\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m [Client 57] fit, config: {'current_round': 6, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m [Client 90] fit, config: {'current_round': 6, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m Epoch 1: train loss 0.00022083196381572634, accuracy 0.3333333333333333\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m Epoch 1: train loss 0.000223344104597345, accuracy 0.2777777777777778\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m [Client 43] fit, config: {'current_round': 6, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m Epoch 1: train loss 0.00022277898096945137, accuracy 0.2962962962962963\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m Epoch 1: train loss 0.00022065042867325246, accuracy 0.2962962962962963\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m Epoch 1: train loss 0.00022189359879121184, accuracy 0.2777777777777778\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m [Client 93] fit, config: {'current_round': 6, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m Epoch 1: train loss 0.00022100958449300379, accuracy 0.3888888888888889\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m Epoch 1: train loss 0.00022175007325131446, accuracy 0.35185185185185186\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m [Client 27] fit, config: {'current_round': 6, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m Epoch 1: train loss 0.00022050709230825305, accuracy 0.37037037037037035\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m [Client 24] fit, config: {'current_round': 6, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m Epoch 1: train loss 0.0002213226252933964, accuracy 0.35185185185185186\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m [Client 28] fit, config: {'current_round': 6, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m Epoch 1: train loss 0.0002230603276984766, accuracy 0.24074074074074073\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m [Client 62] fit, config: {'current_round': 6, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m Epoch 1: train loss 0.00022184706176631153, accuracy 0.3333333333333333\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m [Client 95] fit, config: {'current_round': 6, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m Epoch 1: train loss 0.0002221493050456047, accuracy 0.2777777777777778\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m [Client 33] fit, config: {'current_round': 6, 'local_epochs': 3}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 12:54:41,406 | server.py:216 | fit_round received 30 results and 0 failures\n",
      "DEBUG flower 2023-02-01 12:54:41,454 | server.py:157 | evaluate_round: strategy sampled 30 clients (out of 100)\n",
      "\u001b[2m\u001b[36m(raylet)\u001b[0m Spilled 12226 MiB, 427 objects, write throughput 2206 MiB/s.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m [Client 67] fit, config: {'current_round': 6, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m Epoch 1: train loss 0.00022314887610264122, accuracy 0.25925925925925924\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m [Client 14] fit, config: {'current_round': 6, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m Epoch 1: train loss 0.0002223045885330066, accuracy 0.2777777777777778\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m [Client 76] fit, config: {'current_round': 6, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m Epoch 1: train loss 0.00022088465630076826, accuracy 0.37037037037037035\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m [Client 1] fit, config: {'current_round': 6, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m Epoch 1: train loss 0.0002215063141193241, accuracy 0.42592592592592593\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m Epoch 1: train loss 0.00022296445968095213, accuracy 0.37037037037037035\n",
      "Saving round 6 aggregated_parameters...\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98091)\u001b[0m [Client 72] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98090)\u001b[0m [Client 35] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98090)\u001b[0m [Client 33] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98089)\u001b[0m [Client 19] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98089)\u001b[0m [Client 50] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98091)\u001b[0m [Client 1] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98090)\u001b[0m [Client 12] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98091)\u001b[0m [Client 48] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98091)\u001b[0m [Client 61] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98091)\u001b[0m [Client 79] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98090)\u001b[0m [Client 20] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98090)\u001b[0m [Client 25] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98089)\u001b[0m [Client 3] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98091)\u001b[0m [Client 11] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98089)\u001b[0m [Client 34] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98090)\u001b[0m [Client 68] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98089)\u001b[0m [Client 87] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98090)\u001b[0m [Client 86] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98091)\u001b[0m [Client 36] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98090)\u001b[0m [Client 92] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98093)\u001b[0m [Client 81] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98089)\u001b[0m [Client 66] evaluate, config: {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 12:54:43,586 | server.py:170 | evaluate_round received 0 results and 30 failures\n",
      "DEBUG flower 2023-02-01 12:54:43,587 | server.py:203 | fit_round: strategy sampled 30 clients (out of 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98091)\u001b[0m [Client 95] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98090)\u001b[0m [Client 64] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98088)\u001b[0m [Client 47] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98095)\u001b[0m [Client 40] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98093)\u001b[0m [Client 45] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98089)\u001b[0m [Client 76] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98094)\u001b[0m [Client 52] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98092)\u001b[0m [Client 98] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m [Client 31] fit, config: {'current_round': 7, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m [Client 16] fit, config: {'current_round': 7, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m Epoch 1: train loss 0.0002205030177719891, accuracy 0.2777777777777778\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m Epoch 1: train loss 0.00021934299729764462, accuracy 0.4074074074074074\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m [Client 75] fit, config: {'current_round': 7, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m Epoch 1: train loss 0.00021787104196846485, accuracy 0.42592592592592593\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m [Client 19] fit, config: {'current_round': 7, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m Epoch 1: train loss 0.0002202028699684888, accuracy 0.3148148148148148\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m [Client 38] fit, config: {'current_round': 7, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m Epoch 1: train loss 0.00021840014960616827, accuracy 0.35185185185185186\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m [Client 65] fit, config: {'current_round': 7, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m Epoch 1: train loss 0.00021894958626944572, accuracy 0.4074074074074074\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m [Client 53] fit, config: {'current_round': 7, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m Epoch 1: train loss 0.00021868555631954223, accuracy 0.3148148148148148\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m [Client 21] fit, config: {'current_round': 7, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m [Client 39] fit, config: {'current_round': 7, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m Epoch 1: train loss 0.0002229903475381434, accuracy 0.18518518518518517\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m [Client 56] fit, config: {'current_round': 7, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m Epoch 1: train loss 0.00021956567070446908, accuracy 0.3333333333333333\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m [Client 18] fit, config: {'current_round': 7, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m Epoch 1: train loss 0.00021896020916756243, accuracy 0.3333333333333333\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m Epoch 1: train loss 0.00021635534358210862, accuracy 0.37037037037037035\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m [Client 37] fit, config: {'current_round': 7, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m [Client 35] fit, config: {'current_round': 7, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m [Client 59] fit, config: {'current_round': 7, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m Epoch 1: train loss 0.00021734597976319492, accuracy 0.2962962962962963\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m Epoch 1: train loss 0.0002186803030781448, accuracy 0.4074074074074074\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m Epoch 1: train loss 0.00022002427431289107, accuracy 0.3333333333333333\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m [Client 82] fit, config: {'current_round': 7, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m Epoch 1: train loss 0.00021817776723764837, accuracy 0.35185185185185186\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m [Client 98] fit, config: {'current_round': 7, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m Epoch 1: train loss 0.0002178474242100492, accuracy 0.4444444444444444\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m [Client 50] fit, config: {'current_round': 7, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m Epoch 1: train loss 0.00022114462626632303, accuracy 0.2222222222222222\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m [Client 13] fit, config: {'current_round': 7, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m Epoch 1: train loss 0.0002219582092948258, accuracy 0.3148148148148148\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m [Client 97] fit, config: {'current_round': 7, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m [Client 23] fit, config: {'current_round': 7, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m [Client 45] fit, config: {'current_round': 7, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m Epoch 1: train loss 0.00021614973957184702, accuracy 0.4444444444444444\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m Epoch 1: train loss 0.000219915178604424, accuracy 0.3148148148148148\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m [Client 20] fit, config: {'current_round': 7, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m Epoch 1: train loss 0.0002193900872953236, accuracy 0.37037037037037035\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m Epoch 1: train loss 0.00021903896413277835, accuracy 0.3888888888888889\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m [Client 70] fit, config: {'current_round': 7, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m [Client 7] fit, config: {'current_round': 7, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m [Client 61] fit, config: {'current_round': 7, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m Epoch 1: train loss 0.00022134275059215724, accuracy 0.2962962962962963\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m [Client 3] fit, config: {'current_round': 7, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m Epoch 1: train loss 0.00022010404791217297, accuracy 0.3148148148148148\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 12:54:45,490 | server.py:216 | fit_round received 30 results and 0 failures\n",
      "DEBUG flower 2023-02-01 12:54:45,528 | server.py:157 | evaluate_round: strategy sampled 30 clients (out of 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving round 7 aggregated_parameters...\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m [Client 80] fit, config: {'current_round': 7, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m Epoch 1: train loss 0.00021953134273644537, accuracy 0.37037037037037035\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m [Client 4] fit, config: {'current_round': 7, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m Epoch 1: train loss 0.00021900694991927594, accuracy 0.4074074074074074\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m Epoch 1: train loss 0.00022102556249592453, accuracy 0.2777777777777778\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m [Client 22] fit, config: {'current_round': 7, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m Epoch 1: train loss 0.0002184828044846654, accuracy 0.37037037037037035\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m [Client 6] fit, config: {'current_round': 7, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m Epoch 1: train loss 0.00021787801233585924, accuracy 0.3888888888888889\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m Epoch 1: train loss 0.00022014934802427888, accuracy 0.37037037037037035\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98091)\u001b[0m [Client 0] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98090)\u001b[0m [Client 71] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98091)\u001b[0m [Client 73] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98090)\u001b[0m [Client 83] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98091)\u001b[0m [Client 85] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98091)\u001b[0m [Client 2] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98090)\u001b[0m [Client 25] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98089)\u001b[0m [Client 69] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98088)\u001b[0m [Client 53] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98095)\u001b[0m [Client 70] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98093)\u001b[0m [Client 92] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98094)\u001b[0m [Client 84] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98092)\u001b[0m [Client 64] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98091)\u001b[0m [Client 30] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98090)\u001b[0m [Client 50] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98090)\u001b[0m [Client 49] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98090)\u001b[0m [Client 72] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98091)\u001b[0m [Client 1] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98090)\u001b[0m [Client 58] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98095)\u001b[0m [Client 90] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98091)\u001b[0m [Client 34] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98090)\u001b[0m [Client 61] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98093)\u001b[0m [Client 43] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98091)\u001b[0m [Client 88] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98088)\u001b[0m [Client 21] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98095)\u001b[0m [Client 33] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98093)\u001b[0m [Client 89] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98094)\u001b[0m [Client 28] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98092)\u001b[0m [Client 13] evaluate, config: {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 12:54:47,335 | server.py:170 | evaluate_round received 0 results and 30 failures\n",
      "DEBUG flower 2023-02-01 12:54:47,336 | server.py:203 | fit_round: strategy sampled 30 clients (out of 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98090)\u001b[0m [Client 68] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m [Client 79] fit, config: {'current_round': 8, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m Epoch 1: train loss 0.00021325424313545227, accuracy 0.35185185185185186\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m [Client 97] fit, config: {'current_round': 8, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m Epoch 1: train loss 0.00021615877631120384, accuracy 0.3148148148148148\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m [Client 74] fit, config: {'current_round': 8, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m Epoch 1: train loss 0.00021381006808951497, accuracy 0.3888888888888889\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m [Client 4] fit, config: {'current_round': 8, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m Epoch 1: train loss 0.0002157600101782009, accuracy 0.42592592592592593\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m [Client 26] fit, config: {'current_round': 8, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m Epoch 1: train loss 0.00021675699099432677, accuracy 0.3888888888888889\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(raylet)\u001b[0m Spilled 17271 MiB, 586 objects, write throughput 1682 MiB/s.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m [Client 11] fit, config: {'current_round': 8, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m Epoch 1: train loss 0.00021739938529208302, accuracy 0.37037037037037035\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m [Client 41] fit, config: {'current_round': 8, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m Epoch 1: train loss 0.00021935229597147554, accuracy 0.3333333333333333\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m [Client 90] fit, config: {'current_round': 8, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m Epoch 1: train loss 0.0002136518742190674, accuracy 0.4074074074074074\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m [Client 73] fit, config: {'current_round': 8, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m Epoch 1: train loss 0.0002138257259503007, accuracy 0.5\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m [Client 5] fit, config: {'current_round': 8, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m Epoch 1: train loss 0.00021555750572588295, accuracy 0.2777777777777778\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m [Client 52] fit, config: {'current_round': 8, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m Epoch 1: train loss 0.00021214642038103193, accuracy 0.46296296296296297\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m [Client 40] fit, config: {'current_round': 8, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m Epoch 1: train loss 0.00021350414317566901, accuracy 0.37037037037037035\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m [Client 93] fit, config: {'current_round': 8, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m Epoch 1: train loss 0.00021486790501512587, accuracy 0.4444444444444444\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m [Client 14] fit, config: {'current_round': 8, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m Epoch 1: train loss 0.0002146166079910472, accuracy 0.37037037037037035\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m [Client 71] fit, config: {'current_round': 8, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m Epoch 1: train loss 0.0002157842682208866, accuracy 0.35185185185185186\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m [Client 75] fit, config: {'current_round': 8, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m Epoch 1: train loss 0.00021303196263033897, accuracy 0.42592592592592593\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m [Client 6] fit, config: {'current_round': 8, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m Epoch 1: train loss 0.00021372264018282294, accuracy 0.4074074074074074\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m [Client 77] fit, config: {'current_round': 8, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m Epoch 1: train loss 0.00021379954705480486, accuracy 0.4074074074074074\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 12:54:49,064 | server.py:216 | fit_round received 30 results and 0 failures\n",
      "DEBUG flower 2023-02-01 12:54:49,101 | server.py:157 | evaluate_round: strategy sampled 30 clients (out of 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m [Client 0] fit, config: {'current_round': 8, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m Epoch 1: train loss 0.00021505520271603018, accuracy 0.3148148148148148\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m [Client 21] fit, config: {'current_round': 8, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m Epoch 1: train loss 0.00021941967133898288, accuracy 0.2037037037037037\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m [Client 78] fit, config: {'current_round': 8, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m Epoch 1: train loss 0.0002142580779036507, accuracy 0.4074074074074074\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m [Client 68] fit, config: {'current_round': 8, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m [Client 13] fit, config: {'current_round': 8, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m [Client 33] fit, config: {'current_round': 8, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m Epoch 1: train loss 0.0002156666450900957, accuracy 0.42592592592592593\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m Epoch 1: train loss 0.0002188111247960478, accuracy 0.3148148148148148\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m [Client 67] fit, config: {'current_round': 8, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m [Client 92] fit, config: {'current_round': 8, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m Epoch 1: train loss 0.0002140354918083176, accuracy 0.4444444444444444\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m Epoch 1: train loss 0.00021549040684476495, accuracy 0.3333333333333333\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m [Client 58] fit, config: {'current_round': 8, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m [Client 62] fit, config: {'current_round': 8, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m [Client 61] fit, config: {'current_round': 8, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m Epoch 1: train loss 0.00021743073011748493, accuracy 0.3888888888888889\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m Epoch 1: train loss 0.00021772512991447002, accuracy 0.2777777777777778\n",
      "Saving round 8 aggregated_parameters...\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m [Client 31] fit, config: {'current_round': 8, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m Epoch 1: train loss 0.0002161510055884719, accuracy 0.4074074074074074\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m Epoch 1: train loss 0.00021725289116147906, accuracy 0.2962962962962963\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m Epoch 1: train loss 0.0002158579882234335, accuracy 0.4074074074074074\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98090)\u001b[0m [Client 59] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98090)\u001b[0m [Client 27] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98090)\u001b[0m [Client 66] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98090)\u001b[0m [Client 3] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98088)\u001b[0m [Client 86] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98095)\u001b[0m [Client 84] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98089)\u001b[0m [Client 55] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98094)\u001b[0m [Client 61] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98092)\u001b[0m [Client 29] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98095)\u001b[0m [Client 97] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98088)\u001b[0m [Client 41] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98095)\u001b[0m [Client 73] evaluate, config: {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 12:54:50,846 | server.py:170 | evaluate_round received 0 results and 30 failures\n",
      "DEBUG flower 2023-02-01 12:54:50,847 | server.py:203 | fit_round: strategy sampled 30 clients (out of 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98088)\u001b[0m [Client 92] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98095)\u001b[0m [Client 36] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98094)\u001b[0m [Client 77] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98091)\u001b[0m [Client 23] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98090)\u001b[0m [Client 96] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98088)\u001b[0m [Client 62] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98095)\u001b[0m [Client 88] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98093)\u001b[0m [Client 38] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98089)\u001b[0m [Client 19] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98094)\u001b[0m [Client 87] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98094)\u001b[0m [Client 25] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98092)\u001b[0m [Client 6] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98091)\u001b[0m [Client 12] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98088)\u001b[0m [Client 72] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98095)\u001b[0m [Client 80] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98089)\u001b[0m [Client 90] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98094)\u001b[0m [Client 44] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98092)\u001b[0m [Client 76] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m [Client 8] fit, config: {'current_round': 9, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m Epoch 1: train loss 0.0002146278857253492, accuracy 0.3148148148148148\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m [Client 71] fit, config: {'current_round': 9, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m Epoch 1: train loss 0.00021170247055124491, accuracy 0.35185185185185186\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m [Client 7] fit, config: {'current_round': 9, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m Epoch 1: train loss 0.00021222025679890066, accuracy 0.2962962962962963\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m [Client 79] fit, config: {'current_round': 9, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m [Client 97] fit, config: {'current_round': 9, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m Epoch 1: train loss 0.0002083898289129138, accuracy 0.37037037037037035\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m [Client 17] fit, config: {'current_round': 9, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m [Client 39] fit, config: {'current_round': 9, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m Epoch 1: train loss 0.0002121917495969683, accuracy 0.2962962962962963\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m [Client 40] fit, config: {'current_round': 9, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m [Client 21] fit, config: {'current_round': 9, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m Epoch 1: train loss 0.00021625834051519632, accuracy 0.2037037037037037\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m [Client 41] fit, config: {'current_round': 9, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m Epoch 1: train loss 0.00021569897944573313, accuracy 0.3333333333333333\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m Epoch 1: train loss 0.00020829321874771267, accuracy 0.37037037037037035\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m [Client 6] fit, config: {'current_round': 9, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m Epoch 1: train loss 0.0002092055801767856, accuracy 0.4074074074074074\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m [Client 54] fit, config: {'current_round': 9, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m Epoch 1: train loss 0.0002112197398673743, accuracy 0.4074074074074074\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m Epoch 1: train loss 0.00020757901074830443, accuracy 0.3888888888888889\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m [Client 12] fit, config: {'current_round': 9, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m Epoch 1: train loss 0.0002087358880089596, accuracy 0.3888888888888889\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m Epoch 1: train loss 0.00021054282842669636, accuracy 0.35185185185185186\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m [Client 26] fit, config: {'current_round': 9, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m Epoch 1: train loss 0.0002125013998011127, accuracy 0.4074074074074074\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m [Client 27] fit, config: {'current_round': 9, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m Epoch 1: train loss 0.00020997296087443829, accuracy 0.42592592592592593\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m [Client 22] fit, config: {'current_round': 9, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m Epoch 1: train loss 0.00021023204317316413, accuracy 0.3888888888888889\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m [Client 93] fit, config: {'current_round': 9, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m Epoch 1: train loss 0.00021012280194554478, accuracy 0.4444444444444444\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m [Client 35] fit, config: {'current_round': 9, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m Epoch 1: train loss 0.0002094295050483197, accuracy 0.37037037037037035\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m [Client 72] fit, config: {'current_round': 9, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m Epoch 1: train loss 0.0002108757325913757, accuracy 0.35185185185185186\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m [Client 68] fit, config: {'current_round': 9, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m Epoch 1: train loss 0.00021064607426524162, accuracy 0.35185185185185186\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m [Client 88] fit, config: {'current_round': 9, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m Epoch 1: train loss 0.0002119927667081356, accuracy 0.42592592592592593\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m [Client 42] fit, config: {'current_round': 9, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m [Client 84] fit, config: {'current_round': 9, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m [Client 15] fit, config: {'current_round': 9, 'local_epochs': 3}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 12:54:52,747 | server.py:216 | fit_round received 30 results and 0 failures\n",
      "DEBUG flower 2023-02-01 12:54:52,791 | server.py:157 | evaluate_round: strategy sampled 30 clients (out of 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m [Client 92] fit, config: {'current_round': 9, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m Epoch 1: train loss 0.00020921802206430584, accuracy 0.4444444444444444\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m Epoch 1: train loss 0.00021126623323652893, accuracy 0.42592592592592593\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m [Client 32] fit, config: {'current_round': 9, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m Epoch 1: train loss 0.0002125137107213959, accuracy 0.35185185185185186\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m [Client 29] fit, config: {'current_round': 9, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m Epoch 1: train loss 0.00020998084801249206, accuracy 0.4074074074074074\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m Epoch 1: train loss 0.00020975714141968638, accuracy 0.4444444444444444\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m [Client 3] fit, config: {'current_round': 9, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m Epoch 1: train loss 0.0002128584892489016, accuracy 0.37037037037037035\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m [Client 46] fit, config: {'current_round': 9, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m Epoch 1: train loss 0.00020948503515683115, accuracy 0.48148148148148145\n",
      "Saving round 9 aggregated_parameters...\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m [Client 98] fit, config: {'current_round': 9, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m Epoch 1: train loss 0.00020977870735805482, accuracy 0.42592592592592593\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m Epoch 1: train loss 0.00021209733677096665, accuracy 0.3888888888888889\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98095)\u001b[0m [Client 76] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98088)\u001b[0m [Client 3] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98095)\u001b[0m [Client 13] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98089)\u001b[0m [Client 64] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98092)\u001b[0m [Client 46] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98089)\u001b[0m [Client 80] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98088)\u001b[0m [Client 8] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98089)\u001b[0m [Client 36] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98089)\u001b[0m [Client 72] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98088)\u001b[0m [Client 45] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98089)\u001b[0m [Client 52] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98089)\u001b[0m [Client 43] evaluate, config: {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 12:54:54,526 | server.py:170 | evaluate_round received 0 results and 30 failures\n",
      "DEBUG flower 2023-02-01 12:54:54,528 | server.py:203 | fit_round: strategy sampled 30 clients (out of 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98091)\u001b[0m [Client 39] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98095)\u001b[0m [Client 81] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98093)\u001b[0m [Client 84] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98092)\u001b[0m [Client 86] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98091)\u001b[0m [Client 89] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98090)\u001b[0m [Client 83] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98088)\u001b[0m [Client 69] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98095)\u001b[0m [Client 20] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98089)\u001b[0m [Client 24] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98094)\u001b[0m [Client 97] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98092)\u001b[0m [Client 23] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98091)\u001b[0m [Client 56] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98090)\u001b[0m [Client 77] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98088)\u001b[0m [Client 12] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98095)\u001b[0m [Client 29] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98089)\u001b[0m [Client 21] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98094)\u001b[0m [Client 6] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98092)\u001b[0m [Client 57] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m [Client 60] fit, config: {'current_round': 10, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m Epoch 1: train loss 0.00021022513101343066, accuracy 0.2962962962962963\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m [Client 94] fit, config: {'current_round': 10, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m Epoch 1: train loss 0.00020567889441736042, accuracy 0.4074074074074074\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m [Client 51] fit, config: {'current_round': 10, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m Epoch 1: train loss 0.0002041915722656995, accuracy 0.42592592592592593\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m [Client 35] fit, config: {'current_round': 10, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m [Client 77] fit, config: {'current_round': 10, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m Epoch 1: train loss 0.00020454320474527776, accuracy 0.42592592592592593\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m Epoch 1: train loss 0.00020468862203415483, accuracy 0.4074074074074074\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m [Client 63] fit, config: {'current_round': 10, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m Epoch 1: train loss 0.00020260030578356236, accuracy 0.5555555555555556\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m [Client 22] fit, config: {'current_round': 10, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m Epoch 1: train loss 0.00020592052896972746, accuracy 0.42592592592592593\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m [Client 30] fit, config: {'current_round': 10, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m Epoch 1: train loss 0.0002071160270133987, accuracy 0.37037037037037035\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m [Client 82] fit, config: {'current_round': 10, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m Epoch 1: train loss 0.0002036008081631735, accuracy 0.4074074074074074\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m [Client 42] fit, config: {'current_round': 10, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m Epoch 1: train loss 0.00020571744244080037, accuracy 0.46296296296296297\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m [Client 40] fit, config: {'current_round': 10, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m Epoch 1: train loss 0.0002033849450526759, accuracy 0.42592592592592593\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m [Client 0] fit, config: {'current_round': 10, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m Epoch 1: train loss 0.0002058904938166961, accuracy 0.3333333333333333\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m [Client 98] fit, config: {'current_round': 10, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m [Client 55] fit, config: {'current_round': 10, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m Epoch 1: train loss 0.0002042246633209288, accuracy 0.3888888888888889\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m Epoch 1: train loss 0.00020398008928168565, accuracy 0.42592592592592593\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m [Client 68] fit, config: {'current_round': 10, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m [Client 45] fit, config: {'current_round': 10, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m Epoch 1: train loss 0.0002016154321609065, accuracy 0.48148148148148145\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m [Client 10] fit, config: {'current_round': 10, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m [Client 76] fit, config: {'current_round': 10, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m Epoch 1: train loss 0.00020245030464138836, accuracy 0.4444444444444444\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m [Client 69] fit, config: {'current_round': 10, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m Epoch 1: train loss 0.00020475943165365607, accuracy 0.3888888888888889\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m Epoch 1: train loss 0.00020541042613331228, accuracy 0.3888888888888889\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m [Client 14] fit, config: {'current_round': 10, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m Epoch 1: train loss 0.00020445942936930805, accuracy 0.3888888888888889\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m Epoch 1: train loss 0.00020773954747710377, accuracy 0.3333333333333333\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m [Client 17] fit, config: {'current_round': 10, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m Epoch 1: train loss 0.00020282268815208226, accuracy 0.4074074074074074\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m [Client 2] fit, config: {'current_round': 10, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m Epoch 1: train loss 0.0002019666862906888, accuracy 0.46296296296296297\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m [Client 79] fit, config: {'current_round': 10, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m Epoch 1: train loss 0.00020293111447244883, accuracy 0.42592592592592593\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 12:54:56,295 | server.py:216 | fit_round received 30 results and 0 failures\n",
      "DEBUG flower 2023-02-01 12:54:56,332 | server.py:157 | evaluate_round: strategy sampled 30 clients (out of 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m [Client 50] fit, config: {'current_round': 10, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m [Client 19] fit, config: {'current_round': 10, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m [Client 24] fit, config: {'current_round': 10, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m Epoch 1: train loss 0.0002004391426453367, accuracy 0.46296296296296297\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m [Client 56] fit, config: {'current_round': 10, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m [Client 96] fit, config: {'current_round': 10, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m [Client 66] fit, config: {'current_round': 10, 'local_epochs': 3}\n",
      "Saving round 10 aggregated_parameters...\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m Epoch 1: train loss 0.0002075667871395126, accuracy 0.25925925925925924\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m Epoch 1: train loss 0.00020700838649645448, accuracy 0.3148148148148148\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m [Client 70] fit, config: {'current_round': 10, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m Epoch 1: train loss 0.00020806973043363541, accuracy 0.3888888888888889\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m Epoch 1: train loss 0.00020666036289185286, accuracy 0.37037037037037035\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m Epoch 1: train loss 0.0002033005002886057, accuracy 0.46296296296296297\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m Epoch 1: train loss 0.00020750741532538086, accuracy 0.4074074074074074\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98088)\u001b[0m [Client 27] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98091)\u001b[0m [Client 20] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98090)\u001b[0m [Client 84] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98089)\u001b[0m [Client 10] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98090)\u001b[0m [Client 29] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98090)\u001b[0m [Client 1] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98090)\u001b[0m [Client 14] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98091)\u001b[0m [Client 66] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98090)\u001b[0m [Client 58] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98088)\u001b[0m [Client 89] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98091)\u001b[0m [Client 22] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98090)\u001b[0m [Client 33] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98089)\u001b[0m [Client 18] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98089)\u001b[0m [Client 86] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98094)\u001b[0m [Client 94] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98094)\u001b[0m [Client 7] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98094)\u001b[0m [Client 65] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98091)\u001b[0m [Client 71] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98089)\u001b[0m [Client 83] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98094)\u001b[0m [Client 40] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98094)\u001b[0m [Client 28] evaluate, config: {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 12:54:57,981 | server.py:170 | evaluate_round received 0 results and 30 failures\n",
      "DEBUG flower 2023-02-01 12:54:57,982 | server.py:203 | fit_round: strategy sampled 30 clients (out of 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98091)\u001b[0m [Client 24] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98090)\u001b[0m [Client 11] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98088)\u001b[0m [Client 67] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98095)\u001b[0m [Client 44] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98093)\u001b[0m [Client 85] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98089)\u001b[0m [Client 99] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98094)\u001b[0m [Client 57] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98094)\u001b[0m [Client 78] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98092)\u001b[0m [Client 41] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m [Client 40] fit, config: {'current_round': 11, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m Epoch 1: train loss 0.00019744700693991035, accuracy 0.4074074074074074\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m [Client 47] fit, config: {'current_round': 11, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m Epoch 1: train loss 0.0001984481350518763, accuracy 0.5\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m [Client 36] fit, config: {'current_round': 11, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m Epoch 1: train loss 0.0002084169100271538, accuracy 0.2962962962962963\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m [Client 62] fit, config: {'current_round': 11, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m Epoch 1: train loss 0.00020158899133093655, accuracy 0.42592592592592593\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m [Client 52] fit, config: {'current_round': 11, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m Epoch 1: train loss 0.00019599850929807872, accuracy 0.4444444444444444\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m [Client 33] fit, config: {'current_round': 11, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m [Client 70] fit, config: {'current_round': 11, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m Epoch 1: train loss 0.00020260820747353137, accuracy 0.37037037037037035\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m Epoch 1: train loss 0.0001996045612031594, accuracy 0.4444444444444444\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m [Client 68] fit, config: {'current_round': 11, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m Epoch 1: train loss 0.0002004647540161386, accuracy 0.3333333333333333\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m [Client 20] fit, config: {'current_round': 11, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m Epoch 1: train loss 0.00020359859627205878, accuracy 0.37037037037037035\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m [Client 2] fit, config: {'current_round': 11, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m Epoch 1: train loss 0.00019565550610423088, accuracy 0.4444444444444444\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m [Client 59] fit, config: {'current_round': 11, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m Epoch 1: train loss 0.0002021711115958169, accuracy 0.4074074074074074\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m [Client 22] fit, config: {'current_round': 11, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m Epoch 1: train loss 0.0001988919684663415, accuracy 0.42592592592592593\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m [Client 89] fit, config: {'current_round': 11, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m Epoch 1: train loss 0.0002014317287830636, accuracy 0.3333333333333333\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m [Client 34] fit, config: {'current_round': 11, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m Epoch 1: train loss 0.00020368528203107417, accuracy 0.2962962962962963\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m [Client 7] fit, config: {'current_round': 11, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m Epoch 1: train loss 0.00020087818847969174, accuracy 0.2777777777777778\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 12:54:59,764 | server.py:216 | fit_round received 30 results and 0 failures\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m [Client 17] fit, config: {'current_round': 11, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m Epoch 1: train loss 0.00019604981935117394, accuracy 0.37037037037037035\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m [Client 10] fit, config: {'current_round': 11, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m Epoch 1: train loss 0.00020207672787364572, accuracy 0.2962962962962963\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m [Client 9] fit, config: {'current_round': 11, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m Epoch 1: train loss 0.00020399969071149826, accuracy 0.2777777777777778\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m [Client 14] fit, config: {'current_round': 11, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m Epoch 1: train loss 0.0001978608052013442, accuracy 0.37037037037037035\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m [Client 56] fit, config: {'current_round': 11, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m Epoch 1: train loss 0.00020155317906755954, accuracy 0.37037037037037035\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m [Client 58] fit, config: {'current_round': 11, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m Epoch 1: train loss 0.00020467996364459395, accuracy 0.4074074074074074\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m [Client 72] fit, config: {'current_round': 11, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m Epoch 1: train loss 0.00020050775492563844, accuracy 0.3333333333333333\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m [Client 48] fit, config: {'current_round': 11, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m Epoch 1: train loss 0.00019965851970482618, accuracy 0.3888888888888889\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m [Client 39] fit, config: {'current_round': 11, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m Epoch 1: train loss 0.00019525145762600005, accuracy 0.42592592592592593\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m [Client 27] fit, config: {'current_round': 11, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m Epoch 1: train loss 0.00020017339556943625, accuracy 0.4444444444444444\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m [Client 74] fit, config: {'current_round': 11, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m Epoch 1: train loss 0.00019816483836621046, accuracy 0.3888888888888889\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m [Client 87] fit, config: {'current_round': 11, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m Epoch 1: train loss 0.00020307055092416704, accuracy 0.4074074074074074\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m [Client 93] fit, config: {'current_round': 11, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m [Client 60] fit, config: {'current_round': 11, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m Epoch 1: train loss 0.00020646798657253385, accuracy 0.2962962962962963\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 12:54:59,806 | server.py:157 | evaluate_round: strategy sampled 30 clients (out of 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving round 11 aggregated_parameters...\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m [Client 91] fit, config: {'current_round': 11, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m Epoch 1: train loss 0.00019664864521473646, accuracy 0.37037037037037035\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m Epoch 1: train loss 0.00020031728490721434, accuracy 0.42592592592592593\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98094)\u001b[0m [Client 51] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98091)\u001b[0m [Client 74] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98091)\u001b[0m [Client 44] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98094)\u001b[0m [Client 90] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98091)\u001b[0m [Client 9] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98091)\u001b[0m [Client 70] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98094)\u001b[0m [Client 49] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98091)\u001b[0m [Client 31] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98088)\u001b[0m [Client 15] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98095)\u001b[0m [Client 29] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98094)\u001b[0m [Client 41] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98088)\u001b[0m [Client 14] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98094)\u001b[0m [Client 95] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98088)\u001b[0m [Client 68] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98088)\u001b[0m [Client 42] evaluate, config: {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 12:55:01,487 | server.py:170 | evaluate_round received 0 results and 30 failures\n",
      "DEBUG flower 2023-02-01 12:55:01,488 | server.py:203 | fit_round: strategy sampled 30 clients (out of 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98088)\u001b[0m [Client 97] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98095)\u001b[0m [Client 19] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98094)\u001b[0m [Client 2] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98091)\u001b[0m [Client 6] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98090)\u001b[0m [Client 67] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98088)\u001b[0m [Client 12] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98088)\u001b[0m [Client 16] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98095)\u001b[0m [Client 40] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98093)\u001b[0m [Client 87] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98094)\u001b[0m [Client 25] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98092)\u001b[0m [Client 88] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98088)\u001b[0m [Client 50] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98093)\u001b[0m [Client 45] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98091)\u001b[0m [Client 76] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98090)\u001b[0m [Client 96] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m [Client 17] fit, config: {'current_round': 12, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m Epoch 1: train loss 0.0001907599944388494, accuracy 0.4444444444444444\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m [Client 12] fit, config: {'current_round': 12, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m Epoch 1: train loss 0.00019315755343995988, accuracy 0.42592592592592593\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m [Client 30] fit, config: {'current_round': 12, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m [Client 1] fit, config: {'current_round': 12, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m Epoch 1: train loss 0.00019198976224288344, accuracy 0.5185185185185185\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m [Client 53] fit, config: {'current_round': 12, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m Epoch 1: train loss 0.0001925142714753747, accuracy 0.35185185185185186\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m Epoch 1: train loss 0.00019677735690493137, accuracy 0.3888888888888889\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m [Client 43] fit, config: {'current_round': 12, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m Epoch 1: train loss 0.00019397452706471086, accuracy 0.42592592592592593\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m [Client 80] fit, config: {'current_round': 12, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m Epoch 1: train loss 0.00019083404913544655, accuracy 0.46296296296296297\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m [Client 69] fit, config: {'current_round': 12, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m Epoch 1: train loss 0.00019260482804384083, accuracy 0.3888888888888889\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m [Client 67] fit, config: {'current_round': 12, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m Epoch 1: train loss 0.00020159015548415482, accuracy 0.3333333333333333\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m [Client 55] fit, config: {'current_round': 12, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m Epoch 1: train loss 0.00019248078751843423, accuracy 0.42592592592592593\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m [Client 18] fit, config: {'current_round': 12, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m Epoch 1: train loss 0.00019561518274713308, accuracy 0.42592592592592593\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m [Client 71] fit, config: {'current_round': 12, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m Epoch 1: train loss 0.00019700736447703093, accuracy 0.3888888888888889\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m [Client 94] fit, config: {'current_round': 12, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m Epoch 1: train loss 0.0001939393550856039, accuracy 0.4444444444444444\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m [Client 27] fit, config: {'current_round': 12, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m Epoch 1: train loss 0.0001939603389473632, accuracy 0.4444444444444444\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m [Client 15] fit, config: {'current_round': 12, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m Epoch 1: train loss 0.0001976391504285857, accuracy 0.42592592592592593\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m [Client 16] fit, config: {'current_round': 12, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m Epoch 1: train loss 0.00019367769709788263, accuracy 0.3888888888888889\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m [Client 42] fit, config: {'current_round': 12, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m [Client 98] fit, config: {'current_round': 12, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m Epoch 1: train loss 0.00019058489124290645, accuracy 0.42592592592592593\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m Epoch 1: train loss 0.00019347855413798243, accuracy 0.48148148148148145\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m [Client 14] fit, config: {'current_round': 12, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m Epoch 1: train loss 0.00019253359641879797, accuracy 0.3888888888888889\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m [Client 19] fit, config: {'current_round': 12, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m Epoch 1: train loss 0.0001948273420566693, accuracy 0.3148148148148148\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m [Client 65] fit, config: {'current_round': 12, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m [Client 40] fit, config: {'current_round': 12, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m Epoch 1: train loss 0.00019078933109994978, accuracy 0.48148148148148145\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 12:55:03,514 | server.py:216 | fit_round received 30 results and 0 failures\n",
      "DEBUG flower 2023-02-01 12:55:03,553 | server.py:157 | evaluate_round: strategy sampled 30 clients (out of 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m [Client 84] fit, config: {'current_round': 12, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m Epoch 1: train loss 0.0001906143152154982, accuracy 0.46296296296296297\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m [Client 50] fit, config: {'current_round': 12, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m Epoch 1: train loss 0.0001961415255209431, accuracy 0.2962962962962963\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m Epoch 1: train loss 0.00019290078489575535, accuracy 0.3888888888888889\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m [Client 48] fit, config: {'current_round': 12, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m Epoch 1: train loss 0.00019499020709190518, accuracy 0.3888888888888889\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m [Client 72] fit, config: {'current_round': 12, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m Epoch 1: train loss 0.00019333932141307741, accuracy 0.42592592592592593\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m [Client 10] fit, config: {'current_round': 12, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m Epoch 1: train loss 0.00019755012181121856, accuracy 0.35185185185185186\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m [Client 60] fit, config: {'current_round': 12, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m Epoch 1: train loss 0.00020054368360433728, accuracy 0.3148148148148148\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m [Client 62] fit, config: {'current_round': 12, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m Epoch 1: train loss 0.00019409324158914387, accuracy 0.4444444444444444\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m [Client 51] fit, config: {'current_round': 12, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m Epoch 1: train loss 0.0001918001362355426, accuracy 0.42592592592592593\n",
      "Saving round 12 aggregated_parameters...\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98091)\u001b[0m [Client 78] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98090)\u001b[0m [Client 67] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98093)\u001b[0m [Client 53] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98094)\u001b[0m [Client 89] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98092)\u001b[0m [Client 4] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98090)\u001b[0m [Client 54] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98088)\u001b[0m [Client 1] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98088)\u001b[0m [Client 85] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98090)\u001b[0m [Client 40] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98088)\u001b[0m [Client 6] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98093)\u001b[0m [Client 43] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98091)\u001b[0m [Client 63] evaluate, config: {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 12:55:05,240 | server.py:170 | evaluate_round received 0 results and 30 failures\n",
      "DEBUG flower 2023-02-01 12:55:05,241 | server.py:203 | fit_round: strategy sampled 30 clients (out of 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98090)\u001b[0m [Client 19] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98093)\u001b[0m [Client 72] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98091)\u001b[0m [Client 51] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98090)\u001b[0m [Client 41] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98088)\u001b[0m [Client 20] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98093)\u001b[0m [Client 81] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98094)\u001b[0m [Client 35] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98092)\u001b[0m [Client 2] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98090)\u001b[0m [Client 23] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98095)\u001b[0m [Client 27] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98089)\u001b[0m [Client 25] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98091)\u001b[0m [Client 77] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98090)\u001b[0m [Client 75] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98088)\u001b[0m [Client 9] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98095)\u001b[0m [Client 12] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98093)\u001b[0m [Client 10] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98089)\u001b[0m [Client 87] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98094)\u001b[0m [Client 71] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m [Client 45] fit, config: {'current_round': 13, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m Epoch 1: train loss 0.00018148310482501984, accuracy 0.5185185185185185\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m [Client 0] fit, config: {'current_round': 13, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m Epoch 1: train loss 0.00018725072732195258, accuracy 0.46296296296296297\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m [Client 79] fit, config: {'current_round': 13, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m Epoch 1: train loss 0.00018212241411674768, accuracy 0.46296296296296297\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m [Client 81] fit, config: {'current_round': 13, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m Epoch 1: train loss 0.00018880527932196856, accuracy 0.3888888888888889\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m [Client 61] fit, config: {'current_round': 13, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m Epoch 1: train loss 0.00018925467156805098, accuracy 0.46296296296296297\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m [Client 75] fit, config: {'current_round': 13, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m Epoch 1: train loss 0.00018137045844923705, accuracy 0.5\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m [Client 72] fit, config: {'current_round': 13, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m Epoch 1: train loss 0.00018733442993834615, accuracy 0.46296296296296297\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m [Client 85] fit, config: {'current_round': 13, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m Epoch 1: train loss 0.00018714633188210428, accuracy 0.3888888888888889\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m [Client 53] fit, config: {'current_round': 13, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m Epoch 1: train loss 0.0001857954921433702, accuracy 0.42592592592592593\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m [Client 36] fit, config: {'current_round': 13, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m Epoch 1: train loss 0.0001977430219994858, accuracy 0.3333333333333333\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m [Client 46] fit, config: {'current_round': 13, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m Epoch 1: train loss 0.00018439500126987696, accuracy 0.5370370370370371\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m [Client 16] fit, config: {'current_round': 13, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m Epoch 1: train loss 0.00018701670342124999, accuracy 0.4074074074074074\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m [Client 47] fit, config: {'current_round': 13, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m [Client 50] fit, config: {'current_round': 13, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m Epoch 1: train loss 0.00018803392595145851, accuracy 0.3333333333333333\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m [Client 3] fit, config: {'current_round': 13, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m [Client 65] fit, config: {'current_round': 13, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m Epoch 1: train loss 0.000184955817530863, accuracy 0.4444444444444444\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m Epoch 1: train loss 0.00018537732830736786, accuracy 0.48148148148148145\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m Epoch 1: train loss 0.00018920403090305626, accuracy 0.46296296296296297\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m [Client 32] fit, config: {'current_round': 13, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m Epoch 1: train loss 0.0001894029846880585, accuracy 0.4444444444444444\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m [Client 28] fit, config: {'current_round': 13, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m Epoch 1: train loss 0.00019040380720980465, accuracy 0.48148148148148145\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m [Client 15] fit, config: {'current_round': 13, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m [Client 43] fit, config: {'current_round': 13, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m Epoch 1: train loss 0.00018500628357287496, accuracy 0.5555555555555556\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m [Client 27] fit, config: {'current_round': 13, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m Epoch 1: train loss 0.00018742712563835084, accuracy 0.48148148148148145\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(raylet)\u001b[0m Spilled 32893 MiB, 1104 objects, write throughput 1449 MiB/s.\n",
      "DEBUG flower 2023-02-01 12:55:07,006 | server.py:216 | fit_round received 30 results and 0 failures\n",
      "DEBUG flower 2023-02-01 12:55:07,065 | server.py:157 | evaluate_round: strategy sampled 30 clients (out of 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m [Client 35] fit, config: {'current_round': 13, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m Epoch 1: train loss 0.00019194358901586384, accuracy 0.4444444444444444\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m [Client 10] fit, config: {'current_round': 13, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m Epoch 1: train loss 0.00018978898879140615, accuracy 0.42592592592592593\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m [Client 73] fit, config: {'current_round': 13, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m [Client 9] fit, config: {'current_round': 13, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m Epoch 1: train loss 0.0001926244149217382, accuracy 0.3148148148148148\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m [Client 40] fit, config: {'current_round': 13, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m Epoch 1: train loss 0.00018358914530836046, accuracy 0.4444444444444444\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m Epoch 1: train loss 0.0001871002750704065, accuracy 0.4074074074074074\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m [Client 82] fit, config: {'current_round': 13, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m Epoch 1: train loss 0.00018297668430022895, accuracy 0.48148148148148145\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m [Client 14] fit, config: {'current_round': 13, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m Epoch 1: train loss 0.00018469580390956253, accuracy 0.4444444444444444\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m [Client 84] fit, config: {'current_round': 13, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m Epoch 1: train loss 0.00018342913244850934, accuracy 0.5555555555555556\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m [Client 66] fit, config: {'current_round': 13, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m Epoch 1: train loss 0.00019034558499697596, accuracy 0.4074074074074074\n",
      "Saving round 13 aggregated_parameters...\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m Epoch 1: train loss 0.0001837133168010041, accuracy 0.5185185185185185\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98091)\u001b[0m [Client 51] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98091)\u001b[0m [Client 31] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98088)\u001b[0m [Client 24] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98092)\u001b[0m [Client 46] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98091)\u001b[0m [Client 0] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98088)\u001b[0m [Client 50] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98091)\u001b[0m [Client 89] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98088)\u001b[0m [Client 11] evaluate, config: {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 12:55:08,814 | server.py:170 | evaluate_round received 0 results and 30 failures\n",
      "DEBUG flower 2023-02-01 12:55:08,815 | server.py:203 | fit_round: strategy sampled 30 clients (out of 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98091)\u001b[0m [Client 23] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98091)\u001b[0m [Client 79] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98088)\u001b[0m [Client 7] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98091)\u001b[0m [Client 8] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98088)\u001b[0m [Client 33] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98092)\u001b[0m [Client 76] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98092)\u001b[0m [Client 75] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98091)\u001b[0m [Client 69] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98088)\u001b[0m [Client 87] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98093)\u001b[0m [Client 2] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98089)\u001b[0m [Client 59] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98092)\u001b[0m [Client 97] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98093)\u001b[0m [Client 16] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98093)\u001b[0m [Client 74] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98088)\u001b[0m [Client 62] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98092)\u001b[0m [Client 78] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98091)\u001b[0m [Client 36] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98090)\u001b[0m [Client 40] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98095)\u001b[0m [Client 34] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98093)\u001b[0m [Client 65] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98089)\u001b[0m [Client 60] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98094)\u001b[0m [Client 28] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m [Client 17] fit, config: {'current_round': 14, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m Epoch 1: train loss 0.0001757978170644492, accuracy 0.5185185185185185\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m [Client 49] fit, config: {'current_round': 14, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m Epoch 1: train loss 0.0001803588675102219, accuracy 0.4444444444444444\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m [Client 92] fit, config: {'current_round': 14, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m Epoch 1: train loss 0.0001759463775670156, accuracy 0.48148148148148145\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m [Client 73] fit, config: {'current_round': 14, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m Epoch 1: train loss 0.0001750168448779732, accuracy 0.42592592592592593\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m [Client 1] fit, config: {'current_round': 14, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m Epoch 1: train loss 0.0001766630302881822, accuracy 0.48148148148148145\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m [Client 45] fit, config: {'current_round': 14, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m Epoch 1: train loss 0.00017328023386653513, accuracy 0.5370370370370371\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m [Client 96] fit, config: {'current_round': 14, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m Epoch 1: train loss 0.00017731399566400796, accuracy 0.5185185185185185\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m [Client 88] fit, config: {'current_round': 14, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m [Client 3] fit, config: {'current_round': 14, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m [Client 62] fit, config: {'current_round': 14, 'local_epochs': 3}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 12:55:10,611 | server.py:216 | fit_round received 30 results and 0 failures\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m Epoch 1: train loss 0.00018384246504865587, accuracy 0.37037037037037035\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m Epoch 1: train loss 0.00018144297064282, accuracy 0.48148148148148145\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m [Client 44] fit, config: {'current_round': 14, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m [Client 41] fit, config: {'current_round': 14, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m Epoch 1: train loss 0.00018913258099928498, accuracy 0.3333333333333333\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m [Client 29] fit, config: {'current_round': 14, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m Epoch 1: train loss 0.00017854741599876434, accuracy 0.46296296296296297\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m [Client 15] fit, config: {'current_round': 14, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m Epoch 1: train loss 0.00017953268252313137, accuracy 0.46296296296296297\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m [Client 36] fit, config: {'current_round': 14, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m Epoch 1: train loss 0.00019078106561210006, accuracy 0.4074074074074074\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m [Client 28] fit, config: {'current_round': 14, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m Epoch 1: train loss 0.00018141821783501655, accuracy 0.4444444444444444\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m [Client 61] fit, config: {'current_round': 14, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m Epoch 1: train loss 0.00018253469897899777, accuracy 0.42592592592592593\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m Epoch 1: train loss 0.00018256397743243724, accuracy 0.4444444444444444\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m [Client 57] fit, config: {'current_round': 14, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m Epoch 1: train loss 0.0001875750458566472, accuracy 0.37037037037037035\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m Epoch 1: train loss 0.00018475655815564096, accuracy 0.4444444444444444\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m [Client 8] fit, config: {'current_round': 14, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m Epoch 1: train loss 0.00018700674991123378, accuracy 0.3333333333333333\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m [Client 81] fit, config: {'current_round': 14, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m [Client 94] fit, config: {'current_round': 14, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m Epoch 1: train loss 0.00017994189693126827, accuracy 0.48148148148148145\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m Epoch 1: train loss 0.00018245317914988846, accuracy 0.37037037037037035\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m [Client 99] fit, config: {'current_round': 14, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m [Client 12] fit, config: {'current_round': 14, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m [Client 58] fit, config: {'current_round': 14, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m Epoch 1: train loss 0.00018461770378053188, accuracy 0.37037037037037035\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m [Client 21] fit, config: {'current_round': 14, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m [Client 90] fit, config: {'current_round': 14, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m Epoch 1: train loss 0.00017662823665887117, accuracy 0.5\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m [Client 56] fit, config: {'current_round': 14, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m Epoch 1: train loss 0.00018061348237097263, accuracy 0.4444444444444444\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m [Client 76] fit, config: {'current_round': 14, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m Epoch 1: train loss 0.00017317022138740867, accuracy 0.5740740740740741\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 12:55:10,654 | server.py:157 | evaluate_round: strategy sampled 30 clients (out of 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving round 14 aggregated_parameters...\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m Epoch 1: train loss 0.00018148377421312034, accuracy 0.3888888888888889\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m Epoch 1: train loss 0.0001780376915121451, accuracy 0.5185185185185185\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m [Client 78] fit, config: {'current_round': 14, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m Epoch 1: train loss 0.00018179351172875613, accuracy 0.5\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m Epoch 1: train loss 0.000189620754099451, accuracy 0.3333333333333333\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m [Client 34] fit, config: {'current_round': 14, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m Epoch 1: train loss 0.00018414956866763532, accuracy 0.35185185185185186\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98094)\u001b[0m [Client 87] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98091)\u001b[0m [Client 3] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98095)\u001b[0m [Client 60] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98094)\u001b[0m [Client 70] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98091)\u001b[0m [Client 22] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98095)\u001b[0m [Client 56] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98091)\u001b[0m [Client 11] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98095)\u001b[0m [Client 40] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98094)\u001b[0m [Client 17] evaluate, config: {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 12:55:12,358 | server.py:170 | evaluate_round received 0 results and 30 failures\n",
      "DEBUG flower 2023-02-01 12:55:12,359 | server.py:203 | fit_round: strategy sampled 30 clients (out of 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98091)\u001b[0m [Client 71] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98094)\u001b[0m [Client 37] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98090)\u001b[0m [Client 6] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98095)\u001b[0m [Client 10] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98091)\u001b[0m [Client 73] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98090)\u001b[0m [Client 32] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98095)\u001b[0m [Client 88] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98094)\u001b[0m [Client 16] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98091)\u001b[0m [Client 19] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98091)\u001b[0m [Client 39] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98091)\u001b[0m [Client 48] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98090)\u001b[0m [Client 24] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98095)\u001b[0m [Client 30] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98093)\u001b[0m [Client 8] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98094)\u001b[0m [Client 20] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98091)\u001b[0m [Client 58] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98090)\u001b[0m [Client 53] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98095)\u001b[0m [Client 55] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98089)\u001b[0m [Client 76] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98094)\u001b[0m [Client 52] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98092)\u001b[0m [Client 23] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m [Client 3] fit, config: {'current_round': 15, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m [Client 22] fit, config: {'current_round': 15, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m Epoch 1: train loss 0.00017469696467742324, accuracy 0.5370370370370371\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m Epoch 1: train loss 0.00017569118062965572, accuracy 0.46296296296296297\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m [Client 23] fit, config: {'current_round': 15, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m Epoch 1: train loss 0.0001684017915977165, accuracy 0.5740740740740741\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m [Client 52] fit, config: {'current_round': 15, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m Epoch 1: train loss 0.00016752042574808002, accuracy 0.48148148148148145\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m [Client 13] fit, config: {'current_round': 15, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m Epoch 1: train loss 0.00018317505600862205, accuracy 0.4444444444444444\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m [Client 80] fit, config: {'current_round': 15, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m Epoch 1: train loss 0.00016535079339519143, accuracy 0.6111111111111112\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m [Client 19] fit, config: {'current_round': 15, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m Epoch 1: train loss 0.0001720171421766281, accuracy 0.5370370370370371\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m [Client 83] fit, config: {'current_round': 15, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m Epoch 1: train loss 0.00017394137103110552, accuracy 0.4074074074074074\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m [Client 29] fit, config: {'current_round': 15, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m [Client 27] fit, config: {'current_round': 15, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m Epoch 1: train loss 0.00017325849330518395, accuracy 0.5\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m [Client 95] fit, config: {'current_round': 15, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m [Client 77] fit, config: {'current_round': 15, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m Epoch 1: train loss 0.00017280320753343403, accuracy 0.42592592592592593\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m [Client 87] fit, config: {'current_round': 15, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m Epoch 1: train loss 0.00017424773250240833, accuracy 0.48148148148148145\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m [Client 54] fit, config: {'current_round': 15, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m Epoch 1: train loss 0.00017272777040489018, accuracy 0.46296296296296297\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m [Client 15] fit, config: {'current_round': 15, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m Epoch 1: train loss 0.00017833551100920886, accuracy 0.42592592592592593\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m [Client 51] fit, config: {'current_round': 15, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m Epoch 1: train loss 0.00017048692097887397, accuracy 0.5\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m Epoch 1: train loss 0.0001726780174067244, accuracy 0.5740740740740741\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m [Client 62] fit, config: {'current_round': 15, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m Epoch 1: train loss 0.00017368356930091977, accuracy 0.4444444444444444\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m Epoch 1: train loss 0.00016999624494928867, accuracy 0.5185185185185185\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m [Client 56] fit, config: {'current_round': 15, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m Epoch 1: train loss 0.00017366849351674318, accuracy 0.4444444444444444\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m [Client 8] fit, config: {'current_round': 15, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m Epoch 1: train loss 0.00017908653535414487, accuracy 0.4074074074074074\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m [Client 76] fit, config: {'current_round': 15, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m [Client 67] fit, config: {'current_round': 15, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m [Client 57] fit, config: {'current_round': 15, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m Epoch 1: train loss 0.00017859533545561135, accuracy 0.5\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m [Client 60] fit, config: {'current_round': 15, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m Epoch 1: train loss 0.00018112211546394974, accuracy 0.42592592592592593\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m Epoch 1: train loss 0.00016517617041245103, accuracy 0.5925925925925926\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m Epoch 1: train loss 0.0001837797462940216, accuracy 0.46296296296296297\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m [Client 10] fit, config: {'current_round': 15, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m Epoch 1: train loss 0.00017364400264341384, accuracy 0.46296296296296297\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m [Client 88] fit, config: {'current_round': 15, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m Epoch 1: train loss 0.000176153625943698, accuracy 0.46296296296296297\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m [Client 61] fit, config: {'current_round': 15, 'local_epochs': 3}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 12:55:14,186 | server.py:216 | fit_round received 30 results and 0 failures\n",
      "DEBUG flower 2023-02-01 12:55:14,227 | server.py:157 | evaluate_round: strategy sampled 30 clients (out of 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving round 15 aggregated_parameters...\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m [Client 81] fit, config: {'current_round': 15, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m Epoch 1: train loss 0.00017413200112059712, accuracy 0.4074074074074074\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m [Client 34] fit, config: {'current_round': 15, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m Epoch 1: train loss 0.00017479644156992435, accuracy 0.46296296296296297\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m [Client 84] fit, config: {'current_round': 15, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m Epoch 1: train loss 0.00016791281814221293, accuracy 0.5370370370370371\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m [Client 39] fit, config: {'current_round': 15, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m Epoch 1: train loss 0.00016866246005520225, accuracy 0.5555555555555556\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m Epoch 1: train loss 0.0001728994830045849, accuracy 0.48148148148148145\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98089)\u001b[0m [Client 14] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98089)\u001b[0m [Client 64] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98095)\u001b[0m [Client 26] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98089)\u001b[0m [Client 34] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98095)\u001b[0m [Client 16] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98095)\u001b[0m [Client 54] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98095)\u001b[0m [Client 43] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98089)\u001b[0m [Client 99] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98095)\u001b[0m [Client 86] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98095)\u001b[0m [Client 15] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98089)\u001b[0m [Client 58] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98089)\u001b[0m [Client 11] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98089)\u001b[0m [Client 98] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98089)\u001b[0m [Client 52] evaluate, config: {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 12:55:15,975 | server.py:170 | evaluate_round received 0 results and 30 failures\n",
      "DEBUG flower 2023-02-01 12:55:15,976 | server.py:203 | fit_round: strategy sampled 30 clients (out of 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98091)\u001b[0m [Client 39] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98088)\u001b[0m [Client 1] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98089)\u001b[0m [Client 19] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98091)\u001b[0m [Client 69] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98088)\u001b[0m [Client 4] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98095)\u001b[0m [Client 8] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98091)\u001b[0m [Client 3] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98088)\u001b[0m [Client 46] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98095)\u001b[0m [Client 36] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98091)\u001b[0m [Client 32] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98088)\u001b[0m [Client 67] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98095)\u001b[0m [Client 92] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98093)\u001b[0m [Client 55] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98089)\u001b[0m [Client 80] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98094)\u001b[0m [Client 18] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98092)\u001b[0m [Client 82] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m [Client 77] fit, config: {'current_round': 16, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m Epoch 1: train loss 0.00016938798944465816, accuracy 0.48148148148148145\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m [Client 69] fit, config: {'current_round': 16, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m Epoch 1: train loss 0.0001633043575566262, accuracy 0.48148148148148145\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m [Client 52] fit, config: {'current_round': 16, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m Epoch 1: train loss 0.00015863760199863464, accuracy 0.5740740740740741\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m [Client 44] fit, config: {'current_round': 16, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m Epoch 1: train loss 0.00017236167332157493, accuracy 0.5185185185185185\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m [Client 33] fit, config: {'current_round': 16, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m Epoch 1: train loss 0.00016881502233445644, accuracy 0.46296296296296297\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m [Client 24] fit, config: {'current_round': 16, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m Epoch 1: train loss 0.00016000033065211028, accuracy 0.4444444444444444\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m [Client 1] fit, config: {'current_round': 16, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m Epoch 1: train loss 0.00015985200298018754, accuracy 0.5\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m [Client 23] fit, config: {'current_round': 16, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m Epoch 1: train loss 0.0001655969681451097, accuracy 0.5\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m [Client 87] fit, config: {'current_round': 16, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m [Client 15] fit, config: {'current_round': 16, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m Epoch 1: train loss 0.0001718906278256327, accuracy 0.42592592592592593\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m Epoch 1: train loss 0.00016441356274299324, accuracy 0.5185185185185185\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m [Client 32] fit, config: {'current_round': 16, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m Epoch 1: train loss 0.00016611018509138376, accuracy 0.46296296296296297\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m [Client 12] fit, config: {'current_round': 16, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m Epoch 1: train loss 0.00016472989227622747, accuracy 0.5740740740740741\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 12:55:17,786 | server.py:216 | fit_round received 30 results and 0 failures\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m [Client 4] fit, config: {'current_round': 16, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m Epoch 1: train loss 0.00017463331460021436, accuracy 0.5185185185185185\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m [Client 76] fit, config: {'current_round': 16, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m [Client 86] fit, config: {'current_round': 16, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m Epoch 1: train loss 0.00016716484969947487, accuracy 0.5740740740740741\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m [Client 83] fit, config: {'current_round': 16, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m Epoch 1: train loss 0.0001691412617219612, accuracy 0.42592592592592593\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m [Client 89] fit, config: {'current_round': 16, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m Epoch 1: train loss 0.00017087816377170384, accuracy 0.46296296296296297\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m [Client 70] fit, config: {'current_round': 16, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m Epoch 1: train loss 0.000157540402142331, accuracy 0.5740740740740741\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m [Client 34] fit, config: {'current_round': 16, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m Epoch 1: train loss 0.0001686953182797879, accuracy 0.4444444444444444\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m Epoch 1: train loss 0.00017418584320694208, accuracy 0.5370370370370371\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m [Client 65] fit, config: {'current_round': 16, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m Epoch 1: train loss 0.00016428559320047498, accuracy 0.4444444444444444\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m [Client 64] fit, config: {'current_round': 16, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m Epoch 1: train loss 0.0001683911104919389, accuracy 0.5185185185185185\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m [Client 22] fit, config: {'current_round': 16, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m Epoch 1: train loss 0.00017393249436281621, accuracy 0.5\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m [Client 29] fit, config: {'current_round': 16, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m [Client 20] fit, config: {'current_round': 16, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m Epoch 1: train loss 0.00017655624833423644, accuracy 0.48148148148148145\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m [Client 56] fit, config: {'current_round': 16, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m Epoch 1: train loss 0.00016707942995708436, accuracy 0.5185185185185185\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m [Client 80] fit, config: {'current_round': 16, 'local_epochs': 3}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 12:55:17,827 | server.py:157 | evaluate_round: strategy sampled 30 clients (out of 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m [Client 37] fit, config: {'current_round': 16, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m Epoch 1: train loss 0.00016026436060201377, accuracy 0.5925925925925926\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m Epoch 1: train loss 0.00016381515888497233, accuracy 0.42592592592592593\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m [Client 59] fit, config: {'current_round': 16, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m Epoch 1: train loss 0.00016695244994480163, accuracy 0.5555555555555556\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m [Client 58] fit, config: {'current_round': 16, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m Epoch 1: train loss 0.00016598615911789238, accuracy 0.4074074074074074\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m [Client 8] fit, config: {'current_round': 16, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m Epoch 1: train loss 0.0001705147878965363, accuracy 0.42592592592592593\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m Epoch 1: train loss 0.00015660446661058813, accuracy 0.6296296296296297\n",
      "Saving round 16 aggregated_parameters...\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98093)\u001b[0m [Client 77] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98091)\u001b[0m [Client 83] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98091)\u001b[0m [Client 90] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98091)\u001b[0m [Client 27] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98091)\u001b[0m [Client 13] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98093)\u001b[0m [Client 63] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98089)\u001b[0m [Client 82] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98090)\u001b[0m [Client 71] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98088)\u001b[0m [Client 62] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98090)\u001b[0m [Client 96] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98088)\u001b[0m [Client 78] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98088)\u001b[0m [Client 53] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98090)\u001b[0m [Client 75] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98090)\u001b[0m [Client 95] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98091)\u001b[0m [Client 32] evaluate, config: {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 12:55:19,632 | server.py:170 | evaluate_round received 0 results and 30 failures\n",
      "DEBUG flower 2023-02-01 12:55:19,633 | server.py:203 | fit_round: strategy sampled 30 clients (out of 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98090)\u001b[0m [Client 94] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98090)\u001b[0m [Client 81] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98090)\u001b[0m [Client 29] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98088)\u001b[0m [Client 5] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98093)\u001b[0m [Client 91] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98089)\u001b[0m [Client 7] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98094)\u001b[0m [Client 17] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98092)\u001b[0m [Client 76] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98093)\u001b[0m [Client 69] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98094)\u001b[0m [Client 35] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98092)\u001b[0m [Client 80] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98091)\u001b[0m [Client 23] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98090)\u001b[0m [Client 89] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98088)\u001b[0m [Client 72] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98089)\u001b[0m [Client 67] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m [Client 30] fit, config: {'current_round': 17, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m [Client 31] fit, config: {'current_round': 17, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m [Client 12] fit, config: {'current_round': 17, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m Epoch 1: train loss 0.00016004819190129638, accuracy 0.5925925925925926\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m [Client 83] fit, config: {'current_round': 17, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m Epoch 1: train loss 0.00016241877165157348, accuracy 0.5370370370370371\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m Epoch 1: train loss 0.00016735985991545022, accuracy 0.5\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m [Client 44] fit, config: {'current_round': 17, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m Epoch 1: train loss 0.00016493312432430685, accuracy 0.5\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m [Client 10] fit, config: {'current_round': 17, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m Epoch 1: train loss 0.00016222955309785903, accuracy 0.5\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m Epoch 1: train loss 0.0001632897910894826, accuracy 0.5\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m [Client 3] fit, config: {'current_round': 17, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m Epoch 1: train loss 0.00016649445751681924, accuracy 0.48148148148148145\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m [Client 69] fit, config: {'current_round': 17, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m Epoch 1: train loss 0.00015807582531124353, accuracy 0.5370370370370371\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m [Client 18] fit, config: {'current_round': 17, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m [Client 87] fit, config: {'current_round': 17, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m [Client 84] fit, config: {'current_round': 17, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m Epoch 1: train loss 0.00015766595606692135, accuracy 0.5555555555555556\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m Epoch 1: train loss 0.00016713631339371204, accuracy 0.5\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m [Client 29] fit, config: {'current_round': 17, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m Epoch 1: train loss 0.00016023902571760118, accuracy 0.5370370370370371\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m [Client 90] fit, config: {'current_round': 17, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m Epoch 1: train loss 0.0001609375758562237, accuracy 0.5\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m Epoch 1: train loss 0.0001650597114348784, accuracy 0.5370370370370371\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m [Client 59] fit, config: {'current_round': 17, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m Epoch 1: train loss 0.00016711832722648978, accuracy 0.6111111111111112\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m [Client 22] fit, config: {'current_round': 17, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m Epoch 1: train loss 0.00016403623158112168, accuracy 0.5\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m [Client 97] fit, config: {'current_round': 17, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m Epoch 1: train loss 0.00017095865041483194, accuracy 0.48148148148148145\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m [Client 92] fit, config: {'current_round': 17, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m Epoch 1: train loss 0.00016131081792991608, accuracy 0.5555555555555556\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m [Client 67] fit, config: {'current_round': 17, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m Epoch 1: train loss 0.0001755229168338701, accuracy 0.5\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m [Client 8] fit, config: {'current_round': 17, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m Epoch 1: train loss 0.00016930558194871992, accuracy 0.42592592592592593\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m [Client 15] fit, config: {'current_round': 17, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m Epoch 1: train loss 0.00017065378779079765, accuracy 0.42592592592592593\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m [Client 49] fit, config: {'current_round': 17, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m [Client 34] fit, config: {'current_round': 17, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m [Client 25] fit, config: {'current_round': 17, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m Epoch 1: train loss 0.00015888101188465953, accuracy 0.5740740740740741\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m [Client 9] fit, config: {'current_round': 17, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m Epoch 1: train loss 0.00017050353926606476, accuracy 0.37037037037037035\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m Epoch 1: train loss 0.00016162455722223967, accuracy 0.46296296296296297\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 12:55:21,554 | server.py:216 | fit_round received 30 results and 0 failures\n",
      "DEBUG flower 2023-02-01 12:55:21,594 | server.py:157 | evaluate_round: strategy sampled 30 clients (out of 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving round 17 aggregated_parameters...\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m Epoch 1: train loss 0.00016463774954900146, accuracy 0.46296296296296297\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m [Client 79] fit, config: {'current_round': 17, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m Epoch 1: train loss 0.00015580638137180358, accuracy 0.5185185185185185\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m [Client 58] fit, config: {'current_round': 17, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m Epoch 1: train loss 0.00016667986346874386, accuracy 0.5925925925925926\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m [Client 24] fit, config: {'current_round': 17, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m Epoch 1: train loss 0.00014766379899811, accuracy 0.5740740740740741\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m [Client 95] fit, config: {'current_round': 17, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m Epoch 1: train loss 0.0001626740995561704, accuracy 0.5555555555555556\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m [Client 40] fit, config: {'current_round': 17, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m Epoch 1: train loss 0.00015735025226604193, accuracy 0.5555555555555556\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m [Client 94] fit, config: {'current_round': 17, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m Epoch 1: train loss 0.00016206639702431858, accuracy 0.5370370370370371\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98095)\u001b[0m [Client 66] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98095)\u001b[0m [Client 2] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98088)\u001b[0m [Client 95] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98095)\u001b[0m [Client 38] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98092)\u001b[0m [Client 36] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98088)\u001b[0m [Client 71] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98095)\u001b[0m [Client 91] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98088)\u001b[0m [Client 61] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98095)\u001b[0m [Client 20] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98089)\u001b[0m [Client 93] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98092)\u001b[0m [Client 7] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98089)\u001b[0m [Client 78] evaluate, config: {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 12:55:23,284 | server.py:170 | evaluate_round received 0 results and 30 failures\n",
      "DEBUG flower 2023-02-01 12:55:23,284 | server.py:203 | fit_round: strategy sampled 30 clients (out of 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98095)\u001b[0m [Client 26] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98089)\u001b[0m [Client 70] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98092)\u001b[0m [Client 98] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98088)\u001b[0m [Client 1] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98093)\u001b[0m [Client 74] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98094)\u001b[0m [Client 56] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98094)\u001b[0m [Client 35] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98093)\u001b[0m [Client 22] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98091)\u001b[0m [Client 59] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98090)\u001b[0m [Client 18] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98088)\u001b[0m [Client 88] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98088)\u001b[0m [Client 72] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98095)\u001b[0m [Client 28] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98093)\u001b[0m [Client 83] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98089)\u001b[0m [Client 44] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98094)\u001b[0m [Client 12] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98094)\u001b[0m [Client 62] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98092)\u001b[0m [Client 69] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m [Client 60] fit, config: {'current_round': 18, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m Epoch 1: train loss 0.00016899785259738564, accuracy 0.42592592592592593\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m [Client 66] fit, config: {'current_round': 18, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m Epoch 1: train loss 0.0001557467767270282, accuracy 0.5370370370370371\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m [Client 75] fit, config: {'current_round': 18, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m Epoch 1: train loss 0.0001612376217963174, accuracy 0.5185185185185185\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m [Client 50] fit, config: {'current_round': 18, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m [Client 9] fit, config: {'current_round': 18, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m Epoch 1: train loss 0.00016349782526958734, accuracy 0.5370370370370371\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m Epoch 1: train loss 0.00015793419152032584, accuracy 0.48148148148148145\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m [Client 65] fit, config: {'current_round': 18, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m [Client 82] fit, config: {'current_round': 18, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m Epoch 1: train loss 0.00015694418107159436, accuracy 0.5\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m Epoch 1: train loss 0.0001554901828058064, accuracy 0.42592592592592593\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m [Client 61] fit, config: {'current_round': 18, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m [Client 41] fit, config: {'current_round': 18, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m [Client 85] fit, config: {'current_round': 18, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m Epoch 1: train loss 0.00016091071302071214, accuracy 0.42592592592592593\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m [Client 55] fit, config: {'current_round': 18, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m [Client 84] fit, config: {'current_round': 18, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m Epoch 1: train loss 0.00014729873510077596, accuracy 0.5370370370370371\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m Epoch 1: train loss 0.00015766631986480206, accuracy 0.4074074074074074\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m Epoch 1: train loss 0.00016797284479252994, accuracy 0.37037037037037035\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m Epoch 1: train loss 0.00015965790953487158, accuracy 0.5185185185185185\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m [Client 22] fit, config: {'current_round': 18, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m Epoch 1: train loss 0.00016889916150830686, accuracy 0.4074074074074074\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m [Client 63] fit, config: {'current_round': 18, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m [Client 33] fit, config: {'current_round': 18, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m Epoch 1: train loss 0.00016080730711109936, accuracy 0.48148148148148145\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m [Client 95] fit, config: {'current_round': 18, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m Epoch 1: train loss 0.00015689119754824787, accuracy 0.5370370370370371\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m Epoch 1: train loss 0.000158395356265828, accuracy 0.4074074074074074\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m [Client 17] fit, config: {'current_round': 18, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m Epoch 1: train loss 0.00015814369544386864, accuracy 0.5370370370370371\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m [Client 91] fit, config: {'current_round': 18, 'local_epochs': 3}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 12:55:25,074 | server.py:216 | fit_round received 30 results and 0 failures\n",
      "DEBUG flower 2023-02-01 12:55:25,113 | server.py:157 | evaluate_round: strategy sampled 30 clients (out of 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m [Client 26] fit, config: {'current_round': 18, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m Epoch 1: train loss 0.00016105268150568008, accuracy 0.46296296296296297\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m [Client 62] fit, config: {'current_round': 18, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m Epoch 1: train loss 0.0001527133717900142, accuracy 0.5370370370370371\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m [Client 94] fit, config: {'current_round': 18, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m [Client 99] fit, config: {'current_round': 18, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m [Client 34] fit, config: {'current_round': 18, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m [Client 77] fit, config: {'current_round': 18, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m Epoch 1: train loss 0.00015563603665214032, accuracy 0.6296296296296297\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m [Client 31] fit, config: {'current_round': 18, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m Epoch 1: train loss 0.00015922494640108198, accuracy 0.5370370370370371\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m [Client 89] fit, config: {'current_round': 18, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m Epoch 1: train loss 0.000163309698109515, accuracy 0.4444444444444444\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m [Client 90] fit, config: {'current_round': 18, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m Epoch 1: train loss 0.00015488977078348398, accuracy 0.5\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m Epoch 1: train loss 0.00015843179426155984, accuracy 0.5\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m Epoch 1: train loss 0.00015506597992498428, accuracy 0.5185185185185185\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m Epoch 1: train loss 0.00016008218517526984, accuracy 0.3888888888888889\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m [Client 32] fit, config: {'current_round': 18, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m Epoch 1: train loss 0.0001629108883207664, accuracy 0.46296296296296297\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m [Client 44] fit, config: {'current_round': 18, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m Epoch 1: train loss 0.0001655627420404926, accuracy 0.48148148148148145\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m [Client 19] fit, config: {'current_round': 18, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m Epoch 1: train loss 0.00015174075087998062, accuracy 0.5740740740740741\n",
      "Saving round 18 aggregated_parameters...\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m Epoch 1: train loss 0.00015572214033454657, accuracy 0.4444444444444444\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98090)\u001b[0m [Client 39] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98093)\u001b[0m [Client 84] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98093)\u001b[0m [Client 49] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98092)\u001b[0m [Client 45] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98093)\u001b[0m [Client 2] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98093)\u001b[0m [Client 93] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98092)\u001b[0m [Client 10] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98090)\u001b[0m [Client 41] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98093)\u001b[0m [Client 85] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98093)\u001b[0m [Client 67] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98092)\u001b[0m [Client 7] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98090)\u001b[0m [Client 94] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98090)\u001b[0m [Client 20] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98093)\u001b[0m [Client 15] evaluate, config: {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 12:55:26,785 | server.py:170 | evaluate_round received 0 results and 30 failures\n",
      "DEBUG flower 2023-02-01 12:55:26,786 | server.py:203 | fit_round: strategy sampled 30 clients (out of 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98090)\u001b[0m [Client 96] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98093)\u001b[0m [Client 12] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98094)\u001b[0m [Client 14] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98091)\u001b[0m [Client 80] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98090)\u001b[0m [Client 73] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98093)\u001b[0m [Client 95] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98094)\u001b[0m [Client 65] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98092)\u001b[0m [Client 78] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98090)\u001b[0m [Client 31] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98094)\u001b[0m [Client 28] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98091)\u001b[0m [Client 47] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98090)\u001b[0m [Client 79] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98093)\u001b[0m [Client 50] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98089)\u001b[0m [Client 77] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98094)\u001b[0m [Client 97] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98092)\u001b[0m [Client 0] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m [Client 68] fit, config: {'current_round': 19, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m Epoch 1: train loss 0.00015088477812241763, accuracy 0.5925925925925926\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m [Client 81] fit, config: {'current_round': 19, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m Epoch 1: train loss 0.00015648837143089622, accuracy 0.5\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m [Client 41] fit, config: {'current_round': 19, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m Epoch 1: train loss 0.00016724670422263443, accuracy 0.4444444444444444\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m [Client 73] fit, config: {'current_round': 19, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m Epoch 1: train loss 0.0001502137165516615, accuracy 0.5370370370370371\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m [Client 63] fit, config: {'current_round': 19, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m Epoch 1: train loss 0.00015082272875588387, accuracy 0.5555555555555556\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m [Client 60] fit, config: {'current_round': 19, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m [Client 74] fit, config: {'current_round': 19, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m Epoch 1: train loss 0.00015823105059098452, accuracy 0.5740740740740741\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m [Client 90] fit, config: {'current_round': 19, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m Epoch 1: train loss 0.00015272104064933956, accuracy 0.5370370370370371\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m Epoch 1: train loss 0.0001608177844900638, accuracy 0.5740740740740741\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m [Client 31] fit, config: {'current_round': 19, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m Epoch 1: train loss 0.0001607048325240612, accuracy 0.5185185185185185\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m [Client 72] fit, config: {'current_round': 19, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m Epoch 1: train loss 0.00015541710308752954, accuracy 0.5740740740740741\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m [Client 23] fit, config: {'current_round': 19, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m Epoch 1: train loss 0.0001489523856434971, accuracy 0.5555555555555556\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m [Client 71] fit, config: {'current_round': 19, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m Epoch 1: train loss 0.00015713172615505755, accuracy 0.6296296296296297\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m [Client 48] fit, config: {'current_round': 19, 'local_epochs': 3}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 12:55:28,549 | server.py:216 | fit_round received 30 results and 0 failures\n",
      "DEBUG flower 2023-02-01 12:55:28,603 | server.py:157 | evaluate_round: strategy sampled 30 clients (out of 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m Epoch 1: train loss 0.00016176362987607718, accuracy 0.5370370370370371\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m [Client 61] fit, config: {'current_round': 19, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m [Client 46] fit, config: {'current_round': 19, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m Epoch 1: train loss 0.00015362532576546073, accuracy 0.5740740740740741\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m Epoch 1: train loss 0.00015298266953323036, accuracy 0.6296296296296297\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m [Client 91] fit, config: {'current_round': 19, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m [Client 26] fit, config: {'current_round': 19, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m [Client 54] fit, config: {'current_round': 19, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m Epoch 1: train loss 0.00015549696399830282, accuracy 0.46296296296296297\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m Epoch 1: train loss 0.00014792755246162415, accuracy 0.5\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m Epoch 1: train loss 0.00016753598174545914, accuracy 0.42592592592592593\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m [Client 76] fit, config: {'current_round': 19, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m Epoch 1: train loss 0.00014548889885190874, accuracy 0.6111111111111112\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m [Client 5] fit, config: {'current_round': 19, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m Epoch 1: train loss 0.00014722348714713007, accuracy 0.6111111111111112\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m [Client 88] fit, config: {'current_round': 19, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m Epoch 1: train loss 0.00016133958706632257, accuracy 0.5\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m [Client 22] fit, config: {'current_round': 19, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m Epoch 1: train loss 0.00015658879419788718, accuracy 0.5370370370370371\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m [Client 16] fit, config: {'current_round': 19, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m [Client 58] fit, config: {'current_round': 19, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m Epoch 1: train loss 0.0001595198264112696, accuracy 0.5740740740740741\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m [Client 19] fit, config: {'current_round': 19, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m Epoch 1: train loss 0.0001499748177593574, accuracy 0.5925925925925926\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m [Client 39] fit, config: {'current_round': 19, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m Epoch 1: train loss 0.00015018369595054537, accuracy 0.5925925925925926\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m Epoch 1: train loss 0.00014753297728020698, accuracy 0.5370370370370371\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m [Client 0] fit, config: {'current_round': 19, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m Epoch 1: train loss 0.00015662469377275556, accuracy 0.5740740740740741\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m [Client 28] fit, config: {'current_round': 19, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m Epoch 1: train loss 0.00015887977497186512, accuracy 0.5555555555555556\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m [Client 44] fit, config: {'current_round': 19, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m Epoch 1: train loss 0.00015751394676044583, accuracy 0.5370370370370371\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m [Client 3] fit, config: {'current_round': 19, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m Epoch 1: train loss 0.00015987048391252756, accuracy 0.46296296296296297\n",
      "Saving round 19 aggregated_parameters...\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98093)\u001b[0m [Client 5] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98089)\u001b[0m [Client 35] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98094)\u001b[0m [Client 98] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98093)\u001b[0m [Client 70] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98093)\u001b[0m [Client 89] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98091)\u001b[0m [Client 88] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98091)\u001b[0m [Client 26] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98090)\u001b[0m [Client 95] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98093)\u001b[0m [Client 39] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98089)\u001b[0m [Client 68] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98094)\u001b[0m [Client 19] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98094)\u001b[0m [Client 81] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98092)\u001b[0m [Client 94] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98088)\u001b[0m [Client 27] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98095)\u001b[0m [Client 15] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98093)\u001b[0m [Client 33] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98092)\u001b[0m [Client 16] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98088)\u001b[0m [Client 32] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98091)\u001b[0m [Client 30] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98090)\u001b[0m [Client 57] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98088)\u001b[0m [Client 93] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98095)\u001b[0m [Client 60] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98095)\u001b[0m [Client 1] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98093)\u001b[0m [Client 58] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98089)\u001b[0m [Client 96] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98094)\u001b[0m [Client 17] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98094)\u001b[0m [Client 83] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98092)\u001b[0m [Client 2] evaluate, config: {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 12:55:30,302 | server.py:170 | evaluate_round received 0 results and 30 failures\n",
      "DEBUG flower 2023-02-01 12:55:30,303 | server.py:203 | fit_round: strategy sampled 30 clients (out of 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98089)\u001b[0m [Client 37] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98092)\u001b[0m [Client 9] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m [Client 58] fit, config: {'current_round': 20, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m Epoch 1: train loss 0.00014432641910389066, accuracy 0.5185185185185185\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m [Client 16] fit, config: {'current_round': 20, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m Epoch 1: train loss 0.0001469505950808525, accuracy 0.5\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m [Client 18] fit, config: {'current_round': 20, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m Epoch 1: train loss 0.0001550354209030047, accuracy 0.5740740740740741\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m [Client 33] fit, config: {'current_round': 20, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m Epoch 1: train loss 0.0001524885301478207, accuracy 0.48148148148148145\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m [Client 48] fit, config: {'current_round': 20, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m Epoch 1: train loss 0.00015203474322333932, accuracy 0.5925925925925926\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m [Client 35] fit, config: {'current_round': 20, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m Epoch 1: train loss 0.00015769689343869686, accuracy 0.5925925925925926\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m [Client 24] fit, config: {'current_round': 20, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m Epoch 1: train loss 0.00014553205983247608, accuracy 0.46296296296296297\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m [Client 93] fit, config: {'current_round': 20, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m Epoch 1: train loss 0.00014695129357278347, accuracy 0.48148148148148145\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m [Client 49] fit, config: {'current_round': 20, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m Epoch 1: train loss 0.00015786083531565964, accuracy 0.4444444444444444\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m [Client 97] fit, config: {'current_round': 20, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m Epoch 1: train loss 0.00016364202019758523, accuracy 0.5185185185185185\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m [Client 99] fit, config: {'current_round': 20, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m [Client 80] fit, config: {'current_round': 20, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m Epoch 1: train loss 0.00013589212903752923, accuracy 0.6481481481481481\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m [Client 78] fit, config: {'current_round': 20, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m Epoch 1: train loss 0.00015745408018119633, accuracy 0.5370370370370371\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m [Client 1] fit, config: {'current_round': 20, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m Epoch 1: train loss 0.00014228041982278228, accuracy 0.46296296296296297\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m [Client 79] fit, config: {'current_round': 20, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m Epoch 1: train loss 0.0001565576094435528, accuracy 0.3888888888888889\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m [Client 72] fit, config: {'current_round': 20, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m Epoch 1: train loss 0.00014511248446069658, accuracy 0.6111111111111112\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m Epoch 1: train loss 0.00014608075434807688, accuracy 0.5740740740740741\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m [Client 6] fit, config: {'current_round': 20, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m [Client 56] fit, config: {'current_round': 20, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m Epoch 1: train loss 0.00015122420154511929, accuracy 0.5370370370370371\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m Epoch 1: train loss 0.0001541687233839184, accuracy 0.5555555555555556\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m [Client 21] fit, config: {'current_round': 20, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m Epoch 1: train loss 0.0001614022912690416, accuracy 0.5185185185185185\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m [Client 45] fit, config: {'current_round': 20, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m Epoch 1: train loss 0.00014719628961756825, accuracy 0.6296296296296297\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m [Client 46] fit, config: {'current_round': 20, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m Epoch 1: train loss 0.000137545372126624, accuracy 0.7037037037037037\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m [Client 94] fit, config: {'current_round': 20, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m [Client 27] fit, config: {'current_round': 20, 'local_epochs': 3}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 12:55:32,520 | server.py:216 | fit_round received 30 results and 0 failures\n",
      "DEBUG flower 2023-02-01 12:55:32,586 | server.py:157 | evaluate_round: strategy sampled 30 clients (out of 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m [Client 87] fit, config: {'current_round': 20, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m [Client 13] fit, config: {'current_round': 20, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m Epoch 1: train loss 0.00016089410928543657, accuracy 0.37037037037037035\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m [Client 75] fit, config: {'current_round': 20, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m Epoch 1: train loss 0.00015494180843234062, accuracy 0.5740740740740741\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m [Client 22] fit, config: {'current_round': 20, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m Epoch 1: train loss 0.00014805467799305916, accuracy 0.5555555555555556\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m Epoch 1: train loss 0.0001424312504241243, accuracy 0.6481481481481481\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m [Client 63] fit, config: {'current_round': 20, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m Epoch 1: train loss 0.00015107003855518997, accuracy 0.4444444444444444\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m Epoch 1: train loss 0.00016341566515620798, accuracy 0.4444444444444444\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m [Client 91] fit, config: {'current_round': 20, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m Epoch 1: train loss 0.00014852081949356943, accuracy 0.5925925925925926\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m Epoch 1: train loss 0.0001511957962065935, accuracy 0.5555555555555556\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m [Client 12] fit, config: {'current_round': 20, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m Epoch 1: train loss 0.00015013955999165773, accuracy 0.5555555555555556\n",
      "Saving round 20 aggregated_parameters...\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98090)\u001b[0m [Client 37] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98093)\u001b[0m [Client 60] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98092)\u001b[0m [Client 91] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98091)\u001b[0m [Client 62] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98091)\u001b[0m [Client 4] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98095)\u001b[0m [Client 0] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98091)\u001b[0m [Client 17] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98091)\u001b[0m [Client 69] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98095)\u001b[0m [Client 43] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98093)\u001b[0m [Client 26] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98095)\u001b[0m [Client 16] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98093)\u001b[0m [Client 18] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98095)\u001b[0m [Client 63] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98091)\u001b[0m [Client 94] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98090)\u001b[0m [Client 89] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98095)\u001b[0m [Client 61] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98093)\u001b[0m [Client 11] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98089)\u001b[0m [Client 19] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98092)\u001b[0m [Client 56] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98095)\u001b[0m [Client 24] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98092)\u001b[0m [Client 34] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98095)\u001b[0m [Client 6] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98092)\u001b[0m [Client 28] evaluate, config: {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 12:55:34,299 | server.py:170 | evaluate_round received 0 results and 30 failures\n",
      "DEBUG flower 2023-02-01 12:55:34,300 | server.py:203 | fit_round: strategy sampled 30 clients (out of 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98095)\u001b[0m [Client 77] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98092)\u001b[0m [Client 57] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98092)\u001b[0m [Client 75] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98091)\u001b[0m [Client 33] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98090)\u001b[0m [Client 14] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98095)\u001b[0m [Client 49] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98092)\u001b[0m [Client 29] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m [Client 81] fit, config: {'current_round': 21, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m Epoch 1: train loss 0.00015030837676022202, accuracy 0.48148148148148145\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m [Client 6] fit, config: {'current_round': 21, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m Epoch 1: train loss 0.00014548814215231687, accuracy 0.5555555555555556\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m [Client 92] fit, config: {'current_round': 21, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m Epoch 1: train loss 0.00014766362437512726, accuracy 0.5555555555555556\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m [Client 15] fit, config: {'current_round': 21, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m Epoch 1: train loss 0.00016089994460344315, accuracy 0.42592592592592593\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m [Client 80] fit, config: {'current_round': 21, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m [Client 54] fit, config: {'current_round': 21, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m Epoch 1: train loss 0.00014788965927436948, accuracy 0.5185185185185185\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m Epoch 1: train loss 0.00013397683505900204, accuracy 0.6851851851851852\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m [Client 69] fit, config: {'current_round': 21, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m [Client 10] fit, config: {'current_round': 21, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m Epoch 1: train loss 0.000147974060382694, accuracy 0.5740740740740741\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m Epoch 1: train loss 0.00014132875367067754, accuracy 0.5555555555555556\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m [Client 66] fit, config: {'current_round': 21, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m Epoch 1: train loss 0.00015494166291318834, accuracy 0.5370370370370371\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m [Client 7] fit, config: {'current_round': 21, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m Epoch 1: train loss 0.00014448710135184228, accuracy 0.5925925925925926\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m [Client 51] fit, config: {'current_round': 21, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m Epoch 1: train loss 0.00014928191376384348, accuracy 0.5370370370370371\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m [Client 70] fit, config: {'current_round': 21, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m Epoch 1: train loss 0.00015327789878938347, accuracy 0.5555555555555556\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m [Client 20] fit, config: {'current_round': 21, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m Epoch 1: train loss 0.00015842313587199897, accuracy 0.5185185185185185\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m [Client 60] fit, config: {'current_round': 21, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m Epoch 1: train loss 0.00015408308536279947, accuracy 0.5740740740740741\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m [Client 17] fit, config: {'current_round': 21, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m Epoch 1: train loss 0.0001412722049281001, accuracy 0.6111111111111112\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m [Client 57] fit, config: {'current_round': 21, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m Epoch 1: train loss 0.0001584949204698205, accuracy 0.48148148148148145\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m [Client 85] fit, config: {'current_round': 21, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m Epoch 1: train loss 0.00014643899339716882, accuracy 0.48148148148148145\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m [Client 14] fit, config: {'current_round': 21, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m Epoch 1: train loss 0.00014402170199900866, accuracy 0.5185185185185185\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m [Client 2] fit, config: {'current_round': 21, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m Epoch 1: train loss 0.00014153230586089194, accuracy 0.5740740740740741\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m [Client 90] fit, config: {'current_round': 21, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m Epoch 1: train loss 0.00014455778000410646, accuracy 0.5370370370370371\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m [Client 67] fit, config: {'current_round': 21, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m Epoch 1: train loss 0.0001632183266337961, accuracy 0.5370370370370371\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 12:55:36,091 | server.py:216 | fit_round received 30 results and 0 failures\n",
      "DEBUG flower 2023-02-01 12:55:36,131 | server.py:157 | evaluate_round: strategy sampled 30 clients (out of 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m [Client 72] fit, config: {'current_round': 21, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m [Client 38] fit, config: {'current_round': 21, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m Epoch 1: train loss 0.00015696158516220748, accuracy 0.5555555555555556\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m [Client 23] fit, config: {'current_round': 21, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m [Client 95] fit, config: {'current_round': 21, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m [Client 65] fit, config: {'current_round': 21, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m Epoch 1: train loss 0.00014432956231757998, accuracy 0.5185185185185185\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m Epoch 1: train loss 0.00014731271949131042, accuracy 0.5740740740740741\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m [Client 29] fit, config: {'current_round': 21, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m Epoch 1: train loss 0.00014533530338667333, accuracy 0.5370370370370371\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m [Client 27] fit, config: {'current_round': 21, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m Epoch 1: train loss 0.00015108627849258482, accuracy 0.5555555555555556\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m [Client 71] fit, config: {'current_round': 21, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m Epoch 1: train loss 0.0001496752811362967, accuracy 0.6296296296296297\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m Epoch 1: train loss 0.00014143440057523549, accuracy 0.5740740740740741\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m Epoch 1: train loss 0.00014523572463076562, accuracy 0.5740740740740741\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m [Client 36] fit, config: {'current_round': 21, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m Epoch 1: train loss 0.00017005950212478638, accuracy 0.35185185185185186\n",
      "Saving round 21 aggregated_parameters...\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98093)\u001b[0m [Client 96] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98092)\u001b[0m [Client 85] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98092)\u001b[0m [Client 49] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98092)\u001b[0m [Client 16] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98088)\u001b[0m [Client 36] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98093)\u001b[0m [Client 60] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98092)\u001b[0m [Client 13] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98088)\u001b[0m [Client 53] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98088)\u001b[0m [Client 20] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98093)\u001b[0m [Client 79] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98092)\u001b[0m [Client 97] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98093)\u001b[0m [Client 37] evaluate, config: {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 12:55:37,894 | server.py:170 | evaluate_round received 0 results and 30 failures\n",
      "DEBUG flower 2023-02-01 12:55:37,895 | server.py:203 | fit_round: strategy sampled 30 clients (out of 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98093)\u001b[0m [Client 46] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98088)\u001b[0m [Client 14] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98093)\u001b[0m [Client 8] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98092)\u001b[0m [Client 19] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98091)\u001b[0m [Client 23] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98088)\u001b[0m [Client 54] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98095)\u001b[0m [Client 87] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98093)\u001b[0m [Client 50] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98088)\u001b[0m [Client 77] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98088)\u001b[0m [Client 12] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98095)\u001b[0m [Client 11] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98093)\u001b[0m [Client 9] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98091)\u001b[0m [Client 51] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98088)\u001b[0m [Client 82] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98095)\u001b[0m [Client 32] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98093)\u001b[0m [Client 71] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98089)\u001b[0m [Client 10] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98092)\u001b[0m [Client 67] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m [Client 80] fit, config: {'current_round': 22, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m Epoch 1: train loss 0.00012728231376968324, accuracy 0.6296296296296297\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m [Client 73] fit, config: {'current_round': 22, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m Epoch 1: train loss 0.00014340176130644977, accuracy 0.4074074074074074\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m [Client 25] fit, config: {'current_round': 22, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m [Client 41] fit, config: {'current_round': 22, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m Epoch 1: train loss 0.0001376466971123591, accuracy 0.5\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m Epoch 1: train loss 0.00014411589654628187, accuracy 0.4444444444444444\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m [Client 86] fit, config: {'current_round': 22, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m Epoch 1: train loss 0.00014762883074581623, accuracy 0.46296296296296297\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m [Client 59] fit, config: {'current_round': 22, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m Epoch 1: train loss 0.00014255753194447607, accuracy 0.5555555555555556\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m [Client 95] fit, config: {'current_round': 22, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m Epoch 1: train loss 0.00014003811520524323, accuracy 0.5185185185185185\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m [Client 79] fit, config: {'current_round': 22, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m Epoch 1: train loss 0.00015229596465360373, accuracy 0.3333333333333333\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m [Client 88] fit, config: {'current_round': 22, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m [Client 36] fit, config: {'current_round': 22, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m Epoch 1: train loss 0.00015450762293767184, accuracy 0.4074074074074074\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m [Client 50] fit, config: {'current_round': 22, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m Epoch 1: train loss 0.0001406359951943159, accuracy 0.5185185185185185\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m [Client 68] fit, config: {'current_round': 22, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m [Client 7] fit, config: {'current_round': 22, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m Epoch 1: train loss 0.00014679011655971408, accuracy 0.46296296296296297\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m Epoch 1: train loss 0.00013936354662291706, accuracy 0.48148148148148145\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m [Client 49] fit, config: {'current_round': 22, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m Epoch 1: train loss 0.00015492894453927875, accuracy 0.46296296296296297\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m [Client 24] fit, config: {'current_round': 22, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m Epoch 1: train loss 0.00014096745871938765, accuracy 0.48148148148148145\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m Epoch 1: train loss 0.00013558511273004115, accuracy 0.5185185185185185\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m [Client 5] fit, config: {'current_round': 22, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m [Client 66] fit, config: {'current_round': 22, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m Epoch 1: train loss 0.00013972334272693843, accuracy 0.5370370370370371\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m [Client 35] fit, config: {'current_round': 22, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m Epoch 1: train loss 0.00015379783872049302, accuracy 0.46296296296296297\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m [Client 71] fit, config: {'current_round': 22, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m Epoch 1: train loss 0.0001485670218244195, accuracy 0.48148148148148145\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m Epoch 1: train loss 0.00014659727457910776, accuracy 0.4074074074074074\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m [Client 75] fit, config: {'current_round': 22, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m Epoch 1: train loss 0.0001488400303060189, accuracy 0.5\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m [Client 9] fit, config: {'current_round': 22, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m Epoch 1: train loss 0.00015430132043547928, accuracy 0.5185185185185185\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m [Client 22] fit, config: {'current_round': 22, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m [Client 61] fit, config: {'current_round': 22, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m Epoch 1: train loss 0.00014708720846101642, accuracy 0.5370370370370371\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m [Client 69] fit, config: {'current_round': 22, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m Epoch 1: train loss 0.00016007146041374654, accuracy 0.2962962962962963\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m [Client 53] fit, config: {'current_round': 22, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m Epoch 1: train loss 0.0001420085463905707, accuracy 0.46296296296296297\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m [Client 6] fit, config: {'current_round': 22, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m Epoch 1: train loss 0.00014840438961982727, accuracy 0.5\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m [Client 63] fit, config: {'current_round': 22, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m [Client 91] fit, config: {'current_round': 22, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m Epoch 1: train loss 0.00013891738490201533, accuracy 0.5185185185185185\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m [Client 72] fit, config: {'current_round': 22, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m [Client 62] fit, config: {'current_round': 22, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m Epoch 1: train loss 0.00013706405297853053, accuracy 0.5370370370370371\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 12:55:40,332 | server.py:216 | fit_round received 30 results and 0 failures\n",
      "DEBUG flower 2023-02-01 12:55:40,396 | server.py:157 | evaluate_round: strategy sampled 30 clients (out of 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving round 22 aggregated_parameters...\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m Epoch 1: train loss 0.00014665952767245471, accuracy 0.42592592592592593\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m Epoch 1: train loss 0.00014637589629273862, accuracy 0.3888888888888889\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m Epoch 1: train loss 0.0001386946823913604, accuracy 0.5925925925925926\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98093)\u001b[0m [Client 9] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98088)\u001b[0m [Client 1] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98093)\u001b[0m [Client 96] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98094)\u001b[0m [Client 80] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98094)\u001b[0m [Client 30] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98094)\u001b[0m [Client 82] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98094)\u001b[0m [Client 5] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98088)\u001b[0m [Client 78] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98093)\u001b[0m [Client 87] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98094)\u001b[0m [Client 75] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98088)\u001b[0m [Client 35] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98093)\u001b[0m [Client 53] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98093)\u001b[0m [Client 2] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98093)\u001b[0m [Client 92] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98093)\u001b[0m [Client 12] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98088)\u001b[0m [Client 88] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98093)\u001b[0m [Client 16] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98094)\u001b[0m [Client 71] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98094)\u001b[0m [Client 51] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98091)\u001b[0m [Client 68] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98090)\u001b[0m [Client 0] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98088)\u001b[0m [Client 65] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98093)\u001b[0m [Client 6] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98092)\u001b[0m [Client 25] evaluate, config: {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 12:55:42,540 | server.py:170 | evaluate_round received 0 results and 30 failures\n",
      "DEBUG flower 2023-02-01 12:55:42,541 | server.py:203 | fit_round: strategy sampled 30 clients (out of 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98091)\u001b[0m [Client 10] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98090)\u001b[0m [Client 69] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98088)\u001b[0m [Client 72] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98093)\u001b[0m [Client 34] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98094)\u001b[0m [Client 11] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98092)\u001b[0m [Client 57] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m [Client 30] fit, config: {'current_round': 23, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m [Client 57] fit, config: {'current_round': 23, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m Epoch 1: train loss 0.00015112003893591464, accuracy 0.5\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m Epoch 1: train loss 0.0001457529579056427, accuracy 0.42592592592592593\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m [Client 77] fit, config: {'current_round': 23, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m Epoch 1: train loss 0.0001413979334756732, accuracy 0.6296296296296297\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m [Client 42] fit, config: {'current_round': 23, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m Epoch 1: train loss 0.0001410800323355943, accuracy 0.5555555555555556\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m [Client 65] fit, config: {'current_round': 23, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m Epoch 1: train loss 0.00014039449160918593, accuracy 0.5185185185185185\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m [Client 27] fit, config: {'current_round': 23, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m Epoch 1: train loss 0.00014590888167731464, accuracy 0.5185185185185185\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m [Client 94] fit, config: {'current_round': 23, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m Epoch 1: train loss 0.00013953953748568892, accuracy 0.5185185185185185\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m [Client 95] fit, config: {'current_round': 23, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m Epoch 1: train loss 0.00013583648251369596, accuracy 0.6111111111111112\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m [Client 61] fit, config: {'current_round': 23, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m [Client 29] fit, config: {'current_round': 23, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m Epoch 1: train loss 0.0001422888890374452, accuracy 0.5185185185185185\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m Epoch 1: train loss 0.00013831940304953605, accuracy 0.6481481481481481\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m [Client 69] fit, config: {'current_round': 23, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m Epoch 1: train loss 0.00013537918857764453, accuracy 0.6296296296296297\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m [Client 96] fit, config: {'current_round': 23, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m [Client 31] fit, config: {'current_round': 23, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m Epoch 1: train loss 0.00014990862109698355, accuracy 0.5185185185185185\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m [Client 56] fit, config: {'current_round': 23, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m Epoch 1: train loss 0.00014615411055274308, accuracy 0.5\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m [Client 0] fit, config: {'current_round': 23, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m Epoch 1: train loss 0.0001319460425293073, accuracy 0.7037037037037037\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m [Client 82] fit, config: {'current_round': 23, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m Epoch 1: train loss 0.00013476068852469325, accuracy 0.5740740740740741\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m Epoch 1: train loss 0.0001443293149350211, accuracy 0.5740740740740741\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m [Client 49] fit, config: {'current_round': 23, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m Epoch 1: train loss 0.0001445485686417669, accuracy 0.48148148148148145\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m [Client 39] fit, config: {'current_round': 23, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m [Client 44] fit, config: {'current_round': 23, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m Epoch 1: train loss 0.00014649209333583713, accuracy 0.5740740740740741\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m [Client 48] fit, config: {'current_round': 23, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m Epoch 1: train loss 0.00015305211127270013, accuracy 0.4444444444444444\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m Epoch 1: train loss 0.0001390247925883159, accuracy 0.5555555555555556\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m [Client 93] fit, config: {'current_round': 23, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m Epoch 1: train loss 0.00014298873429652303, accuracy 0.5185185185185185\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m [Client 1] fit, config: {'current_round': 23, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m [Client 90] fit, config: {'current_round': 23, 'local_epochs': 3}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 12:55:44,800 | server.py:216 | fit_round received 30 results and 0 failures\n",
      "DEBUG flower 2023-02-01 12:55:44,859 | server.py:157 | evaluate_round: strategy sampled 30 clients (out of 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m Epoch 1: train loss 0.00014719620230607688, accuracy 0.5\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m [Client 3] fit, config: {'current_round': 23, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m [Client 38] fit, config: {'current_round': 23, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m Epoch 1: train loss 0.00013958674389868975, accuracy 0.5555555555555556\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m [Client 15] fit, config: {'current_round': 23, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m Epoch 1: train loss 0.00015679372882004827, accuracy 0.4074074074074074\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m [Client 84] fit, config: {'current_round': 23, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m Epoch 1: train loss 0.00014972344797570258, accuracy 0.5185185185185185\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m [Client 70] fit, config: {'current_round': 23, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m Epoch 1: train loss 0.00014872608880978078, accuracy 0.5555555555555556\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m Epoch 1: train loss 0.00015202481881715357, accuracy 0.5\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m [Client 85] fit, config: {'current_round': 23, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m Epoch 1: train loss 0.00014276226283982396, accuracy 0.46296296296296297\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m [Client 88] fit, config: {'current_round': 23, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m Epoch 1: train loss 0.00014818859926890582, accuracy 0.5555555555555556\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m Epoch 1: train loss 0.00013552505697589368, accuracy 0.6481481481481481\n",
      "Saving round 23 aggregated_parameters...\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98088)\u001b[0m [Client 13] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98095)\u001b[0m [Client 56] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98093)\u001b[0m [Client 26] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98094)\u001b[0m [Client 41] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98095)\u001b[0m [Client 17] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98088)\u001b[0m [Client 21] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98088)\u001b[0m [Client 60] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98088)\u001b[0m [Client 97] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98095)\u001b[0m [Client 92] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98088)\u001b[0m [Client 78] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98088)\u001b[0m [Client 30] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98095)\u001b[0m [Client 54] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98093)\u001b[0m [Client 40] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98094)\u001b[0m [Client 44] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98090)\u001b[0m [Client 0] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98092)\u001b[0m [Client 67] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98088)\u001b[0m [Client 58] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98092)\u001b[0m [Client 82] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98088)\u001b[0m [Client 32] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98094)\u001b[0m [Client 7] evaluate, config: {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 12:55:47,048 | server.py:170 | evaluate_round received 0 results and 30 failures\n",
      "DEBUG flower 2023-02-01 12:55:47,049 | server.py:203 | fit_round: strategy sampled 30 clients (out of 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98090)\u001b[0m [Client 68] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98095)\u001b[0m [Client 59] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98093)\u001b[0m [Client 90] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98089)\u001b[0m [Client 1] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98092)\u001b[0m [Client 94] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98094)\u001b[0m [Client 89] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98091)\u001b[0m [Client 86] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98088)\u001b[0m [Client 64] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98093)\u001b[0m [Client 29] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98092)\u001b[0m [Client 22] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m [Client 26] fit, config: {'current_round': 24, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m Epoch 1: train loss 0.00014402683882508427, accuracy 0.4444444444444444\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m [Client 9] fit, config: {'current_round': 24, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m Epoch 1: train loss 0.00015239306958392262, accuracy 0.48148148148148145\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m [Client 55] fit, config: {'current_round': 24, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m Epoch 1: train loss 0.00014012085739523172, accuracy 0.5370370370370371\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m [Client 5] fit, config: {'current_round': 24, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m Epoch 1: train loss 0.00014309678226709366, accuracy 0.4444444444444444\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m [Client 98] fit, config: {'current_round': 24, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m Epoch 1: train loss 0.00013372366083785892, accuracy 0.5370370370370371\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m [Client 31] fit, config: {'current_round': 24, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m Epoch 1: train loss 0.00013964567915536463, accuracy 0.5740740740740741\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m [Client 77] fit, config: {'current_round': 24, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m [Client 68] fit, config: {'current_round': 24, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m Epoch 1: train loss 0.00012892019003629684, accuracy 0.5925925925925926\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m Epoch 1: train loss 0.00014662368630524725, accuracy 0.46296296296296297\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m [Client 89] fit, config: {'current_round': 24, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m Epoch 1: train loss 0.00014538610412273556, accuracy 0.42592592592592593\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m [Client 60] fit, config: {'current_round': 24, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m Epoch 1: train loss 0.00015023283776827157, accuracy 0.5740740740740741\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m [Client 54] fit, config: {'current_round': 24, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m Epoch 1: train loss 0.00013427663361653686, accuracy 0.5740740740740741\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m [Client 8] fit, config: {'current_round': 24, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m [Client 37] fit, config: {'current_round': 24, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m Epoch 1: train loss 0.00012482423335313797, accuracy 0.5740740740740741\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m [Client 19] fit, config: {'current_round': 24, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m [Client 46] fit, config: {'current_round': 24, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m Epoch 1: train loss 0.00012382042768877, accuracy 0.6481481481481481\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m [Client 49] fit, config: {'current_round': 24, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m [Client 13] fit, config: {'current_round': 24, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m Epoch 1: train loss 0.00014964760339353234, accuracy 0.4074074074074074\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m Epoch 1: train loss 0.00014134717639535666, accuracy 0.48148148148148145\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m [Client 84] fit, config: {'current_round': 24, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m Epoch 1: train loss 0.00012544001219794154, accuracy 0.5555555555555556\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m [Client 24] fit, config: {'current_round': 24, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m Epoch 1: train loss 0.00013173579645808786, accuracy 0.5\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m [Client 7] fit, config: {'current_round': 24, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m Epoch 1: train loss 0.00014823611127212644, accuracy 0.4444444444444444\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m [Client 65] fit, config: {'current_round': 24, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m [Client 29] fit, config: {'current_round': 24, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m Epoch 1: train loss 0.0001330800587311387, accuracy 0.5370370370370371\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m [Client 59] fit, config: {'current_round': 24, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m Epoch 1: train loss 0.00013876370212528855, accuracy 0.5185185185185185\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m Epoch 1: train loss 0.00013456666783895344, accuracy 0.5185185185185185\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m Epoch 1: train loss 0.00014410537551157176, accuracy 0.48148148148148145\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m Epoch 1: train loss 0.00013632567424792796, accuracy 0.5185185185185185\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m [Client 53] fit, config: {'current_round': 24, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m Epoch 1: train loss 0.000138873714604415, accuracy 0.48148148148148145\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m [Client 70] fit, config: {'current_round': 24, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m [Client 23] fit, config: {'current_round': 24, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m Epoch 1: train loss 0.0001414341968484223, accuracy 0.5370370370370371\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m [Client 43] fit, config: {'current_round': 24, 'local_epochs': 3}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 12:55:49,376 | server.py:216 | fit_round received 30 results and 0 failures\n",
      "DEBUG flower 2023-02-01 12:55:49,433 | server.py:157 | evaluate_round: strategy sampled 30 clients (out of 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m [Client 41] fit, config: {'current_round': 24, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m Epoch 1: train loss 0.0001323877804679796, accuracy 0.5185185185185185\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m [Client 3] fit, config: {'current_round': 24, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m Epoch 1: train loss 0.00014896251377649605, accuracy 0.4444444444444444\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m Epoch 1: train loss 0.00015115713176783174, accuracy 0.5740740740740741\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m [Client 58] fit, config: {'current_round': 24, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m Epoch 1: train loss 0.00012978141603525728, accuracy 0.5740740740740741\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m Epoch 1: train loss 0.00014019095397088677, accuracy 0.5555555555555556\n",
      "Saving round 24 aggregated_parameters...\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98094)\u001b[0m [Client 79] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98088)\u001b[0m [Client 5] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98088)\u001b[0m [Client 86] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98088)\u001b[0m [Client 69] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98088)\u001b[0m [Client 48] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98088)\u001b[0m [Client 66] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98090)\u001b[0m [Client 87] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98095)\u001b[0m [Client 3] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98094)\u001b[0m [Client 83] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98090)\u001b[0m [Client 44] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98088)\u001b[0m [Client 50] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98093)\u001b[0m [Client 17] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98092)\u001b[0m [Client 76] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98092)\u001b[0m [Client 38] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98090)\u001b[0m [Client 33] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98090)\u001b[0m [Client 47] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98090)\u001b[0m [Client 29] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98090)\u001b[0m [Client 71] evaluate, config: {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(raylet)\u001b[0m Spilled 65891 MiB, 2203 objects, write throughput 1365 MiB/s.\n",
      "DEBUG flower 2023-02-01 12:55:51,793 | server.py:170 | evaluate_round received 0 results and 30 failures\n",
      "DEBUG flower 2023-02-01 12:55:51,794 | server.py:203 | fit_round: strategy sampled 30 clients (out of 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98092)\u001b[0m [Client 26] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98090)\u001b[0m [Client 93] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98088)\u001b[0m [Client 94] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98095)\u001b[0m [Client 64] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98093)\u001b[0m [Client 4] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98094)\u001b[0m [Client 6] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98090)\u001b[0m [Client 57] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98088)\u001b[0m [Client 91] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98094)\u001b[0m [Client 72] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98095)\u001b[0m [Client 10] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98093)\u001b[0m [Client 14] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98092)\u001b[0m [Client 25] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m [Client 15] fit, config: {'current_round': 25, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m Epoch 1: train loss 0.00015196403546724468, accuracy 0.37037037037037035\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m [Client 99] fit, config: {'current_round': 25, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m Epoch 1: train loss 0.00013951784058008343, accuracy 0.5740740740740741\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m [Client 67] fit, config: {'current_round': 25, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m Epoch 1: train loss 0.000154422246851027, accuracy 0.5555555555555556\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m [Client 17] fit, config: {'current_round': 25, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m Epoch 1: train loss 0.000128124316688627, accuracy 0.6296296296296297\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m [Client 41] fit, config: {'current_round': 25, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m Epoch 1: train loss 0.00014753562572877854, accuracy 0.42592592592592593\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m [Client 28] fit, config: {'current_round': 25, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m Epoch 1: train loss 0.00013850440154783428, accuracy 0.5740740740740741\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m [Client 54] fit, config: {'current_round': 25, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m [Client 80] fit, config: {'current_round': 25, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m Epoch 1: train loss 0.00011871298193000257, accuracy 0.7037037037037037\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m [Client 52] fit, config: {'current_round': 25, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m Epoch 1: train loss 0.00013551043230108917, accuracy 0.5185185185185185\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m Epoch 1: train loss 0.0001378335291519761, accuracy 0.5370370370370371\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m [Client 23] fit, config: {'current_round': 25, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m [Client 95] fit, config: {'current_round': 25, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m Epoch 1: train loss 0.00013041064084973186, accuracy 0.6296296296296297\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m Epoch 1: train loss 0.0001302287564612925, accuracy 0.5555555555555556\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m [Client 85] fit, config: {'current_round': 25, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m Epoch 1: train loss 0.0001369966339552775, accuracy 0.46296296296296297\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m [Client 22] fit, config: {'current_round': 25, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m [Client 65] fit, config: {'current_round': 25, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m Epoch 1: train loss 0.00014187376655172557, accuracy 0.5185185185185185\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m [Client 35] fit, config: {'current_round': 25, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m Epoch 1: train loss 0.00014232734974939376, accuracy 0.5555555555555556\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m [Client 48] fit, config: {'current_round': 25, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m Epoch 1: train loss 0.00013469850819092244, accuracy 0.5185185185185185\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m [Client 69] fit, config: {'current_round': 25, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m [Client 75] fit, config: {'current_round': 25, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m [Client 34] fit, config: {'current_round': 25, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m [Client 62] fit, config: {'current_round': 25, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m Epoch 1: train loss 0.0001489978894824162, accuracy 0.42592592592592593\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m Epoch 1: train loss 0.00012882103328593075, accuracy 0.6111111111111112\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m [Client 14] fit, config: {'current_round': 25, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m Epoch 1: train loss 0.0001323493052041158, accuracy 0.5925925925925926\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m Epoch 1: train loss 0.00013463063805829734, accuracy 0.5925925925925926\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m [Client 83] fit, config: {'current_round': 25, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m Epoch 1: train loss 0.00013436131121125072, accuracy 0.6111111111111112\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m Epoch 1: train loss 0.0001390505931340158, accuracy 0.5370370370370371\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m [Client 87] fit, config: {'current_round': 25, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m Epoch 1: train loss 0.00013221694098319858, accuracy 0.5555555555555556\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m [Client 43] fit, config: {'current_round': 25, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m Epoch 1: train loss 0.00013140382361598313, accuracy 0.6851851851851852\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m Epoch 1: train loss 0.0001372744736727327, accuracy 0.5555555555555556\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 12:55:54,092 | server.py:216 | fit_round received 30 results and 0 failures\n",
      "DEBUG flower 2023-02-01 12:55:54,156 | server.py:157 | evaluate_round: strategy sampled 30 clients (out of 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m [Client 20] fit, config: {'current_round': 25, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m [Client 3] fit, config: {'current_round': 25, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m Epoch 1: train loss 0.00014296105655375868, accuracy 0.5\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m [Client 59] fit, config: {'current_round': 25, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m Epoch 1: train loss 0.00014013596228323877, accuracy 0.5740740740740741\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m [Client 37] fit, config: {'current_round': 25, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m Epoch 1: train loss 0.00013128896534908563, accuracy 0.5370370370370371\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m Epoch 1: train loss 0.0001502915984019637, accuracy 0.46296296296296297\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m [Client 5] fit, config: {'current_round': 25, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m Epoch 1: train loss 0.00012471145601011813, accuracy 0.6666666666666666\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m [Client 6] fit, config: {'current_round': 25, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m Epoch 1: train loss 0.00013628570013679564, accuracy 0.5370370370370371\n",
      "Saving round 25 aggregated_parameters...\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98095)\u001b[0m [Client 43] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98095)\u001b[0m [Client 48] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98091)\u001b[0m [Client 8] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98095)\u001b[0m [Client 46] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98093)\u001b[0m [Client 73] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98089)\u001b[0m [Client 35] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98089)\u001b[0m [Client 93] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98089)\u001b[0m [Client 49] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98089)\u001b[0m [Client 75] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98089)\u001b[0m [Client 31] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98089)\u001b[0m [Client 41] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98095)\u001b[0m [Client 16] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98089)\u001b[0m [Client 29] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98091)\u001b[0m [Client 15] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98090)\u001b[0m [Client 67] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98095)\u001b[0m [Client 33] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98093)\u001b[0m [Client 81] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98089)\u001b[0m [Client 12] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98094)\u001b[0m [Client 19] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98092)\u001b[0m [Client 1] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98094)\u001b[0m [Client 13] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98094)\u001b[0m [Client 50] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98092)\u001b[0m [Client 0] evaluate, config: {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 12:55:56,382 | server.py:170 | evaluate_round received 0 results and 30 failures\n",
      "DEBUG flower 2023-02-01 12:55:56,383 | server.py:203 | fit_round: strategy sampled 30 clients (out of 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98091)\u001b[0m [Client 97] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98089)\u001b[0m [Client 99] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98094)\u001b[0m [Client 40] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98092)\u001b[0m [Client 22] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98090)\u001b[0m [Client 64] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98095)\u001b[0m [Client 86] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98093)\u001b[0m [Client 89] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m [Client 72] fit, config: {'current_round': 26, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m Epoch 1: train loss 0.00012712468742392957, accuracy 0.6296296296296297\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m [Client 43] fit, config: {'current_round': 26, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m Epoch 1: train loss 0.00013382438919506967, accuracy 0.5925925925925926\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m [Client 50] fit, config: {'current_round': 26, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m Epoch 1: train loss 0.00012924116163048893, accuracy 0.5\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m [Client 60] fit, config: {'current_round': 26, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m Epoch 1: train loss 0.00014509445463772863, accuracy 0.5370370370370371\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m [Client 81] fit, config: {'current_round': 26, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m Epoch 1: train loss 0.00014483451377600431, accuracy 0.46296296296296297\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m [Client 68] fit, config: {'current_round': 26, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m [Client 54] fit, config: {'current_round': 26, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m Epoch 1: train loss 0.00012757322110701352, accuracy 0.5740740740740741\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m Epoch 1: train loss 0.0001227558241225779, accuracy 0.5925925925925926\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m [Client 49] fit, config: {'current_round': 26, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m Epoch 1: train loss 0.00014407691196538508, accuracy 0.4444444444444444\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m [Client 87] fit, config: {'current_round': 26, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m Epoch 1: train loss 0.00012340332614257932, accuracy 0.6111111111111112\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m [Client 51] fit, config: {'current_round': 26, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m [Client 10] fit, config: {'current_round': 26, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m [Client 5] fit, config: {'current_round': 26, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m Epoch 1: train loss 0.00013716223475057632, accuracy 0.46296296296296297\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m Epoch 1: train loss 0.000123894089483656, accuracy 0.5740740740740741\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m [Client 34] fit, config: {'current_round': 26, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m Epoch 1: train loss 0.0001392931881127879, accuracy 0.46296296296296297\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m [Client 89] fit, config: {'current_round': 26, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m Epoch 1: train loss 0.00013932172441855073, accuracy 0.42592592592592593\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m [Client 66] fit, config: {'current_round': 26, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m Epoch 1: train loss 0.00012846894969698042, accuracy 0.5185185185185185\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m Epoch 1: train loss 0.00013966779806651175, accuracy 0.35185185185185186\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m [Client 94] fit, config: {'current_round': 26, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m Epoch 1: train loss 0.00013535743346437812, accuracy 0.5185185185185185\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m [Client 4] fit, config: {'current_round': 26, 'local_epochs': 3}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 12:55:58,699 | server.py:216 | fit_round received 30 results and 0 failures\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m [Client 78] fit, config: {'current_round': 26, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m [Client 22] fit, config: {'current_round': 26, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m Epoch 1: train loss 0.00015095874550752342, accuracy 0.3333333333333333\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m [Client 41] fit, config: {'current_round': 26, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m Epoch 1: train loss 0.0001271578366868198, accuracy 0.5185185185185185\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m [Client 0] fit, config: {'current_round': 26, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m Epoch 1: train loss 0.00014032037870492786, accuracy 0.5370370370370371\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m Epoch 1: train loss 0.0001474962045904249, accuracy 0.48148148148148145\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m [Client 59] fit, config: {'current_round': 26, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m Epoch 1: train loss 0.00013281316205393523, accuracy 0.5370370370370371\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m Epoch 1: train loss 0.00013881483755540103, accuracy 0.5\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m [Client 11] fit, config: {'current_round': 26, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m Epoch 1: train loss 0.00013804496848024428, accuracy 0.5740740740740741\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m [Client 9] fit, config: {'current_round': 26, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m Epoch 1: train loss 0.00014621317677665502, accuracy 0.48148148148148145\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m [Client 8] fit, config: {'current_round': 26, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m Epoch 1: train loss 0.0001349809463135898, accuracy 0.48148148148148145\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m [Client 65] fit, config: {'current_round': 26, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m Epoch 1: train loss 0.00013076773029752076, accuracy 0.5185185185185185\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m [Client 82] fit, config: {'current_round': 26, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m [Client 88] fit, config: {'current_round': 26, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m Epoch 1: train loss 0.00012950008385814726, accuracy 0.5\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m Epoch 1: train loss 0.0001312073873123154, accuracy 0.5740740740740741\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m [Client 18] fit, config: {'current_round': 26, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m Epoch 1: train loss 0.00013932639558333904, accuracy 0.4444444444444444\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m [Client 13] fit, config: {'current_round': 26, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m Epoch 1: train loss 0.00014452198229264468, accuracy 0.4444444444444444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 12:55:58,777 | server.py:157 | evaluate_round: strategy sampled 30 clients (out of 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving round 26 aggregated_parameters...\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98094)\u001b[0m [Client 60] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98095)\u001b[0m [Client 51] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98094)\u001b[0m [Client 39] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98094)\u001b[0m [Client 74] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98094)\u001b[0m [Client 3] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98094)\u001b[0m [Client 87] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98094)\u001b[0m [Client 26] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98095)\u001b[0m [Client 75] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98090)\u001b[0m [Client 20] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98095)\u001b[0m [Client 5] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98094)\u001b[0m [Client 37] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98094)\u001b[0m [Client 7] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98090)\u001b[0m [Client 13] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98095)\u001b[0m [Client 50] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98094)\u001b[0m [Client 24] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98095)\u001b[0m [Client 19] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98095)\u001b[0m [Client 2] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98095)\u001b[0m [Client 91] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98095)\u001b[0m [Client 14] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98090)\u001b[0m [Client 12] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98090)\u001b[0m [Client 95] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98094)\u001b[0m [Client 84] evaluate, config: {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 12:56:00,856 | server.py:170 | evaluate_round received 0 results and 30 failures\n",
      "DEBUG flower 2023-02-01 12:56:00,857 | server.py:203 | fit_round: strategy sampled 30 clients (out of 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98091)\u001b[0m [Client 86] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98090)\u001b[0m [Client 67] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98088)\u001b[0m [Client 10] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98095)\u001b[0m [Client 9] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98093)\u001b[0m [Client 11] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98089)\u001b[0m [Client 30] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98094)\u001b[0m [Client 70] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98092)\u001b[0m [Client 43] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m [Client 23] fit, config: {'current_round': 27, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m Epoch 1: train loss 0.00012598051398526877, accuracy 0.5555555555555556\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m [Client 43] fit, config: {'current_round': 27, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m Epoch 1: train loss 0.00012631079880520701, accuracy 0.6851851851851852\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m [Client 65] fit, config: {'current_round': 27, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m [Client 88] fit, config: {'current_round': 27, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m Epoch 1: train loss 0.00013091490836814046, accuracy 0.5185185185185185\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m [Client 64] fit, config: {'current_round': 27, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m Epoch 1: train loss 0.0001319215662078932, accuracy 0.6296296296296297\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m Epoch 1: train loss 0.00013704964658245444, accuracy 0.5740740740740741\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m [Client 81] fit, config: {'current_round': 27, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m Epoch 1: train loss 0.00013468245742842555, accuracy 0.5\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m [Client 19] fit, config: {'current_round': 27, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m Epoch 1: train loss 0.00012153540592407808, accuracy 0.6666666666666666\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m [Client 60] fit, config: {'current_round': 27, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m [Client 47] fit, config: {'current_round': 27, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m Epoch 1: train loss 0.00013607461005449295, accuracy 0.5370370370370371\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m Epoch 1: train loss 0.00013658175885211676, accuracy 0.5925925925925926\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m [Client 7] fit, config: {'current_round': 27, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m Epoch 1: train loss 0.0001288975472562015, accuracy 0.5925925925925926\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m [Client 90] fit, config: {'current_round': 27, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m Epoch 1: train loss 0.00012956262798979878, accuracy 0.5740740740740741\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m [Client 67] fit, config: {'current_round': 27, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m Epoch 1: train loss 0.00014957005623728037, accuracy 0.5740740740740741\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m [Client 35] fit, config: {'current_round': 27, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m [Client 48] fit, config: {'current_round': 27, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m Epoch 1: train loss 0.00014558553812094033, accuracy 0.4444444444444444\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m [Client 53] fit, config: {'current_round': 27, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m Epoch 1: train loss 0.00013831582327838987, accuracy 0.5740740740740741\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m [Client 34] fit, config: {'current_round': 27, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m [Client 71] fit, config: {'current_round': 27, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m Epoch 1: train loss 0.00013376816059462726, accuracy 0.6666666666666666\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m [Client 30] fit, config: {'current_round': 27, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m Epoch 1: train loss 0.00013744038005825132, accuracy 0.5\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m [Client 58] fit, config: {'current_round': 27, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m [Client 33] fit, config: {'current_round': 27, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m Epoch 1: train loss 0.0001348607474938035, accuracy 0.7037037037037037\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m Epoch 1: train loss 0.00012918544234707952, accuracy 0.6111111111111112\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m Epoch 1: train loss 0.0001290765212615952, accuracy 0.6296296296296297\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m Epoch 1: train loss 0.0001388157979818061, accuracy 0.5925925925925926\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m [Client 96] fit, config: {'current_round': 27, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m Epoch 1: train loss 0.00012029494246235117, accuracy 0.6851851851851852\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m [Client 32] fit, config: {'current_round': 27, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m [Client 66] fit, config: {'current_round': 27, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m Epoch 1: train loss 0.00013912637950852513, accuracy 0.48148148148148145\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m [Client 17] fit, config: {'current_round': 27, 'local_epochs': 3}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 12:56:03,338 | server.py:216 | fit_round received 30 results and 0 failures\n",
      "DEBUG flower 2023-02-01 12:56:03,416 | server.py:157 | evaluate_round: strategy sampled 30 clients (out of 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m [Client 38] fit, config: {'current_round': 27, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m Epoch 1: train loss 0.0001451864663977176, accuracy 0.5185185185185185\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m [Client 70] fit, config: {'current_round': 27, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m Epoch 1: train loss 0.00013992279127705842, accuracy 0.5925925925925926\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m [Client 10] fit, config: {'current_round': 27, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m Epoch 1: train loss 0.00012881703150924295, accuracy 0.6296296296296297\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m [Client 45] fit, config: {'current_round': 27, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m Epoch 1: train loss 0.00013384269550442696, accuracy 0.5555555555555556\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m Epoch 1: train loss 0.00013207034498918802, accuracy 0.5\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m [Client 63] fit, config: {'current_round': 27, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m Epoch 1: train loss 0.0001316970301559195, accuracy 0.5\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m Epoch 1: train loss 0.00012374336074572057, accuracy 0.6111111111111112\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m [Client 22] fit, config: {'current_round': 27, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m Epoch 1: train loss 0.000138232164317742, accuracy 0.5370370370370371\n",
      "Saving round 27 aggregated_parameters...\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98088)\u001b[0m [Client 8] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98090)\u001b[0m [Client 51] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98088)\u001b[0m [Client 14] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98088)\u001b[0m [Client 52] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98090)\u001b[0m [Client 1] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98090)\u001b[0m [Client 19] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98088)\u001b[0m [Client 81] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98088)\u001b[0m [Client 71] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98091)\u001b[0m [Client 85] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98090)\u001b[0m [Client 76] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98088)\u001b[0m [Client 92] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98088)\u001b[0m [Client 60] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98089)\u001b[0m [Client 83] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98088)\u001b[0m [Client 58] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98089)\u001b[0m [Client 38] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98089)\u001b[0m [Client 95] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98089)\u001b[0m [Client 74] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98089)\u001b[0m [Client 65] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98091)\u001b[0m [Client 63] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98090)\u001b[0m [Client 17] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98088)\u001b[0m [Client 30] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98089)\u001b[0m [Client 53] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98091)\u001b[0m [Client 18] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98090)\u001b[0m [Client 98] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98088)\u001b[0m [Client 21] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98095)\u001b[0m [Client 68] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98093)\u001b[0m [Client 50] evaluate, config: {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 12:56:05,536 | server.py:170 | evaluate_round received 0 results and 30 failures\n",
      "DEBUG flower 2023-02-01 12:56:05,538 | server.py:203 | fit_round: strategy sampled 30 clients (out of 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98089)\u001b[0m [Client 62] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98094)\u001b[0m [Client 86] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98092)\u001b[0m [Client 91] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m [Client 34] fit, config: {'current_round': 28, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m Epoch 1: train loss 0.00013352227688301355, accuracy 0.3333333333333333\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m [Client 90] fit, config: {'current_round': 28, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m [Client 69] fit, config: {'current_round': 28, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m Epoch 1: train loss 0.00012230832362547517, accuracy 0.5555555555555556\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m [Client 71] fit, config: {'current_round': 28, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m [Client 38] fit, config: {'current_round': 28, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m Epoch 1: train loss 0.00012809380132239312, accuracy 0.6296296296296297\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m Epoch 1: train loss 0.0001236370881088078, accuracy 0.5925925925925926\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m [Client 62] fit, config: {'current_round': 28, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m Epoch 1: train loss 0.00012080225860700011, accuracy 0.5740740740740741\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m Epoch 1: train loss 0.00013002388004679233, accuracy 0.5740740740740741\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m [Client 92] fit, config: {'current_round': 28, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m Epoch 1: train loss 0.0001176785008283332, accuracy 0.6111111111111112\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m [Client 26] fit, config: {'current_round': 28, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m [Client 3] fit, config: {'current_round': 28, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m Epoch 1: train loss 0.000134940622956492, accuracy 0.46296296296296297\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m Epoch 1: train loss 0.00014039048983249813, accuracy 0.48148148148148145\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m [Client 37] fit, config: {'current_round': 28, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m Epoch 1: train loss 0.00011236208956688643, accuracy 0.5925925925925926\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m [Client 6] fit, config: {'current_round': 28, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m Epoch 1: train loss 0.00013274443335831165, accuracy 0.5555555555555556\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m [Client 88] fit, config: {'current_round': 28, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m Epoch 1: train loss 0.0001224785519298166, accuracy 0.5555555555555556\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m [Client 74] fit, config: {'current_round': 28, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m Epoch 1: train loss 0.0001339091977570206, accuracy 0.5555555555555556\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m [Client 79] fit, config: {'current_round': 28, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m Epoch 1: train loss 0.00013752473751083016, accuracy 0.3888888888888889\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m [Client 21] fit, config: {'current_round': 28, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m Epoch 1: train loss 0.00014783223741687834, accuracy 0.4444444444444444\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m [Client 95] fit, config: {'current_round': 28, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m Epoch 1: train loss 0.00012207507097627968, accuracy 0.5555555555555556\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m [Client 42] fit, config: {'current_round': 28, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m Epoch 1: train loss 0.00012695776240434498, accuracy 0.5925925925925926\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m [Client 45] fit, config: {'current_round': 28, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m Epoch 1: train loss 0.0001279991993214935, accuracy 0.5555555555555556\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m [Client 2] fit, config: {'current_round': 28, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m Epoch 1: train loss 0.00011388335406081751, accuracy 0.5555555555555556\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m [Client 47] fit, config: {'current_round': 28, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m [Client 54] fit, config: {'current_round': 28, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m Epoch 1: train loss 0.00012406006862875074, accuracy 0.5925925925925926\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m Epoch 1: train loss 0.00012368420721031725, accuracy 0.5740740740740741\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m [Client 91] fit, config: {'current_round': 28, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m Epoch 1: train loss 0.00013008713722229004, accuracy 0.46296296296296297\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m [Client 97] fit, config: {'current_round': 28, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m Epoch 1: train loss 0.0001491167495260015, accuracy 0.5185185185185185\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m [Client 65] fit, config: {'current_round': 28, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m [Client 13] fit, config: {'current_round': 28, 'local_epochs': 3}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 12:56:07,703 | server.py:216 | fit_round received 30 results and 0 failures\n",
      "DEBUG flower 2023-02-01 12:56:07,761 | server.py:157 | evaluate_round: strategy sampled 30 clients (out of 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m [Client 27] fit, config: {'current_round': 28, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m Epoch 1: train loss 0.00012664544919971377, accuracy 0.5370370370370371\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m [Client 52] fit, config: {'current_round': 28, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m Epoch 1: train loss 0.00012534583220258355, accuracy 0.5740740740740741\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m [Client 0] fit, config: {'current_round': 28, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m Epoch 1: train loss 0.00013716546527575701, accuracy 0.5370370370370371\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m Epoch 1: train loss 0.00012663706729654223, accuracy 0.5370370370370371\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m [Client 50] fit, config: {'current_round': 28, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m Epoch 1: train loss 0.00012322339171078056, accuracy 0.5185185185185185\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m [Client 66] fit, config: {'current_round': 28, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m Epoch 1: train loss 0.00012326757132541388, accuracy 0.5740740740740741\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m Epoch 1: train loss 0.00013873445277567953, accuracy 0.4444444444444444\n",
      "Saving round 28 aggregated_parameters...\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98091)\u001b[0m [Client 24] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98094)\u001b[0m [Client 89] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98094)\u001b[0m [Client 4] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98091)\u001b[0m [Client 48] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98091)\u001b[0m [Client 6] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98091)\u001b[0m [Client 65] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98091)\u001b[0m [Client 81] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98088)\u001b[0m [Client 22] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98089)\u001b[0m [Client 25] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98094)\u001b[0m [Client 26] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98090)\u001b[0m [Client 37] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98093)\u001b[0m [Client 15] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98092)\u001b[0m [Client 84] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98089)\u001b[0m [Client 0] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98089)\u001b[0m [Client 93] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98090)\u001b[0m [Client 36] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98089)\u001b[0m [Client 40] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98089)\u001b[0m [Client 98] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98090)\u001b[0m [Client 39] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98089)\u001b[0m [Client 70] evaluate, config: {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 12:56:10,170 | server.py:170 | evaluate_round received 0 results and 30 failures\n",
      "DEBUG flower 2023-02-01 12:56:10,171 | server.py:203 | fit_round: strategy sampled 30 clients (out of 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98088)\u001b[0m [Client 76] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98092)\u001b[0m [Client 54] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98091)\u001b[0m [Client 8] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98090)\u001b[0m [Client 21] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98088)\u001b[0m [Client 28] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98095)\u001b[0m [Client 64] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98093)\u001b[0m [Client 7] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98089)\u001b[0m [Client 79] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98094)\u001b[0m [Client 42] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98092)\u001b[0m [Client 9] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m [Client 32] fit, config: {'current_round': 29, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m Epoch 1: train loss 0.0001299752329941839, accuracy 0.48148148148148145\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m [Client 50] fit, config: {'current_round': 29, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m Epoch 1: train loss 0.00013070176646579057, accuracy 0.5370370370370371\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m [Client 23] fit, config: {'current_round': 29, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m Epoch 1: train loss 0.00012307928409427404, accuracy 0.5740740740740741\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m [Client 2] fit, config: {'current_round': 29, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m [Client 11] fit, config: {'current_round': 29, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m [Client 51] fit, config: {'current_round': 29, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m Epoch 1: train loss 0.000132466564537026, accuracy 0.5555555555555556\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m [Client 78] fit, config: {'current_round': 29, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m Epoch 1: train loss 0.00013087020488455892, accuracy 0.5\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m Epoch 1: train loss 0.00012107053771615028, accuracy 0.5\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m Epoch 1: train loss 0.0001386719522997737, accuracy 0.5370370370370371\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m [Client 85] fit, config: {'current_round': 29, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m [Client 70] fit, config: {'current_round': 29, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m Epoch 1: train loss 0.0001311734231421724, accuracy 0.42592592592592593\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m [Client 31] fit, config: {'current_round': 29, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m Epoch 1: train loss 0.00013809891242999583, accuracy 0.5370370370370371\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m Epoch 1: train loss 0.00013755075633525848, accuracy 0.5925925925925926\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m [Client 10] fit, config: {'current_round': 29, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m Epoch 1: train loss 0.00012829045590478927, accuracy 0.6296296296296297\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m [Client 82] fit, config: {'current_round': 29, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m [Client 28] fit, config: {'current_round': 29, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m Epoch 1: train loss 0.00013461685739457607, accuracy 0.5740740740740741\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m Epoch 1: train loss 0.00012001104187220335, accuracy 0.5925925925925926\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m [Client 7] fit, config: {'current_round': 29, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m Epoch 1: train loss 0.0001258593110833317, accuracy 0.5740740740740741\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m [Client 65] fit, config: {'current_round': 29, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m Epoch 1: train loss 0.00012718696962110698, accuracy 0.5370370370370371\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m [Client 61] fit, config: {'current_round': 29, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m Epoch 1: train loss 0.0001245622697751969, accuracy 0.6296296296296297\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 12:56:12,321 | server.py:216 | fit_round received 30 results and 0 failures\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m [Client 77] fit, config: {'current_round': 29, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m [Client 5] fit, config: {'current_round': 29, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m [Client 41] fit, config: {'current_round': 29, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m Epoch 1: train loss 0.00014149137132335454, accuracy 0.46296296296296297\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m [Client 13] fit, config: {'current_round': 29, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m Epoch 1: train loss 0.0001430880365660414, accuracy 0.5\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m [Client 54] fit, config: {'current_round': 29, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m Epoch 1: train loss 0.0001305936893913895, accuracy 0.5925925925925926\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m [Client 92] fit, config: {'current_round': 29, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m [Client 38] fit, config: {'current_round': 29, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m Epoch 1: train loss 0.00014016444038134068, accuracy 0.5740740740740741\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m Epoch 1: train loss 0.00012642861111089587, accuracy 0.7037037037037037\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m Epoch 1: train loss 0.00011635560804279521, accuracy 0.6481481481481481\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m Epoch 1: train loss 0.0001316870329901576, accuracy 0.5\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m [Client 43] fit, config: {'current_round': 29, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m Epoch 1: train loss 0.00012127913214499131, accuracy 0.7037037037037037\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m [Client 47] fit, config: {'current_round': 29, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m Epoch 1: train loss 0.00013143949036020786, accuracy 0.5555555555555556\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m [Client 29] fit, config: {'current_round': 29, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m [Client 73] fit, config: {'current_round': 29, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m Epoch 1: train loss 0.00011934147914871573, accuracy 0.5925925925925926\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m [Client 14] fit, config: {'current_round': 29, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m Epoch 1: train loss 0.00012497595162130892, accuracy 0.5925925925925926\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m [Client 0] fit, config: {'current_round': 29, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m Epoch 1: train loss 0.00013316773402038962, accuracy 0.5925925925925926\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m Epoch 1: train loss 0.0001307363127125427, accuracy 0.5\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m [Client 79] fit, config: {'current_round': 29, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m Epoch 1: train loss 0.00012055106344632804, accuracy 0.5740740740740741\n",
      "Saving round 29 aggregated_parameters...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 12:56:12,376 | server.py:157 | evaluate_round: strategy sampled 30 clients (out of 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98088)\u001b[0m [Client 25] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98093)\u001b[0m [Client 57] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98092)\u001b[0m [Client 83] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98093)\u001b[0m [Client 39] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98092)\u001b[0m [Client 59] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98088)\u001b[0m [Client 24] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98093)\u001b[0m [Client 53] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98088)\u001b[0m [Client 44] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98088)\u001b[0m [Client 89] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98095)\u001b[0m [Client 17] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98093)\u001b[0m [Client 9] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98089)\u001b[0m [Client 18] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98092)\u001b[0m [Client 3] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98088)\u001b[0m [Client 49] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98088)\u001b[0m [Client 11] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98089)\u001b[0m [Client 56] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98092)\u001b[0m [Client 92] evaluate, config: {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 12:56:14,623 | server.py:170 | evaluate_round received 0 results and 30 failures\n",
      "DEBUG flower 2023-02-01 12:56:14,624 | server.py:203 | fit_round: strategy sampled 30 clients (out of 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98089)\u001b[0m [Client 41] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98092)\u001b[0m [Client 55] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98088)\u001b[0m [Client 64] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98089)\u001b[0m [Client 16] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98092)\u001b[0m [Client 73] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98091)\u001b[0m [Client 23] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98088)\u001b[0m [Client 85] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98093)\u001b[0m [Client 67] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98094)\u001b[0m [Client 26] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98092)\u001b[0m [Client 94] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98090)\u001b[0m [Client 61] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98095)\u001b[0m [Client 52] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98089)\u001b[0m [Client 22] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m [Client 45] fit, config: {'current_round': 30, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m Epoch 1: train loss 0.0001271358341909945, accuracy 0.5370370370370371\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m [Client 69] fit, config: {'current_round': 30, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m Epoch 1: train loss 0.00011918604286620393, accuracy 0.5555555555555556\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m [Client 25] fit, config: {'current_round': 30, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m Epoch 1: train loss 0.00012581475311890244, accuracy 0.48148148148148145\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m [Client 41] fit, config: {'current_round': 30, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m [Client 18] fit, config: {'current_round': 30, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m Epoch 1: train loss 0.00013454625150188804, accuracy 0.4444444444444444\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m [Client 13] fit, config: {'current_round': 30, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m Epoch 1: train loss 0.00013552006566897035, accuracy 0.3888888888888889\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m [Client 39] fit, config: {'current_round': 30, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m Epoch 1: train loss 0.00012434310337994248, accuracy 0.5740740740740741\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m Epoch 1: train loss 0.00011528107279445976, accuracy 0.5370370370370371\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m [Client 27] fit, config: {'current_round': 30, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m Epoch 1: train loss 0.00012424953456502408, accuracy 0.5925925925925926\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m [Client 42] fit, config: {'current_round': 30, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m Epoch 1: train loss 0.0001240754936588928, accuracy 0.6111111111111112\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m [Client 6] fit, config: {'current_round': 30, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m Epoch 1: train loss 0.000130888307467103, accuracy 0.5185185185185185\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m [Client 44] fit, config: {'current_round': 30, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m Epoch 1: train loss 0.00013628964370582253, accuracy 0.46296296296296297\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m [Client 87] fit, config: {'current_round': 30, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m [Client 37] fit, config: {'current_round': 30, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m Epoch 1: train loss 0.0001081741793313995, accuracy 0.5370370370370371\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m [Client 81] fit, config: {'current_round': 30, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m Epoch 1: train loss 0.0001391473488183692, accuracy 0.48148148148148145\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m Epoch 1: train loss 0.00011383360833860934, accuracy 0.6111111111111112\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m [Client 96] fit, config: {'current_round': 30, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m Epoch 1: train loss 0.00012318487279117107, accuracy 0.5\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m [Client 15] fit, config: {'current_round': 30, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m Epoch 1: train loss 0.00014175695832818747, accuracy 0.5185185185185185\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m [Client 51] fit, config: {'current_round': 30, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m Epoch 1: train loss 0.0001144184498116374, accuracy 0.6296296296296297\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m [Client 46] fit, config: {'current_round': 30, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m Epoch 1: train loss 0.00011033510963898152, accuracy 0.6296296296296297\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m [Client 19] fit, config: {'current_round': 30, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m Epoch 1: train loss 0.00011739980982383713, accuracy 0.5370370370370371\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m [Client 80] fit, config: {'current_round': 30, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m [Client 24] fit, config: {'current_round': 30, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m [Client 79] fit, config: {'current_round': 30, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m Epoch 1: train loss 0.0001373681443510577, accuracy 0.3333333333333333\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m Epoch 1: train loss 0.00010670885967556387, accuracy 0.6666666666666666\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m [Client 73] fit, config: {'current_round': 30, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m Epoch 1: train loss 0.0001240427081938833, accuracy 0.46296296296296297\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 12:56:16,962 | server.py:216 | fit_round received 30 results and 0 failures\n",
      "DEBUG flower 2023-02-01 12:56:17,030 | server.py:157 | evaluate_round: strategy sampled 30 clients (out of 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m Epoch 1: train loss 0.000128558196593076, accuracy 0.5\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m [Client 71] fit, config: {'current_round': 30, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m Epoch 1: train loss 0.00012963468907400966, accuracy 0.5555555555555556\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m [Client 83] fit, config: {'current_round': 30, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m Epoch 1: train loss 0.00012833040091209114, accuracy 0.42592592592592593\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m [Client 22] fit, config: {'current_round': 30, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m Epoch 1: train loss 0.0001478526392020285, accuracy 0.35185185185185186\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m [Client 28] fit, config: {'current_round': 30, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m Epoch 1: train loss 0.00011390419967938215, accuracy 0.6111111111111112\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m [Client 95] fit, config: {'current_round': 30, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m Epoch 1: train loss 0.00011956547677982599, accuracy 0.5555555555555556\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m [Client 16] fit, config: {'current_round': 30, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m [Client 35] fit, config: {'current_round': 30, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m Epoch 1: train loss 0.0001387595693813637, accuracy 0.5\n",
      "Saving round 30 aggregated_parameters...\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m Epoch 1: train loss 0.00012915756087750196, accuracy 0.48148148148148145\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98090)\u001b[0m [Client 54] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98095)\u001b[0m [Client 11] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98089)\u001b[0m [Client 77] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98094)\u001b[0m [Client 84] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98094)\u001b[0m [Client 41] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98095)\u001b[0m [Client 16] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98094)\u001b[0m [Client 45] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98095)\u001b[0m [Client 60] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98095)\u001b[0m [Client 27] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98095)\u001b[0m [Client 80] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98090)\u001b[0m [Client 34] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98094)\u001b[0m [Client 19] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98090)\u001b[0m [Client 83] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98095)\u001b[0m [Client 66] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98094)\u001b[0m [Client 17] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98095)\u001b[0m [Client 55] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98094)\u001b[0m [Client 56] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98090)\u001b[0m [Client 78] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98095)\u001b[0m [Client 52] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98090)\u001b[0m [Client 1] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98090)\u001b[0m [Client 73] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98095)\u001b[0m [Client 0] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98095)\u001b[0m [Client 59] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98090)\u001b[0m [Client 8] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98088)\u001b[0m [Client 24] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98093)\u001b[0m [Client 15] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98089)\u001b[0m [Client 29] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98094)\u001b[0m [Client 70] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98092)\u001b[0m [Client 68] evaluate, config: {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 12:56:19,233 | server.py:170 | evaluate_round received 0 results and 30 failures\n",
      "DEBUG flower 2023-02-01 12:56:19,234 | server.py:203 | fit_round: strategy sampled 30 clients (out of 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98091)\u001b[0m [Client 99] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m [Client 26] fit, config: {'current_round': 31, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m Epoch 1: train loss 0.00014424181426875293, accuracy 0.5\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m [Client 93] fit, config: {'current_round': 31, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m Epoch 1: train loss 0.00012432293442543596, accuracy 0.5740740740740741\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m [Client 96] fit, config: {'current_round': 31, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m Epoch 1: train loss 0.00010963201202685013, accuracy 0.7407407407407407\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m [Client 6] fit, config: {'current_round': 31, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m Epoch 1: train loss 0.00012468991917558014, accuracy 0.5925925925925926\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m [Client 22] fit, config: {'current_round': 31, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m Epoch 1: train loss 0.00013212701014708728, accuracy 0.5\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m [Client 87] fit, config: {'current_round': 31, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m [Client 46] fit, config: {'current_round': 31, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m Epoch 1: train loss 0.00012602224887814373, accuracy 0.6111111111111112\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m Epoch 1: train loss 0.00011834573524538428, accuracy 0.6666666666666666\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m [Client 83] fit, config: {'current_round': 31, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m Epoch 1: train loss 0.0001249960478162393, accuracy 0.5740740740740741\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m [Client 0] fit, config: {'current_round': 31, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m Epoch 1: train loss 0.00013367438805289567, accuracy 0.5740740740740741\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m [Client 49] fit, config: {'current_round': 31, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m Epoch 1: train loss 0.00012797507224604487, accuracy 0.5740740740740741\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m [Client 35] fit, config: {'current_round': 31, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m [Client 3] fit, config: {'current_round': 31, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m [Client 27] fit, config: {'current_round': 31, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m [Client 81] fit, config: {'current_round': 31, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m Epoch 1: train loss 0.00013788252545055002, accuracy 0.48148148148148145\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m Epoch 1: train loss 0.00012831625645048916, accuracy 0.5555555555555556\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m Epoch 1: train loss 0.00012800301192328334, accuracy 0.5740740740740741\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m [Client 64] fit, config: {'current_round': 31, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m Epoch 1: train loss 0.00012875028187409043, accuracy 0.5\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m [Client 84] fit, config: {'current_round': 31, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m Epoch 1: train loss 0.00011821102089015767, accuracy 0.6296296296296297\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m [Client 66] fit, config: {'current_round': 31, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m Epoch 1: train loss 0.0001217289682244882, accuracy 0.6296296296296297\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m [Client 57] fit, config: {'current_round': 31, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m Epoch 1: train loss 0.00013387984654400498, accuracy 0.46296296296296297\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m [Client 31] fit, config: {'current_round': 31, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m Epoch 1: train loss 0.00013399911404121667, accuracy 0.5370370370370371\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m [Client 89] fit, config: {'current_round': 31, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m Epoch 1: train loss 0.00013268610928207636, accuracy 0.46296296296296297\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m [Client 56] fit, config: {'current_round': 31, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m Epoch 1: train loss 0.00013080229109618813, accuracy 0.42592592592592593\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m Epoch 1: train loss 0.00013018048775848, accuracy 0.5555555555555556\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m [Client 43] fit, config: {'current_round': 31, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m Epoch 1: train loss 0.0001188166716019623, accuracy 0.7037037037037037\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m [Client 48] fit, config: {'current_round': 31, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m Epoch 1: train loss 0.000137440423713997, accuracy 0.5\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m [Client 15] fit, config: {'current_round': 31, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m Epoch 1: train loss 0.00014716027362737805, accuracy 0.4444444444444444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 12:56:21,582 | server.py:216 | fit_round received 30 results and 0 failures\n",
      "DEBUG flower 2023-02-01 12:56:21,669 | server.py:157 | evaluate_round: strategy sampled 30 clients (out of 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m [Client 42] fit, config: {'current_round': 31, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m [Client 55] fit, config: {'current_round': 31, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m [Client 71] fit, config: {'current_round': 31, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m [Client 97] fit, config: {'current_round': 31, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m Epoch 1: train loss 0.00014868949074298143, accuracy 0.5\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m [Client 14] fit, config: {'current_round': 31, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m Epoch 1: train loss 0.00012055449769832194, accuracy 0.6481481481481481\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m Epoch 1: train loss 0.00012280576629564166, accuracy 0.6296296296296297\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m Epoch 1: train loss 0.0001156240250566043, accuracy 0.6666666666666666\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m Epoch 1: train loss 0.00012294409680180252, accuracy 0.7222222222222222\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m [Client 18] fit, config: {'current_round': 31, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m Epoch 1: train loss 0.00013729481725022197, accuracy 0.5\n",
      "Saving round 31 aggregated_parameters...\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98094)\u001b[0m [Client 70] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98090)\u001b[0m [Client 61] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98088)\u001b[0m [Client 52] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98088)\u001b[0m [Client 42] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98094)\u001b[0m [Client 40] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98094)\u001b[0m [Client 4] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98088)\u001b[0m [Client 92] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98094)\u001b[0m [Client 73] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98094)\u001b[0m [Client 26] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98088)\u001b[0m [Client 17] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98088)\u001b[0m [Client 64] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98088)\u001b[0m [Client 35] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98094)\u001b[0m [Client 88] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98090)\u001b[0m [Client 27] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98095)\u001b[0m [Client 67] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98093)\u001b[0m [Client 16] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98094)\u001b[0m [Client 77] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98090)\u001b[0m [Client 65] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98090)\u001b[0m [Client 50] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98090)\u001b[0m [Client 48] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98090)\u001b[0m [Client 57] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98093)\u001b[0m [Client 5] evaluate, config: {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 12:56:23,742 | server.py:170 | evaluate_round received 0 results and 30 failures\n",
      "DEBUG flower 2023-02-01 12:56:23,743 | server.py:203 | fit_round: strategy sampled 30 clients (out of 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98091)\u001b[0m [Client 79] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98088)\u001b[0m [Client 95] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98095)\u001b[0m [Client 80] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98093)\u001b[0m [Client 98] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98089)\u001b[0m [Client 7] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98094)\u001b[0m [Client 91] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98092)\u001b[0m [Client 36] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98090)\u001b[0m [Client 87] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m [Client 9] fit, config: {'current_round': 32, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m Epoch 1: train loss 0.00013785361079499125, accuracy 0.5185185185185185\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m [Client 18] fit, config: {'current_round': 32, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m Epoch 1: train loss 0.00013240643602330238, accuracy 0.46296296296296297\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m [Client 21] fit, config: {'current_round': 32, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m Epoch 1: train loss 0.00014354272570926696, accuracy 0.48148148148148145\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m [Client 29] fit, config: {'current_round': 32, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m [Client 75] fit, config: {'current_round': 32, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m Epoch 1: train loss 0.00013378252333495766, accuracy 0.48148148148148145\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m Epoch 1: train loss 0.00011849424481624737, accuracy 0.5555555555555556\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m [Client 7] fit, config: {'current_round': 32, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m [Client 10] fit, config: {'current_round': 32, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m Epoch 1: train loss 0.00012989492097403854, accuracy 0.5740740740740741\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m Epoch 1: train loss 0.00013016686716582626, accuracy 0.48148148148148145\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m [Client 13] fit, config: {'current_round': 32, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m Epoch 1: train loss 0.00013398109877016395, accuracy 0.4074074074074074\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m [Client 71] fit, config: {'current_round': 32, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m [Client 92] fit, config: {'current_round': 32, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m [Client 60] fit, config: {'current_round': 32, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m [Client 57] fit, config: {'current_round': 32, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m Epoch 1: train loss 0.00012924641487188637, accuracy 0.46296296296296297\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m Epoch 1: train loss 0.00012281729141250253, accuracy 0.5740740740740741\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m Epoch 1: train loss 0.00011493165220599622, accuracy 0.5925925925925926\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m Epoch 1: train loss 0.00013185125135350972, accuracy 0.5555555555555556\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m [Client 48] fit, config: {'current_round': 32, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m Epoch 1: train loss 0.00012112281547160819, accuracy 0.5740740740740741\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m [Client 69] fit, config: {'current_round': 32, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m Epoch 1: train loss 0.00011731543781934306, accuracy 0.5\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m [Client 37] fit, config: {'current_round': 32, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m Epoch 1: train loss 0.00010619037493597716, accuracy 0.6111111111111112\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m [Client 74] fit, config: {'current_round': 32, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m Epoch 1: train loss 0.0001302532764384523, accuracy 0.4444444444444444\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m [Client 96] fit, config: {'current_round': 32, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m Epoch 1: train loss 0.00012124426575610414, accuracy 0.5555555555555556\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m [Client 38] fit, config: {'current_round': 32, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m [Client 89] fit, config: {'current_round': 32, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m [Client 36] fit, config: {'current_round': 32, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m Epoch 1: train loss 0.0001374288840452209, accuracy 0.46296296296296297\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m [Client 23] fit, config: {'current_round': 32, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m Epoch 1: train loss 0.00013160021626390517, accuracy 0.5185185185185185\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m [Client 5] fit, config: {'current_round': 32, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m Epoch 1: train loss 0.00012654669990297407, accuracy 0.48148148148148145\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m Epoch 1: train loss 0.00012109671661164612, accuracy 0.5740740740740741\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m Epoch 1: train loss 0.00012727991270367056, accuracy 0.4444444444444444\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m [Client 72] fit, config: {'current_round': 32, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m Epoch 1: train loss 0.0001169526221929118, accuracy 0.6296296296296297\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m [Client 44] fit, config: {'current_round': 32, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m Epoch 1: train loss 0.0001353501429548487, accuracy 0.46296296296296297\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m [Client 39] fit, config: {'current_round': 32, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m Epoch 1: train loss 0.0001212886199937202, accuracy 0.5925925925925926\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m [Client 49] fit, config: {'current_round': 32, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m Epoch 1: train loss 0.00013372726971283555, accuracy 0.46296296296296297\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m [Client 19] fit, config: {'current_round': 32, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m Epoch 1: train loss 0.00011412313324399292, accuracy 0.5555555555555556\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m [Client 81] fit, config: {'current_round': 32, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m Epoch 1: train loss 0.00013699379633180797, accuracy 0.48148148148148145\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m [Client 97] fit, config: {'current_round': 32, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m Epoch 1: train loss 0.00014626634947489947, accuracy 0.5185185185185185\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 12:56:26,154 | server.py:216 | fit_round received 30 results and 0 failures\n",
      "DEBUG flower 2023-02-01 12:56:26,212 | server.py:157 | evaluate_round: strategy sampled 30 clients (out of 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m [Client 20] fit, config: {'current_round': 32, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m Epoch 1: train loss 0.00013450738333631307, accuracy 0.5185185185185185\n",
      "Saving round 32 aggregated_parameters...\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98094)\u001b[0m [Client 19] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98092)\u001b[0m [Client 39] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98089)\u001b[0m [Client 25] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98094)\u001b[0m [Client 23] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98092)\u001b[0m [Client 5] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98094)\u001b[0m [Client 75] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98094)\u001b[0m [Client 1] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98094)\u001b[0m [Client 77] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98091)\u001b[0m [Client 65] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98090)\u001b[0m [Client 85] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98089)\u001b[0m [Client 82] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98094)\u001b[0m [Client 46] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98092)\u001b[0m [Client 22] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98091)\u001b[0m [Client 87] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98090)\u001b[0m [Client 81] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98092)\u001b[0m [Client 95] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98092)\u001b[0m [Client 41] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98091)\u001b[0m [Client 53] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98092)\u001b[0m [Client 97] evaluate, config: {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 12:56:28,510 | server.py:170 | evaluate_round received 0 results and 30 failures\n",
      "DEBUG flower 2023-02-01 12:56:28,513 | server.py:203 | fit_round: strategy sampled 30 clients (out of 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98088)\u001b[0m [Client 50] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98088)\u001b[0m [Client 40] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98095)\u001b[0m [Client 15] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98094)\u001b[0m [Client 89] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98091)\u001b[0m [Client 33] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98095)\u001b[0m [Client 84] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98093)\u001b[0m [Client 37] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98094)\u001b[0m [Client 28] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98090)\u001b[0m [Client 62] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98089)\u001b[0m [Client 34] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98092)\u001b[0m [Client 93] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m [Client 81] fit, config: {'current_round': 33, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m [Client 47] fit, config: {'current_round': 33, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m Epoch 1: train loss 0.00012714613694697618, accuracy 0.5740740740740741\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m Epoch 1: train loss 0.00012857541150879115, accuracy 0.5555555555555556\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m [Client 4] fit, config: {'current_round': 33, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m Epoch 1: train loss 0.00013309773930814117, accuracy 0.46296296296296297\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m [Client 99] fit, config: {'current_round': 33, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m Epoch 1: train loss 0.0001289200590690598, accuracy 0.6111111111111112\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m [Client 97] fit, config: {'current_round': 33, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m [Client 18] fit, config: {'current_round': 33, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m Epoch 1: train loss 0.00013652624329552054, accuracy 0.5370370370370371\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m Epoch 1: train loss 0.0001499149075243622, accuracy 0.5185185185185185\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m [Client 66] fit, config: {'current_round': 33, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m Epoch 1: train loss 0.00013121757365297526, accuracy 0.46296296296296297\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m [Client 60] fit, config: {'current_round': 33, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m Epoch 1: train loss 0.0001267557090613991, accuracy 0.5925925925925926\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m [Client 79] fit, config: {'current_round': 33, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m Epoch 1: train loss 0.00011618853750405833, accuracy 0.5555555555555556\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m [Client 2] fit, config: {'current_round': 33, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m Epoch 1: train loss 0.00011531067866599187, accuracy 0.5740740740740741\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m [Client 50] fit, config: {'current_round': 33, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m [Client 70] fit, config: {'current_round': 33, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m Epoch 1: train loss 0.00013146409764885902, accuracy 0.6296296296296297\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m [Client 41] fit, config: {'current_round': 33, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m Epoch 1: train loss 0.00012414657976478338, accuracy 0.5370370370370371\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m [Client 37] fit, config: {'current_round': 33, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m [Client 91] fit, config: {'current_round': 33, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m Epoch 1: train loss 0.00011573835945455357, accuracy 0.6666666666666666\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m [Client 73] fit, config: {'current_round': 33, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m Epoch 1: train loss 0.00011498769163154066, accuracy 0.5555555555555556\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m Epoch 1: train loss 0.0001353238185402006, accuracy 0.4444444444444444\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m [Client 23] fit, config: {'current_round': 33, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m [Client 24] fit, config: {'current_round': 33, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m Epoch 1: train loss 0.00010560581722529605, accuracy 0.6851851851851852\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m Epoch 1: train loss 0.0001174858189187944, accuracy 0.5740740740740741\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m [Client 59] fit, config: {'current_round': 33, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m Epoch 1: train loss 0.00012867592158727348, accuracy 0.6111111111111112\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m Epoch 1: train loss 0.00011677130532916635, accuracy 0.5740740740740741\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m [Client 33] fit, config: {'current_round': 33, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m Epoch 1: train loss 0.00012409755436237901, accuracy 0.6481481481481481\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m [Client 28] fit, config: {'current_round': 33, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m Epoch 1: train loss 0.00012821328709833324, accuracy 0.5925925925925926\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m [Client 27] fit, config: {'current_round': 33, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m [Client 7] fit, config: {'current_round': 33, 'local_epochs': 3}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 12:56:30,822 | server.py:216 | fit_round received 30 results and 0 failures\n",
      "DEBUG flower 2023-02-01 12:56:30,875 | server.py:157 | evaluate_round: strategy sampled 30 clients (out of 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m Epoch 1: train loss 0.0001287922787014395, accuracy 0.5555555555555556\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m Epoch 1: train loss 0.00011980271665379405, accuracy 0.5925925925925926\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m [Client 48] fit, config: {'current_round': 33, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m [Client 87] fit, config: {'current_round': 33, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m Epoch 1: train loss 0.00012473024253267795, accuracy 0.5740740740740741\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m [Client 72] fit, config: {'current_round': 33, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m Epoch 1: train loss 0.00012021153816021979, accuracy 0.6666666666666666\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m [Client 39] fit, config: {'current_round': 33, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m Epoch 1: train loss 0.00012144751235609874, accuracy 0.5185185185185185\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m [Client 94] fit, config: {'current_round': 33, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m Epoch 1: train loss 0.0001188274472951889, accuracy 0.5740740740740741\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m [Client 11] fit, config: {'current_round': 33, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m Epoch 1: train loss 0.00013491316349245608, accuracy 0.5185185185185185\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m [Client 74] fit, config: {'current_round': 33, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m Epoch 1: train loss 0.00013783841859549284, accuracy 0.6296296296296297\n",
      "Saving round 33 aggregated_parameters...\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m Epoch 1: train loss 0.00013947095430921763, accuracy 0.5185185185185185\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98090)\u001b[0m [Client 53] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98092)\u001b[0m [Client 48] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98095)\u001b[0m [Client 54] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98095)\u001b[0m [Client 55] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98090)\u001b[0m [Client 36] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98092)\u001b[0m [Client 82] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98093)\u001b[0m [Client 2] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98093)\u001b[0m [Client 8] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98093)\u001b[0m [Client 83] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98088)\u001b[0m [Client 4] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98095)\u001b[0m [Client 86] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98089)\u001b[0m [Client 74] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98090)\u001b[0m [Client 16] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98095)\u001b[0m [Client 5] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98089)\u001b[0m [Client 28] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98092)\u001b[0m [Client 23] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98091)\u001b[0m [Client 93] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98088)\u001b[0m [Client 41] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98093)\u001b[0m [Client 88] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98094)\u001b[0m [Client 75] evaluate, config: {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 12:56:33,358 | server.py:170 | evaluate_round received 0 results and 30 failures\n",
      "DEBUG flower 2023-02-01 12:56:33,361 | server.py:203 | fit_round: strategy sampled 30 clients (out of 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98093)\u001b[0m [Client 89] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98091)\u001b[0m [Client 56] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98093)\u001b[0m [Client 0] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98094)\u001b[0m [Client 44] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98091)\u001b[0m [Client 51] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98088)\u001b[0m [Client 91] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98095)\u001b[0m [Client 95] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98093)\u001b[0m [Client 27] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98089)\u001b[0m [Client 17] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98094)\u001b[0m [Client 45] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m [Client 6] fit, config: {'current_round': 34, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m Epoch 1: train loss 0.00012614592560566962, accuracy 0.5370370370370371\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m [Client 67] fit, config: {'current_round': 34, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m Epoch 1: train loss 0.00013946504623163491, accuracy 0.5370370370370371\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m [Client 0] fit, config: {'current_round': 34, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m Epoch 1: train loss 0.00013112286978866905, accuracy 0.5740740740740741\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m [Client 2] fit, config: {'current_round': 34, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m Epoch 1: train loss 0.00010439698962727562, accuracy 0.5925925925925926\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m [Client 97] fit, config: {'current_round': 34, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m Epoch 1: train loss 0.00014312872372101992, accuracy 0.5185185185185185\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m [Client 49] fit, config: {'current_round': 34, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m Epoch 1: train loss 0.0001296331756748259, accuracy 0.5185185185185185\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m [Client 32] fit, config: {'current_round': 34, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m Epoch 1: train loss 0.00011283488129265606, accuracy 0.5185185185185185\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m [Client 36] fit, config: {'current_round': 34, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m Epoch 1: train loss 0.00013190449681133032, accuracy 0.46296296296296297\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m [Client 37] fit, config: {'current_round': 34, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m Epoch 1: train loss 0.00010108038259204477, accuracy 0.6296296296296297\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m [Client 71] fit, config: {'current_round': 34, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m Epoch 1: train loss 0.00011992980580544099, accuracy 0.5740740740740741\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m [Client 27] fit, config: {'current_round': 34, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m [Client 52] fit, config: {'current_round': 34, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m [Client 15] fit, config: {'current_round': 34, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m Epoch 1: train loss 0.00013813379337079823, accuracy 0.5370370370370371\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m [Client 94] fit, config: {'current_round': 34, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m Epoch 1: train loss 0.00012179113400634378, accuracy 0.5740740740740741\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m Epoch 1: train loss 0.00011910628381883726, accuracy 0.5370370370370371\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m Epoch 1: train loss 0.00011632399400696158, accuracy 0.5925925925925926\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m [Client 8] fit, config: {'current_round': 34, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m Epoch 1: train loss 0.00011843428364954889, accuracy 0.5185185185185185\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m [Client 57] fit, config: {'current_round': 34, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m Epoch 1: train loss 0.00012366923328954726, accuracy 0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 12:56:35,461 | server.py:216 | fit_round received 30 results and 0 failures\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m [Client 26] fit, config: {'current_round': 34, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m Epoch 1: train loss 0.00012511045497376472, accuracy 0.4444444444444444\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m [Client 74] fit, config: {'current_round': 34, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m Epoch 1: train loss 0.00012648092524614185, accuracy 0.5370370370370371\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m [Client 69] fit, config: {'current_round': 34, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m [Client 77] fit, config: {'current_round': 34, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m Epoch 1: train loss 0.00012804841389879584, accuracy 0.48148148148148145\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m [Client 43] fit, config: {'current_round': 34, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m Epoch 1: train loss 0.00012220525240991265, accuracy 0.6296296296296297\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m [Client 7] fit, config: {'current_round': 34, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m Epoch 1: train loss 0.00012520677410066128, accuracy 0.5925925925925926\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m [Client 73] fit, config: {'current_round': 34, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m [Client 19] fit, config: {'current_round': 34, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m Epoch 1: train loss 0.00010832279804162681, accuracy 0.5925925925925926\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m Epoch 1: train loss 0.00011148564954055473, accuracy 0.5185185185185185\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m [Client 45] fit, config: {'current_round': 34, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m Epoch 1: train loss 0.00012046202755300328, accuracy 0.5925925925925926\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m Epoch 1: train loss 0.00012119803432142362, accuracy 0.5\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m [Client 90] fit, config: {'current_round': 34, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m [Client 25] fit, config: {'current_round': 34, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m Epoch 1: train loss 0.00011998373520327732, accuracy 0.48148148148148145\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m [Client 39] fit, config: {'current_round': 34, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m Epoch 1: train loss 0.00011682050535455346, accuracy 0.5740740740740741\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m [Client 98] fit, config: {'current_round': 34, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m Epoch 1: train loss 0.00011568579793674871, accuracy 0.5185185185185185\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 12:56:35,515 | server.py:157 | evaluate_round: strategy sampled 30 clients (out of 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving round 34 aggregated_parameters...\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m [Client 53] fit, config: {'current_round': 34, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m Epoch 1: train loss 0.000117708565085195, accuracy 0.5\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m Epoch 1: train loss 0.00011416356574045494, accuracy 0.5555555555555556\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98091)\u001b[0m [Client 42] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98091)\u001b[0m [Client 54] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98088)\u001b[0m [Client 40] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98091)\u001b[0m [Client 62] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98091)\u001b[0m [Client 80] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98088)\u001b[0m [Client 18] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98095)\u001b[0m [Client 95] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98089)\u001b[0m [Client 12] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98092)\u001b[0m [Client 81] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98093)\u001b[0m [Client 88] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98089)\u001b[0m [Client 96] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98094)\u001b[0m [Client 99] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98094)\u001b[0m [Client 43] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98089)\u001b[0m [Client 20] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98094)\u001b[0m [Client 83] evaluate, config: {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 12:56:37,675 | server.py:170 | evaluate_round received 0 results and 30 failures\n",
      "DEBUG flower 2023-02-01 12:56:37,676 | server.py:203 | fit_round: strategy sampled 30 clients (out of 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98093)\u001b[0m [Client 58] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98089)\u001b[0m [Client 6] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98091)\u001b[0m [Client 65] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98090)\u001b[0m [Client 50] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98095)\u001b[0m [Client 75] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98089)\u001b[0m [Client 67] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98094)\u001b[0m [Client 7] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98092)\u001b[0m [Client 55] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98091)\u001b[0m [Client 23] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98090)\u001b[0m [Client 35] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98088)\u001b[0m [Client 17] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98093)\u001b[0m [Client 36] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98091)\u001b[0m [Client 91] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98090)\u001b[0m [Client 2] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98088)\u001b[0m [Client 5] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m [Client 14] fit, config: {'current_round': 35, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m Epoch 1: train loss 0.00011737432214431465, accuracy 0.6481481481481481\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m [Client 2] fit, config: {'current_round': 35, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m Epoch 1: train loss 0.0001107528805732727, accuracy 0.5370370370370371\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m [Client 50] fit, config: {'current_round': 35, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m Epoch 1: train loss 0.00012276569032110274, accuracy 0.5370370370370371\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m [Client 33] fit, config: {'current_round': 35, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m Epoch 1: train loss 0.00012115889694541693, accuracy 0.7037037037037037\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m [Client 67] fit, config: {'current_round': 35, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m Epoch 1: train loss 0.00014308303070720285, accuracy 0.5925925925925926\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m [Client 6] fit, config: {'current_round': 35, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m Epoch 1: train loss 0.00011951859050896019, accuracy 0.6111111111111112\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m [Client 28] fit, config: {'current_round': 35, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m Epoch 1: train loss 0.00012574407446663827, accuracy 0.6111111111111112\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m [Client 83] fit, config: {'current_round': 35, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m [Client 63] fit, config: {'current_round': 35, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m Epoch 1: train loss 0.00011693695705616847, accuracy 0.5740740740740741\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m Epoch 1: train loss 0.00012027099000988528, accuracy 0.6481481481481481\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m [Client 52] fit, config: {'current_round': 35, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m Epoch 1: train loss 0.00011847405403386801, accuracy 0.6111111111111112\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m [Client 17] fit, config: {'current_round': 35, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m Epoch 1: train loss 0.0001099010551115498, accuracy 0.6481481481481481\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m [Client 16] fit, config: {'current_round': 35, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m Epoch 1: train loss 0.00011357928451616317, accuracy 0.5925925925925926\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m [Client 51] fit, config: {'current_round': 35, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m Epoch 1: train loss 0.0001245974563062191, accuracy 0.5740740740740741\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m [Client 9] fit, config: {'current_round': 35, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m Epoch 1: train loss 0.0001306430931435898, accuracy 0.5740740740740741\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m [Client 15] fit, config: {'current_round': 35, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m Epoch 1: train loss 0.00014153732627164572, accuracy 0.4444444444444444\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m [Client 35] fit, config: {'current_round': 35, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m [Client 42] fit, config: {'current_round': 35, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m Epoch 1: train loss 0.00011761266068788245, accuracy 0.6111111111111112\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m Epoch 1: train loss 0.00012574960419442505, accuracy 0.5925925925925926\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m [Client 40] fit, config: {'current_round': 35, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m Epoch 1: train loss 0.00011052826448576525, accuracy 0.6481481481481481\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m [Client 32] fit, config: {'current_round': 35, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m Epoch 1: train loss 0.00012107770453440025, accuracy 0.5185185185185185\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m [Client 43] fit, config: {'current_round': 35, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m [Client 74] fit, config: {'current_round': 35, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m Epoch 1: train loss 0.00013536593178287148, accuracy 0.6481481481481481\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m Epoch 1: train loss 0.0001115741251851432, accuracy 0.7592592592592593\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m [Client 23] fit, config: {'current_round': 35, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m Epoch 1: train loss 0.00011442278628237545, accuracy 0.6296296296296297\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m [Client 53] fit, config: {'current_round': 35, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m Epoch 1: train loss 0.00011860345694003627, accuracy 0.5925925925925926\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m [Client 29] fit, config: {'current_round': 35, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m Epoch 1: train loss 0.00012350300676189363, accuracy 0.5555555555555556\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m [Client 93] fit, config: {'current_round': 35, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m [Client 44] fit, config: {'current_round': 35, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m Epoch 1: train loss 0.00012865768803749233, accuracy 0.5925925925925926\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m [Client 75] fit, config: {'current_round': 35, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m Epoch 1: train loss 0.00011934601934626698, accuracy 0.6666666666666666\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m [Client 20] fit, config: {'current_round': 35, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m [Client 4] fit, config: {'current_round': 35, 'local_epochs': 3}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 12:56:39,854 | server.py:216 | fit_round received 30 results and 0 failures\n",
      "DEBUG flower 2023-02-01 12:56:39,927 | server.py:157 | evaluate_round: strategy sampled 30 clients (out of 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m [Client 87] fit, config: {'current_round': 35, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m Epoch 1: train loss 0.00011964605073444545, accuracy 0.5925925925925926\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m Epoch 1: train loss 0.00013844441855326295, accuracy 0.5740740740740741\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m Epoch 1: train loss 0.00012983576743863523, accuracy 0.5\n",
      "Saving round 35 aggregated_parameters...\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m Epoch 1: train loss 0.00012181814963696525, accuracy 0.5925925925925926\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98091)\u001b[0m [Client 1] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98095)\u001b[0m [Client 60] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98092)\u001b[0m [Client 53] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98091)\u001b[0m [Client 36] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98091)\u001b[0m [Client 79] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98090)\u001b[0m [Client 90] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98093)\u001b[0m [Client 65] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98089)\u001b[0m [Client 75] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98094)\u001b[0m [Client 27] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98092)\u001b[0m [Client 68] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98088)\u001b[0m [Client 10] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98095)\u001b[0m [Client 93] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98091)\u001b[0m [Client 96] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98095)\u001b[0m [Client 46] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98094)\u001b[0m [Client 5] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98090)\u001b[0m [Client 97] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98088)\u001b[0m [Client 84] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98095)\u001b[0m [Client 16] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98093)\u001b[0m [Client 15] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98094)\u001b[0m [Client 63] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98092)\u001b[0m [Client 50] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98091)\u001b[0m [Client 45] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98089)\u001b[0m [Client 92] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98094)\u001b[0m [Client 42] evaluate, config: {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 12:56:42,489 | server.py:170 | evaluate_round received 0 results and 30 failures\n",
      "DEBUG flower 2023-02-01 12:56:42,490 | server.py:203 | fit_round: strategy sampled 30 clients (out of 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98091)\u001b[0m [Client 95] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98095)\u001b[0m [Client 29] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98093)\u001b[0m [Client 98] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98089)\u001b[0m [Client 67] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98094)\u001b[0m [Client 4] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98092)\u001b[0m [Client 34] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m [Client 65] fit, config: {'current_round': 36, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m [Client 50] fit, config: {'current_round': 36, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m Epoch 1: train loss 0.00011664404883049428, accuracy 0.5740740740740741\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m [Client 76] fit, config: {'current_round': 36, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m Epoch 1: train loss 0.00010042252688435838, accuracy 0.5740740740740741\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m [Client 28] fit, config: {'current_round': 36, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m Epoch 1: train loss 0.00010405077773611993, accuracy 0.6666666666666666\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m [Client 39] fit, config: {'current_round': 36, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m Epoch 1: train loss 0.00010973589087370783, accuracy 0.5555555555555556\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m [Client 12] fit, config: {'current_round': 36, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m Epoch 1: train loss 0.00012495751434471458, accuracy 0.5185185185185185\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m Epoch 1: train loss 0.00011296156299067661, accuracy 0.5740740740740741\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m [Client 62] fit, config: {'current_round': 36, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m Epoch 1: train loss 0.00010786957864183933, accuracy 0.6111111111111112\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m [Client 73] fit, config: {'current_round': 36, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m Epoch 1: train loss 0.00011930220352951437, accuracy 0.5\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m [Client 15] fit, config: {'current_round': 36, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m [Client 83] fit, config: {'current_round': 36, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m [Client 85] fit, config: {'current_round': 36, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m [Client 43] fit, config: {'current_round': 36, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m Epoch 1: train loss 0.00013647832383867353, accuracy 0.5370370370370371\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m Epoch 1: train loss 0.00011742392962332815, accuracy 0.4444444444444444\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m [Client 60] fit, config: {'current_round': 36, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m [Client 80] fit, config: {'current_round': 36, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m Epoch 1: train loss 0.000133185472805053, accuracy 0.46296296296296297\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m [Client 53] fit, config: {'current_round': 36, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m Epoch 1: train loss 0.00011545981396920979, accuracy 0.5185185185185185\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m Epoch 1: train loss 0.00011784661910496652, accuracy 0.6296296296296297\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m [Client 3] fit, config: {'current_round': 36, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m Epoch 1: train loss 0.00012404356675688177, accuracy 0.5925925925925926\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m [Client 61] fit, config: {'current_round': 36, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m Epoch 1: train loss 9.908457286655903e-05, accuracy 0.6296296296296297\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m [Client 84] fit, config: {'current_round': 36, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m Epoch 1: train loss 0.00010439146717544645, accuracy 0.6111111111111112\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m Epoch 1: train loss 0.00012678091297857463, accuracy 0.5\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m Epoch 1: train loss 0.00011982040450675413, accuracy 0.5740740740740741\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m [Client 78] fit, config: {'current_round': 36, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m Epoch 1: train loss 0.00012138429883634672, accuracy 0.5185185185185185\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m [Client 26] fit, config: {'current_round': 36, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m Epoch 1: train loss 0.0001239967386936769, accuracy 0.46296296296296297\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m [Client 25] fit, config: {'current_round': 36, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m Epoch 1: train loss 0.00011718268069671467, accuracy 0.5555555555555556\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m [Client 67] fit, config: {'current_round': 36, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m [Client 88] fit, config: {'current_round': 36, 'local_epochs': 3}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 12:56:44,884 | server.py:216 | fit_round received 30 results and 0 failures\n",
      "DEBUG flower 2023-02-01 12:56:44,935 | server.py:157 | evaluate_round: strategy sampled 30 clients (out of 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m [Client 4] fit, config: {'current_round': 36, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m [Client 70] fit, config: {'current_round': 36, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m Epoch 1: train loss 0.00013454511645250022, accuracy 0.6111111111111112\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m Epoch 1: train loss 0.0001372982660541311, accuracy 0.5370370370370371\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m [Client 36] fit, config: {'current_round': 36, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m [Client 18] fit, config: {'current_round': 36, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m [Client 57] fit, config: {'current_round': 36, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m Epoch 1: train loss 0.00012103826156817377, accuracy 0.5185185185185185\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m Epoch 1: train loss 0.00010932274017250165, accuracy 0.6111111111111112\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m [Client 16] fit, config: {'current_round': 36, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m [Client 2] fit, config: {'current_round': 36, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m Epoch 1: train loss 0.00010015734733315185, accuracy 0.6296296296296297\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m Epoch 1: train loss 0.00012689291907008737, accuracy 0.46296296296296297\n",
      "Saving round 36 aggregated_parameters...\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m Epoch 1: train loss 0.00013165344716981053, accuracy 0.5370370370370371\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m Epoch 1: train loss 0.0001286686019739136, accuracy 0.48148148148148145\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m Epoch 1: train loss 0.00011644919140962884, accuracy 0.5185185185185185\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98091)\u001b[0m [Client 57] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98088)\u001b[0m [Client 23] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98091)\u001b[0m [Client 26] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98088)\u001b[0m [Client 10] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98088)\u001b[0m [Client 53] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98091)\u001b[0m [Client 16] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98088)\u001b[0m [Client 70] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98094)\u001b[0m [Client 94] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98091)\u001b[0m [Client 60] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98088)\u001b[0m [Client 46] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98094)\u001b[0m [Client 87] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98091)\u001b[0m [Client 24] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98094)\u001b[0m [Client 82] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98091)\u001b[0m [Client 39] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98091)\u001b[0m [Client 74] evaluate, config: {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 12:56:47,014 | server.py:170 | evaluate_round received 0 results and 30 failures\n",
      "DEBUG flower 2023-02-01 12:56:47,016 | server.py:203 | fit_round: strategy sampled 30 clients (out of 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98091)\u001b[0m [Client 3] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98088)\u001b[0m [Client 85] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98094)\u001b[0m [Client 21] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98090)\u001b[0m [Client 12] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98095)\u001b[0m [Client 18] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98093)\u001b[0m [Client 95] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98089)\u001b[0m [Client 0] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98092)\u001b[0m [Client 20] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98091)\u001b[0m [Client 44] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98091)\u001b[0m [Client 67] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98091)\u001b[0m [Client 96] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98090)\u001b[0m [Client 43] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98093)\u001b[0m [Client 38] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98089)\u001b[0m [Client 64] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98092)\u001b[0m [Client 41] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m [Client 24] fit, config: {'current_round': 37, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m [Client 7] fit, config: {'current_round': 37, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m [Client 84] fit, config: {'current_round': 37, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m Epoch 1: train loss 0.00010941756045212969, accuracy 0.6851851851851852\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m Epoch 1: train loss 0.00010057511099148542, accuracy 0.6666666666666666\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m Epoch 1: train loss 0.00011532894131960347, accuracy 0.6296296296296297\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m [Client 97] fit, config: {'current_round': 37, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m Epoch 1: train loss 0.0001471973373554647, accuracy 0.5370370370370371\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m [Client 72] fit, config: {'current_round': 37, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m [Client 46] fit, config: {'current_round': 37, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m Epoch 1: train loss 0.00010984648542944342, accuracy 0.7222222222222222\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m Epoch 1: train loss 0.00011364478996256366, accuracy 0.7037037037037037\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m [Client 92] fit, config: {'current_round': 37, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m Epoch 1: train loss 0.00012258318020030856, accuracy 0.5925925925925926\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m [Client 15] fit, config: {'current_round': 37, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m Epoch 1: train loss 0.00013944720558356494, accuracy 0.46296296296296297\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m [Client 99] fit, config: {'current_round': 37, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m Epoch 1: train loss 0.00012229324784129858, accuracy 0.6111111111111112\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m [Client 91] fit, config: {'current_round': 37, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m Epoch 1: train loss 0.00010947432747343555, accuracy 0.6851851851851852\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m [Client 13] fit, config: {'current_round': 37, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m Epoch 1: train loss 0.00013106576807331294, accuracy 0.5185185185185185\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m [Client 74] fit, config: {'current_round': 37, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m [Client 0] fit, config: {'current_round': 37, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m [Client 23] fit, config: {'current_round': 37, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m Epoch 1: train loss 0.0001120941960834898, accuracy 0.5555555555555556\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m Epoch 1: train loss 0.00013370771193876863, accuracy 0.6481481481481481\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m [Client 55] fit, config: {'current_round': 37, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m Epoch 1: train loss 0.0001102028982131742, accuracy 0.7222222222222222\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m Epoch 1: train loss 0.00012472325761336833, accuracy 0.6111111111111112\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m [Client 65] fit, config: {'current_round': 37, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m [Client 10] fit, config: {'current_round': 37, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m Epoch 1: train loss 0.00011535413068486378, accuracy 0.6481481481481481\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m Epoch 1: train loss 0.00011773674486903474, accuracy 0.6111111111111112\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m [Client 21] fit, config: {'current_round': 37, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m Epoch 1: train loss 0.00013626668078359216, accuracy 0.42592592592592593\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m [Client 35] fit, config: {'current_round': 37, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m Epoch 1: train loss 0.00012286622950341552, accuracy 0.5370370370370371\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m [Client 86] fit, config: {'current_round': 37, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m Epoch 1: train loss 0.00011436164641054347, accuracy 0.6481481481481481\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m [Client 32] fit, config: {'current_round': 37, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m Epoch 1: train loss 0.00011723348870873451, accuracy 0.5185185185185185\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 12:56:49,296 | server.py:216 | fit_round received 30 results and 0 failures\n",
      "DEBUG flower 2023-02-01 12:56:49,352 | server.py:157 | evaluate_round: strategy sampled 30 clients (out of 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m [Client 11] fit, config: {'current_round': 37, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m [Client 69] fit, config: {'current_round': 37, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m [Client 88] fit, config: {'current_round': 37, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m Epoch 1: train loss 0.00012023205636069179, accuracy 0.5740740740740741\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m [Client 94] fit, config: {'current_round': 37, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m [Client 16] fit, config: {'current_round': 37, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m Epoch 1: train loss 0.00012795596558135003, accuracy 0.5555555555555556\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m Epoch 1: train loss 0.00010871799167944118, accuracy 0.6481481481481481\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m [Client 93] fit, config: {'current_round': 37, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m [Client 67] fit, config: {'current_round': 37, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m [Client 26] fit, config: {'current_round': 37, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m Epoch 1: train loss 0.00011171699588885531, accuracy 0.6666666666666666\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m [Client 36] fit, config: {'current_round': 37, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m Epoch 1: train loss 0.0001113792386604473, accuracy 0.5925925925925926\n",
      "Saving round 37 aggregated_parameters...\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m Epoch 1: train loss 0.00011664730118354782, accuracy 0.5925925925925926\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m Epoch 1: train loss 0.00014014480984769762, accuracy 0.5925925925925926\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m Epoch 1: train loss 0.00013730170030612499, accuracy 0.5370370370370371\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m Epoch 1: train loss 0.00014643561735283583, accuracy 0.42592592592592593\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98094)\u001b[0m [Client 34] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98088)\u001b[0m [Client 54] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98095)\u001b[0m [Client 8] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98093)\u001b[0m [Client 85] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98094)\u001b[0m [Client 45] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98093)\u001b[0m [Client 61] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98093)\u001b[0m [Client 43] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98091)\u001b[0m [Client 64] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98090)\u001b[0m [Client 4] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98088)\u001b[0m [Client 71] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98095)\u001b[0m [Client 46] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98093)\u001b[0m [Client 16] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98094)\u001b[0m [Client 5] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98094)\u001b[0m [Client 41] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98092)\u001b[0m [Client 75] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98088)\u001b[0m [Client 39] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98095)\u001b[0m [Client 98] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98093)\u001b[0m [Client 96] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98089)\u001b[0m [Client 13] evaluate, config: {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 12:56:51,700 | server.py:170 | evaluate_round received 0 results and 30 failures\n",
      "DEBUG flower 2023-02-01 12:56:51,701 | server.py:203 | fit_round: strategy sampled 30 clients (out of 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98091)\u001b[0m [Client 1] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98093)\u001b[0m [Client 77] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98094)\u001b[0m [Client 92] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98091)\u001b[0m [Client 30] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98090)\u001b[0m [Client 3] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98088)\u001b[0m [Client 55] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98095)\u001b[0m [Client 89] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98094)\u001b[0m [Client 50] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98092)\u001b[0m [Client 33] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98093)\u001b[0m [Client 35] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98089)\u001b[0m [Client 26] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m [Client 62] fit, config: {'current_round': 38, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m Epoch 1: train loss 0.00010430852125864476, accuracy 0.6111111111111112\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m [Client 84] fit, config: {'current_round': 38, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m Epoch 1: train loss 0.00010137235949514434, accuracy 0.6296296296296297\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m [Client 79] fit, config: {'current_round': 38, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m [Client 5] fit, config: {'current_round': 38, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m Epoch 1: train loss 0.0001179049359052442, accuracy 0.5555555555555556\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m [Client 88] fit, config: {'current_round': 38, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m Epoch 1: train loss 0.00010609249147819355, accuracy 0.6481481481481481\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m Epoch 1: train loss 0.00012544632772915065, accuracy 0.4444444444444444\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m [Client 36] fit, config: {'current_round': 38, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m Epoch 1: train loss 0.0001261438592337072, accuracy 0.5740740740740741\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m [Client 35] fit, config: {'current_round': 38, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m Epoch 1: train loss 0.00012035253166686743, accuracy 0.6111111111111112\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m [Client 38] fit, config: {'current_round': 38, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m Epoch 1: train loss 0.00011539345723576844, accuracy 0.6111111111111112\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m [Client 34] fit, config: {'current_round': 38, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m Epoch 1: train loss 0.00011689725215546787, accuracy 0.5\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m [Client 52] fit, config: {'current_round': 38, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m Epoch 1: train loss 0.00011033831833628938, accuracy 0.5925925925925926\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m [Client 94] fit, config: {'current_round': 38, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m Epoch 1: train loss 0.00011780727072618902, accuracy 0.6111111111111112\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m [Client 97] fit, config: {'current_round': 38, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m Epoch 1: train loss 0.00014058640226721764, accuracy 0.5\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m [Client 26] fit, config: {'current_round': 38, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m [Client 16] fit, config: {'current_round': 38, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m [Client 3] fit, config: {'current_round': 38, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m Epoch 1: train loss 0.00012488808715716004, accuracy 0.5\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m [Client 41] fit, config: {'current_round': 38, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m Epoch 1: train loss 0.00010621074761729687, accuracy 0.5740740740740741\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m Epoch 1: train loss 0.00012005279131699353, accuracy 0.42592592592592593\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m Epoch 1: train loss 0.00011307834211038426, accuracy 0.5740740740740741\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m [Client 81] fit, config: {'current_round': 38, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m Epoch 1: train loss 0.00012577124289236963, accuracy 0.5370370370370371\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m [Client 8] fit, config: {'current_round': 38, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m Epoch 1: train loss 0.00011118088877992705, accuracy 0.5555555555555556\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m [Client 46] fit, config: {'current_round': 38, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m Epoch 1: train loss 9.642449003877118e-05, accuracy 0.6481481481481481\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m [Client 75] fit, config: {'current_round': 38, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m Epoch 1: train loss 0.00012566789519041777, accuracy 0.5185185185185185\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m [Client 39] fit, config: {'current_round': 38, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m Epoch 1: train loss 0.00011226318019907922, accuracy 0.5370370370370371\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m [Client 54] fit, config: {'current_round': 38, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m [Client 30] fit, config: {'current_round': 38, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m [Client 87] fit, config: {'current_round': 38, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m Epoch 1: train loss 0.00010191408364335075, accuracy 0.6666666666666666\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m [Client 43] fit, config: {'current_round': 38, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m Epoch 1: train loss 0.00010822692274814472, accuracy 0.6851851851851852\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m Epoch 1: train loss 0.00012429433991201222, accuracy 0.42592592592592593\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m [Client 27] fit, config: {'current_round': 38, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m Epoch 1: train loss 0.00011727501259883866, accuracy 0.5370370370370371\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m [Client 2] fit, config: {'current_round': 38, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m [Client 10] fit, config: {'current_round': 38, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m [Client 17] fit, config: {'current_round': 38, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m [Client 73] fit, config: {'current_round': 38, 'local_epochs': 3}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 12:56:54,024 | server.py:216 | fit_round received 30 results and 0 failures\n",
      "DEBUG flower 2023-02-01 12:56:54,083 | server.py:157 | evaluate_round: strategy sampled 30 clients (out of 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving round 38 aggregated_parameters...\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m Epoch 1: train loss 0.00011741751222871244, accuracy 0.6296296296296297\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m Epoch 1: train loss 9.850024071056396e-05, accuracy 0.5370370370370371\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m Epoch 1: train loss 0.00011773060396080837, accuracy 0.5740740740740741\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m Epoch 1: train loss 0.00011751877900678664, accuracy 0.6851851851851852\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m Epoch 1: train loss 0.00011663445184240118, accuracy 0.5555555555555556\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98089)\u001b[0m [Client 94] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98092)\u001b[0m [Client 26] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98091)\u001b[0m [Client 58] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98094)\u001b[0m [Client 71] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98094)\u001b[0m [Client 42] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98091)\u001b[0m [Client 77] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98094)\u001b[0m [Client 1] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98091)\u001b[0m [Client 98] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98094)\u001b[0m [Client 35] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98091)\u001b[0m [Client 45] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98091)\u001b[0m [Client 37] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98089)\u001b[0m [Client 91] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98091)\u001b[0m [Client 95] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98089)\u001b[0m [Client 24] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98094)\u001b[0m [Client 80] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98091)\u001b[0m [Client 81] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98089)\u001b[0m [Client 8] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98094)\u001b[0m [Client 41] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98091)\u001b[0m [Client 79] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98089)\u001b[0m [Client 43] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98091)\u001b[0m [Client 86] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98088)\u001b[0m [Client 67] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98093)\u001b[0m [Client 39] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98094)\u001b[0m [Client 78] evaluate, config: {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 12:56:56,293 | server.py:170 | evaluate_round received 0 results and 30 failures\n",
      "DEBUG flower 2023-02-01 12:56:56,294 | server.py:203 | fit_round: strategy sampled 30 clients (out of 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98091)\u001b[0m [Client 56] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98090)\u001b[0m [Client 28] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98095)\u001b[0m [Client 70] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98089)\u001b[0m [Client 0] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98094)\u001b[0m [Client 87] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98092)\u001b[0m [Client 74] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m [Client 81] fit, config: {'current_round': 39, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m Epoch 1: train loss 0.00012061630695825443, accuracy 0.5555555555555556\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m [Client 70] fit, config: {'current_round': 39, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m Epoch 1: train loss 0.00012299371883273125, accuracy 0.5925925925925926\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m [Client 45] fit, config: {'current_round': 39, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m Epoch 1: train loss 0.00011578047269722447, accuracy 0.5370370370370371\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m [Client 65] fit, config: {'current_round': 39, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m Epoch 1: train loss 0.00011633650137810037, accuracy 0.5555555555555556\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m [Client 84] fit, config: {'current_round': 39, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m Epoch 1: train loss 0.00010632027260726318, accuracy 0.6481481481481481\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m [Client 47] fit, config: {'current_round': 39, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m Epoch 1: train loss 0.00011627517960732803, accuracy 0.6296296296296297\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m [Client 63] fit, config: {'current_round': 39, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m Epoch 1: train loss 0.00010905127419391647, accuracy 0.6111111111111112\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m [Client 72] fit, config: {'current_round': 39, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m [Client 74] fit, config: {'current_round': 39, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m Epoch 1: train loss 0.00011267705849604681, accuracy 0.6296296296296297\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m [Client 62] fit, config: {'current_round': 39, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m Epoch 1: train loss 0.00011413170432206243, accuracy 0.6111111111111112\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m Epoch 1: train loss 0.00012857688125222921, accuracy 0.6666666666666666\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m [Client 5] fit, config: {'current_round': 39, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m [Client 54] fit, config: {'current_round': 39, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m Epoch 1: train loss 0.000119437238026876, accuracy 0.5555555555555556\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m [Client 83] fit, config: {'current_round': 39, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m Epoch 1: train loss 0.00011333994916640222, accuracy 0.5925925925925926\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m Epoch 1: train loss 9.937702998286113e-05, accuracy 0.6296296296296297\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m [Client 58] fit, config: {'current_round': 39, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m [Client 38] fit, config: {'current_round': 39, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m Epoch 1: train loss 0.00012301027891226113, accuracy 0.6481481481481481\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m [Client 19] fit, config: {'current_round': 39, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m Epoch 1: train loss 0.00012267693819012493, accuracy 0.6481481481481481\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m [Client 73] fit, config: {'current_round': 39, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m Epoch 1: train loss 0.00010453812137711793, accuracy 0.6111111111111112\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m Epoch 1: train loss 0.00010067456605611369, accuracy 0.6666666666666666\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m [Client 95] fit, config: {'current_round': 39, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m [Client 67] fit, config: {'current_round': 39, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m Epoch 1: train loss 0.0001387986703775823, accuracy 0.6111111111111112\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m Epoch 1: train loss 9.831867646425962e-05, accuracy 0.6111111111111112\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m [Client 31] fit, config: {'current_round': 39, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m Epoch 1: train loss 0.00012298073852434754, accuracy 0.5370370370370371\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m [Client 14] fit, config: {'current_round': 39, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m Epoch 1: train loss 0.00010944571840809658, accuracy 0.7037037037037037\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 12:56:58,435 | server.py:216 | fit_round received 30 results and 0 failures\n",
      "DEBUG flower 2023-02-01 12:56:58,496 | server.py:157 | evaluate_round: strategy sampled 30 clients (out of 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m [Client 49] fit, config: {'current_round': 39, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m Epoch 1: train loss 0.00011760953930206597, accuracy 0.6296296296296297\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m [Client 97] fit, config: {'current_round': 39, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m Epoch 1: train loss 0.00014358339831233025, accuracy 0.5185185185185185\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m [Client 15] fit, config: {'current_round': 39, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m Epoch 1: train loss 0.00013850249524693936, accuracy 0.46296296296296297\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m [Client 39] fit, config: {'current_round': 39, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m Epoch 1: train loss 0.0001070270300260745, accuracy 0.6296296296296297\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m [Client 89] fit, config: {'current_round': 39, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m [Client 66] fit, config: {'current_round': 39, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m Epoch 1: train loss 0.00011744214134523645, accuracy 0.6111111111111112\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m [Client 51] fit, config: {'current_round': 39, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m Epoch 1: train loss 0.00011858833022415638, accuracy 0.5370370370370371\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m [Client 44] fit, config: {'current_round': 39, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m [Client 34] fit, config: {'current_round': 39, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m Epoch 1: train loss 0.00011057658412028104, accuracy 0.6296296296296297\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m Epoch 1: train loss 0.0001175940633402206, accuracy 0.5370370370370371\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m Epoch 1: train loss 0.00012292330211494118, accuracy 0.5925925925925926\n",
      "Saving round 39 aggregated_parameters...\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98095)\u001b[0m [Client 81] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98093)\u001b[0m [Client 38] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98093)\u001b[0m [Client 49] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98095)\u001b[0m [Client 66] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98093)\u001b[0m [Client 5] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98095)\u001b[0m [Client 69] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98093)\u001b[0m [Client 36] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98090)\u001b[0m [Client 54] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98095)\u001b[0m [Client 78] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98095)\u001b[0m [Client 2] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98090)\u001b[0m [Client 20] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98095)\u001b[0m [Client 57] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98095)\u001b[0m [Client 40] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98095)\u001b[0m [Client 82] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98090)\u001b[0m [Client 58] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98095)\u001b[0m [Client 80] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98095)\u001b[0m [Client 0] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98091)\u001b[0m [Client 74] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98090)\u001b[0m [Client 71] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98093)\u001b[0m [Client 91] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98094)\u001b[0m [Client 44] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98092)\u001b[0m [Client 27] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98091)\u001b[0m [Client 18] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98094)\u001b[0m [Client 63] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98095)\u001b[0m [Client 14] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98093)\u001b[0m [Client 45] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98089)\u001b[0m [Client 39] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98094)\u001b[0m [Client 32] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98092)\u001b[0m [Client 59] evaluate, config: {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 12:57:00,807 | server.py:170 | evaluate_round received 0 results and 30 failures\n",
      "DEBUG flower 2023-02-01 12:57:00,808 | server.py:203 | fit_round: strategy sampled 30 clients (out of 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98090)\u001b[0m [Client 8] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m [Client 58] fit, config: {'current_round': 40, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m Epoch 1: train loss 0.00010238341201329604, accuracy 0.5370370370370371\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m [Client 73] fit, config: {'current_round': 40, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m Epoch 1: train loss 0.00011707586236298084, accuracy 0.5185185185185185\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m [Client 74] fit, config: {'current_round': 40, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m Epoch 1: train loss 0.00012379614054225385, accuracy 0.5185185185185185\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m [Client 40] fit, config: {'current_round': 40, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m Epoch 1: train loss 0.00010759216820588335, accuracy 0.6296296296296297\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m [Client 22] fit, config: {'current_round': 40, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m Epoch 1: train loss 0.00013985999976284802, accuracy 0.42592592592592593\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m [Client 7] fit, config: {'current_round': 40, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m Epoch 1: train loss 0.00012006399629171938, accuracy 0.6111111111111112\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m [Client 64] fit, config: {'current_round': 40, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m [Client 87] fit, config: {'current_round': 40, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m Epoch 1: train loss 0.00010110323637491092, accuracy 0.6296296296296297\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m [Client 85] fit, config: {'current_round': 40, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m Epoch 1: train loss 0.00013520315405912697, accuracy 0.42592592592592593\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m Epoch 1: train loss 0.00011324419028824195, accuracy 0.5740740740740741\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m [Client 46] fit, config: {'current_round': 40, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m Epoch 1: train loss 9.352475171908736e-05, accuracy 0.6666666666666666\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m [Client 27] fit, config: {'current_round': 40, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m Epoch 1: train loss 0.00011687212099786848, accuracy 0.5185185185185185\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m [Client 39] fit, config: {'current_round': 40, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m Epoch 1: train loss 0.00011282875493634492, accuracy 0.5185185185185185\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m [Client 83] fit, config: {'current_round': 40, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m Epoch 1: train loss 0.00011577836266951635, accuracy 0.5\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m [Client 45] fit, config: {'current_round': 40, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m [Client 2] fit, config: {'current_round': 40, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m Epoch 1: train loss 9.892718662740663e-05, accuracy 0.5370370370370371\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m Epoch 1: train loss 0.00011604821338551119, accuracy 0.5925925925925926\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m [Client 86] fit, config: {'current_round': 40, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m [Client 65] fit, config: {'current_round': 40, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m Epoch 1: train loss 0.00011468249431345612, accuracy 0.5370370370370371\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m [Client 36] fit, config: {'current_round': 40, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m Epoch 1: train loss 0.00012571200204547495, accuracy 0.5555555555555556\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m Epoch 1: train loss 0.00011245856148889288, accuracy 0.5925925925925926\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m [Client 0] fit, config: {'current_round': 40, 'local_epochs': 3}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 12:57:03,304 | server.py:216 | fit_round received 30 results and 0 failures\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m Epoch 1: train loss 0.0001281870499951765, accuracy 0.5370370370370371\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m [Client 21] fit, config: {'current_round': 40, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m [Client 72] fit, config: {'current_round': 40, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m [Client 26] fit, config: {'current_round': 40, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m Epoch 1: train loss 0.0001187109955935739, accuracy 0.5\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m Epoch 1: train loss 0.00013047248648945242, accuracy 0.5\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m [Client 98] fit, config: {'current_round': 40, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m Epoch 1: train loss 0.00011041947436751798, accuracy 0.48148148148148145\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m Epoch 1: train loss 0.0001026461977744475, accuracy 0.6851851851851852\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m [Client 44] fit, config: {'current_round': 40, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m Epoch 1: train loss 0.00012660019274335355, accuracy 0.5\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m [Client 81] fit, config: {'current_round': 40, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m Epoch 1: train loss 0.0001274444512091577, accuracy 0.48148148148148145\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m [Client 90] fit, config: {'current_round': 40, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m Epoch 1: train loss 0.00010885936353588477, accuracy 0.5370370370370371\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m [Client 6] fit, config: {'current_round': 40, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m Epoch 1: train loss 0.00012390411575324833, accuracy 0.5370370370370371\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m [Client 10] fit, config: {'current_round': 40, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m Epoch 1: train loss 0.00011951253691222519, accuracy 0.5185185185185185\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m [Client 69] fit, config: {'current_round': 40, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m Epoch 1: train loss 0.00010405496141174808, accuracy 0.6111111111111112\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m [Client 11] fit, config: {'current_round': 40, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m Epoch 1: train loss 0.00011595799878705293, accuracy 0.6111111111111112\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 12:57:03,369 | server.py:157 | evaluate_round: strategy sampled 30 clients (out of 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving round 40 aggregated_parameters...\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98092)\u001b[0m [Client 14] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98094)\u001b[0m [Client 19] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98092)\u001b[0m [Client 21] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98094)\u001b[0m [Client 22] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98089)\u001b[0m [Client 1] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98094)\u001b[0m [Client 91] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98092)\u001b[0m [Client 46] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98092)\u001b[0m [Client 73] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98090)\u001b[0m [Client 13] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98089)\u001b[0m [Client 95] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98094)\u001b[0m [Client 36] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98092)\u001b[0m [Client 85] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98095)\u001b[0m [Client 48] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98094)\u001b[0m [Client 86] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98092)\u001b[0m [Client 88] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98092)\u001b[0m [Client 97] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98092)\u001b[0m [Client 72] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98092)\u001b[0m [Client 49] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98092)\u001b[0m [Client 10] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98092)\u001b[0m [Client 77] evaluate, config: {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 12:57:05,460 | server.py:170 | evaluate_round received 0 results and 30 failures\n",
      "DEBUG flower 2023-02-01 12:57:05,462 | server.py:203 | fit_round: strategy sampled 30 clients (out of 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98091)\u001b[0m [Client 52] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98090)\u001b[0m [Client 99] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98088)\u001b[0m [Client 11] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98095)\u001b[0m [Client 16] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98095)\u001b[0m [Client 87] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98089)\u001b[0m [Client 70] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98094)\u001b[0m [Client 64] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98094)\u001b[0m [Client 90] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98093)\u001b[0m [Client 8] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98092)\u001b[0m [Client 39] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m [Client 53] fit, config: {'current_round': 41, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m Epoch 1: train loss 0.00011062854173360392, accuracy 0.5925925925925926\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m [Client 77] fit, config: {'current_round': 41, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m Epoch 1: train loss 0.00010936152830254287, accuracy 0.6296296296296297\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m [Client 57] fit, config: {'current_round': 41, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m Epoch 1: train loss 0.00012384112051222473, accuracy 0.5370370370370371\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m [Client 40] fit, config: {'current_round': 41, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m Epoch 1: train loss 0.00010204903810517862, accuracy 0.6481481481481481\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m [Client 64] fit, config: {'current_round': 41, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m Epoch 1: train loss 0.0001082266098819673, accuracy 0.7037037037037037\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m [Client 23] fit, config: {'current_round': 41, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m Epoch 1: train loss 0.00010769924847409129, accuracy 0.6851851851851852\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m [Client 20] fit, config: {'current_round': 41, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m Epoch 1: train loss 0.00013142895477358252, accuracy 0.5555555555555556\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m [Client 87] fit, config: {'current_round': 41, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m [Client 76] fit, config: {'current_round': 41, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m [Client 41] fit, config: {'current_round': 41, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m Epoch 1: train loss 0.00011362333316355944, accuracy 0.6111111111111112\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m Epoch 1: train loss 8.966968016466126e-05, accuracy 0.7037037037037037\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m Epoch 1: train loss 0.0001254504022654146, accuracy 0.5555555555555556\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m [Client 25] fit, config: {'current_round': 41, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m [Client 99] fit, config: {'current_round': 41, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m Epoch 1: train loss 0.0001172792908619158, accuracy 0.6296296296296297\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m [Client 68] fit, config: {'current_round': 41, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m Epoch 1: train loss 0.00010179315722780302, accuracy 0.6481481481481481\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m Epoch 1: train loss 0.00010413554991828278, accuracy 0.6296296296296297\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m [Client 62] fit, config: {'current_round': 41, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m Epoch 1: train loss 0.00011414223990868777, accuracy 0.6111111111111112\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m [Client 63] fit, config: {'current_round': 41, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m Epoch 1: train loss 0.00010899786866502836, accuracy 0.5555555555555556\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m [Client 29] fit, config: {'current_round': 41, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m Epoch 1: train loss 0.00011707074736477807, accuracy 0.5555555555555556\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m [Client 72] fit, config: {'current_round': 41, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m [Client 86] fit, config: {'current_round': 41, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m Epoch 1: train loss 0.00010710913920775056, accuracy 0.7222222222222222\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m [Client 82] fit, config: {'current_round': 41, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m Epoch 1: train loss 0.00010128468420589343, accuracy 0.6666666666666666\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m Epoch 1: train loss 0.00010889010445680469, accuracy 0.7222222222222222\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m [Client 70] fit, config: {'current_round': 41, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m [Client 94] fit, config: {'current_round': 41, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m Epoch 1: train loss 0.00010815923451445997, accuracy 0.6481481481481481\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m [Client 26] fit, config: {'current_round': 41, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m [Client 55] fit, config: {'current_round': 41, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m Epoch 1: train loss 0.00012310923193581402, accuracy 0.6481481481481481\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m [Client 32] fit, config: {'current_round': 41, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m Epoch 1: train loss 0.00013407619553618133, accuracy 0.5555555555555556\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m Epoch 1: train loss 0.00010465890227351338, accuracy 0.7407407407407407\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m [Client 7] fit, config: {'current_round': 41, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m Epoch 1: train loss 0.00011419114889577031, accuracy 0.5370370370370371\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 12:57:07,619 | server.py:216 | fit_round received 30 results and 0 failures\n",
      "DEBUG flower 2023-02-01 12:57:07,706 | server.py:157 | evaluate_round: strategy sampled 30 clients (out of 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m [Client 98] fit, config: {'current_round': 41, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m Epoch 1: train loss 0.00013141953968442976, accuracy 0.5\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m [Client 17] fit, config: {'current_round': 41, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m Epoch 1: train loss 0.00011038436059607193, accuracy 0.6666666666666666\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m [Client 6] fit, config: {'current_round': 41, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m Epoch 1: train loss 0.00011147248733323067, accuracy 0.6666666666666666\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m [Client 39] fit, config: {'current_round': 41, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m [Client 3] fit, config: {'current_round': 41, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m Epoch 1: train loss 0.00012570692342706025, accuracy 0.5740740740740741\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m Epoch 1: train loss 0.00010160233796341345, accuracy 0.6851851851851852\n",
      "Saving round 41 aggregated_parameters...\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m Epoch 1: train loss 0.00010764830221887678, accuracy 0.5925925925925926\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98094)\u001b[0m [Client 73] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98094)\u001b[0m [Client 68] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98094)\u001b[0m [Client 89] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98088)\u001b[0m [Client 49] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98094)\u001b[0m [Client 57] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98088)\u001b[0m [Client 12] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98094)\u001b[0m [Client 40] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98088)\u001b[0m [Client 39] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98094)\u001b[0m [Client 34] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98094)\u001b[0m [Client 86] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98088)\u001b[0m [Client 30] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98088)\u001b[0m [Client 10] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98094)\u001b[0m [Client 24] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98092)\u001b[0m [Client 87] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98090)\u001b[0m [Client 94] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98093)\u001b[0m [Client 85] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98088)\u001b[0m [Client 75] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98094)\u001b[0m [Client 79] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98092)\u001b[0m [Client 61] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98094)\u001b[0m [Client 0] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98092)\u001b[0m [Client 37] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98091)\u001b[0m [Client 32] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98090)\u001b[0m [Client 25] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98095)\u001b[0m [Client 20] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98094)\u001b[0m [Client 98] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98092)\u001b[0m [Client 2] evaluate, config: {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 12:57:10,661 | server.py:170 | evaluate_round received 0 results and 30 failures\n",
      "DEBUG flower 2023-02-01 12:57:10,662 | server.py:203 | fit_round: strategy sampled 30 clients (out of 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98088)\u001b[0m [Client 63] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98093)\u001b[0m [Client 26] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98089)\u001b[0m [Client 38] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98092)\u001b[0m [Client 80] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m [Client 54] fit, config: {'current_round': 42, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m [Client 49] fit, config: {'current_round': 42, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m Epoch 1: train loss 0.00012140284525230527, accuracy 0.4444444444444444\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m Epoch 1: train loss 0.00010655465302988887, accuracy 0.5925925925925926\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m [Client 58] fit, config: {'current_round': 42, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m Epoch 1: train loss 9.825816960074008e-05, accuracy 0.5925925925925926\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m [Client 71] fit, config: {'current_round': 42, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m Epoch 1: train loss 0.00010716004180721939, accuracy 0.5740740740740741\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m [Client 31] fit, config: {'current_round': 42, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m Epoch 1: train loss 0.00010778747673612088, accuracy 0.6296296296296297\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m [Client 59] fit, config: {'current_round': 42, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m Epoch 1: train loss 0.00010850888793356717, accuracy 0.5555555555555556\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m [Client 18] fit, config: {'current_round': 42, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m Epoch 1: train loss 0.00012463959865272045, accuracy 0.5\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m [Client 84] fit, config: {'current_round': 42, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m Epoch 1: train loss 9.70419860095717e-05, accuracy 0.6296296296296297\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m [Client 64] fit, config: {'current_round': 42, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m [Client 83] fit, config: {'current_round': 42, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m [Client 57] fit, config: {'current_round': 42, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m Epoch 1: train loss 0.00010525416291784495, accuracy 0.5555555555555556\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m [Client 39] fit, config: {'current_round': 42, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m Epoch 1: train loss 0.00010720203863456845, accuracy 0.5370370370370371\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m Epoch 1: train loss 0.00010991400631610304, accuracy 0.5\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m [Client 73] fit, config: {'current_round': 42, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m [Client 94] fit, config: {'current_round': 42, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m Epoch 1: train loss 0.00011114338849438354, accuracy 0.5925925925925926\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m Epoch 1: train loss 0.00011398588685551658, accuracy 0.5370370370370371\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m [Client 91] fit, config: {'current_round': 42, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m [Client 38] fit, config: {'current_round': 42, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m Epoch 1: train loss 0.00010763304453575984, accuracy 0.5925925925925926\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m Epoch 1: train loss 0.00011389367864467204, accuracy 0.5370370370370371\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m Epoch 1: train loss 0.00010956860933220014, accuracy 0.42592592592592593\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m [Client 62] fit, config: {'current_round': 42, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m [Client 88] fit, config: {'current_round': 42, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m [Client 50] fit, config: {'current_round': 42, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m Epoch 1: train loss 0.00010007023956859484, accuracy 0.6296296296296297\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m Epoch 1: train loss 0.00010159960947930813, accuracy 0.6111111111111112\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m Epoch 1: train loss 0.00010230179032078013, accuracy 0.5925925925925926\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m [Client 60] fit, config: {'current_round': 42, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m Epoch 1: train loss 0.00011346379324095324, accuracy 0.6111111111111112\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m [Client 81] fit, config: {'current_round': 42, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m Epoch 1: train loss 0.0001232153008459136, accuracy 0.5\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m [Client 98] fit, config: {'current_round': 42, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m Epoch 1: train loss 0.00011133046064060181, accuracy 0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 12:57:12,979 | server.py:216 | fit_round received 30 results and 0 failures\n",
      "DEBUG flower 2023-02-01 12:57:13,033 | server.py:157 | evaluate_round: strategy sampled 30 clients (out of 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m [Client 69] fit, config: {'current_round': 42, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m Epoch 1: train loss 9.99179610516876e-05, accuracy 0.6111111111111112\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m [Client 51] fit, config: {'current_round': 42, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m [Client 77] fit, config: {'current_round': 42, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m [Client 19] fit, config: {'current_round': 42, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m [Client 14] fit, config: {'current_round': 42, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m Epoch 1: train loss 0.00011985325545538217, accuracy 0.3888888888888889\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m Epoch 1: train loss 0.00010098972416017205, accuracy 0.6481481481481481\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m [Client 70] fit, config: {'current_round': 42, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m Epoch 1: train loss 0.00013235215737950057, accuracy 0.5925925925925926\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m Epoch 1: train loss 0.00011819123028544709, accuracy 0.48148148148148145\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m [Client 96] fit, config: {'current_round': 42, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m Epoch 1: train loss 0.00010504031524760649, accuracy 0.5740740740740741\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m Epoch 1: train loss 9.836294339038432e-05, accuracy 0.6111111111111112\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m [Client 56] fit, config: {'current_round': 42, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m Epoch 1: train loss 0.00012141441402491182, accuracy 0.5\n",
      "Saving round 42 aggregated_parameters...\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98089)\u001b[0m [Client 19] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98090)\u001b[0m [Client 53] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98089)\u001b[0m [Client 59] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98090)\u001b[0m [Client 74] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98089)\u001b[0m [Client 24] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98090)\u001b[0m [Client 57] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98089)\u001b[0m [Client 14] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98090)\u001b[0m [Client 71] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98095)\u001b[0m [Client 84] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98089)\u001b[0m [Client 18] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98092)\u001b[0m [Client 7] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98090)\u001b[0m [Client 68] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98090)\u001b[0m [Client 81] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98092)\u001b[0m [Client 39] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98090)\u001b[0m [Client 29] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98090)\u001b[0m [Client 41] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98095)\u001b[0m [Client 3] evaluate, config: {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 12:57:15,225 | server.py:170 | evaluate_round received 0 results and 30 failures\n",
      "DEBUG flower 2023-02-01 12:57:15,226 | server.py:203 | fit_round: strategy sampled 30 clients (out of 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98090)\u001b[0m [Client 86] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98089)\u001b[0m [Client 55] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98094)\u001b[0m [Client 13] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98092)\u001b[0m [Client 65] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98090)\u001b[0m [Client 93] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98089)\u001b[0m [Client 63] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98092)\u001b[0m [Client 96] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98090)\u001b[0m [Client 54] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98095)\u001b[0m [Client 64] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98090)\u001b[0m [Client 46] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98095)\u001b[0m [Client 75] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98089)\u001b[0m [Client 76] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98094)\u001b[0m [Client 47] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m [Client 98] fit, config: {'current_round': 43, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m Epoch 1: train loss 0.00012976785365026444, accuracy 0.5555555555555556\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m [Client 7] fit, config: {'current_round': 43, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m Epoch 1: train loss 0.00011085591540904716, accuracy 0.6296296296296297\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m [Client 87] fit, config: {'current_round': 43, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m Epoch 1: train loss 0.00011269557580817491, accuracy 0.5740740740740741\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m [Client 56] fit, config: {'current_round': 43, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m Epoch 1: train loss 0.00011749714758479968, accuracy 0.6296296296296297\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m [Client 85] fit, config: {'current_round': 43, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m [Client 78] fit, config: {'current_round': 43, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m Epoch 1: train loss 0.00011849797738250345, accuracy 0.48148148148148145\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m [Client 38] fit, config: {'current_round': 43, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m Epoch 1: train loss 0.00012302599498070776, accuracy 0.6481481481481481\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m [Client 8] fit, config: {'current_round': 43, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m Epoch 1: train loss 0.00012099397281417623, accuracy 0.48148148148148145\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m Epoch 1: train loss 0.00011651841487037018, accuracy 0.5185185185185185\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m [Client 92] fit, config: {'current_round': 43, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m Epoch 1: train loss 0.00011980951967416331, accuracy 0.5185185185185185\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m [Client 72] fit, config: {'current_round': 43, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m Epoch 1: train loss 0.0001048265112331137, accuracy 0.7222222222222222\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m [Client 43] fit, config: {'current_round': 43, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m Epoch 1: train loss 0.00010235813533654436, accuracy 0.7407407407407407\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m [Client 62] fit, config: {'current_round': 43, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m [Client 13] fit, config: {'current_round': 43, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m Epoch 1: train loss 0.00012662923836614937, accuracy 0.5370370370370371\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m [Client 0] fit, config: {'current_round': 43, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m Epoch 1: train loss 0.00012152249837527052, accuracy 0.6111111111111112\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m Epoch 1: train loss 0.00011133874795632437, accuracy 0.6296296296296297\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m [Client 93] fit, config: {'current_round': 43, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m [Client 90] fit, config: {'current_round': 43, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m Epoch 1: train loss 0.00010562253009993583, accuracy 0.6481481481481481\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m Epoch 1: train loss 0.00010835293505806476, accuracy 0.6666666666666666\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m [Client 75] fit, config: {'current_round': 43, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m Epoch 1: train loss 0.00011409664148231968, accuracy 0.6666666666666666\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m [Client 81] fit, config: {'current_round': 43, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m Epoch 1: train loss 0.00011985935998382047, accuracy 0.5185185185185185\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m [Client 91] fit, config: {'current_round': 43, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m Epoch 1: train loss 9.905009937938303e-05, accuracy 0.7222222222222222\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m [Client 52] fit, config: {'current_round': 43, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m Epoch 1: train loss 0.00010539899085415527, accuracy 0.6481481481481481\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m [Client 29] fit, config: {'current_round': 43, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m Epoch 1: train loss 0.000117067014798522, accuracy 0.5370370370370371\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m [Client 39] fit, config: {'current_round': 43, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m Epoch 1: train loss 0.00010573914187261835, accuracy 0.5740740740740741\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m [Client 57] fit, config: {'current_round': 43, 'local_epochs': 3}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 12:57:17,476 | server.py:216 | fit_round received 30 results and 0 failures\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m [Client 6] fit, config: {'current_round': 43, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m [Client 88] fit, config: {'current_round': 43, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m Epoch 1: train loss 0.0001129410884459503, accuracy 0.6296296296296297\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m Epoch 1: train loss 0.00012088929361198097, accuracy 0.5370370370370371\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m [Client 68] fit, config: {'current_round': 43, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m Epoch 1: train loss 0.00010342652967665344, accuracy 0.6296296296296297\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m [Client 71] fit, config: {'current_round': 43, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m Epoch 1: train loss 0.00010913037112914026, accuracy 0.7037037037037037\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m Epoch 1: train loss 0.00010962621308863163, accuracy 0.7037037037037037\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m [Client 16] fit, config: {'current_round': 43, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m Epoch 1: train loss 0.00010581484093563631, accuracy 0.5740740740740741\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m [Client 22] fit, config: {'current_round': 43, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m Epoch 1: train loss 0.00012114425771869719, accuracy 0.6111111111111112\n",
      "Saving round 43 aggregated_parameters...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 12:57:17,531 | server.py:157 | evaluate_round: strategy sampled 30 clients (out of 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m [Client 4] fit, config: {'current_round': 43, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m Epoch 1: train loss 0.000121494427730795, accuracy 0.5\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98093)\u001b[0m [Client 18] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98092)\u001b[0m [Client 51] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98093)\u001b[0m [Client 48] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98088)\u001b[0m [Client 13] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98093)\u001b[0m [Client 97] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98094)\u001b[0m [Client 17] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98092)\u001b[0m [Client 27] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98090)\u001b[0m [Client 44] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98088)\u001b[0m [Client 62] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98093)\u001b[0m [Client 70] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98094)\u001b[0m [Client 8] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98092)\u001b[0m [Client 65] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98095)\u001b[0m [Client 53] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98093)\u001b[0m [Client 16] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98092)\u001b[0m [Client 34] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98088)\u001b[0m [Client 86] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98088)\u001b[0m [Client 42] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98088)\u001b[0m [Client 41] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98088)\u001b[0m [Client 64] evaluate, config: {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 12:57:19,885 | server.py:170 | evaluate_round received 0 results and 30 failures\n",
      "DEBUG flower 2023-02-01 12:57:19,887 | server.py:203 | fit_round: strategy sampled 30 clients (out of 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98088)\u001b[0m [Client 60] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98095)\u001b[0m [Client 1] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98092)\u001b[0m [Client 22] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98091)\u001b[0m [Client 31] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98090)\u001b[0m [Client 69] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98088)\u001b[0m [Client 12] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98095)\u001b[0m [Client 33] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98093)\u001b[0m [Client 77] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98089)\u001b[0m [Client 29] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98094)\u001b[0m [Client 36] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98092)\u001b[0m [Client 0] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m [Client 70] fit, config: {'current_round': 44, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m Epoch 1: train loss 0.0001312004023930058, accuracy 0.5740740740740741\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m [Client 97] fit, config: {'current_round': 44, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m Epoch 1: train loss 0.000136962000397034, accuracy 0.5185185185185185\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m [Client 6] fit, config: {'current_round': 44, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m Epoch 1: train loss 0.00011405145050957799, accuracy 0.5740740740740741\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m [Client 52] fit, config: {'current_round': 44, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m Epoch 1: train loss 0.00011035893840016797, accuracy 0.6296296296296297\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m [Client 35] fit, config: {'current_round': 44, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m Epoch 1: train loss 0.00011933281348319724, accuracy 0.5555555555555556\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m [Client 81] fit, config: {'current_round': 44, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m Epoch 1: train loss 0.00012009954662062228, accuracy 0.5\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m [Client 51] fit, config: {'current_round': 44, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m Epoch 1: train loss 9.965252684196457e-05, accuracy 0.6481481481481481\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m [Client 20] fit, config: {'current_round': 44, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m Epoch 1: train loss 0.00011696422006934881, accuracy 0.5370370370370371\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m [Client 72] fit, config: {'current_round': 44, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m Epoch 1: train loss 9.961921750800684e-05, accuracy 0.6481481481481481\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m [Client 0] fit, config: {'current_round': 44, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m Epoch 1: train loss 0.00012198180047562346, accuracy 0.5925925925925926\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m [Client 19] fit, config: {'current_round': 44, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m Epoch 1: train loss 9.64033097261563e-05, accuracy 0.6296296296296297\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m [Client 25] fit, config: {'current_round': 44, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m [Client 96] fit, config: {'current_round': 44, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m [Client 2] fit, config: {'current_round': 44, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m Epoch 1: train loss 8.804332173895091e-05, accuracy 0.6296296296296297\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m Epoch 1: train loss 0.00010451655543874949, accuracy 0.5925925925925926\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m Epoch 1: train loss 0.00010071610449813306, accuracy 0.5925925925925926\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m [Client 92] fit, config: {'current_round': 44, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m Epoch 1: train loss 9.998806490330026e-05, accuracy 0.6666666666666666\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m [Client 28] fit, config: {'current_round': 44, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m Epoch 1: train loss 9.994838910643011e-05, accuracy 0.7222222222222222\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m [Client 93] fit, config: {'current_round': 44, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m [Client 41] fit, config: {'current_round': 44, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m Epoch 1: train loss 9.219807543559e-05, accuracy 0.6111111111111112\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m Epoch 1: train loss 0.00010015161387855187, accuracy 0.6111111111111112\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m [Client 11] fit, config: {'current_round': 44, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m Epoch 1: train loss 0.00010729020868893713, accuracy 0.6296296296296297\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m [Client 38] fit, config: {'current_round': 44, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m Epoch 1: train loss 0.00010500587086426094, accuracy 0.6481481481481481\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m [Client 16] fit, config: {'current_round': 44, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m Epoch 1: train loss 0.00010798482981044799, accuracy 0.5740740740740741\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m [Client 53] fit, config: {'current_round': 44, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m [Client 14] fit, config: {'current_round': 44, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m [Client 42] fit, config: {'current_round': 44, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m [Client 90] fit, config: {'current_round': 44, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m [Client 95] fit, config: {'current_round': 44, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m [Client 67] fit, config: {'current_round': 44, 'local_epochs': 3}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 12:57:22,247 | server.py:216 | fit_round received 30 results and 0 failures\n",
      "DEBUG flower 2023-02-01 12:57:22,304 | server.py:157 | evaluate_round: strategy sampled 30 clients (out of 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m Epoch 1: train loss 0.00011056083167204633, accuracy 0.5370370370370371\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m [Client 49] fit, config: {'current_round': 44, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m Epoch 1: train loss 0.00011829484719783068, accuracy 0.42592592592592593\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m Epoch 1: train loss 0.0001106161143979989, accuracy 0.6111111111111112\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m Epoch 1: train loss 0.00010255785309709609, accuracy 0.5555555555555556\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m [Client 34] fit, config: {'current_round': 44, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m Epoch 1: train loss 0.00011135289969388396, accuracy 0.5185185185185185\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m Epoch 1: train loss 9.316195792052895e-05, accuracy 0.6111111111111112\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m [Client 78] fit, config: {'current_round': 44, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m Epoch 1: train loss 0.00011026750871678814, accuracy 0.5740740740740741\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m Epoch 1: train loss 0.00012768669694196433, accuracy 0.5740740740740741\n",
      "Saving round 44 aggregated_parameters...\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m Epoch 1: train loss 0.00011886739957844839, accuracy 0.4074074074074074\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98091)\u001b[0m [Client 51] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98091)\u001b[0m [Client 14] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98091)\u001b[0m [Client 55] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98091)\u001b[0m [Client 44] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98093)\u001b[0m [Client 9] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98094)\u001b[0m [Client 46] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98090)\u001b[0m [Client 71] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98090)\u001b[0m [Client 12] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98094)\u001b[0m [Client 19] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98090)\u001b[0m [Client 80] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98090)\u001b[0m [Client 42] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98091)\u001b[0m [Client 11] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98090)\u001b[0m [Client 82] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98095)\u001b[0m [Client 91] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98093)\u001b[0m [Client 36] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98094)\u001b[0m [Client 31] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98091)\u001b[0m [Client 35] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98088)\u001b[0m [Client 38] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98095)\u001b[0m [Client 58] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98093)\u001b[0m [Client 72] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98089)\u001b[0m [Client 75] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98092)\u001b[0m [Client 7] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98088)\u001b[0m [Client 68] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98092)\u001b[0m [Client 21] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98091)\u001b[0m [Client 63] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98095)\u001b[0m [Client 3] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98093)\u001b[0m [Client 8] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98089)\u001b[0m [Client 77] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98094)\u001b[0m [Client 99] evaluate, config: {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 12:57:24,959 | server.py:170 | evaluate_round received 0 results and 30 failures\n",
      "DEBUG flower 2023-02-01 12:57:24,960 | server.py:203 | fit_round: strategy sampled 30 clients (out of 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98090)\u001b[0m [Client 0] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m [Client 92] fit, config: {'current_round': 45, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m Epoch 1: train loss 0.00011758061737054959, accuracy 0.6111111111111112\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m [Client 41] fit, config: {'current_round': 45, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m Epoch 1: train loss 0.00012084645277354866, accuracy 0.5925925925925926\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m [Client 47] fit, config: {'current_round': 45, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m [Client 79] fit, config: {'current_round': 45, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m Epoch 1: train loss 0.00010879814362851903, accuracy 0.6666666666666666\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m [Client 28] fit, config: {'current_round': 45, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m [Client 24] fit, config: {'current_round': 45, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m Epoch 1: train loss 8.992075163405389e-05, accuracy 0.7222222222222222\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m [Client 59] fit, config: {'current_round': 45, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m Epoch 1: train loss 9.991568367695436e-05, accuracy 0.6481481481481481\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m [Client 96] fit, config: {'current_round': 45, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m Epoch 1: train loss 8.954761869972572e-05, accuracy 0.7037037037037037\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m [Client 49] fit, config: {'current_round': 45, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m Epoch 1: train loss 0.00011472467303974554, accuracy 0.5925925925925926\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m Epoch 1: train loss 0.00010889974510064349, accuracy 0.6666666666666666\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m [Client 39] fit, config: {'current_round': 45, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m Epoch 1: train loss 9.982708434108645e-05, accuracy 0.6296296296296297\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m [Client 34] fit, config: {'current_round': 45, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m Epoch 1: train loss 0.00010595491039566696, accuracy 0.6481481481481481\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m [Client 7] fit, config: {'current_round': 45, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m Epoch 1: train loss 0.00011317125608911738, accuracy 0.6296296296296297\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m [Client 43] fit, config: {'current_round': 45, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m Epoch 1: train loss 9.855285316007212e-05, accuracy 0.7592592592592593\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m Epoch 1: train loss 0.00011008966976078227, accuracy 0.6111111111111112\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m [Client 80] fit, config: {'current_round': 45, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m Epoch 1: train loss 9.34599302127026e-05, accuracy 0.7222222222222222\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m [Client 81] fit, config: {'current_round': 45, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m Epoch 1: train loss 0.00011842612002510577, accuracy 0.5740740740740741\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m [Client 60] fit, config: {'current_round': 45, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m Epoch 1: train loss 0.00010985151311615482, accuracy 0.6296296296296297\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m [Client 29] fit, config: {'current_round': 45, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m Epoch 1: train loss 0.00011621484736679122, accuracy 0.5185185185185185\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m [Client 23] fit, config: {'current_round': 45, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m [Client 12] fit, config: {'current_round': 45, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m Epoch 1: train loss 0.00010477117029950023, accuracy 0.7222222222222222\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m [Client 82] fit, config: {'current_round': 45, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m [Client 93] fit, config: {'current_round': 45, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m [Client 1] fit, config: {'current_round': 45, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m Epoch 1: train loss 0.0001078925488400273, accuracy 0.6481481481481481\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m [Client 11] fit, config: {'current_round': 45, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m [Client 36] fit, config: {'current_round': 45, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m Epoch 1: train loss 0.00014022439427208155, accuracy 0.46296296296296297\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m Epoch 1: train loss 9.894416143652052e-05, accuracy 0.6481481481481481\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m Epoch 1: train loss 0.00010636519436957315, accuracy 0.6111111111111112\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m [Client 17] fit, config: {'current_round': 45, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m Epoch 1: train loss 9.409531048731878e-05, accuracy 0.7222222222222222\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m Epoch 1: train loss 0.00011320305202389136, accuracy 0.6111111111111112\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m [Client 66] fit, config: {'current_round': 45, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m Epoch 1: train loss 0.00011039857781725004, accuracy 0.6296296296296297\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m Epoch 1: train loss 0.00011748200631700456, accuracy 0.5925925925925926\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m [Client 51] fit, config: {'current_round': 45, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m Epoch 1: train loss 0.00011377908958820626, accuracy 0.5925925925925926\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 12:57:27,467 | server.py:216 | fit_round received 30 results and 0 failures\n",
      "DEBUG flower 2023-02-01 12:57:27,522 | server.py:157 | evaluate_round: strategy sampled 30 clients (out of 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m [Client 54] fit, config: {'current_round': 45, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m [Client 40] fit, config: {'current_round': 45, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m [Client 48] fit, config: {'current_round': 45, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m Epoch 1: train loss 0.00011172647646162659, accuracy 0.6851851851851852\n",
      "Saving round 45 aggregated_parameters...\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m Epoch 1: train loss 9.389717888552696e-05, accuracy 0.6851851851851852\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m Epoch 1: train loss 0.0001199922407977283, accuracy 0.6481481481481481\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98093)\u001b[0m [Client 33] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98092)\u001b[0m [Client 80] evaluate, config: {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(raylet)\u001b[0m Spilled 131243 MiB, 4355 objects, write throughput 1133 MiB/s.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98090)\u001b[0m [Client 74] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98093)\u001b[0m [Client 34] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98092)\u001b[0m [Client 58] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98090)\u001b[0m [Client 56] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98093)\u001b[0m [Client 11] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98091)\u001b[0m [Client 2] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98090)\u001b[0m [Client 70] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98093)\u001b[0m [Client 41] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98092)\u001b[0m [Client 30] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98091)\u001b[0m [Client 57] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98088)\u001b[0m [Client 8] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98091)\u001b[0m [Client 0] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98090)\u001b[0m [Client 91] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98095)\u001b[0m [Client 78] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98093)\u001b[0m [Client 94] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98089)\u001b[0m [Client 50] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98094)\u001b[0m [Client 54] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98092)\u001b[0m [Client 24] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98089)\u001b[0m [Client 93] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98094)\u001b[0m [Client 86] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98089)\u001b[0m [Client 47] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98089)\u001b[0m [Client 20] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98094)\u001b[0m [Client 22] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98095)\u001b[0m [Client 43] evaluate, config: {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 12:57:29,716 | server.py:170 | evaluate_round received 0 results and 30 failures\n",
      "DEBUG flower 2023-02-01 12:57:29,717 | server.py:203 | fit_round: strategy sampled 30 clients (out of 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98091)\u001b[0m [Client 26] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98090)\u001b[0m [Client 96] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98092)\u001b[0m [Client 55] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98093)\u001b[0m [Client 87] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m [Client 4] fit, config: {'current_round': 46, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m [Client 69] fit, config: {'current_round': 46, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m [Client 87] fit, config: {'current_round': 46, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m Epoch 1: train loss 0.00011917945084860548, accuracy 0.5370370370370371\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m Epoch 1: train loss 9.463806782150641e-05, accuracy 0.6481481481481481\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m Epoch 1: train loss 9.11610695766285e-05, accuracy 0.7037037037037037\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m [Client 59] fit, config: {'current_round': 46, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m [Client 6] fit, config: {'current_round': 46, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m Epoch 1: train loss 0.00011269460082985461, accuracy 0.6111111111111112\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m [Client 65] fit, config: {'current_round': 46, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m Epoch 1: train loss 0.00010611208563204855, accuracy 0.5925925925925926\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m Epoch 1: train loss 0.00010625461436575279, accuracy 0.6111111111111112\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m [Client 99] fit, config: {'current_round': 46, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m [Client 62] fit, config: {'current_round': 46, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m Epoch 1: train loss 9.506250353297219e-05, accuracy 0.6481481481481481\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m Epoch 1: train loss 9.692154708318412e-05, accuracy 0.6851851851851852\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m [Client 90] fit, config: {'current_round': 46, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m Epoch 1: train loss 0.00010067529365187511, accuracy 0.5370370370370371\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m [Client 61] fit, config: {'current_round': 46, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m Epoch 1: train loss 0.00010731785005191341, accuracy 0.6111111111111112\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m [Client 17] fit, config: {'current_round': 46, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m Epoch 1: train loss 0.00010402013140264899, accuracy 0.6481481481481481\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m [Client 63] fit, config: {'current_round': 46, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m Epoch 1: train loss 0.0001089035504264757, accuracy 0.5185185185185185\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m [Client 95] fit, config: {'current_round': 46, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m [Client 73] fit, config: {'current_round': 46, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m Epoch 1: train loss 0.00011101277777925134, accuracy 0.5740740740740741\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m [Client 33] fit, config: {'current_round': 46, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m Epoch 1: train loss 0.00011457965592853725, accuracy 0.5185185185185185\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m Epoch 1: train loss 9.041049634106457e-05, accuracy 0.6666666666666666\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m [Client 85] fit, config: {'current_round': 46, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m Epoch 1: train loss 0.00012665502435993403, accuracy 0.48148148148148145\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m [Client 71] fit, config: {'current_round': 46, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m [Client 54] fit, config: {'current_round': 46, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m Epoch 1: train loss 0.000103370999568142, accuracy 0.6111111111111112\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m Epoch 1: train loss 0.00010010765981860459, accuracy 0.6481481481481481\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m [Client 36] fit, config: {'current_round': 46, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m [Client 57] fit, config: {'current_round': 46, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m Epoch 1: train loss 0.00010754587856354192, accuracy 0.5925925925925926\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m Epoch 1: train loss 0.00011735655425582081, accuracy 0.5555555555555556\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 12:57:32,212 | server.py:216 | fit_round received 30 results and 0 failures\n",
      "DEBUG flower 2023-02-01 12:57:32,265 | server.py:157 | evaluate_round: strategy sampled 30 clients (out of 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m [Client 72] fit, config: {'current_round': 46, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m [Client 43] fit, config: {'current_round': 46, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m Epoch 1: train loss 0.00010825356002897024, accuracy 0.6296296296296297\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m [Client 75] fit, config: {'current_round': 46, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m [Client 8] fit, config: {'current_round': 46, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m Epoch 1: train loss 0.0001016021633404307, accuracy 0.6666666666666666\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m [Client 40] fit, config: {'current_round': 46, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m [Client 11] fit, config: {'current_round': 46, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m Epoch 1: train loss 0.00010529111750656739, accuracy 0.6666666666666666\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m Epoch 1: train loss 9.700947703095153e-05, accuracy 0.6481481481481481\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m [Client 88] fit, config: {'current_round': 46, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m Epoch 1: train loss 9.466785559197888e-05, accuracy 0.6481481481481481\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m [Client 20] fit, config: {'current_round': 46, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m Epoch 1: train loss 0.00011538284161360934, accuracy 0.5370370370370371\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m Epoch 1: train loss 0.00011651669774437323, accuracy 0.5555555555555556\n",
      "Saving round 46 aggregated_parameters...\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m Epoch 1: train loss 0.00010040125926025212, accuracy 0.6296296296296297\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m [Client 78] fit, config: {'current_round': 46, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m Epoch 1: train loss 0.00011046013969462365, accuracy 0.6296296296296297\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m [Client 18] fit, config: {'current_round': 46, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m Epoch 1: train loss 0.00012065956252627075, accuracy 0.5370370370370371\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98090)\u001b[0m [Client 13] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98090)\u001b[0m [Client 40] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98094)\u001b[0m [Client 1] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98090)\u001b[0m [Client 78] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98090)\u001b[0m [Client 61] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98094)\u001b[0m [Client 93] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98091)\u001b[0m [Client 25] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98089)\u001b[0m [Client 92] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98094)\u001b[0m [Client 2] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98092)\u001b[0m [Client 97] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98091)\u001b[0m [Client 0] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98090)\u001b[0m [Client 65] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98089)\u001b[0m [Client 73] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98089)\u001b[0m [Client 56] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98089)\u001b[0m [Client 86] evaluate, config: {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 12:57:34,397 | server.py:170 | evaluate_round received 0 results and 30 failures\n",
      "DEBUG flower 2023-02-01 12:57:34,399 | server.py:203 | fit_round: strategy sampled 30 clients (out of 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98091)\u001b[0m [Client 34] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98090)\u001b[0m [Client 85] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98090)\u001b[0m [Client 38] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98094)\u001b[0m [Client 53] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98092)\u001b[0m [Client 31] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98090)\u001b[0m [Client 39] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98094)\u001b[0m [Client 98] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98092)\u001b[0m [Client 26] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98090)\u001b[0m [Client 4] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98091)\u001b[0m [Client 28] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98090)\u001b[0m [Client 49] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98088)\u001b[0m [Client 33] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98089)\u001b[0m [Client 22] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98094)\u001b[0m [Client 60] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98092)\u001b[0m [Client 5] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m [Client 32] fit, config: {'current_round': 47, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m Epoch 1: train loss 0.00011348981934133917, accuracy 0.5555555555555556\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m [Client 5] fit, config: {'current_round': 47, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m Epoch 1: train loss 9.344369027530774e-05, accuracy 0.6481481481481481\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m [Client 57] fit, config: {'current_round': 47, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m Epoch 1: train loss 0.00011728281970135868, accuracy 0.6111111111111112\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m [Client 18] fit, config: {'current_round': 47, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m Epoch 1: train loss 0.00011926188744837418, accuracy 0.6111111111111112\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m [Client 84] fit, config: {'current_round': 47, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m Epoch 1: train loss 9.929597581503913e-05, accuracy 0.7407407407407407\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m [Client 22] fit, config: {'current_round': 47, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m Epoch 1: train loss 0.00011764761438826099, accuracy 0.5740740740740741\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m [Client 97] fit, config: {'current_round': 47, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m Epoch 1: train loss 0.00014617516717407852, accuracy 0.5370370370370371\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m [Client 56] fit, config: {'current_round': 47, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m Epoch 1: train loss 0.00011493280908325687, accuracy 0.6481481481481481\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m [Client 24] fit, config: {'current_round': 47, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m Epoch 1: train loss 8.797996997600421e-05, accuracy 0.7037037037037037\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m [Client 14] fit, config: {'current_round': 47, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m [Client 55] fit, config: {'current_round': 47, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m [Client 10] fit, config: {'current_round': 47, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m Epoch 1: train loss 0.00010376431600889191, accuracy 0.6481481481481481\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m [Client 1] fit, config: {'current_round': 47, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m [Client 82] fit, config: {'current_round': 47, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m [Client 64] fit, config: {'current_round': 47, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m Epoch 1: train loss 0.00010002057388192043, accuracy 0.6851851851851852\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m Epoch 1: train loss 0.00011070649634348229, accuracy 0.6296296296296297\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m [Client 74] fit, config: {'current_round': 47, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m Epoch 1: train loss 0.00012667299597524107, accuracy 0.6481481481481481\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m Epoch 1: train loss 0.00011090973566751927, accuracy 0.5740740740740741\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m Epoch 1: train loss 9.59667595452629e-05, accuracy 0.6666666666666666\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m [Client 92] fit, config: {'current_round': 47, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m Epoch 1: train loss 9.910980588756502e-05, accuracy 0.7037037037037037\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m [Client 19] fit, config: {'current_round': 47, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m Epoch 1: train loss 9.306116407969967e-05, accuracy 0.7037037037037037\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m [Client 80] fit, config: {'current_round': 47, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m Epoch 1: train loss 9.048086940310895e-05, accuracy 0.7037037037037037\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m [Client 31] fit, config: {'current_round': 47, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m Epoch 1: train loss 0.00011489664029795676, accuracy 0.5925925925925926\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m [Client 43] fit, config: {'current_round': 47, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m Epoch 1: train loss 9.567772940499708e-05, accuracy 0.7592592592592593\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m Epoch 1: train loss 0.00011775616439990699, accuracy 0.5925925925925926\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m [Client 7] fit, config: {'current_round': 47, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m Epoch 1: train loss 0.0001094411127269268, accuracy 0.6296296296296297\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 12:57:36,642 | server.py:216 | fit_round received 30 results and 0 failures\n",
      "DEBUG flower 2023-02-01 12:57:36,697 | server.py:157 | evaluate_round: strategy sampled 30 clients (out of 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m [Client 15] fit, config: {'current_round': 47, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m [Client 73] fit, config: {'current_round': 47, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m Epoch 1: train loss 9.420362039236352e-05, accuracy 0.6666666666666666\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m [Client 8] fit, config: {'current_round': 47, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m [Client 78] fit, config: {'current_round': 47, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m Epoch 1: train loss 0.00010975790064549074, accuracy 0.5740740740740741\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m [Client 53] fit, config: {'current_round': 47, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m Epoch 1: train loss 0.00010392566036898643, accuracy 0.5925925925925926\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m [Client 65] fit, config: {'current_round': 47, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m Epoch 1: train loss 0.00010783925245050341, accuracy 0.6111111111111112\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m Epoch 1: train loss 0.00013244109868537635, accuracy 0.48148148148148145\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m [Client 34] fit, config: {'current_round': 47, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m Epoch 1: train loss 0.00010471745918039232, accuracy 0.7037037037037037\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m Epoch 1: train loss 0.0001190275652334094, accuracy 0.5185185185185185\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m [Client 23] fit, config: {'current_round': 47, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m Epoch 1: train loss 0.00010468198161106557, accuracy 0.6296296296296297\n",
      "Saving round 47 aggregated_parameters...\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98091)\u001b[0m [Client 91] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98090)\u001b[0m [Client 49] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98088)\u001b[0m [Client 12] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98093)\u001b[0m [Client 22] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98094)\u001b[0m [Client 30] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98090)\u001b[0m [Client 19] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98093)\u001b[0m [Client 7] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98091)\u001b[0m [Client 52] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98090)\u001b[0m [Client 8] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98088)\u001b[0m [Client 38] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98094)\u001b[0m [Client 20] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98092)\u001b[0m [Client 3] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98090)\u001b[0m [Client 21] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98092)\u001b[0m [Client 64] evaluate, config: {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 12:57:38,824 | server.py:170 | evaluate_round received 0 results and 30 failures\n",
      "DEBUG flower 2023-02-01 12:57:38,825 | server.py:203 | fit_round: strategy sampled 30 clients (out of 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98090)\u001b[0m [Client 60] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98090)\u001b[0m [Client 47] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98090)\u001b[0m [Client 43] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98092)\u001b[0m [Client 77] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98091)\u001b[0m [Client 5] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98088)\u001b[0m [Client 55] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98088)\u001b[0m [Client 67] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98093)\u001b[0m [Client 39] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98094)\u001b[0m [Client 74] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98092)\u001b[0m [Client 56] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98091)\u001b[0m [Client 27] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98090)\u001b[0m [Client 4] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98093)\u001b[0m [Client 53] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98089)\u001b[0m [Client 99] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98094)\u001b[0m [Client 34] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98092)\u001b[0m [Client 94] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m [Client 57] fit, config: {'current_round': 48, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m [Client 32] fit, config: {'current_round': 48, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m Epoch 1: train loss 9.03502368601039e-05, accuracy 0.6851851851851852\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m Epoch 1: train loss 0.00010471850691828877, accuracy 0.6111111111111112\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m [Client 83] fit, config: {'current_round': 48, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m Epoch 1: train loss 9.994300489779562e-05, accuracy 0.6111111111111112\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m [Client 1] fit, config: {'current_round': 48, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m Epoch 1: train loss 0.00010761211888166144, accuracy 0.6111111111111112\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m [Client 43] fit, config: {'current_round': 48, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m [Client 27] fit, config: {'current_round': 48, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m Epoch 1: train loss 0.00010591041063889861, accuracy 0.5925925925925926\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m [Client 72] fit, config: {'current_round': 48, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m [Client 28] fit, config: {'current_round': 48, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m [Client 7] fit, config: {'current_round': 48, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m [Client 52] fit, config: {'current_round': 48, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m Epoch 1: train loss 0.00010526862024562433, accuracy 0.6111111111111112\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m Epoch 1: train loss 9.530793613521382e-05, accuracy 0.6481481481481481\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m [Client 69] fit, config: {'current_round': 48, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m Epoch 1: train loss 9.2580150521826e-05, accuracy 0.6481481481481481\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m Epoch 1: train loss 0.00010251545609207824, accuracy 0.7037037037037037\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m Epoch 1: train loss 0.00010712631774367765, accuracy 0.5925925925925926\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m [Client 89] fit, config: {'current_round': 48, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m Epoch 1: train loss 0.00010134378680959344, accuracy 0.5555555555555556\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m Epoch 1: train loss 9.07518042367883e-05, accuracy 0.6481481481481481\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m [Client 45] fit, config: {'current_round': 48, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m [Client 88] fit, config: {'current_round': 48, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m Epoch 1: train loss 0.00011075710062868893, accuracy 0.5185185185185185\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m Epoch 1: train loss 9.212515578838065e-05, accuracy 0.6666666666666666\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m [Client 13] fit, config: {'current_round': 48, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m Epoch 1: train loss 0.00011009639274561778, accuracy 0.5925925925925926\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m [Client 10] fit, config: {'current_round': 48, 'local_epochs': 3}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 12:57:41,131 | server.py:216 | fit_round received 30 results and 0 failures\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m [Client 30] fit, config: {'current_round': 48, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m Epoch 1: train loss 0.0001082852395484224, accuracy 0.5925925925925926\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m Epoch 1: train loss 0.00010312636004528031, accuracy 0.6666666666666666\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m [Client 22] fit, config: {'current_round': 48, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m [Client 71] fit, config: {'current_round': 48, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m Epoch 1: train loss 9.799707913771272e-05, accuracy 0.6481481481481481\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m [Client 60] fit, config: {'current_round': 48, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m Epoch 1: train loss 0.00010011850827140734, accuracy 0.7037037037037037\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m Epoch 1: train loss 0.00013008697715122253, accuracy 0.3148148148148148\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m [Client 66] fit, config: {'current_round': 48, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m [Client 31] fit, config: {'current_round': 48, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m [Client 87] fit, config: {'current_round': 48, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m Epoch 1: train loss 8.780013740761206e-05, accuracy 0.7592592592592593\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m [Client 68] fit, config: {'current_round': 48, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m [Client 79] fit, config: {'current_round': 48, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m Epoch 1: train loss 9.577468154020607e-05, accuracy 0.6111111111111112\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m Epoch 1: train loss 9.738052176544443e-05, accuracy 0.6296296296296297\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m [Client 3] fit, config: {'current_round': 48, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m Epoch 1: train loss 8.852241444401443e-05, accuracy 0.6851851851851852\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m Epoch 1: train loss 0.00011052629997720942, accuracy 0.5370370370370371\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m [Client 24] fit, config: {'current_round': 48, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m [Client 20] fit, config: {'current_round': 48, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m Epoch 1: train loss 0.00011228026414755732, accuracy 0.5185185185185185\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m [Client 84] fit, config: {'current_round': 48, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m Epoch 1: train loss 0.00011491750774439424, accuracy 0.5\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m [Client 56] fit, config: {'current_round': 48, 'local_epochs': 3}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 12:57:41,186 | server.py:157 | evaluate_round: strategy sampled 30 clients (out of 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving round 48 aggregated_parameters...\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m Epoch 1: train loss 0.00010064367234008387, accuracy 0.5925925925925926\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m Epoch 1: train loss 9.01669409358874e-05, accuracy 0.6666666666666666\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m Epoch 1: train loss 0.00011486356379464269, accuracy 0.5370370370370371\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98090)\u001b[0m [Client 99] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98090)\u001b[0m [Client 12] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98088)\u001b[0m [Client 57] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98093)\u001b[0m [Client 88] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98092)\u001b[0m [Client 3] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98092)\u001b[0m [Client 63] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98093)\u001b[0m [Client 40] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98092)\u001b[0m [Client 51] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98092)\u001b[0m [Client 10] evaluate, config: {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 12:57:43,379 | server.py:170 | evaluate_round received 0 results and 30 failures\n",
      "DEBUG flower 2023-02-01 12:57:43,380 | server.py:203 | fit_round: strategy sampled 30 clients (out of 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98093)\u001b[0m [Client 95] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98090)\u001b[0m [Client 60] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98088)\u001b[0m [Client 76] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98093)\u001b[0m [Client 62] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98092)\u001b[0m [Client 90] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98090)\u001b[0m [Client 79] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98093)\u001b[0m [Client 6] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98092)\u001b[0m [Client 61] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98093)\u001b[0m [Client 43] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98093)\u001b[0m [Client 75] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98091)\u001b[0m [Client 48] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98090)\u001b[0m [Client 70] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98088)\u001b[0m [Client 32] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98088)\u001b[0m [Client 25] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98095)\u001b[0m [Client 5] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98089)\u001b[0m [Client 87] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98094)\u001b[0m [Client 2] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98092)\u001b[0m [Client 9] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98090)\u001b[0m [Client 59] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98093)\u001b[0m [Client 42] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98094)\u001b[0m [Client 15] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m [Client 52] fit, config: {'current_round': 49, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m Epoch 1: train loss 9.555025462759659e-05, accuracy 0.5925925925925926\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m [Client 3] fit, config: {'current_round': 49, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m Epoch 1: train loss 0.00012417920515872538, accuracy 0.6111111111111112\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m [Client 89] fit, config: {'current_round': 49, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m Epoch 1: train loss 0.00010619491513352841, accuracy 0.5\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m [Client 41] fit, config: {'current_round': 49, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m Epoch 1: train loss 0.00011873265611939132, accuracy 0.5\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m [Client 37] fit, config: {'current_round': 49, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m Epoch 1: train loss 9.697036148281768e-05, accuracy 0.6111111111111112\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m [Client 7] fit, config: {'current_round': 49, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m Epoch 1: train loss 0.00011348730186000466, accuracy 0.5740740740740741\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m [Client 1] fit, config: {'current_round': 49, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m Epoch 1: train loss 0.00011020938109140843, accuracy 0.5555555555555556\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m [Client 73] fit, config: {'current_round': 49, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m Epoch 1: train loss 9.365773439640179e-05, accuracy 0.6296296296296297\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m [Client 69] fit, config: {'current_round': 49, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m [Client 43] fit, config: {'current_round': 49, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m [Client 29] fit, config: {'current_round': 49, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m [Client 49] fit, config: {'current_round': 49, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m [Client 27] fit, config: {'current_round': 49, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m Epoch 1: train loss 0.00010882430069614202, accuracy 0.5740740740740741\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m Epoch 1: train loss 0.00011330764391459525, accuracy 0.5555555555555556\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m [Client 97] fit, config: {'current_round': 49, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m Epoch 1: train loss 0.00014852509775664657, accuracy 0.46296296296296297\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m [Client 77] fit, config: {'current_round': 49, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m Epoch 1: train loss 9.514160046819597e-05, accuracy 0.6296296296296297\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m Epoch 1: train loss 9.5329261966981e-05, accuracy 0.7407407407407407\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m Epoch 1: train loss 0.00011421010276535526, accuracy 0.5185185185185185\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m Epoch 1: train loss 9.581757331034169e-05, accuracy 0.6111111111111112\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m [Client 48] fit, config: {'current_round': 49, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m Epoch 1: train loss 0.00011186512710992247, accuracy 0.7222222222222222\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m [Client 47] fit, config: {'current_round': 49, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m Epoch 1: train loss 0.00010182012192672119, accuracy 0.6481481481481481\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 12:57:45,519 | server.py:216 | fit_round received 30 results and 0 failures\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m [Client 51] fit, config: {'current_round': 49, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m Epoch 1: train loss 0.00011147267650812864, accuracy 0.5740740740740741\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m [Client 40] fit, config: {'current_round': 49, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m Epoch 1: train loss 9.142390626948327e-05, accuracy 0.6296296296296297\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m [Client 86] fit, config: {'current_round': 49, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m [Client 36] fit, config: {'current_round': 49, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m Epoch 1: train loss 9.394709195476025e-05, accuracy 0.6851851851851852\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m Epoch 1: train loss 0.00014294161519501358, accuracy 0.3888888888888889\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m [Client 83] fit, config: {'current_round': 49, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m [Client 74] fit, config: {'current_round': 49, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m Epoch 1: train loss 0.0001239831472048536, accuracy 0.5925925925925926\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m [Client 26] fit, config: {'current_round': 49, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m Epoch 1: train loss 0.00012459717981982976, accuracy 0.5555555555555556\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m Epoch 1: train loss 0.00011161376460222527, accuracy 0.5370370370370371\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m [Client 91] fit, config: {'current_round': 49, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m Epoch 1: train loss 9.746284922584891e-05, accuracy 0.5740740740740741\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m [Client 44] fit, config: {'current_round': 49, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m [Client 17] fit, config: {'current_round': 49, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m Epoch 1: train loss 9.214871533913538e-05, accuracy 0.6666666666666666\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m [Client 10] fit, config: {'current_round': 49, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m Epoch 1: train loss 0.00011513195204315707, accuracy 0.5555555555555556\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m [Client 11] fit, config: {'current_round': 49, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m Epoch 1: train loss 0.00011181416630279273, accuracy 0.6111111111111112\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m [Client 99] fit, config: {'current_round': 49, 'local_epochs': 3}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 12:57:45,575 | server.py:157 | evaluate_round: strategy sampled 30 clients (out of 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving round 49 aggregated_parameters...\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m Epoch 1: train loss 0.00011867722059832886, accuracy 0.5370370370370371\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m Epoch 1: train loss 0.00011110447667306289, accuracy 0.6111111111111112\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98092)\u001b[0m [Client 61] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98095)\u001b[0m [Client 67] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98092)\u001b[0m [Client 30] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98092)\u001b[0m [Client 48] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98092)\u001b[0m [Client 72] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98092)\u001b[0m [Client 25] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98092)\u001b[0m [Client 95] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98092)\u001b[0m [Client 44] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98095)\u001b[0m [Client 90] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98093)\u001b[0m [Client 23] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98094)\u001b[0m [Client 92] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98093)\u001b[0m [Client 51] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98093)\u001b[0m [Client 39] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98095)\u001b[0m [Client 65] evaluate, config: {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 12:57:47,805 | server.py:170 | evaluate_round received 0 results and 30 failures\n",
      "DEBUG flower 2023-02-01 12:57:47,807 | server.py:203 | fit_round: strategy sampled 30 clients (out of 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98095)\u001b[0m [Client 78] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98093)\u001b[0m [Client 83] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98095)\u001b[0m [Client 97] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98093)\u001b[0m [Client 11] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98089)\u001b[0m [Client 94] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98092)\u001b[0m [Client 89] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98092)\u001b[0m [Client 15] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98093)\u001b[0m [Client 76] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98094)\u001b[0m [Client 33] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98094)\u001b[0m [Client 37] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98088)\u001b[0m [Client 14] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98095)\u001b[0m [Client 43] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98093)\u001b[0m [Client 24] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98089)\u001b[0m [Client 40] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98094)\u001b[0m [Client 66] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98092)\u001b[0m [Client 4] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m [Client 60] fit, config: {'current_round': 50, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m Epoch 1: train loss 0.00010126653796760365, accuracy 0.6296296296296297\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m [Client 44] fit, config: {'current_round': 50, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m Epoch 1: train loss 0.00011705255747074261, accuracy 0.5370370370370371\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m [Client 87] fit, config: {'current_round': 50, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m Epoch 1: train loss 9.556103032082319e-05, accuracy 0.7037037037037037\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m [Client 89] fit, config: {'current_round': 50, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m Epoch 1: train loss 0.00010583383118500933, accuracy 0.5925925925925926\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m [Client 85] fit, config: {'current_round': 50, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m Epoch 1: train loss 0.0001317537680733949, accuracy 0.4444444444444444\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m [Client 58] fit, config: {'current_round': 50, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m [Client 75] fit, config: {'current_round': 50, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m [Client 81] fit, config: {'current_round': 50, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m [Client 86] fit, config: {'current_round': 50, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m Epoch 1: train loss 0.00010163200931856409, accuracy 0.6296296296296297\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m Epoch 1: train loss 9.877636330202222e-05, accuracy 0.6111111111111112\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m Epoch 1: train loss 0.00012201542995171621, accuracy 0.5925925925925926\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m Epoch 1: train loss 0.00011670851381495595, accuracy 0.6111111111111112\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m [Client 12] fit, config: {'current_round': 50, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m Epoch 1: train loss 0.0001145771166193299, accuracy 0.6296296296296297\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m [Client 20] fit, config: {'current_round': 50, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m Epoch 1: train loss 0.00012493287795223296, accuracy 0.5555555555555556\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m [Client 17] fit, config: {'current_round': 50, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m [Client 69] fit, config: {'current_round': 50, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m [Client 71] fit, config: {'current_round': 50, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m [Client 57] fit, config: {'current_round': 50, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m Epoch 1: train loss 0.0001008654580800794, accuracy 0.6666666666666666\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m Epoch 1: train loss 9.56410076469183e-05, accuracy 0.6296296296296297\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m [Client 31] fit, config: {'current_round': 50, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m [Client 67] fit, config: {'current_round': 50, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m Epoch 1: train loss 0.00010366587957832962, accuracy 0.6296296296296297\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m [Client 6] fit, config: {'current_round': 50, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m Epoch 1: train loss 0.00012005463941022754, accuracy 0.5555555555555556\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m Epoch 1: train loss 0.00010949787974823266, accuracy 0.5740740740740741\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m [Client 64] fit, config: {'current_round': 50, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m Epoch 1: train loss 0.00010658774408511817, accuracy 0.6296296296296297\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m Epoch 1: train loss 0.00013153361214790493, accuracy 0.5925925925925926\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m [Client 9] fit, config: {'current_round': 50, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m Epoch 1: train loss 0.00011125038872705773, accuracy 0.6851851851851852\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m [Client 88] fit, config: {'current_round': 50, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m [Client 5] fit, config: {'current_round': 50, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m [Client 61] fit, config: {'current_round': 50, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m Epoch 1: train loss 9.560952457832173e-05, accuracy 0.7037037037037037\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m Epoch 1: train loss 9.359526302432641e-05, accuracy 0.6481481481481481\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m Epoch 1: train loss 9.750923345563933e-05, accuracy 0.6296296296296297\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m Epoch 1: train loss 9.832463547354564e-05, accuracy 0.5925925925925926\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m [Client 82] fit, config: {'current_round': 50, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m [Client 83] fit, config: {'current_round': 50, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m [Client 70] fit, config: {'current_round': 50, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m Epoch 1: train loss 0.00012521292956080288, accuracy 0.6296296296296297\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m [Client 47] fit, config: {'current_round': 50, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m Epoch 1: train loss 0.00010771731467684731, accuracy 0.7037037037037037\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 12:57:50,122 | server.py:216 | fit_round received 30 results and 0 failures\n",
      "DEBUG flower 2023-02-01 12:57:50,174 | server.py:157 | evaluate_round: strategy sampled 30 clients (out of 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m Epoch 1: train loss 0.00010926836694125086, accuracy 0.6111111111111112\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m [Client 74] fit, config: {'current_round': 50, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m Epoch 1: train loss 0.00012629808043129742, accuracy 0.5925925925925926\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m Epoch 1: train loss 9.923588368110359e-05, accuracy 0.7037037037037037\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m [Client 96] fit, config: {'current_round': 50, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m Epoch 1: train loss 9.877212141873315e-05, accuracy 0.6666666666666666\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m [Client 30] fit, config: {'current_round': 50, 'local_epochs': 3}\n",
      "Saving round 50 aggregated_parameters...\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m Epoch 1: train loss 0.00011738963075913489, accuracy 0.5740740740740741\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98088)\u001b[0m [Client 65] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98093)\u001b[0m [Client 51] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98092)\u001b[0m [Client 36] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98090)\u001b[0m [Client 61] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98095)\u001b[0m [Client 53] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98094)\u001b[0m [Client 94] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98091)\u001b[0m [Client 82] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98093)\u001b[0m [Client 64] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98093)\u001b[0m [Client 3] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98093)\u001b[0m [Client 54] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98093)\u001b[0m [Client 4] evaluate, config: {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 12:57:52,579 | server.py:170 | evaluate_round received 0 results and 30 failures\n",
      "DEBUG flower 2023-02-01 12:57:52,580 | server.py:203 | fit_round: strategy sampled 30 clients (out of 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98089)\u001b[0m [Client 73] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98094)\u001b[0m [Client 12] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98091)\u001b[0m [Client 2] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98088)\u001b[0m [Client 24] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98095)\u001b[0m [Client 86] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98089)\u001b[0m [Client 10] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98092)\u001b[0m [Client 5] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98091)\u001b[0m [Client 46] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98090)\u001b[0m [Client 22] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98093)\u001b[0m [Client 30] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98094)\u001b[0m [Client 98] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98091)\u001b[0m [Client 57] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98091)\u001b[0m [Client 31] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98090)\u001b[0m [Client 0] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98093)\u001b[0m [Client 37] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98092)\u001b[0m [Client 95] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98088)\u001b[0m [Client 42] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98095)\u001b[0m [Client 89] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98094)\u001b[0m [Client 85] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m [Client 92] fit, config: {'current_round': 51, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m Epoch 1: train loss 0.00010295587708242238, accuracy 0.6851851851851852\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m [Client 4] fit, config: {'current_round': 51, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m Epoch 1: train loss 0.00010936852777376771, accuracy 0.5555555555555556\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m [Client 52] fit, config: {'current_round': 51, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m Epoch 1: train loss 9.519082232145593e-05, accuracy 0.5925925925925926\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m [Client 43] fit, config: {'current_round': 51, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m [Client 24] fit, config: {'current_round': 51, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m [Client 95] fit, config: {'current_round': 51, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m Epoch 1: train loss 8.406541019212455e-05, accuracy 0.6666666666666666\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m Epoch 1: train loss 9.573677380103618e-05, accuracy 0.6851851851851852\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m [Client 42] fit, config: {'current_round': 51, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m Epoch 1: train loss 0.00010832239058800042, accuracy 0.6296296296296297\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m Epoch 1: train loss 8.694192365510389e-05, accuracy 0.6296296296296297\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m [Client 32] fit, config: {'current_round': 51, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m Epoch 1: train loss 0.00010435611329739913, accuracy 0.5925925925925926\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m [Client 30] fit, config: {'current_round': 51, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m Epoch 1: train loss 0.0001105702031054534, accuracy 0.5\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m [Client 15] fit, config: {'current_round': 51, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m Epoch 1: train loss 0.0001313476386712864, accuracy 0.5\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m [Client 45] fit, config: {'current_round': 51, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m Epoch 1: train loss 9.735296771395952e-05, accuracy 0.6296296296296297\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m [Client 5] fit, config: {'current_round': 51, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m Epoch 1: train loss 0.00010207110608462244, accuracy 0.5925925925925926\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m [Client 33] fit, config: {'current_round': 51, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m Epoch 1: train loss 0.00011859022197313607, accuracy 0.5555555555555556\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m [Client 76] fit, config: {'current_round': 51, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m Epoch 1: train loss 7.900305354269221e-05, accuracy 0.6481481481481481\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m [Client 8] fit, config: {'current_round': 51, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m Epoch 1: train loss 0.00011693407577695325, accuracy 0.46296296296296297\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m [Client 48] fit, config: {'current_round': 51, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m Epoch 1: train loss 0.00010455140727572143, accuracy 0.6666666666666666\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m [Client 26] fit, config: {'current_round': 51, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m Epoch 1: train loss 0.00011971436470048502, accuracy 0.5370370370370371\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m [Client 9] fit, config: {'current_round': 51, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m Epoch 1: train loss 0.0001188307287520729, accuracy 0.46296296296296297\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m [Client 35] fit, config: {'current_round': 51, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m Epoch 1: train loss 9.745830902829766e-05, accuracy 0.6481481481481481\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m [Client 90] fit, config: {'current_round': 51, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m Epoch 1: train loss 9.329689055448398e-05, accuracy 0.6111111111111112\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m [Client 84] fit, config: {'current_round': 51, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m [Client 51] fit, config: {'current_round': 51, 'local_epochs': 3}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 12:57:54,805 | server.py:216 | fit_round received 30 results and 0 failures\n",
      "DEBUG flower 2023-02-01 12:57:54,865 | server.py:157 | evaluate_round: strategy sampled 30 clients (out of 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m [Client 61] fit, config: {'current_round': 51, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m Epoch 1: train loss 0.00011685518984450027, accuracy 0.6851851851851852\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m [Client 53] fit, config: {'current_round': 51, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m Epoch 1: train loss 0.00010353627294534817, accuracy 0.5185185185185185\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m [Client 72] fit, config: {'current_round': 51, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m Epoch 1: train loss 9.086445061257109e-05, accuracy 0.6666666666666666\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m [Client 74] fit, config: {'current_round': 51, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m [Client 31] fit, config: {'current_round': 51, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m Epoch 1: train loss 0.00011004330008290708, accuracy 0.5555555555555556\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m Epoch 1: train loss 0.00010878290049731731, accuracy 0.6111111111111112\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m [Client 50] fit, config: {'current_round': 51, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m Epoch 1: train loss 9.331202454632148e-05, accuracy 0.6851851851851852\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m [Client 37] fit, config: {'current_round': 51, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m Epoch 1: train loss 9.22256731428206e-05, accuracy 0.6296296296296297\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m Epoch 1: train loss 0.00011947785969823599, accuracy 0.5370370370370371\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m [Client 39] fit, config: {'current_round': 51, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m Epoch 1: train loss 9.164803486783057e-05, accuracy 0.7222222222222222\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m Epoch 1: train loss 0.00011499642278067768, accuracy 0.5740740740740741\n",
      "Saving round 51 aggregated_parameters...\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98095)\u001b[0m [Client 82] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98094)\u001b[0m [Client 50] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98095)\u001b[0m [Client 16] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98093)\u001b[0m [Client 7] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98094)\u001b[0m [Client 18] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98093)\u001b[0m [Client 13] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98093)\u001b[0m [Client 79] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98095)\u001b[0m [Client 93] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98094)\u001b[0m [Client 39] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98092)\u001b[0m [Client 12] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98095)\u001b[0m [Client 67] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98094)\u001b[0m [Client 40] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98094)\u001b[0m [Client 95] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98095)\u001b[0m [Client 90] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98094)\u001b[0m [Client 66] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98092)\u001b[0m [Client 94] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98092)\u001b[0m [Client 0] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98092)\u001b[0m [Client 99] evaluate, config: {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 12:57:56,944 | server.py:170 | evaluate_round received 0 results and 30 failures\n",
      "DEBUG flower 2023-02-01 12:57:56,945 | server.py:203 | fit_round: strategy sampled 30 clients (out of 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98088)\u001b[0m [Client 4] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98095)\u001b[0m [Client 78] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98093)\u001b[0m [Client 51] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98093)\u001b[0m [Client 58] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98094)\u001b[0m [Client 74] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98092)\u001b[0m [Client 81] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98091)\u001b[0m [Client 83] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98090)\u001b[0m [Client 25] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98090)\u001b[0m [Client 98] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98095)\u001b[0m [Client 97] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98089)\u001b[0m [Client 45] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98094)\u001b[0m [Client 11] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m [Client 48] fit, config: {'current_round': 52, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m Epoch 1: train loss 0.00011385937978047878, accuracy 0.5740740740740741\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m [Client 95] fit, config: {'current_round': 52, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m Epoch 1: train loss 8.199764852179214e-05, accuracy 0.7037037037037037\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m [Client 49] fit, config: {'current_round': 52, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m [Client 45] fit, config: {'current_round': 52, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m Epoch 1: train loss 0.00011658074799925089, accuracy 0.6111111111111112\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m [Client 51] fit, config: {'current_round': 52, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m Epoch 1: train loss 9.861784928943962e-05, accuracy 0.6851851851851852\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m Epoch 1: train loss 0.0001210575137520209, accuracy 0.5370370370370371\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m [Client 21] fit, config: {'current_round': 52, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m [Client 44] fit, config: {'current_round': 52, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m Epoch 1: train loss 0.00011306611122563481, accuracy 0.6666666666666666\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m Epoch 1: train loss 0.00011106902093160897, accuracy 0.7037037037037037\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m [Client 37] fit, config: {'current_round': 52, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m Epoch 1: train loss 8.235820132540539e-05, accuracy 0.7222222222222222\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m [Client 17] fit, config: {'current_round': 52, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m Epoch 1: train loss 9.491157834418118e-05, accuracy 0.6851851851851852\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m [Client 19] fit, config: {'current_round': 52, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m Epoch 1: train loss 8.629098010715097e-05, accuracy 0.7037037037037037\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m [Client 67] fit, config: {'current_round': 52, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m Epoch 1: train loss 0.0001327552308794111, accuracy 0.6111111111111112\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m [Client 71] fit, config: {'current_round': 52, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m [Client 73] fit, config: {'current_round': 52, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m Epoch 1: train loss 0.0001017473841784522, accuracy 0.5925925925925926\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m [Client 72] fit, config: {'current_round': 52, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m Epoch 1: train loss 0.00010989278234774247, accuracy 0.5925925925925926\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m [Client 90] fit, config: {'current_round': 52, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m [Client 97] fit, config: {'current_round': 52, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m Epoch 1: train loss 0.00013368298823479563, accuracy 0.5\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m Epoch 1: train loss 9.670733561506495e-05, accuracy 0.7037037037037037\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m Epoch 1: train loss 0.00010576821659924462, accuracy 0.6296296296296297\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m [Client 42] fit, config: {'current_round': 52, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m [Client 0] fit, config: {'current_round': 52, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m [Client 98] fit, config: {'current_round': 52, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m Epoch 1: train loss 0.00010610519530018792, accuracy 0.6851851851851852\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m [Client 38] fit, config: {'current_round': 52, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m Epoch 1: train loss 0.00010833890701178461, accuracy 0.5740740740740741\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m [Client 89] fit, config: {'current_round': 52, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m Epoch 1: train loss 0.00010534738248679787, accuracy 0.6296296296296297\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m [Client 11] fit, config: {'current_round': 52, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m Epoch 1: train loss 0.00010873946303036064, accuracy 0.5555555555555556\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m Epoch 1: train loss 0.00012352087651379406, accuracy 0.5740740740740741\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m [Client 24] fit, config: {'current_round': 52, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m Epoch 1: train loss 0.00010567994468146935, accuracy 0.6481481481481481\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m Epoch 1: train loss 0.00010434605792397633, accuracy 0.5740740740740741\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m [Client 56] fit, config: {'current_round': 52, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m [Client 99] fit, config: {'current_round': 52, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m Epoch 1: train loss 9.247510024579242e-05, accuracy 0.7407407407407407\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 12:57:59,239 | server.py:216 | fit_round received 30 results and 0 failures\n",
      "DEBUG flower 2023-02-01 12:57:59,301 | server.py:157 | evaluate_round: strategy sampled 30 clients (out of 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m [Client 88] fit, config: {'current_round': 52, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m Epoch 1: train loss 0.00011173639359185472, accuracy 0.5925925925925926\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m [Client 3] fit, config: {'current_round': 52, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m [Client 65] fit, config: {'current_round': 52, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m Epoch 1: train loss 0.00010933816520264372, accuracy 0.6481481481481481\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m [Client 92] fit, config: {'current_round': 52, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m Epoch 1: train loss 0.00011416077904868871, accuracy 0.5555555555555556\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m Epoch 1: train loss 0.0001008601684588939, accuracy 0.6296296296296297\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m Epoch 1: train loss 0.00011580226419027895, accuracy 0.5370370370370371\n",
      "Saving round 52 aggregated_parameters...\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m [Client 41] fit, config: {'current_round': 52, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m Epoch 1: train loss 9.493275138083845e-05, accuracy 0.6111111111111112\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98091)\u001b[0m [Client 6] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98091)\u001b[0m [Client 97] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98091)\u001b[0m [Client 59] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98091)\u001b[0m [Client 56] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98090)\u001b[0m [Client 86] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98088)\u001b[0m [Client 96] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98092)\u001b[0m [Client 39] evaluate, config: {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 12:58:01,408 | server.py:170 | evaluate_round received 0 results and 30 failures\n",
      "DEBUG flower 2023-02-01 12:58:01,408 | server.py:203 | fit_round: strategy sampled 30 clients (out of 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98092)\u001b[0m [Client 7] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98088)\u001b[0m [Client 30] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98088)\u001b[0m [Client 72] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98088)\u001b[0m [Client 2] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98092)\u001b[0m [Client 91] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98092)\u001b[0m [Client 16] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98088)\u001b[0m [Client 82] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98092)\u001b[0m [Client 43] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98091)\u001b[0m [Client 54] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98090)\u001b[0m [Client 8] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98088)\u001b[0m [Client 34] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98092)\u001b[0m [Client 48] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98091)\u001b[0m [Client 66] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98088)\u001b[0m [Client 95] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98091)\u001b[0m [Client 74] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98091)\u001b[0m [Client 22] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98090)\u001b[0m [Client 5] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98088)\u001b[0m [Client 65] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98095)\u001b[0m [Client 9] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98093)\u001b[0m [Client 37] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98089)\u001b[0m [Client 68] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98094)\u001b[0m [Client 84] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98092)\u001b[0m [Client 44] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m [Client 5] fit, config: {'current_round': 53, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m Epoch 1: train loss 0.00010906335955951363, accuracy 0.5740740740740741\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m [Client 52] fit, config: {'current_round': 53, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m [Client 72] fit, config: {'current_round': 53, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m [Client 46] fit, config: {'current_round': 53, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m Epoch 1: train loss 9.349216270493343e-05, accuracy 0.5925925925925926\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m Epoch 1: train loss 9.146279626293108e-05, accuracy 0.6666666666666666\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m [Client 7] fit, config: {'current_round': 53, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m Epoch 1: train loss 0.00011670625099213794, accuracy 0.5925925925925926\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m Epoch 1: train loss 8.428416913375258e-05, accuracy 0.6481481481481481\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m [Client 74] fit, config: {'current_round': 53, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m Epoch 1: train loss 0.00011673422704916447, accuracy 0.5555555555555556\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m [Client 32] fit, config: {'current_round': 53, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m [Client 28] fit, config: {'current_round': 53, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m Epoch 1: train loss 0.00011675866699079052, accuracy 0.5740740740740741\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m Epoch 1: train loss 0.00010134385956916958, accuracy 0.5370370370370371\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m [Client 10] fit, config: {'current_round': 53, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m Epoch 1: train loss 0.00011108857142971829, accuracy 0.48148148148148145\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m [Client 54] fit, config: {'current_round': 53, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m Epoch 1: train loss 9.781275730347261e-05, accuracy 0.6111111111111112\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m [Client 80] fit, config: {'current_round': 53, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m [Client 26] fit, config: {'current_round': 53, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m [Client 6] fit, config: {'current_round': 53, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m [Client 48] fit, config: {'current_round': 53, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m Epoch 1: train loss 9.956222493201494e-05, accuracy 0.6481481481481481\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m Epoch 1: train loss 8.910549513529986e-05, accuracy 0.6666666666666666\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m [Client 41] fit, config: {'current_round': 53, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m Epoch 1: train loss 0.0001145590576925315, accuracy 0.46296296296296297\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m Epoch 1: train loss 0.00010172520705964416, accuracy 0.6666666666666666\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m Epoch 1: train loss 0.00010051602293970063, accuracy 0.5740740740740741\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m [Client 95] fit, config: {'current_round': 53, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m Epoch 1: train loss 8.579363202443346e-05, accuracy 0.6666666666666666\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m [Client 0] fit, config: {'current_round': 53, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m Epoch 1: train loss 0.00011516344238771126, accuracy 0.6296296296296297\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m [Client 98] fit, config: {'current_round': 53, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m [Client 38] fit, config: {'current_round': 53, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m Epoch 1: train loss 0.00010119389480678365, accuracy 0.6851851851851852\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m [Client 84] fit, config: {'current_round': 53, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m Epoch 1: train loss 8.975166565505788e-05, accuracy 0.6666666666666666\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m Epoch 1: train loss 0.00012476461415644735, accuracy 0.48148148148148145\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m [Client 67] fit, config: {'current_round': 53, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m Epoch 1: train loss 0.0001219677651533857, accuracy 0.6111111111111112\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m [Client 78] fit, config: {'current_round': 53, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m Epoch 1: train loss 0.00011200029985047877, accuracy 0.5740740740740741\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m [Client 25] fit, config: {'current_round': 53, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m Epoch 1: train loss 9.517378202872351e-05, accuracy 0.5740740740740741\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m [Client 85] fit, config: {'current_round': 53, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m Epoch 1: train loss 0.00011892683687619865, accuracy 0.5370370370370371\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m [Client 63] fit, config: {'current_round': 53, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m [Client 31] fit, config: {'current_round': 53, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m [Client 20] fit, config: {'current_round': 53, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m [Client 69] fit, config: {'current_round': 53, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m [Client 49] fit, config: {'current_round': 53, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m Epoch 1: train loss 0.00011596638069022447, accuracy 0.5\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m Epoch 1: train loss 9.110836981562898e-05, accuracy 0.5740740740740741\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 12:58:03,968 | server.py:216 | fit_round received 30 results and 0 failures\n",
      "DEBUG flower 2023-02-01 12:58:04,023 | server.py:157 | evaluate_round: strategy sampled 30 clients (out of 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving round 53 aggregated_parameters...\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m [Client 92] fit, config: {'current_round': 53, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m Epoch 1: train loss 9.821197454584762e-05, accuracy 0.6851851851851852\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m Epoch 1: train loss 0.00010230571933789179, accuracy 0.6296296296296297\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m Epoch 1: train loss 0.00010436700540594757, accuracy 0.5370370370370371\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m Epoch 1: train loss 0.0001180206672870554, accuracy 0.6111111111111112\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98088)\u001b[0m [Client 6] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98088)\u001b[0m [Client 84] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98088)\u001b[0m [Client 71] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98088)\u001b[0m [Client 9] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98093)\u001b[0m [Client 86] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98089)\u001b[0m [Client 83] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98093)\u001b[0m [Client 56] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98089)\u001b[0m [Client 97] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98089)\u001b[0m [Client 47] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98089)\u001b[0m [Client 17] evaluate, config: {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 12:58:06,036 | server.py:170 | evaluate_round received 0 results and 30 failures\n",
      "DEBUG flower 2023-02-01 12:58:06,038 | server.py:203 | fit_round: strategy sampled 30 clients (out of 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98088)\u001b[0m [Client 27] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98095)\u001b[0m [Client 35] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98094)\u001b[0m [Client 21] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98090)\u001b[0m [Client 95] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98093)\u001b[0m [Client 19] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98089)\u001b[0m [Client 22] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98092)\u001b[0m [Client 85] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98090)\u001b[0m [Client 42] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98092)\u001b[0m [Client 52] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98090)\u001b[0m [Client 91] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98094)\u001b[0m [Client 67] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98092)\u001b[0m [Client 49] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98091)\u001b[0m [Client 37] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98090)\u001b[0m [Client 36] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98088)\u001b[0m [Client 5] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98095)\u001b[0m [Client 12] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98093)\u001b[0m [Client 1] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98089)\u001b[0m [Client 92] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98094)\u001b[0m [Client 53] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98092)\u001b[0m [Client 68] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m [Client 66] fit, config: {'current_round': 54, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m Epoch 1: train loss 9.882560698315501e-05, accuracy 0.6111111111111112\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m [Client 91] fit, config: {'current_round': 54, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m Epoch 1: train loss 0.00010093743912875652, accuracy 0.6296296296296297\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m [Client 33] fit, config: {'current_round': 54, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m Epoch 1: train loss 0.00010558046051301062, accuracy 0.6666666666666666\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m [Client 56] fit, config: {'current_round': 54, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m Epoch 1: train loss 0.0001123465335695073, accuracy 0.5555555555555556\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m [Client 92] fit, config: {'current_round': 54, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m Epoch 1: train loss 0.00011525239096954465, accuracy 0.5740740740740741\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m [Client 88] fit, config: {'current_round': 54, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m [Client 93] fit, config: {'current_round': 54, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m Epoch 1: train loss 0.00010873735300265253, accuracy 0.5925925925925926\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m [Client 3] fit, config: {'current_round': 54, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m Epoch 1: train loss 0.00011132382496725768, accuracy 0.5555555555555556\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m [Client 14] fit, config: {'current_round': 54, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m Epoch 1: train loss 0.00010402403131593019, accuracy 0.6481481481481481\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m Epoch 1: train loss 0.00010081999062094837, accuracy 0.5740740740740741\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m [Client 41] fit, config: {'current_round': 54, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m Epoch 1: train loss 9.158276952803135e-05, accuracy 0.6666666666666666\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m [Client 80] fit, config: {'current_round': 54, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m Epoch 1: train loss 8.342104410985485e-05, accuracy 0.6851851851851852\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m [Client 46] fit, config: {'current_round': 54, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m [Client 77] fit, config: {'current_round': 54, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m Epoch 1: train loss 0.00010871714039240032, accuracy 0.48148148148148145\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m [Client 52] fit, config: {'current_round': 54, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m [Client 9] fit, config: {'current_round': 54, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m Epoch 1: train loss 0.00010825062054209411, accuracy 0.6666666666666666\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m [Client 48] fit, config: {'current_round': 54, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m Epoch 1: train loss 0.00011322417412884533, accuracy 0.5925925925925926\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m [Client 69] fit, config: {'current_round': 54, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m Epoch 1: train loss 9.290778689319268e-05, accuracy 0.6851851851851852\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m Epoch 1: train loss 9.012893860926852e-05, accuracy 0.6666666666666666\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m Epoch 1: train loss 0.00011981707939412445, accuracy 0.5555555555555556\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m [Client 71] fit, config: {'current_round': 54, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m Epoch 1: train loss 9.9588418379426e-05, accuracy 0.6296296296296297\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m [Client 19] fit, config: {'current_round': 54, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m Epoch 1: train loss 8.478827658109367e-05, accuracy 0.7222222222222222\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m [Client 62] fit, config: {'current_round': 54, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m Epoch 1: train loss 9.752895130077377e-05, accuracy 0.6296296296296297\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m [Client 17] fit, config: {'current_round': 54, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m Epoch 1: train loss 9.32402690523304e-05, accuracy 0.6666666666666666\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m [Client 99] fit, config: {'current_round': 54, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m [Client 43] fit, config: {'current_round': 54, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m [Client 7] fit, config: {'current_round': 54, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m Epoch 1: train loss 0.00010039388143923134, accuracy 0.7222222222222222\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m [Client 60] fit, config: {'current_round': 54, 'local_epochs': 3}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 12:58:08,235 | server.py:216 | fit_round received 30 results and 0 failures\n",
      "DEBUG flower 2023-02-01 12:58:08,295 | server.py:157 | evaluate_round: strategy sampled 30 clients (out of 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m [Client 84] fit, config: {'current_round': 54, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m [Client 29] fit, config: {'current_round': 54, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m Epoch 1: train loss 0.00010921835928456858, accuracy 0.6666666666666666\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m Epoch 1: train loss 9.507413778919727e-05, accuracy 0.6851851851851852\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m [Client 82] fit, config: {'current_round': 54, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m Epoch 1: train loss 0.00010459493205416948, accuracy 0.6481481481481481\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m Epoch 1: train loss 0.00010237257811240852, accuracy 0.6481481481481481\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m [Client 40] fit, config: {'current_round': 54, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m Epoch 1: train loss 9.015957766678184e-05, accuracy 0.6666666666666666\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m Epoch 1: train loss 9.638287883717567e-05, accuracy 0.6481481481481481\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m [Client 63] fit, config: {'current_round': 54, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m Epoch 1: train loss 0.00011811449803644791, accuracy 0.48148148148148145\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m Epoch 1: train loss 0.00010161176032852381, accuracy 0.6296296296296297\n",
      "Saving round 54 aggregated_parameters...\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98091)\u001b[0m [Client 90] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98091)\u001b[0m [Client 3] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98095)\u001b[0m [Client 66] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98095)\u001b[0m [Client 42] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98091)\u001b[0m [Client 35] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98090)\u001b[0m [Client 60] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98089)\u001b[0m [Client 84] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98091)\u001b[0m [Client 92] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98090)\u001b[0m [Client 4] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98089)\u001b[0m [Client 11] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98095)\u001b[0m [Client 41] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98089)\u001b[0m [Client 51] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98089)\u001b[0m [Client 13] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98089)\u001b[0m [Client 97] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98090)\u001b[0m [Client 71] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98095)\u001b[0m [Client 89] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98089)\u001b[0m [Client 2] evaluate, config: {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 12:58:10,423 | server.py:170 | evaluate_round received 0 results and 30 failures\n",
      "DEBUG flower 2023-02-01 12:58:10,424 | server.py:203 | fit_round: strategy sampled 30 clients (out of 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98090)\u001b[0m [Client 63] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98091)\u001b[0m [Client 36] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98090)\u001b[0m [Client 82] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98095)\u001b[0m [Client 79] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98089)\u001b[0m [Client 20] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98092)\u001b[0m [Client 46] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98091)\u001b[0m [Client 72] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98090)\u001b[0m [Client 67] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98088)\u001b[0m [Client 6] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98095)\u001b[0m [Client 14] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98093)\u001b[0m [Client 28] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98089)\u001b[0m [Client 58] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98094)\u001b[0m [Client 98] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m [Client 39] fit, config: {'current_round': 55, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m Epoch 1: train loss 9.064832556759939e-05, accuracy 0.6851851851851852\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m [Client 90] fit, config: {'current_round': 55, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m Epoch 1: train loss 9.09783921088092e-05, accuracy 0.6481481481481481\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m [Client 65] fit, config: {'current_round': 55, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m Epoch 1: train loss 9.850363130681217e-05, accuracy 0.5740740740740741\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m [Client 64] fit, config: {'current_round': 55, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m [Client 41] fit, config: {'current_round': 55, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m Epoch 1: train loss 0.00010301244037691504, accuracy 0.5555555555555556\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m [Client 17] fit, config: {'current_round': 55, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m [Client 3] fit, config: {'current_round': 55, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m Epoch 1: train loss 0.00012526694627013057, accuracy 0.6296296296296297\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m [Client 71] fit, config: {'current_round': 55, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m Epoch 1: train loss 9.46184663916938e-05, accuracy 0.6481481481481481\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m Epoch 1: train loss 9.722109098220244e-05, accuracy 0.6851851851851852\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m Epoch 1: train loss 0.0001004147416097112, accuracy 0.5925925925925926\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m [Client 49] fit, config: {'current_round': 55, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m Epoch 1: train loss 0.00011356712639098987, accuracy 0.5185185185185185\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m [Client 76] fit, config: {'current_round': 55, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m Epoch 1: train loss 8.18520929897204e-05, accuracy 0.6481481481481481\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m [Client 7] fit, config: {'current_round': 55, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m Epoch 1: train loss 0.00011416463530622423, accuracy 0.5925925925925926\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m [Client 50] fit, config: {'current_round': 55, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m Epoch 1: train loss 0.00011583677405724302, accuracy 0.5370370370370371\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m [Client 35] fit, config: {'current_round': 55, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m Epoch 1: train loss 9.314245835412294e-05, accuracy 0.7037037037037037\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m [Client 93] fit, config: {'current_round': 55, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m Epoch 1: train loss 8.607966447016224e-05, accuracy 0.6851851851851852\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m [Client 0] fit, config: {'current_round': 55, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m [Client 42] fit, config: {'current_round': 55, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m [Client 16] fit, config: {'current_round': 55, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m [Client 95] fit, config: {'current_round': 55, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m Epoch 1: train loss 0.0001156416765297763, accuracy 0.5370370370370371\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m [Client 52] fit, config: {'current_round': 55, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m Epoch 1: train loss 8.93659089342691e-05, accuracy 0.6111111111111112\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m Epoch 1: train loss 0.00011327501852065325, accuracy 0.6111111111111112\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m [Client 27] fit, config: {'current_round': 55, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m Epoch 1: train loss 0.00010927770199486986, accuracy 0.5555555555555556\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m Epoch 1: train loss 0.00010899964399868622, accuracy 0.5185185185185185\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m Epoch 1: train loss 8.438552322331816e-05, accuracy 0.6666666666666666\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m [Client 15] fit, config: {'current_round': 55, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m Epoch 1: train loss 0.0001284377067349851, accuracy 0.5\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m [Client 30] fit, config: {'current_round': 55, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m [Client 14] fit, config: {'current_round': 55, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m Epoch 1: train loss 0.00011165763135068119, accuracy 0.5370370370370371\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m Epoch 1: train loss 0.0001122930261772126, accuracy 0.5925925925925926\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m [Client 68] fit, config: {'current_round': 55, 'local_epochs': 3}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 12:58:12,786 | server.py:216 | fit_round received 30 results and 0 failures\n",
      "DEBUG flower 2023-02-01 12:58:12,844 | server.py:157 | evaluate_round: strategy sampled 30 clients (out of 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m [Client 56] fit, config: {'current_round': 55, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m [Client 18] fit, config: {'current_round': 55, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m [Client 58] fit, config: {'current_round': 55, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m Epoch 1: train loss 0.00010472317808307707, accuracy 0.5185185185185185\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m [Client 85] fit, config: {'current_round': 55, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m Epoch 1: train loss 8.941417036112398e-05, accuracy 0.5925925925925926\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m [Client 62] fit, config: {'current_round': 55, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m [Client 96] fit, config: {'current_round': 55, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m Epoch 1: train loss 9.204468369716778e-05, accuracy 0.7037037037037037\n",
      "Saving round 55 aggregated_parameters...\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m Epoch 1: train loss 0.00011613415699684992, accuracy 0.5\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m Epoch 1: train loss 0.00011243772314628586, accuracy 0.5\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m Epoch 1: train loss 0.0001180166145786643, accuracy 0.5185185185185185\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m Epoch 1: train loss 9.095884161069989e-05, accuracy 0.6111111111111112\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98089)\u001b[0m [Client 78] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98091)\u001b[0m [Client 8] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98090)\u001b[0m [Client 85] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98095)\u001b[0m [Client 40] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98090)\u001b[0m [Client 4] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98090)\u001b[0m [Client 30] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98091)\u001b[0m [Client 43] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98095)\u001b[0m [Client 60] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98095)\u001b[0m [Client 58] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98091)\u001b[0m [Client 92] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98090)\u001b[0m [Client 49] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98095)\u001b[0m [Client 66] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98089)\u001b[0m [Client 91] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98091)\u001b[0m [Client 74] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98090)\u001b[0m [Client 48] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98089)\u001b[0m [Client 46] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98091)\u001b[0m [Client 22] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98090)\u001b[0m [Client 83] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98091)\u001b[0m [Client 16] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98091)\u001b[0m [Client 98] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98090)\u001b[0m [Client 56] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98091)\u001b[0m [Client 51] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98090)\u001b[0m [Client 10] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98088)\u001b[0m [Client 65] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98095)\u001b[0m [Client 89] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98093)\u001b[0m [Client 15] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98094)\u001b[0m [Client 42] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98092)\u001b[0m [Client 71] evaluate, config: {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 12:58:15,097 | server.py:170 | evaluate_round received 0 results and 30 failures\n",
      "DEBUG flower 2023-02-01 12:58:15,098 | server.py:203 | fit_round: strategy sampled 30 clients (out of 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98090)\u001b[0m [Client 57] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98089)\u001b[0m [Client 36] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m [Client 99] fit, config: {'current_round': 56, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m Epoch 1: train loss 9.710616723168641e-05, accuracy 0.6481481481481481\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m [Client 91] fit, config: {'current_round': 56, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m Epoch 1: train loss 0.00010209850006503984, accuracy 0.5740740740740741\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m [Client 11] fit, config: {'current_round': 56, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m [Client 13] fit, config: {'current_round': 56, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m Epoch 1: train loss 0.00010571148595772684, accuracy 0.6111111111111112\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m [Client 50] fit, config: {'current_round': 56, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m Epoch 1: train loss 8.646849892102182e-05, accuracy 0.7037037037037037\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m Epoch 1: train loss 0.00011913203343283385, accuracy 0.5185185185185185\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m [Client 65] fit, config: {'current_round': 56, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m Epoch 1: train loss 0.00011370015272404999, accuracy 0.46296296296296297\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m [Client 34] fit, config: {'current_round': 56, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m Epoch 1: train loss 9.872737427940592e-05, accuracy 0.5925925925925926\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m [Client 86] fit, config: {'current_round': 56, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m Epoch 1: train loss 9.785453585209325e-05, accuracy 0.6296296296296297\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m [Client 25] fit, config: {'current_round': 56, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m Epoch 1: train loss 0.00010425287473481148, accuracy 0.5555555555555556\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m [Client 26] fit, config: {'current_round': 56, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m Epoch 1: train loss 0.0001241942518390715, accuracy 0.5\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m [Client 24] fit, config: {'current_round': 56, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m [Client 83] fit, config: {'current_round': 56, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m Epoch 1: train loss 9.721919195726514e-05, accuracy 0.7037037037037037\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m [Client 1] fit, config: {'current_round': 56, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m Epoch 1: train loss 0.00010078446939587593, accuracy 0.5370370370370371\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m [Client 69] fit, config: {'current_round': 56, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m [Client 79] fit, config: {'current_round': 56, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m Epoch 1: train loss 0.00011058291420340538, accuracy 0.48148148148148145\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m Epoch 1: train loss 9.275296179112047e-05, accuracy 0.6481481481481481\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m [Client 80] fit, config: {'current_round': 56, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m Epoch 1: train loss 8.300319314002991e-05, accuracy 0.6666666666666666\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m Epoch 1: train loss 0.00010854584979824722, accuracy 0.5555555555555556\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m [Client 70] fit, config: {'current_round': 56, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m Epoch 1: train loss 0.00011385678226361051, accuracy 0.5925925925925926\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 12:58:17,329 | server.py:216 | fit_round received 30 results and 0 failures\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m [Client 2] fit, config: {'current_round': 56, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m Epoch 1: train loss 9.386767487740144e-05, accuracy 0.5370370370370371\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m [Client 66] fit, config: {'current_round': 56, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m Epoch 1: train loss 9.972811676561832e-05, accuracy 0.5370370370370371\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m [Client 41] fit, config: {'current_round': 56, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m [Client 35] fit, config: {'current_round': 56, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m Epoch 1: train loss 8.942284330260009e-05, accuracy 0.6666666666666666\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m [Client 31] fit, config: {'current_round': 56, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m [Client 73] fit, config: {'current_round': 56, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m Epoch 1: train loss 0.00010703157022362575, accuracy 0.5555555555555556\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m [Client 16] fit, config: {'current_round': 56, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m Epoch 1: train loss 9.153551945928484e-05, accuracy 0.6481481481481481\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m [Client 47] fit, config: {'current_round': 56, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m Epoch 1: train loss 0.00011144461313961074, accuracy 0.5925925925925926\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m Epoch 1: train loss 0.00010896784078795463, accuracy 0.5185185185185185\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m [Client 84] fit, config: {'current_round': 56, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m Epoch 1: train loss 0.00010098930943058804, accuracy 0.5555555555555556\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m [Client 88] fit, config: {'current_round': 56, 'local_epochs': 3}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 12:58:17,390 | server.py:157 | evaluate_round: strategy sampled 30 clients (out of 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m Epoch 1: train loss 0.00011081087723141536, accuracy 0.5740740740740741\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m [Client 76] fit, config: {'current_round': 56, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m Epoch 1: train loss 8.36954204714857e-05, accuracy 0.5740740740740741\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m [Client 36] fit, config: {'current_round': 56, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m Epoch 1: train loss 0.00011483645357657224, accuracy 0.5555555555555556\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m [Client 12] fit, config: {'current_round': 56, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m Epoch 1: train loss 0.00010662481508916244, accuracy 0.6111111111111112\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m Epoch 1: train loss 9.964214405044913e-05, accuracy 0.5370370370370371\n",
      "Saving round 56 aggregated_parameters...\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98090)\u001b[0m [Client 90] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98090)\u001b[0m [Client 0] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98090)\u001b[0m [Client 2] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98088)\u001b[0m [Client 55] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98093)\u001b[0m [Client 5] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98091)\u001b[0m [Client 71] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98088)\u001b[0m [Client 77] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98093)\u001b[0m [Client 41] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98094)\u001b[0m [Client 20] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98091)\u001b[0m [Client 80] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98090)\u001b[0m [Client 96] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98088)\u001b[0m [Client 38] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98094)\u001b[0m [Client 87] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98091)\u001b[0m [Client 66] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98091)\u001b[0m [Client 6] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98094)\u001b[0m [Client 49] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98090)\u001b[0m [Client 33] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98090)\u001b[0m [Client 78] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98090)\u001b[0m [Client 89] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98090)\u001b[0m [Client 73] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98090)\u001b[0m [Client 84] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98088)\u001b[0m [Client 63] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98093)\u001b[0m [Client 16] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98089)\u001b[0m [Client 48] evaluate, config: {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 12:58:19,639 | server.py:170 | evaluate_round received 0 results and 30 failures\n",
      "DEBUG flower 2023-02-01 12:58:19,640 | server.py:203 | fit_round: strategy sampled 30 clients (out of 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98091)\u001b[0m [Client 34] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98088)\u001b[0m [Client 21] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98089)\u001b[0m [Client 14] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98094)\u001b[0m [Client 28] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98092)\u001b[0m [Client 64] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98095)\u001b[0m [Client 54] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m [Client 34] fit, config: {'current_round': 57, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m Epoch 1: train loss 0.00010124604887096211, accuracy 0.5555555555555556\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m [Client 32] fit, config: {'current_round': 57, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m Epoch 1: train loss 9.949877858161926e-05, accuracy 0.5740740740740741\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m [Client 98] fit, config: {'current_round': 57, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m [Client 75] fit, config: {'current_round': 57, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m Epoch 1: train loss 0.00011157942935824394, accuracy 0.5925925925925926\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m [Client 66] fit, config: {'current_round': 57, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m Epoch 1: train loss 8.958149555837736e-05, accuracy 0.6851851851851852\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m [Client 69] fit, config: {'current_round': 57, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m Epoch 1: train loss 8.762005745666102e-05, accuracy 0.5740740740740741\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m Epoch 1: train loss 0.00011188189091626555, accuracy 0.5\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m [Client 24] fit, config: {'current_round': 57, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m Epoch 1: train loss 8.908651943784207e-05, accuracy 0.6111111111111112\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m [Client 63] fit, config: {'current_round': 57, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m [Client 13] fit, config: {'current_round': 57, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m Epoch 1: train loss 0.00011111446656286716, accuracy 0.48148148148148145\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m [Client 33] fit, config: {'current_round': 57, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m Epoch 1: train loss 9.97171810013242e-05, accuracy 0.6296296296296297\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m [Client 59] fit, config: {'current_round': 57, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m Epoch 1: train loss 0.00010320948058506474, accuracy 0.5925925925925926\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m [Client 12] fit, config: {'current_round': 57, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m Epoch 1: train loss 0.00010783258767332882, accuracy 0.6296296296296297\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m [Client 56] fit, config: {'current_round': 57, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m Epoch 1: train loss 0.00011265108332736418, accuracy 0.5\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m [Client 3] fit, config: {'current_round': 57, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m Epoch 1: train loss 0.00011368715786375105, accuracy 0.5555555555555556\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m [Client 0] fit, config: {'current_round': 57, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m Epoch 1: train loss 0.00011223737237742171, accuracy 0.5370370370370371\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m [Client 89] fit, config: {'current_round': 57, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m Epoch 1: train loss 9.603997023077682e-05, accuracy 0.5740740740740741\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m [Client 68] fit, config: {'current_round': 57, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m Epoch 1: train loss 8.716590673429891e-05, accuracy 0.5925925925925926\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m [Client 72] fit, config: {'current_round': 57, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m Epoch 1: train loss 8.428630098933354e-05, accuracy 0.7407407407407407\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m Epoch 1: train loss 0.00012171882553957403, accuracy 0.6111111111111112\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m [Client 91] fit, config: {'current_round': 57, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m Epoch 1: train loss 9.20814200071618e-05, accuracy 0.6481481481481481\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m [Client 65] fit, config: {'current_round': 57, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m Epoch 1: train loss 9.735248750075698e-05, accuracy 0.5740740740740741\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m [Client 5] fit, config: {'current_round': 57, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m Epoch 1: train loss 0.00010619691602187231, accuracy 0.5185185185185185\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 12:58:22,053 | server.py:216 | fit_round received 30 results and 0 failures\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m [Client 70] fit, config: {'current_round': 57, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m [Client 31] fit, config: {'current_round': 57, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m [Client 73] fit, config: {'current_round': 57, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m Epoch 1: train loss 0.00013172044418752193, accuracy 0.5555555555555556\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m Epoch 1: train loss 9.704985131975263e-05, accuracy 0.5740740740740741\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m [Client 87] fit, config: {'current_round': 57, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m Epoch 1: train loss 9.933138790074736e-05, accuracy 0.6666666666666666\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m [Client 7] fit, config: {'current_round': 57, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m Epoch 1: train loss 0.00011242694017710164, accuracy 0.5925925925925926\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 12:58:22,111 | server.py:157 | evaluate_round: strategy sampled 30 clients (out of 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m [Client 17] fit, config: {'current_round': 57, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m Epoch 1: train loss 9.586425585439429e-05, accuracy 0.7037037037037037\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m [Client 54] fit, config: {'current_round': 57, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m Epoch 1: train loss 9.305002458859235e-05, accuracy 0.6666666666666666\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m [Client 94] fit, config: {'current_round': 57, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m Epoch 1: train loss 0.00010156950884265825, accuracy 0.6296296296296297\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m Epoch 1: train loss 9.230028808815405e-05, accuracy 0.5555555555555556\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m [Client 39] fit, config: {'current_round': 57, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m Epoch 1: train loss 9.053303801920265e-05, accuracy 0.7222222222222222\n",
      "Saving round 57 aggregated_parameters...\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98095)\u001b[0m [Client 91] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98093)\u001b[0m [Client 25] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98094)\u001b[0m [Client 64] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98088)\u001b[0m [Client 13] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98088)\u001b[0m [Client 50] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98088)\u001b[0m [Client 19] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98088)\u001b[0m [Client 39] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98088)\u001b[0m [Client 44] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98095)\u001b[0m [Client 76] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98093)\u001b[0m [Client 48] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98089)\u001b[0m [Client 56] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98094)\u001b[0m [Client 72] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98088)\u001b[0m [Client 33] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98095)\u001b[0m [Client 11] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98093)\u001b[0m [Client 67] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98089)\u001b[0m [Client 60] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98094)\u001b[0m [Client 23] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98090)\u001b[0m [Client 2] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98090)\u001b[0m [Client 28] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98091)\u001b[0m [Client 0] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98088)\u001b[0m [Client 15] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98093)\u001b[0m [Client 78] evaluate, config: {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 12:58:24,404 | server.py:170 | evaluate_round received 0 results and 30 failures\n",
      "DEBUG flower 2023-02-01 12:58:24,405 | server.py:203 | fit_round: strategy sampled 30 clients (out of 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98091)\u001b[0m [Client 58] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98090)\u001b[0m [Client 18] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98088)\u001b[0m [Client 6] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98095)\u001b[0m [Client 43] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98093)\u001b[0m [Client 40] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98089)\u001b[0m [Client 68] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98094)\u001b[0m [Client 12] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98092)\u001b[0m [Client 38] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m [Client 80] fit, config: {'current_round': 58, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m Epoch 1: train loss 7.960505172377452e-05, accuracy 0.6851851851851852\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m [Client 60] fit, config: {'current_round': 58, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m Epoch 1: train loss 9.415984823135659e-05, accuracy 0.6851851851851852\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m [Client 75] fit, config: {'current_round': 58, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m Epoch 1: train loss 0.00010708174522733316, accuracy 0.6481481481481481\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m [Client 69] fit, config: {'current_round': 58, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m Epoch 1: train loss 8.9435932750348e-05, accuracy 0.6851851851851852\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m [Client 12] fit, config: {'current_round': 58, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m Epoch 1: train loss 0.00010528000711929053, accuracy 0.6481481481481481\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m [Client 55] fit, config: {'current_round': 58, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m Epoch 1: train loss 9.336083894595504e-05, accuracy 0.6481481481481481\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m [Client 77] fit, config: {'current_round': 58, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m Epoch 1: train loss 0.00010339479194954038, accuracy 0.5740740740740741\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m [Client 98] fit, config: {'current_round': 58, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m Epoch 1: train loss 0.00010966412810375914, accuracy 0.5740740740740741\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m [Client 14] fit, config: {'current_round': 58, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m Epoch 1: train loss 9.846488683251664e-05, accuracy 0.6666666666666666\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m [Client 23] fit, config: {'current_round': 58, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m Epoch 1: train loss 0.00010729394853115082, accuracy 0.5740740740740741\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m [Client 83] fit, config: {'current_round': 58, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m [Client 32] fit, config: {'current_round': 58, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m Epoch 1: train loss 9.590515401214361e-05, accuracy 0.6296296296296297\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m Epoch 1: train loss 9.426882024854422e-05, accuracy 0.6851851851851852\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m [Client 10] fit, config: {'current_round': 58, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m Epoch 1: train loss 0.00010117573401657864, accuracy 0.6851851851851852\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m [Client 13] fit, config: {'current_round': 58, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m Epoch 1: train loss 0.00011627799540292472, accuracy 0.5370370370370371\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m [Client 8] fit, config: {'current_round': 58, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m Epoch 1: train loss 9.557194425724447e-05, accuracy 0.6111111111111112\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m [Client 95] fit, config: {'current_round': 58, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m Epoch 1: train loss 7.714364619459957e-05, accuracy 0.7222222222222222\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m [Client 19] fit, config: {'current_round': 58, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m Epoch 1: train loss 8.23146037873812e-05, accuracy 0.7592592592592593\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m [Client 51] fit, config: {'current_round': 58, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m Epoch 1: train loss 9.927461360348389e-05, accuracy 0.6481481481481481\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m [Client 28] fit, config: {'current_round': 58, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m Epoch 1: train loss 8.955920930020511e-05, accuracy 0.7407407407407407\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m [Client 61] fit, config: {'current_round': 58, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m Epoch 1: train loss 8.855537453200668e-05, accuracy 0.6851851851851852\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m [Client 22] fit, config: {'current_round': 58, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m Epoch 1: train loss 0.00012475348194129765, accuracy 0.37037037037037035\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m [Client 63] fit, config: {'current_round': 58, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m Epoch 1: train loss 0.00010943967936327681, accuracy 0.48148148148148145\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 12:58:26,567 | server.py:216 | fit_round received 30 results and 0 failures\n",
      "DEBUG flower 2023-02-01 12:58:26,625 | server.py:157 | evaluate_round: strategy sampled 30 clients (out of 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m [Client 93] fit, config: {'current_round': 58, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m Epoch 1: train loss 0.00010365183698013425, accuracy 0.6111111111111112\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m [Client 72] fit, config: {'current_round': 58, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m [Client 84] fit, config: {'current_round': 58, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m Epoch 1: train loss 9.777639934327453e-05, accuracy 0.6111111111111112\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m [Client 87] fit, config: {'current_round': 58, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m Epoch 1: train loss 9.439227142138407e-05, accuracy 0.6296296296296297\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m [Client 73] fit, config: {'current_round': 58, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m Epoch 1: train loss 0.00010367945651523769, accuracy 0.5925925925925926\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m [Client 21] fit, config: {'current_round': 58, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m Epoch 1: train loss 0.00011426470155129209, accuracy 0.6111111111111112\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m [Client 58] fit, config: {'current_round': 58, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m Epoch 1: train loss 0.00010334707621950656, accuracy 0.5925925925925926\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m [Client 38] fit, config: {'current_round': 58, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m Epoch 1: train loss 0.00010739742720033973, accuracy 0.5370370370370371\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m Epoch 1: train loss 9.701684030005708e-05, accuracy 0.6851851851851852\n",
      "Saving round 58 aggregated_parameters...\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98088)\u001b[0m [Client 5] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98088)\u001b[0m [Client 88] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98091)\u001b[0m [Client 83] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98088)\u001b[0m [Client 78] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98093)\u001b[0m [Client 4] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98093)\u001b[0m [Client 66] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98088)\u001b[0m [Client 36] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98091)\u001b[0m [Client 41] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98090)\u001b[0m [Client 70] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98088)\u001b[0m [Client 43] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98093)\u001b[0m [Client 59] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98090)\u001b[0m [Client 17] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98095)\u001b[0m [Client 67] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98090)\u001b[0m [Client 19] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98090)\u001b[0m [Client 44] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98095)\u001b[0m [Client 45] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98095)\u001b[0m [Client 93] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98095)\u001b[0m [Client 50] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98095)\u001b[0m [Client 24] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98090)\u001b[0m [Client 55] evaluate, config: {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 12:58:28,751 | server.py:170 | evaluate_round received 0 results and 30 failures\n",
      "DEBUG flower 2023-02-01 12:58:28,752 | server.py:203 | fit_round: strategy sampled 30 clients (out of 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98091)\u001b[0m [Client 42] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98090)\u001b[0m [Client 91] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98088)\u001b[0m [Client 9] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98088)\u001b[0m [Client 12] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98095)\u001b[0m [Client 86] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98093)\u001b[0m [Client 31] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98089)\u001b[0m [Client 8] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98094)\u001b[0m [Client 35] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98092)\u001b[0m [Client 6] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98093)\u001b[0m [Client 23] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m [Client 35] fit, config: {'current_round': 59, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m [Client 6] fit, config: {'current_round': 59, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m Epoch 1: train loss 9.911201777867973e-05, accuracy 0.6666666666666666\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m [Client 21] fit, config: {'current_round': 59, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m Epoch 1: train loss 0.00012790555774699897, accuracy 0.4444444444444444\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m [Client 59] fit, config: {'current_round': 59, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m Epoch 1: train loss 9.288157161790878e-05, accuracy 0.7037037037037037\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m Epoch 1: train loss 0.00010327826748834923, accuracy 0.6851851851851852\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m [Client 40] fit, config: {'current_round': 59, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m [Client 60] fit, config: {'current_round': 59, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m Epoch 1: train loss 9.739279630593956e-05, accuracy 0.6481481481481481\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m [Client 41] fit, config: {'current_round': 59, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m Epoch 1: train loss 9.780997788766399e-05, accuracy 0.5370370370370371\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m [Client 63] fit, config: {'current_round': 59, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m Epoch 1: train loss 9.957729344023392e-05, accuracy 0.5925925925925926\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m [Client 55] fit, config: {'current_round': 59, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m Epoch 1: train loss 9.980934555642307e-05, accuracy 0.6111111111111112\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m Epoch 1: train loss 8.893466292647645e-05, accuracy 0.6481481481481481\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m [Client 56] fit, config: {'current_round': 59, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m Epoch 1: train loss 0.00011223478213651106, accuracy 0.5\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m [Client 15] fit, config: {'current_round': 59, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m Epoch 1: train loss 0.00012429739581421018, accuracy 0.5370370370370371\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m [Client 79] fit, config: {'current_round': 59, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m Epoch 1: train loss 9.714823681861162e-05, accuracy 0.5370370370370371\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m [Client 5] fit, config: {'current_round': 59, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m [Client 22] fit, config: {'current_round': 59, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m Epoch 1: train loss 0.00011838450154755265, accuracy 0.5\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m Epoch 1: train loss 0.00010222863056696951, accuracy 0.5555555555555556\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m [Client 14] fit, config: {'current_round': 59, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m Epoch 1: train loss 0.00010775967530207708, accuracy 0.5925925925925926\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m [Client 34] fit, config: {'current_round': 59, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m Epoch 1: train loss 0.0001018843031488359, accuracy 0.5185185185185185\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m [Client 2] fit, config: {'current_round': 59, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m Epoch 1: train loss 7.494209421565756e-05, accuracy 0.7037037037037037\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m [Client 78] fit, config: {'current_round': 59, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m Epoch 1: train loss 0.0001096490741474554, accuracy 0.5555555555555556\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m [Client 69] fit, config: {'current_round': 59, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m [Client 19] fit, config: {'current_round': 59, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m Epoch 1: train loss 8.856486965669319e-05, accuracy 0.5925925925925926\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m [Client 51] fit, config: {'current_round': 59, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m Epoch 1: train loss 9.896194387692958e-05, accuracy 0.5925925925925926\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m Epoch 1: train loss 8.404464460909367e-05, accuracy 0.6296296296296297\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m [Client 75] fit, config: {'current_round': 59, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m [Client 20] fit, config: {'current_round': 59, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m [Client 42] fit, config: {'current_round': 59, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m Epoch 1: train loss 0.00010955426841974258, accuracy 0.5925925925925926\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m [Client 77] fit, config: {'current_round': 59, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m Epoch 1: train loss 0.00010716308315750211, accuracy 0.6481481481481481\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m [Client 26] fit, config: {'current_round': 59, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m Epoch 1: train loss 0.0001072977902367711, accuracy 0.5555555555555556\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m Epoch 1: train loss 0.00011280176840955392, accuracy 0.6111111111111112\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 12:58:31,073 | server.py:216 | fit_round received 30 results and 0 failures\n",
      "DEBUG flower 2023-02-01 12:58:31,131 | server.py:157 | evaluate_round: strategy sampled 30 clients (out of 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m [Client 89] fit, config: {'current_round': 59, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m Epoch 1: train loss 9.370234329253435e-05, accuracy 0.5740740740740741\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m Epoch 1: train loss 9.575708099873737e-05, accuracy 0.6851851851851852\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m [Client 72] fit, config: {'current_round': 59, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m Epoch 1: train loss 8.362545486306772e-05, accuracy 0.7037037037037037\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m [Client 7] fit, config: {'current_round': 59, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m Epoch 1: train loss 0.00010761551675386727, accuracy 0.6111111111111112\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m [Client 47] fit, config: {'current_round': 59, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m Epoch 1: train loss 8.9869718067348e-05, accuracy 0.6481481481481481\n",
      "Saving round 59 aggregated_parameters...\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98091)\u001b[0m [Client 24] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98091)\u001b[0m [Client 1] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98091)\u001b[0m [Client 55] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98091)\u001b[0m [Client 38] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98095)\u001b[0m [Client 27] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98094)\u001b[0m [Client 86] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98092)\u001b[0m [Client 57] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98095)\u001b[0m [Client 70] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98091)\u001b[0m [Client 4] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98094)\u001b[0m [Client 73] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98092)\u001b[0m [Client 91] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98095)\u001b[0m [Client 82] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98091)\u001b[0m [Client 56] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98094)\u001b[0m [Client 17] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98094)\u001b[0m [Client 54] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98094)\u001b[0m [Client 63] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98091)\u001b[0m [Client 87] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98094)\u001b[0m [Client 97] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98092)\u001b[0m [Client 33] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98090)\u001b[0m [Client 72] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98088)\u001b[0m [Client 22] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98095)\u001b[0m [Client 9] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98093)\u001b[0m [Client 96] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98089)\u001b[0m [Client 88] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98094)\u001b[0m [Client 15] evaluate, config: {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 12:58:33,572 | server.py:170 | evaluate_round received 0 results and 30 failures\n",
      "DEBUG flower 2023-02-01 12:58:33,573 | server.py:203 | fit_round: strategy sampled 30 clients (out of 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98090)\u001b[0m [Client 95] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98088)\u001b[0m [Client 39] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98095)\u001b[0m [Client 13] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98093)\u001b[0m [Client 45] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98094)\u001b[0m [Client 99] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m [Client 35] fit, config: {'current_round': 60, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m Epoch 1: train loss 0.00010657704115146771, accuracy 0.6296296296296297\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m [Client 54] fit, config: {'current_round': 60, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m Epoch 1: train loss 0.00011077476665377617, accuracy 0.5185185185185185\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m [Client 96] fit, config: {'current_round': 60, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m Epoch 1: train loss 8.330214768648148e-05, accuracy 0.7037037037037037\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m [Client 32] fit, config: {'current_round': 60, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m Epoch 1: train loss 9.947671060217544e-05, accuracy 0.5925925925925926\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m [Client 16] fit, config: {'current_round': 60, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m Epoch 1: train loss 8.825794793665409e-05, accuracy 0.6666666666666666\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m [Client 98] fit, config: {'current_round': 60, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m Epoch 1: train loss 0.00010933019075309858, accuracy 0.6296296296296297\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m [Client 40] fit, config: {'current_round': 60, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m Epoch 1: train loss 8.65341498865746e-05, accuracy 0.7037037037037037\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m [Client 94] fit, config: {'current_round': 60, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m Epoch 1: train loss 0.00010040385677712038, accuracy 0.5740740740740741\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m [Client 1] fit, config: {'current_round': 60, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m Epoch 1: train loss 0.00010397044388810173, accuracy 0.5740740740740741\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m [Client 29] fit, config: {'current_round': 60, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m Epoch 1: train loss 0.00010559197835391387, accuracy 0.5925925925925926\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m [Client 26] fit, config: {'current_round': 60, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m Epoch 1: train loss 0.00011932808411074802, accuracy 0.5370370370370371\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m [Client 59] fit, config: {'current_round': 60, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m Epoch 1: train loss 9.413925727130845e-05, accuracy 0.6666666666666666\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m [Client 92] fit, config: {'current_round': 60, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m [Client 33] fit, config: {'current_round': 60, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m [Client 86] fit, config: {'current_round': 60, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m Epoch 1: train loss 0.00011460018140496686, accuracy 0.6111111111111112\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m [Client 55] fit, config: {'current_round': 60, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m Epoch 1: train loss 9.226112888427451e-05, accuracy 0.6481481481481481\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m [Client 45] fit, config: {'current_round': 60, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m [Client 11] fit, config: {'current_round': 60, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m Epoch 1: train loss 9.79934775386937e-05, accuracy 0.6481481481481481\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m Epoch 1: train loss 9.26716675166972e-05, accuracy 0.7222222222222222\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m [Client 71] fit, config: {'current_round': 60, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m [Client 66] fit, config: {'current_round': 60, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m [Client 58] fit, config: {'current_round': 60, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m Epoch 1: train loss 0.00010476203897269443, accuracy 0.5740740740740741\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m Epoch 1: train loss 0.00011206087219761685, accuracy 0.5925925925925926\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m Epoch 1: train loss 0.00010375255078542978, accuracy 0.6111111111111112\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m [Client 19] fit, config: {'current_round': 60, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m Epoch 1: train loss 8.119096310110763e-05, accuracy 0.7037037037037037\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m Epoch 1: train loss 9.418917034054175e-05, accuracy 0.7407407407407407\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m Epoch 1: train loss 9.521323954686522e-05, accuracy 0.6851851851851852\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m [Client 69] fit, config: {'current_round': 60, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m [Client 22] fit, config: {'current_round': 60, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m Epoch 1: train loss 0.0001241776189999655, accuracy 0.42592592592592593\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m [Client 24] fit, config: {'current_round': 60, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m [Client 78] fit, config: {'current_round': 60, 'local_epochs': 3}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 12:58:35,798 | server.py:216 | fit_round received 30 results and 0 failures\n",
      "DEBUG flower 2023-02-01 12:58:35,873 | server.py:157 | evaluate_round: strategy sampled 30 clients (out of 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m Epoch 1: train loss 0.00010362530883867294, accuracy 0.6111111111111112\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m [Client 60] fit, config: {'current_round': 60, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m Epoch 1: train loss 9.312356996815652e-05, accuracy 0.6666666666666666\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m [Client 63] fit, config: {'current_round': 60, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m Epoch 1: train loss 0.00010823239426827058, accuracy 0.5\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m [Client 10] fit, config: {'current_round': 60, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m Epoch 1: train loss 0.00010093592572957277, accuracy 0.6296296296296297\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m Epoch 1: train loss 9.104044875130057e-05, accuracy 0.6851851851851852\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m [Client 76] fit, config: {'current_round': 60, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m Epoch 1: train loss 8.048755989875644e-05, accuracy 0.6481481481481481\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m Epoch 1: train loss 9.705061529530212e-05, accuracy 0.6111111111111112\n",
      "Saving round 60 aggregated_parameters...\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98090)\u001b[0m [Client 22] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98094)\u001b[0m [Client 47] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98094)\u001b[0m [Client 93] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98090)\u001b[0m [Client 79] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98094)\u001b[0m [Client 56] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98090)\u001b[0m [Client 43] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98090)\u001b[0m [Client 73] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98094)\u001b[0m [Client 44] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98090)\u001b[0m [Client 23] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98095)\u001b[0m [Client 8] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98091)\u001b[0m [Client 63] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98088)\u001b[0m [Client 39] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98095)\u001b[0m [Client 65] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98094)\u001b[0m [Client 66] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98092)\u001b[0m [Client 55] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98088)\u001b[0m [Client 76] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98088)\u001b[0m [Client 70] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98092)\u001b[0m [Client 41] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98091)\u001b[0m [Client 16] evaluate, config: {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 12:58:37,976 | server.py:170 | evaluate_round received 0 results and 30 failures\n",
      "DEBUG flower 2023-02-01 12:58:37,977 | server.py:203 | fit_round: strategy sampled 30 clients (out of 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98088)\u001b[0m [Client 5] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98095)\u001b[0m [Client 54] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98092)\u001b[0m [Client 19] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98090)\u001b[0m [Client 96] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98095)\u001b[0m [Client 77] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98093)\u001b[0m [Client 48] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98089)\u001b[0m [Client 40] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98094)\u001b[0m [Client 14] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98092)\u001b[0m [Client 29] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98091)\u001b[0m [Client 34] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98088)\u001b[0m [Client 97] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m [Client 7] fit, config: {'current_round': 61, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m Epoch 1: train loss 0.00010944822133751586, accuracy 0.6111111111111112\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m [Client 27] fit, config: {'current_round': 61, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m Epoch 1: train loss 0.00010530884173931554, accuracy 0.5555555555555556\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m [Client 84] fit, config: {'current_round': 61, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m [Client 76] fit, config: {'current_round': 61, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m [Client 62] fit, config: {'current_round': 61, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m Epoch 1: train loss 8.70039511937648e-05, accuracy 0.6111111111111112\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m [Client 34] fit, config: {'current_round': 61, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m Epoch 1: train loss 0.00010283179290127009, accuracy 0.5370370370370371\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m [Client 54] fit, config: {'current_round': 61, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m Epoch 1: train loss 8.369697025045753e-05, accuracy 0.6666666666666666\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m Epoch 1: train loss 7.636933150934055e-05, accuracy 0.6851851851851852\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m Epoch 1: train loss 9.2466470960062e-05, accuracy 0.6296296296296297\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m [Client 97] fit, config: {'current_round': 61, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m [Client 61] fit, config: {'current_round': 61, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m [Client 81] fit, config: {'current_round': 61, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m Epoch 1: train loss 0.0001388984965160489, accuracy 0.46296296296296297\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m Epoch 1: train loss 0.00011296874436084181, accuracy 0.6666666666666666\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m [Client 11] fit, config: {'current_round': 61, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m Epoch 1: train loss 0.00010634535283315927, accuracy 0.5925925925925926\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m [Client 19] fit, config: {'current_round': 61, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m [Client 53] fit, config: {'current_round': 61, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m Epoch 1: train loss 9.64408609434031e-05, accuracy 0.5555555555555556\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m [Client 99] fit, config: {'current_round': 61, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m Epoch 1: train loss 9.591882553650066e-05, accuracy 0.6296296296296297\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m [Client 17] fit, config: {'current_round': 61, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m [Client 68] fit, config: {'current_round': 61, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m [Client 42] fit, config: {'current_round': 61, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m Epoch 1: train loss 0.00010739339631982148, accuracy 0.6111111111111112\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m Epoch 1: train loss 9.687030251370743e-05, accuracy 0.6481481481481481\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m Epoch 1: train loss 9.022191079566255e-05, accuracy 0.5925925925925926\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m [Client 1] fit, config: {'current_round': 61, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m Epoch 1: train loss 0.00010347037459723651, accuracy 0.5925925925925926\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m Epoch 1: train loss 8.988283661892638e-05, accuracy 0.6666666666666666\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m Epoch 1: train loss 8.427973079960793e-05, accuracy 0.6481481481481481\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m [Client 83] fit, config: {'current_round': 61, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m Epoch 1: train loss 0.00010616429062793031, accuracy 0.5\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m [Client 13] fit, config: {'current_round': 61, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m [Client 50] fit, config: {'current_round': 61, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m Epoch 1: train loss 0.00010866718366742134, accuracy 0.5740740740740741\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m [Client 3] fit, config: {'current_round': 61, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m Epoch 1: train loss 0.0001205221051350236, accuracy 0.5740740740740741\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m [Client 57] fit, config: {'current_round': 61, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m Epoch 1: train loss 0.00010707604815252125, accuracy 0.5555555555555556\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m [Client 58] fit, config: {'current_round': 61, 'local_epochs': 3}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 12:58:40,364 | server.py:216 | fit_round received 30 results and 0 failures\n",
      "DEBUG flower 2023-02-01 12:58:40,421 | server.py:157 | evaluate_round: strategy sampled 30 clients (out of 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m [Client 75] fit, config: {'current_round': 61, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m [Client 48] fit, config: {'current_round': 61, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m Epoch 1: train loss 0.00010703309817472473, accuracy 0.5740740740740741\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m [Client 18] fit, config: {'current_round': 61, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m Epoch 1: train loss 9.915116243064404e-05, accuracy 0.5555555555555556\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m [Client 35] fit, config: {'current_round': 61, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m [Client 12] fit, config: {'current_round': 61, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m Epoch 1: train loss 0.00010510192805668339, accuracy 0.6111111111111112\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m Epoch 1: train loss 9.195965685648844e-05, accuracy 0.6481481481481481\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m Epoch 1: train loss 0.00010641434346325696, accuracy 0.6481481481481481\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m Epoch 1: train loss 9.358103125123307e-05, accuracy 0.6666666666666666\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m [Client 16] fit, config: {'current_round': 61, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m Epoch 1: train loss 0.00010506084799999371, accuracy 0.48148148148148145\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m Epoch 1: train loss 0.00011025036656064913, accuracy 0.5185185185185185\n",
      "Saving round 61 aggregated_parameters...\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98089)\u001b[0m [Client 67] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98089)\u001b[0m [Client 27] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98089)\u001b[0m [Client 28] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98089)\u001b[0m [Client 78] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98091)\u001b[0m [Client 87] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98090)\u001b[0m [Client 19] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98088)\u001b[0m [Client 77] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98089)\u001b[0m [Client 16] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98091)\u001b[0m [Client 66] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98091)\u001b[0m [Client 0] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98090)\u001b[0m [Client 46] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98091)\u001b[0m [Client 8] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98091)\u001b[0m [Client 75] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98090)\u001b[0m [Client 44] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98088)\u001b[0m [Client 63] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98091)\u001b[0m [Client 40] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98091)\u001b[0m [Client 92] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98088)\u001b[0m [Client 65] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98088)\u001b[0m [Client 73] evaluate, config: {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 12:58:42,622 | server.py:170 | evaluate_round received 0 results and 30 failures\n",
      "DEBUG flower 2023-02-01 12:58:42,623 | server.py:203 | fit_round: strategy sampled 30 clients (out of 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98091)\u001b[0m [Client 82] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98095)\u001b[0m [Client 74] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98094)\u001b[0m [Client 12] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98092)\u001b[0m [Client 68] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98091)\u001b[0m [Client 32] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98090)\u001b[0m [Client 13] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98088)\u001b[0m [Client 91] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98095)\u001b[0m [Client 71] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98093)\u001b[0m [Client 10] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98089)\u001b[0m [Client 94] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98094)\u001b[0m [Client 41] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m [Client 66] fit, config: {'current_round': 62, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m Epoch 1: train loss 9.244298416888341e-05, accuracy 0.6481481481481481\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m [Client 35] fit, config: {'current_round': 62, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m Epoch 1: train loss 0.00010711554205045104, accuracy 0.5925925925925926\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m [Client 4] fit, config: {'current_round': 62, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m Epoch 1: train loss 0.00012509230873547494, accuracy 0.46296296296296297\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m [Client 51] fit, config: {'current_round': 62, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m Epoch 1: train loss 9.595556912245229e-05, accuracy 0.7037037037037037\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m [Client 90] fit, config: {'current_round': 62, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m [Client 39] fit, config: {'current_round': 62, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m Epoch 1: train loss 0.00010085561370942742, accuracy 0.6296296296296297\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m Epoch 1: train loss 0.00010078810737468302, accuracy 0.6111111111111112\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m [Client 79] fit, config: {'current_round': 62, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m [Client 63] fit, config: {'current_round': 62, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m Epoch 1: train loss 0.0001154038545791991, accuracy 0.5\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m [Client 83] fit, config: {'current_round': 62, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m Epoch 1: train loss 9.308326843893155e-05, accuracy 0.7037037037037037\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m Epoch 1: train loss 0.00010813214612426236, accuracy 0.6111111111111112\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m [Client 91] fit, config: {'current_round': 62, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m Epoch 1: train loss 9.509154915576801e-05, accuracy 0.7037037037037037\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m [Client 87] fit, config: {'current_round': 62, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m [Client 7] fit, config: {'current_round': 62, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m Epoch 1: train loss 9.884557221084833e-05, accuracy 0.7037037037037037\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m Epoch 1: train loss 9.259676153305918e-05, accuracy 0.6666666666666666\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m [Client 75] fit, config: {'current_round': 62, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m Epoch 1: train loss 0.00011349659325787798, accuracy 0.6111111111111112\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m [Client 46] fit, config: {'current_round': 62, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m Epoch 1: train loss 8.765782695263624e-05, accuracy 0.6666666666666666\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m [Client 27] fit, config: {'current_round': 62, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m Epoch 1: train loss 0.00010081162326969206, accuracy 0.6296296296296297\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 12:58:44,901 | server.py:216 | fit_round received 30 results and 0 failures\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m [Client 85] fit, config: {'current_round': 62, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m [Client 78] fit, config: {'current_round': 62, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m Epoch 1: train loss 0.00010803221812238917, accuracy 0.5925925925925926\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m [Client 10] fit, config: {'current_round': 62, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m [Client 24] fit, config: {'current_round': 62, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m Epoch 1: train loss 9.974387648981065e-05, accuracy 0.6481481481481481\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m [Client 96] fit, config: {'current_round': 62, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m Epoch 1: train loss 8.608589268987998e-05, accuracy 0.6481481481481481\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m Epoch 1: train loss 0.00012378541578073055, accuracy 0.46296296296296297\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m [Client 93] fit, config: {'current_round': 62, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m Epoch 1: train loss 0.00010419256432214752, accuracy 0.6111111111111112\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m Epoch 1: train loss 9.827681788010523e-05, accuracy 0.6481481481481481\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m [Client 40] fit, config: {'current_round': 62, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m Epoch 1: train loss 8.563141454942524e-05, accuracy 0.6666666666666666\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m [Client 84] fit, config: {'current_round': 62, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m Epoch 1: train loss 9.854919335339218e-05, accuracy 0.6296296296296297\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m [Client 30] fit, config: {'current_round': 62, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m [Client 71] fit, config: {'current_round': 62, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m [Client 9] fit, config: {'current_round': 62, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m Epoch 1: train loss 0.00010122360981767997, accuracy 0.7407407407407407\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m Epoch 1: train loss 0.00010738855780800804, accuracy 0.5370370370370371\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m [Client 62] fit, config: {'current_round': 62, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m Epoch 1: train loss 9.246419358532876e-05, accuracy 0.6666666666666666\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m Epoch 1: train loss 9.329633030574769e-05, accuracy 0.6296296296296297\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m [Client 12] fit, config: {'current_round': 62, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m Epoch 1: train loss 0.0001031855572364293, accuracy 0.6296296296296297\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m [Client 72] fit, config: {'current_round': 62, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m Epoch 1: train loss 9.287074499297887e-05, accuracy 0.6851851851851852\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m [Client 15] fit, config: {'current_round': 62, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m Epoch 1: train loss 0.00013519746426027268, accuracy 0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 12:58:44,960 | server.py:157 | evaluate_round: strategy sampled 30 clients (out of 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving round 62 aggregated_parameters...\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98093)\u001b[0m [Client 72] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98093)\u001b[0m [Client 48] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98089)\u001b[0m [Client 35] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98093)\u001b[0m [Client 91] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98089)\u001b[0m [Client 30] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98091)\u001b[0m [Client 8] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98088)\u001b[0m [Client 18] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98093)\u001b[0m [Client 66] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98089)\u001b[0m [Client 9] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98094)\u001b[0m [Client 13] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98088)\u001b[0m [Client 21] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98093)\u001b[0m [Client 46] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98094)\u001b[0m [Client 34] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98094)\u001b[0m [Client 54] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98088)\u001b[0m [Client 42] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98094)\u001b[0m [Client 65] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98088)\u001b[0m [Client 64] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98093)\u001b[0m [Client 26] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98089)\u001b[0m [Client 78] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98094)\u001b[0m [Client 44] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98089)\u001b[0m [Client 29] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98094)\u001b[0m [Client 83] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98091)\u001b[0m [Client 11] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98088)\u001b[0m [Client 19] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98095)\u001b[0m [Client 5] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98093)\u001b[0m [Client 69] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98089)\u001b[0m [Client 25] evaluate, config: {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 12:58:47,200 | server.py:170 | evaluate_round received 0 results and 30 failures\n",
      "DEBUG flower 2023-02-01 12:58:47,206 | server.py:203 | fit_round: strategy sampled 30 clients (out of 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98090)\u001b[0m [Client 17] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98094)\u001b[0m [Client 95] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98092)\u001b[0m [Client 33] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m [Client 52] fit, config: {'current_round': 63, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m Epoch 1: train loss 8.912174962460995e-05, accuracy 0.6481481481481481\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m [Client 23] fit, config: {'current_round': 63, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m Epoch 1: train loss 9.625056554796174e-05, accuracy 0.6296296296296297\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m [Client 17] fit, config: {'current_round': 63, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m Epoch 1: train loss 8.524859003955498e-05, accuracy 0.7222222222222222\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m [Client 51] fit, config: {'current_round': 63, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m Epoch 1: train loss 9.781333210412413e-05, accuracy 0.6111111111111112\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m [Client 11] fit, config: {'current_round': 63, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m Epoch 1: train loss 9.734981722431257e-05, accuracy 0.6666666666666666\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m [Client 59] fit, config: {'current_round': 63, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m [Client 25] fit, config: {'current_round': 63, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m Epoch 1: train loss 8.987033652374521e-05, accuracy 0.6111111111111112\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m [Client 74] fit, config: {'current_round': 63, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m Epoch 1: train loss 0.00011084094876423478, accuracy 0.5555555555555556\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m Epoch 1: train loss 9.792861965252087e-05, accuracy 0.7222222222222222\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m [Client 75] fit, config: {'current_round': 63, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m Epoch 1: train loss 0.00010265374294249341, accuracy 0.6481481481481481\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m [Client 67] fit, config: {'current_round': 63, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m Epoch 1: train loss 0.00012000823335256428, accuracy 0.6111111111111112\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m [Client 81] fit, config: {'current_round': 63, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m [Client 6] fit, config: {'current_round': 63, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m Epoch 1: train loss 0.00010590421152301133, accuracy 0.5740740740740741\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m Epoch 1: train loss 9.368130122311413e-05, accuracy 0.6851851851851852\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m [Client 63] fit, config: {'current_round': 63, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m [Client 65] fit, config: {'current_round': 63, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m Epoch 1: train loss 9.344347927253693e-05, accuracy 0.5925925925925926\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m [Client 64] fit, config: {'current_round': 63, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m Epoch 1: train loss 9.036129631567746e-05, accuracy 0.6111111111111112\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m [Client 38] fit, config: {'current_round': 63, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m Epoch 1: train loss 9.388435864821076e-05, accuracy 0.7222222222222222\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m [Client 56] fit, config: {'current_round': 63, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m Epoch 1: train loss 9.49469322222285e-05, accuracy 0.6666666666666666\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m [Client 93] fit, config: {'current_round': 63, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m [Client 62] fit, config: {'current_round': 63, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m Epoch 1: train loss 0.00011193819955224171, accuracy 0.5\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m [Client 92] fit, config: {'current_round': 63, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m Epoch 1: train loss 9.594939911039546e-05, accuracy 0.6851851851851852\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m Epoch 1: train loss 8.298701868625358e-05, accuracy 0.7407407407407407\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m [Client 82] fit, config: {'current_round': 63, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m Epoch 1: train loss 8.396604971494526e-05, accuracy 0.6666666666666666\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m [Client 45] fit, config: {'current_round': 63, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m Epoch 1: train loss 8.885514398571104e-05, accuracy 0.6481481481481481\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m Epoch 1: train loss 8.630543015897274e-05, accuracy 0.6111111111111112\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m [Client 20] fit, config: {'current_round': 63, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m Epoch 1: train loss 0.00011352349247317761, accuracy 0.6481481481481481\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m [Client 15] fit, config: {'current_round': 63, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m Epoch 1: train loss 0.00012359852553345263, accuracy 0.5555555555555556\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m [Client 61] fit, config: {'current_round': 63, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m [Client 4] fit, config: {'current_round': 63, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m [Client 7] fit, config: {'current_round': 63, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m Epoch 1: train loss 0.00010844477219507098, accuracy 0.5925925925925926\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m [Client 49] fit, config: {'current_round': 63, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m Epoch 1: train loss 0.00010885494702961296, accuracy 0.5370370370370371\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m [Client 70] fit, config: {'current_round': 63, 'local_epochs': 3}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 12:58:49,789 | server.py:216 | fit_round received 30 results and 0 failures\n",
      "DEBUG flower 2023-02-01 12:58:49,842 | server.py:157 | evaluate_round: strategy sampled 30 clients (out of 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving round 63 aggregated_parameters...\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m Epoch 1: train loss 0.00011007140710717067, accuracy 0.7037037037037037\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m Epoch 1: train loss 0.00010623811249388382, accuracy 0.6111111111111112\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m [Client 13] fit, config: {'current_round': 63, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m Epoch 1: train loss 0.0001080161237041466, accuracy 0.5740740740740741\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m Epoch 1: train loss 0.00012341875117272139, accuracy 0.6296296296296297\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98090)\u001b[0m [Client 73] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98088)\u001b[0m [Client 9] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98089)\u001b[0m [Client 53] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98092)\u001b[0m [Client 95] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98092)\u001b[0m [Client 13] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98090)\u001b[0m [Client 76] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98092)\u001b[0m [Client 52] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98088)\u001b[0m [Client 37] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98089)\u001b[0m [Client 35] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98092)\u001b[0m [Client 75] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98088)\u001b[0m [Client 11] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98088)\u001b[0m [Client 16] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98090)\u001b[0m [Client 25] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98089)\u001b[0m [Client 7] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98092)\u001b[0m [Client 79] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98088)\u001b[0m [Client 24] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98088)\u001b[0m [Client 17] evaluate, config: {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 12:58:52,384 | server.py:170 | evaluate_round received 0 results and 30 failures\n",
      "DEBUG flower 2023-02-01 12:58:52,385 | server.py:203 | fit_round: strategy sampled 30 clients (out of 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98092)\u001b[0m [Client 39] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98090)\u001b[0m [Client 57] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98091)\u001b[0m [Client 59] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98090)\u001b[0m [Client 21] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98088)\u001b[0m [Client 68] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98095)\u001b[0m [Client 0] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98089)\u001b[0m [Client 2] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98090)\u001b[0m [Client 58] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98093)\u001b[0m [Client 19] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98093)\u001b[0m [Client 65] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98089)\u001b[0m [Client 45] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98094)\u001b[0m [Client 41] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98092)\u001b[0m [Client 80] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m [Client 76] fit, config: {'current_round': 64, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m Epoch 1: train loss 7.509798160754144e-05, accuracy 0.6851851851851852\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m [Client 21] fit, config: {'current_round': 64, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m Epoch 1: train loss 0.000111361026938539, accuracy 0.5370370370370371\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m [Client 30] fit, config: {'current_round': 64, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m Epoch 1: train loss 0.00010065038077300414, accuracy 0.5185185185185185\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m [Client 41] fit, config: {'current_round': 64, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m [Client 54] fit, config: {'current_round': 64, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m Epoch 1: train loss 0.00010295666288584471, accuracy 0.5185185185185185\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m Epoch 1: train loss 7.910680142231286e-05, accuracy 0.7777777777777778\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m [Client 89] fit, config: {'current_round': 64, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m Epoch 1: train loss 9.838539699558169e-05, accuracy 0.6111111111111112\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m [Client 60] fit, config: {'current_round': 64, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m [Client 96] fit, config: {'current_round': 64, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m [Client 82] fit, config: {'current_round': 64, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m Epoch 1: train loss 9.293421317124739e-05, accuracy 0.6296296296296297\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m Epoch 1: train loss 8.856161730363965e-05, accuracy 0.7037037037037037\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m Epoch 1: train loss 8.018852531677112e-05, accuracy 0.6666666666666666\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m [Client 22] fit, config: {'current_round': 64, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m Epoch 1: train loss 0.00012362838606350124, accuracy 0.4074074074074074\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m [Client 11] fit, config: {'current_round': 64, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m Epoch 1: train loss 9.561199840391055e-05, accuracy 0.6851851851851852\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m [Client 90] fit, config: {'current_round': 64, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m Epoch 1: train loss 9.423452138435096e-05, accuracy 0.5925925925925926\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m [Client 59] fit, config: {'current_round': 64, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m Epoch 1: train loss 9.164015500573441e-05, accuracy 0.7037037037037037\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m [Client 86] fit, config: {'current_round': 64, 'local_epochs': 3}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 12:58:54,643 | server.py:216 | fit_round received 30 results and 0 failures\n",
      "DEBUG flower 2023-02-01 12:58:54,698 | server.py:157 | evaluate_round: strategy sampled 30 clients (out of 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m [Client 91] fit, config: {'current_round': 64, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m Epoch 1: train loss 9.405442688148469e-05, accuracy 0.5925925925925926\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m [Client 49] fit, config: {'current_round': 64, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m Epoch 1: train loss 0.00010711608047131449, accuracy 0.5\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m [Client 39] fit, config: {'current_round': 64, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m Epoch 1: train loss 9.528839291306213e-05, accuracy 0.5740740740740741\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m [Client 40] fit, config: {'current_round': 64, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m [Client 84] fit, config: {'current_round': 64, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m [Client 43] fit, config: {'current_round': 64, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m Epoch 1: train loss 9.647894330555573e-05, accuracy 0.6481481481481481\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m Epoch 1: train loss 8.848403376759961e-05, accuracy 0.6851851851851852\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m [Client 65] fit, config: {'current_round': 64, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m Epoch 1: train loss 0.00010345742339268327, accuracy 0.5370370370370371\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m [Client 44] fit, config: {'current_round': 64, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m Epoch 1: train loss 8.488009916618466e-05, accuracy 0.6296296296296297\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m Epoch 1: train loss 8.841345697874203e-05, accuracy 0.6666666666666666\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m [Client 4] fit, config: {'current_round': 64, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m Epoch 1: train loss 0.00011581580474739894, accuracy 0.5\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m Epoch 1: train loss 0.00010672465577954426, accuracy 0.5925925925925926\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m [Client 55] fit, config: {'current_round': 64, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m Epoch 1: train loss 9.30671812966466e-05, accuracy 0.6481481481481481\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m [Client 78] fit, config: {'current_round': 64, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m Epoch 1: train loss 9.864685853244737e-05, accuracy 0.6111111111111112\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m [Client 9] fit, config: {'current_round': 64, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m Epoch 1: train loss 0.00010520933574298397, accuracy 0.6666666666666666\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m [Client 56] fit, config: {'current_round': 64, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m Epoch 1: train loss 0.0001056574474205263, accuracy 0.5555555555555556\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m [Client 63] fit, config: {'current_round': 64, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m Epoch 1: train loss 0.00010477999603608623, accuracy 0.5370370370370371\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m [Client 3] fit, config: {'current_round': 64, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m Epoch 1: train loss 0.00010522608499741182, accuracy 0.5370370370370371\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m [Client 38] fit, config: {'current_round': 64, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m Epoch 1: train loss 9.951022366294637e-05, accuracy 0.5740740740740741\n",
      "Saving round 64 aggregated_parameters...\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98091)\u001b[0m [Client 14] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98095)\u001b[0m [Client 87] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98094)\u001b[0m [Client 76] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98091)\u001b[0m [Client 53] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98091)\u001b[0m [Client 16] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98094)\u001b[0m [Client 32] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98091)\u001b[0m [Client 29] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98095)\u001b[0m [Client 60] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98095)\u001b[0m [Client 74] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98095)\u001b[0m [Client 17] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98091)\u001b[0m [Client 31] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98091)\u001b[0m [Client 79] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98091)\u001b[0m [Client 27] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98091)\u001b[0m [Client 69] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98090)\u001b[0m [Client 20] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98094)\u001b[0m [Client 5] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98091)\u001b[0m [Client 12] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98095)\u001b[0m [Client 13] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98089)\u001b[0m [Client 54] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98092)\u001b[0m [Client 47] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98091)\u001b[0m [Client 94] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98095)\u001b[0m [Client 1] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98092)\u001b[0m [Client 45] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98091)\u001b[0m [Client 64] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98091)\u001b[0m [Client 25] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98090)\u001b[0m [Client 95] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98095)\u001b[0m [Client 88] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98089)\u001b[0m [Client 23] evaluate, config: {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 12:58:57,127 | server.py:170 | evaluate_round received 0 results and 30 failures\n",
      "DEBUG flower 2023-02-01 12:58:57,128 | server.py:203 | fit_round: strategy sampled 30 clients (out of 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98092)\u001b[0m [Client 56] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98094)\u001b[0m [Client 62] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m [Client 35] fit, config: {'current_round': 65, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m Epoch 1: train loss 8.526867895852774e-05, accuracy 0.7037037037037037\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m [Client 9] fit, config: {'current_round': 65, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m [Client 2] fit, config: {'current_round': 65, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m Epoch 1: train loss 7.88509933045134e-05, accuracy 0.7037037037037037\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m Epoch 1: train loss 0.00010739096614997834, accuracy 0.5740740740740741\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m [Client 57] fit, config: {'current_round': 65, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m [Client 50] fit, config: {'current_round': 65, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m Epoch 1: train loss 0.00011599426215980202, accuracy 0.5925925925925926\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m [Client 76] fit, config: {'current_round': 65, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m Epoch 1: train loss 7.549705333076417e-05, accuracy 0.7592592592592593\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m [Client 95] fit, config: {'current_round': 65, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m Epoch 1: train loss 0.00010994750482495874, accuracy 0.5370370370370371\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m [Client 1] fit, config: {'current_round': 65, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m [Client 16] fit, config: {'current_round': 65, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m Epoch 1: train loss 0.00010183802805840969, accuracy 0.48148148148148145\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m [Client 5] fit, config: {'current_round': 65, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m Epoch 1: train loss 9.43048726185225e-05, accuracy 0.5740740740740741\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m Epoch 1: train loss 7.398152229143307e-05, accuracy 0.7222222222222222\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m [Client 70] fit, config: {'current_round': 65, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m Epoch 1: train loss 0.00012588142999447882, accuracy 0.6111111111111112\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m Epoch 1: train loss 0.00010132959869224578, accuracy 0.6481481481481481\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m [Client 56] fit, config: {'current_round': 65, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m [Client 31] fit, config: {'current_round': 65, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m [Client 93] fit, config: {'current_round': 65, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m Epoch 1: train loss 0.00010901894711423665, accuracy 0.5555555555555556\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m Epoch 1: train loss 0.0001037265537888743, accuracy 0.5925925925925926\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m [Client 77] fit, config: {'current_round': 65, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m Epoch 1: train loss 8.684027125127614e-05, accuracy 0.6666666666666666\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m Epoch 1: train loss 8.278519817395136e-05, accuracy 0.6851851851851852\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m [Client 21] fit, config: {'current_round': 65, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m Epoch 1: train loss 0.0001274769747396931, accuracy 0.46296296296296297\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m [Client 68] fit, config: {'current_round': 65, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m Epoch 1: train loss 8.822784730000421e-05, accuracy 0.6851851851851852\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m [Client 27] fit, config: {'current_round': 65, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m Epoch 1: train loss 0.00010728181950980797, accuracy 0.5925925925925926\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m [Client 65] fit, config: {'current_round': 65, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m [Client 37] fit, config: {'current_round': 65, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m Epoch 1: train loss 8.522748248651624e-05, accuracy 0.6851851851851852\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m [Client 23] fit, config: {'current_round': 65, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m Epoch 1: train loss 0.00010068355913972482, accuracy 0.6481481481481481\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m Epoch 1: train loss 9.371837950311601e-05, accuracy 0.6481481481481481\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m [Client 88] fit, config: {'current_round': 65, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m Epoch 1: train loss 9.923703328240663e-05, accuracy 0.5925925925925926\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m [Client 89] fit, config: {'current_round': 65, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m [Client 10] fit, config: {'current_round': 65, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m Epoch 1: train loss 0.00011102102143922821, accuracy 0.6111111111111112\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m [Client 52] fit, config: {'current_round': 65, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m Epoch 1: train loss 8.770181011641398e-05, accuracy 0.6666666666666666\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m [Client 79] fit, config: {'current_round': 65, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m [Client 33] fit, config: {'current_round': 65, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m Epoch 1: train loss 0.00010190907778451219, accuracy 0.5925925925925926\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m Epoch 1: train loss 9.31758841034025e-05, accuracy 0.5925925925925926\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m [Client 36] fit, config: {'current_round': 65, 'local_epochs': 3}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 12:58:59,446 | server.py:216 | fit_round received 30 results and 0 failures\n",
      "DEBUG flower 2023-02-01 12:58:59,508 | server.py:157 | evaluate_round: strategy sampled 30 clients (out of 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m [Client 54] fit, config: {'current_round': 65, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m Epoch 1: train loss 9.221037907991558e-05, accuracy 0.7037037037037037\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m [Client 42] fit, config: {'current_round': 65, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m Epoch 1: train loss 0.00010498015763005242, accuracy 0.6481481481481481\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m Epoch 1: train loss 8.989615162136033e-05, accuracy 0.6296296296296297\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m Epoch 1: train loss 0.00012911461817566305, accuracy 0.5\n",
      "Saving round 65 aggregated_parameters...\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98090)\u001b[0m [Client 1] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98090)\u001b[0m [Client 93] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98090)\u001b[0m [Client 92] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98090)\u001b[0m [Client 49] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98095)\u001b[0m [Client 79] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98093)\u001b[0m [Client 98] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98093)\u001b[0m [Client 16] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98095)\u001b[0m [Client 29] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98092)\u001b[0m [Client 73] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98090)\u001b[0m [Client 94] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98090)\u001b[0m [Client 86] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98090)\u001b[0m [Client 67] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98090)\u001b[0m [Client 59] evaluate, config: {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 12:59:02,018 | server.py:170 | evaluate_round received 0 results and 30 failures\n",
      "DEBUG flower 2023-02-01 12:59:02,019 | server.py:203 | fit_round: strategy sampled 30 clients (out of 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98090)\u001b[0m [Client 64] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98088)\u001b[0m [Client 44] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98091)\u001b[0m [Client 99] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98091)\u001b[0m [Client 56] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98095)\u001b[0m [Client 55] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98093)\u001b[0m [Client 69] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98093)\u001b[0m [Client 91] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98089)\u001b[0m [Client 35] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98094)\u001b[0m [Client 37] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98090)\u001b[0m [Client 63] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98088)\u001b[0m [Client 5] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98092)\u001b[0m [Client 65] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98091)\u001b[0m [Client 60] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98090)\u001b[0m [Client 6] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98088)\u001b[0m [Client 10] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98093)\u001b[0m [Client 97] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98092)\u001b[0m [Client 96] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m [Client 99] fit, config: {'current_round': 66, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m Epoch 1: train loss 8.656115824123845e-05, accuracy 0.7222222222222222\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m [Client 63] fit, config: {'current_round': 66, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m [Client 55] fit, config: {'current_round': 66, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m Epoch 1: train loss 9.192943980451673e-05, accuracy 0.6111111111111112\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m [Client 59] fit, config: {'current_round': 66, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m Epoch 1: train loss 0.00010256379755446687, accuracy 0.48148148148148145\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m [Client 95] fit, config: {'current_round': 66, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m Epoch 1: train loss 7.24711935617961e-05, accuracy 0.6851851851851852\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m Epoch 1: train loss 9.334949572803453e-05, accuracy 0.7037037037037037\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m [Client 61] fit, config: {'current_round': 66, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m Epoch 1: train loss 8.550059283152223e-05, accuracy 0.6851851851851852\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m [Client 26] fit, config: {'current_round': 66, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m Epoch 1: train loss 0.00010781819582916796, accuracy 0.6481481481481481\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m [Client 96] fit, config: {'current_round': 66, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m Epoch 1: train loss 7.831626862753183e-05, accuracy 0.6481481481481481\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m [Client 18] fit, config: {'current_round': 66, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m Epoch 1: train loss 0.00011684829951263964, accuracy 0.5555555555555556\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m [Client 52] fit, config: {'current_round': 66, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m [Client 39] fit, config: {'current_round': 66, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m Epoch 1: train loss 9.541492181597278e-05, accuracy 0.5555555555555556\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m [Client 83] fit, config: {'current_round': 66, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m Epoch 1: train loss 9.211890574079007e-05, accuracy 0.6666666666666666\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m Epoch 1: train loss 0.00011009244917659089, accuracy 0.5370370370370371\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m [Client 24] fit, config: {'current_round': 66, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m Epoch 1: train loss 9.348322782898322e-05, accuracy 0.5740740740740741\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m [Client 67] fit, config: {'current_round': 66, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m Epoch 1: train loss 0.00012299537775106728, accuracy 0.5555555555555556\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m [Client 10] fit, config: {'current_round': 66, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m [Client 27] fit, config: {'current_round': 66, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m Epoch 1: train loss 9.66425723163411e-05, accuracy 0.6111111111111112\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m Epoch 1: train loss 9.471667726757005e-05, accuracy 0.6666666666666666\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m [Client 68] fit, config: {'current_round': 66, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m Epoch 1: train loss 8.45455433591269e-05, accuracy 0.6851851851851852\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m [Client 0] fit, config: {'current_round': 66, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m [Client 47] fit, config: {'current_round': 66, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m Epoch 1: train loss 9.561326442053542e-05, accuracy 0.7222222222222222\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m Epoch 1: train loss 0.00011741347407223657, accuracy 0.5555555555555556\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m [Client 70] fit, config: {'current_round': 66, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m Epoch 1: train loss 0.00011309958790661767, accuracy 0.6296296296296297\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m [Client 45] fit, config: {'current_round': 66, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m [Client 56] fit, config: {'current_round': 66, 'local_epochs': 3}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 12:59:04,844 | server.py:216 | fit_round received 30 results and 0 failures\n",
      "DEBUG flower 2023-02-01 12:59:04,906 | server.py:157 | evaluate_round: strategy sampled 30 clients (out of 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m Epoch 1: train loss 0.00010589297744445503, accuracy 0.5370370370370371\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m [Client 34] fit, config: {'current_round': 66, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m Epoch 1: train loss 9.1556939878501e-05, accuracy 0.6296296296296297\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m [Client 62] fit, config: {'current_round': 66, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m [Client 73] fit, config: {'current_round': 66, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m Epoch 1: train loss 0.0001004427540465258, accuracy 0.5370370370370371\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m Epoch 1: train loss 0.00010705061140470207, accuracy 0.5370370370370371\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m [Client 72] fit, config: {'current_round': 66, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m Epoch 1: train loss 8.985440217657015e-05, accuracy 0.6666666666666666\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m Epoch 1: train loss 8.758618059800938e-05, accuracy 0.6481481481481481\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m [Client 30] fit, config: {'current_round': 66, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m [Client 79] fit, config: {'current_round': 66, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m Epoch 1: train loss 0.0001011134881991893, accuracy 0.5555555555555556\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m [Client 22] fit, config: {'current_round': 66, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m Epoch 1: train loss 0.00012396267266012728, accuracy 0.3888888888888889\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m [Client 13] fit, config: {'current_round': 66, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m Epoch 1: train loss 0.0001045718090608716, accuracy 0.5925925925925926\n",
      "Saving round 66 aggregated_parameters...\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m Epoch 1: train loss 9.7963675216306e-05, accuracy 0.5185185185185185\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98093)\u001b[0m [Client 70] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98092)\u001b[0m [Client 73] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98092)\u001b[0m [Client 79] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98092)\u001b[0m [Client 67] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98092)\u001b[0m [Client 60] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98092)\u001b[0m [Client 22] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98092)\u001b[0m [Client 30] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98092)\u001b[0m [Client 18] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98091)\u001b[0m [Client 89] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98093)\u001b[0m [Client 91] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98089)\u001b[0m [Client 36] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98092)\u001b[0m [Client 47] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98091)\u001b[0m [Client 82] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98091)\u001b[0m [Client 55] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98091)\u001b[0m [Client 51] evaluate, config: {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 12:59:07,085 | server.py:170 | evaluate_round received 0 results and 30 failures\n",
      "DEBUG flower 2023-02-01 12:59:07,087 | server.py:203 | fit_round: strategy sampled 30 clients (out of 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98091)\u001b[0m [Client 10] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98093)\u001b[0m [Client 45] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98089)\u001b[0m [Client 94] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98092)\u001b[0m [Client 53] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98093)\u001b[0m [Client 35] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98092)\u001b[0m [Client 66] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98093)\u001b[0m [Client 32] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98092)\u001b[0m [Client 76] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98091)\u001b[0m [Client 58] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98090)\u001b[0m [Client 93] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98088)\u001b[0m [Client 9] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98095)\u001b[0m [Client 48] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98089)\u001b[0m [Client 90] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98092)\u001b[0m [Client 29] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98094)\u001b[0m [Client 87] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m [Client 68] fit, config: {'current_round': 67, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m [Client 86] fit, config: {'current_round': 67, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m Epoch 1: train loss 8.149568748194724e-05, accuracy 0.7037037037037037\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m Epoch 1: train loss 8.82055755937472e-05, accuracy 0.6296296296296297\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m [Client 25] fit, config: {'current_round': 67, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m Epoch 1: train loss 8.972965588327497e-05, accuracy 0.6666666666666666\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m [Client 14] fit, config: {'current_round': 67, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m Epoch 1: train loss 9.931711974786595e-05, accuracy 0.6296296296296297\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m [Client 35] fit, config: {'current_round': 67, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m Epoch 1: train loss 8.55292018968612e-05, accuracy 0.7037037037037037\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m [Client 16] fit, config: {'current_round': 67, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m [Client 49] fit, config: {'current_round': 67, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m Epoch 1: train loss 0.00010830136307049543, accuracy 0.5185185185185185\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m [Client 34] fit, config: {'current_round': 67, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m [Client 64] fit, config: {'current_round': 67, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m Epoch 1: train loss 8.938667451729998e-05, accuracy 0.6296296296296297\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m [Client 56] fit, config: {'current_round': 67, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m Epoch 1: train loss 0.00010592554463073611, accuracy 0.5740740740740741\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m Epoch 1: train loss 0.00010134420153917745, accuracy 0.5\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m [Client 45] fit, config: {'current_round': 67, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m Epoch 1: train loss 9.852625953499228e-05, accuracy 0.5370370370370371\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m [Client 80] fit, config: {'current_round': 67, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m [Client 58] fit, config: {'current_round': 67, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m Epoch 1: train loss 0.00011217343853786588, accuracy 0.5185185185185185\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m [Client 42] fit, config: {'current_round': 67, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m Epoch 1: train loss 0.00010739160643424839, accuracy 0.6111111111111112\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m Epoch 1: train loss 8.92707976163365e-05, accuracy 0.6666666666666666\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m [Client 65] fit, config: {'current_round': 67, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m Epoch 1: train loss 9.620495984563604e-05, accuracy 0.6296296296296297\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m [Client 30] fit, config: {'current_round': 67, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m Epoch 1: train loss 0.00011117989924969152, accuracy 0.48148148148148145\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m Epoch 1: train loss 8.58459243318066e-05, accuracy 0.6666666666666666\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m [Client 96] fit, config: {'current_round': 67, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m Epoch 1: train loss 8.312430145451799e-05, accuracy 0.6296296296296297\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m [Client 83] fit, config: {'current_round': 67, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m Epoch 1: train loss 0.00010406268847873434, accuracy 0.5370370370370371\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m [Client 41] fit, config: {'current_round': 67, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m Epoch 1: train loss 0.0001086196061805822, accuracy 0.5370370370370371\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m [Client 13] fit, config: {'current_round': 67, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m [Client 81] fit, config: {'current_round': 67, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m [Client 70] fit, config: {'current_round': 67, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m [Client 84] fit, config: {'current_round': 67, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m Epoch 1: train loss 8.756022725719959e-05, accuracy 0.7222222222222222\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m Epoch 1: train loss 0.00011272571282461286, accuracy 0.5370370370370371\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m Epoch 1: train loss 0.00010756633128039539, accuracy 0.5370370370370371\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m [Client 63] fit, config: {'current_round': 67, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m Epoch 1: train loss 9.58327145781368e-05, accuracy 0.6111111111111112\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m [Client 69] fit, config: {'current_round': 67, 'local_epochs': 3}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 12:59:09,490 | server.py:216 | fit_round received 30 results and 0 failures\n",
      "DEBUG flower 2023-02-01 12:59:09,546 | server.py:157 | evaluate_round: strategy sampled 30 clients (out of 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m [Client 24] fit, config: {'current_round': 67, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m Epoch 1: train loss 8.013655315153301e-05, accuracy 0.6481481481481481\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m [Client 98] fit, config: {'current_round': 67, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m [Client 28] fit, config: {'current_round': 67, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m [Client 91] fit, config: {'current_round': 67, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m Epoch 1: train loss 8.44036549096927e-05, accuracy 0.6666666666666666\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m Epoch 1: train loss 0.00012690671428572387, accuracy 0.6296296296296297\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m [Client 36] fit, config: {'current_round': 67, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m Epoch 1: train loss 0.00012651296856347471, accuracy 0.5185185185185185\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m Epoch 1: train loss 8.513518696418032e-05, accuracy 0.6481481481481481\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m Epoch 1: train loss 0.00011064851423725486, accuracy 0.5740740740740741\n",
      "Saving round 67 aggregated_parameters...\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m Epoch 1: train loss 0.0001064567913999781, accuracy 0.5555555555555556\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98095)\u001b[0m [Client 49] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98088)\u001b[0m [Client 48] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98095)\u001b[0m [Client 28] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98091)\u001b[0m [Client 78] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98088)\u001b[0m [Client 80] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98095)\u001b[0m [Client 34] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98088)\u001b[0m [Client 30] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98088)\u001b[0m [Client 0] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98095)\u001b[0m [Client 47] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98093)\u001b[0m [Client 92] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98091)\u001b[0m [Client 11] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98090)\u001b[0m [Client 59] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98088)\u001b[0m [Client 73] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98095)\u001b[0m [Client 85] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98092)\u001b[0m [Client 64] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98091)\u001b[0m [Client 69] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98090)\u001b[0m [Client 42] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98092)\u001b[0m [Client 86] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98091)\u001b[0m [Client 41] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98090)\u001b[0m [Client 45] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98092)\u001b[0m [Client 81] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98090)\u001b[0m [Client 94] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98090)\u001b[0m [Client 68] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98088)\u001b[0m [Client 61] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98092)\u001b[0m [Client 93] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98091)\u001b[0m [Client 21] evaluate, config: {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 12:59:12,040 | server.py:170 | evaluate_round received 0 results and 30 failures\n",
      "DEBUG flower 2023-02-01 12:59:12,041 | server.py:203 | fit_round: strategy sampled 30 clients (out of 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98095)\u001b[0m [Client 1] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98093)\u001b[0m [Client 99] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98089)\u001b[0m [Client 39] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98094)\u001b[0m [Client 97] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m [Client 1] fit, config: {'current_round': 68, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m Epoch 1: train loss 0.00010015603038482368, accuracy 0.5740740740740741\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m [Client 52] fit, config: {'current_round': 68, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m Epoch 1: train loss 0.00011206749331904575, accuracy 0.5740740740740741\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m [Client 47] fit, config: {'current_round': 68, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m [Client 11] fit, config: {'current_round': 68, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m Epoch 1: train loss 9.631719876779243e-05, accuracy 0.6666666666666666\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m Epoch 1: train loss 9.552841947879642e-05, accuracy 0.6851851851851852\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m [Client 65] fit, config: {'current_round': 68, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m Epoch 1: train loss 9.946132195182145e-05, accuracy 0.5925925925925926\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m [Client 61] fit, config: {'current_round': 68, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m Epoch 1: train loss 8.68457937031053e-05, accuracy 0.7037037037037037\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m [Client 92] fit, config: {'current_round': 68, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m Epoch 1: train loss 0.00010024638322647661, accuracy 0.6666666666666666\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m [Client 74] fit, config: {'current_round': 68, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m Epoch 1: train loss 0.00010494209709577262, accuracy 0.5925925925925926\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m [Client 68] fit, config: {'current_round': 68, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m [Client 66] fit, config: {'current_round': 68, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m Epoch 1: train loss 8.611728844698519e-05, accuracy 0.6111111111111112\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m Epoch 1: train loss 8.30159624456428e-05, accuracy 0.6851851851851852\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m [Client 10] fit, config: {'current_round': 68, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m [Client 51] fit, config: {'current_round': 68, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m Epoch 1: train loss 9.118285379372537e-05, accuracy 0.6481481481481481\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m [Client 48] fit, config: {'current_round': 68, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m Epoch 1: train loss 9.26271895878017e-05, accuracy 0.6851851851851852\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m Epoch 1: train loss 9.516127465758473e-05, accuracy 0.6481481481481481\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m [Client 46] fit, config: {'current_round': 68, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m [Client 26] fit, config: {'current_round': 68, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m [Client 33] fit, config: {'current_round': 68, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m Epoch 1: train loss 8.351871656486765e-05, accuracy 0.6296296296296297\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m [Client 49] fit, config: {'current_round': 68, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m Epoch 1: train loss 0.00010443697101436555, accuracy 0.5\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m Epoch 1: train loss 0.00010826931975316256, accuracy 0.6111111111111112\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m Epoch 1: train loss 9.346942533738911e-05, accuracy 0.6481481481481481\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m [Client 20] fit, config: {'current_round': 68, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m Epoch 1: train loss 0.00010552634194027632, accuracy 0.5185185185185185\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m [Client 72] fit, config: {'current_round': 68, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m [Client 84] fit, config: {'current_round': 68, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m [Client 32] fit, config: {'current_round': 68, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m [Client 31] fit, config: {'current_round': 68, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m Epoch 1: train loss 9.588710963726044e-05, accuracy 0.6296296296296297\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 12:59:14,322 | server.py:216 | fit_round received 30 results and 0 failures\n",
      "DEBUG flower 2023-02-01 12:59:14,375 | server.py:157 | evaluate_round: strategy sampled 30 clients (out of 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m Epoch 1: train loss 9.029285138240084e-05, accuracy 0.6666666666666666\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m [Client 89] fit, config: {'current_round': 68, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m Epoch 1: train loss 8.646635251352564e-05, accuracy 0.6481481481481481\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m [Client 5] fit, config: {'current_round': 68, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m Epoch 1: train loss 8.520950359525159e-05, accuracy 0.6296296296296297\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m Epoch 1: train loss 8.349662675755098e-05, accuracy 0.6666666666666666\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m [Client 96] fit, config: {'current_round': 68, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m Epoch 1: train loss 7.603481208207086e-05, accuracy 0.6666666666666666\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m [Client 7] fit, config: {'current_round': 68, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m Epoch 1: train loss 0.0001021934294840321, accuracy 0.5370370370370371\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m [Client 37] fit, config: {'current_round': 68, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m Epoch 1: train loss 7.245115557452664e-05, accuracy 0.7037037037037037\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m [Client 30] fit, config: {'current_round': 68, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m Epoch 1: train loss 9.378083632327616e-05, accuracy 0.5740740740740741\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m [Client 22] fit, config: {'current_round': 68, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m [Client 82] fit, config: {'current_round': 68, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m Epoch 1: train loss 8.881071698851883e-05, accuracy 0.6481481481481481\n",
      "Saving round 68 aggregated_parameters...\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m Epoch 1: train loss 9.660473733674735e-05, accuracy 0.7037037037037037\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m Epoch 1: train loss 0.0001219107725773938, accuracy 0.3888888888888889\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98091)\u001b[0m [Client 18] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98089)\u001b[0m [Client 12] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98094)\u001b[0m [Client 16] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98094)\u001b[0m [Client 97] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98094)\u001b[0m [Client 93] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98091)\u001b[0m [Client 20] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98094)\u001b[0m [Client 55] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98095)\u001b[0m [Client 78] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98089)\u001b[0m [Client 59] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98095)\u001b[0m [Client 31] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98095)\u001b[0m [Client 14] evaluate, config: {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 12:59:16,736 | server.py:170 | evaluate_round received 0 results and 30 failures\n",
      "DEBUG flower 2023-02-01 12:59:16,737 | server.py:203 | fit_round: strategy sampled 30 clients (out of 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98089)\u001b[0m [Client 9] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98091)\u001b[0m [Client 52] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98090)\u001b[0m [Client 62] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98088)\u001b[0m [Client 23] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98095)\u001b[0m [Client 45] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98089)\u001b[0m [Client 34] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98094)\u001b[0m [Client 54] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98089)\u001b[0m [Client 81] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98094)\u001b[0m [Client 29] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98089)\u001b[0m [Client 92] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98094)\u001b[0m [Client 94] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98094)\u001b[0m [Client 91] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98094)\u001b[0m [Client 86] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98091)\u001b[0m [Client 15] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98090)\u001b[0m [Client 39] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98088)\u001b[0m [Client 67] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98095)\u001b[0m [Client 8] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98093)\u001b[0m [Client 89] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98089)\u001b[0m [Client 44] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m [Client 56] fit, config: {'current_round': 69, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m [Client 6] fit, config: {'current_round': 69, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m Epoch 1: train loss 0.00010661641135811806, accuracy 0.5925925925925926\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m [Client 16] fit, config: {'current_round': 69, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m Epoch 1: train loss 9.381827112520114e-05, accuracy 0.6296296296296297\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m [Client 33] fit, config: {'current_round': 69, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m [Client 9] fit, config: {'current_round': 69, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m [Client 95] fit, config: {'current_round': 69, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m Epoch 1: train loss 0.00010850522812688723, accuracy 0.5370370370370371\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m [Client 74] fit, config: {'current_round': 69, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m Epoch 1: train loss 0.0001052717343554832, accuracy 0.6481481481481481\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m Epoch 1: train loss 9.84064390650019e-05, accuracy 0.5555555555555556\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m Epoch 1: train loss 9.882412268780172e-05, accuracy 0.5925925925925926\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m Epoch 1: train loss 7.45403376640752e-05, accuracy 0.7222222222222222\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m [Client 29] fit, config: {'current_round': 69, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m Epoch 1: train loss 0.00010476098395884037, accuracy 0.5555555555555556\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m [Client 75] fit, config: {'current_round': 69, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m Epoch 1: train loss 0.00010287443728884682, accuracy 0.6296296296296297\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m [Client 57] fit, config: {'current_round': 69, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m Epoch 1: train loss 0.0001113910402636975, accuracy 0.5740740740740741\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m [Client 17] fit, config: {'current_round': 69, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m Epoch 1: train loss 8.398807403864339e-05, accuracy 0.7222222222222222\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m [Client 93] fit, config: {'current_round': 69, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m Epoch 1: train loss 7.914361049188301e-05, accuracy 0.7037037037037037\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m [Client 99] fit, config: {'current_round': 69, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m [Client 96] fit, config: {'current_round': 69, 'local_epochs': 3}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 12:59:19,053 | server.py:216 | fit_round received 30 results and 0 failures\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m [Client 22] fit, config: {'current_round': 69, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m Epoch 1: train loss 9.205867536365986e-05, accuracy 0.6851851851851852\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m [Client 47] fit, config: {'current_round': 69, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m [Client 34] fit, config: {'current_round': 69, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m [Client 40] fit, config: {'current_round': 69, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m [Client 76] fit, config: {'current_round': 69, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m Epoch 1: train loss 7.345982157858089e-05, accuracy 0.7222222222222222\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m [Client 98] fit, config: {'current_round': 69, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m Epoch 1: train loss 8.134694508044049e-05, accuracy 0.7037037037037037\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m Epoch 1: train loss 0.00011389737483114004, accuracy 0.5555555555555556\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m [Client 24] fit, config: {'current_round': 69, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m Epoch 1: train loss 8.44168389448896e-05, accuracy 0.7037037037037037\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m Epoch 1: train loss 9.916938142850995e-05, accuracy 0.5925925925925926\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m Epoch 1: train loss 8.076805534074083e-05, accuracy 0.6851851851851852\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m [Client 87] fit, config: {'current_round': 69, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m Epoch 1: train loss 9.294440678786486e-05, accuracy 0.5740740740740741\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m Epoch 1: train loss 0.00010787848441395909, accuracy 0.5740740740740741\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m [Client 3] fit, config: {'current_round': 69, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m Epoch 1: train loss 0.00010769179789349437, accuracy 0.6296296296296297\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m Epoch 1: train loss 7.799285231158137e-05, accuracy 0.6296296296296297\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m [Client 30] fit, config: {'current_round': 69, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m Epoch 1: train loss 0.00010619607201078907, accuracy 0.5370370370370371\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m [Client 62] fit, config: {'current_round': 69, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m Epoch 1: train loss 8.59560095705092e-05, accuracy 0.6851851851851852\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m [Client 10] fit, config: {'current_round': 69, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m [Client 28] fit, config: {'current_round': 69, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m [Client 92] fit, config: {'current_round': 69, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m Epoch 1: train loss 9.672661690274253e-05, accuracy 0.6851851851851852\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m Epoch 1: train loss 0.00010404405475128442, accuracy 0.6296296296296297\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m [Client 38] fit, config: {'current_round': 69, 'local_epochs': 3}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 12:59:19,128 | server.py:157 | evaluate_round: strategy sampled 30 clients (out of 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m [Client 60] fit, config: {'current_round': 69, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m Epoch 1: train loss 9.922585013555363e-05, accuracy 0.6296296296296297\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m Epoch 1: train loss 9.283728286391124e-05, accuracy 0.7222222222222222\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m Epoch 1: train loss 9.804419823922217e-05, accuracy 0.6111111111111112\n",
      "Saving round 69 aggregated_parameters...\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98089)\u001b[0m [Client 97] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98089)\u001b[0m [Client 37] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98090)\u001b[0m [Client 3] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98090)\u001b[0m [Client 83] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98089)\u001b[0m [Client 13] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98089)\u001b[0m [Client 79] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98089)\u001b[0m [Client 60] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98090)\u001b[0m [Client 41] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98089)\u001b[0m [Client 32] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98090)\u001b[0m [Client 29] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98089)\u001b[0m [Client 93] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98094)\u001b[0m [Client 61] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98090)\u001b[0m [Client 71] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98094)\u001b[0m [Client 87] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98089)\u001b[0m [Client 24] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98090)\u001b[0m [Client 14] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98088)\u001b[0m [Client 39] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98089)\u001b[0m [Client 76] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98094)\u001b[0m [Client 62] evaluate, config: {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 12:59:21,444 | server.py:170 | evaluate_round received 0 results and 30 failures\n",
      "DEBUG flower 2023-02-01 12:59:21,446 | server.py:203 | fit_round: strategy sampled 30 clients (out of 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98088)\u001b[0m [Client 1] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98089)\u001b[0m [Client 25] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98091)\u001b[0m [Client 50] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98090)\u001b[0m [Client 68] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98095)\u001b[0m [Client 45] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98091)\u001b[0m [Client 7] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98088)\u001b[0m [Client 20] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98093)\u001b[0m [Client 2] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98089)\u001b[0m [Client 59] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98094)\u001b[0m [Client 75] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98092)\u001b[0m [Client 33] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m [Client 29] fit, config: {'current_round': 70, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m Epoch 1: train loss 9.426590986549854e-05, accuracy 0.6851851851851852\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m [Client 70] fit, config: {'current_round': 70, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m [Client 80] fit, config: {'current_round': 70, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m Epoch 1: train loss 7.425590592902154e-05, accuracy 0.7592592592592593\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m Epoch 1: train loss 0.00011154120147693902, accuracy 0.6851851851851852\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m [Client 19] fit, config: {'current_round': 70, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m Epoch 1: train loss 7.622153498232365e-05, accuracy 0.7407407407407407\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m [Client 40] fit, config: {'current_round': 70, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m Epoch 1: train loss 8.246533980127424e-05, accuracy 0.6851851851851852\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m [Client 44] fit, config: {'current_round': 70, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m [Client 61] fit, config: {'current_round': 70, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m Epoch 1: train loss 8.400745718972757e-05, accuracy 0.6851851851851852\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m Epoch 1: train loss 0.00010344690963393077, accuracy 0.6851851851851852\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m [Client 98] fit, config: {'current_round': 70, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m [Client 56] fit, config: {'current_round': 70, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m Epoch 1: train loss 0.00010356938582845032, accuracy 0.5925925925925926\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m Epoch 1: train loss 0.00010324514005333185, accuracy 0.5370370370370371\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m [Client 8] fit, config: {'current_round': 70, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m Epoch 1: train loss 8.94842523848638e-05, accuracy 0.6296296296296297\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m [Client 76] fit, config: {'current_round': 70, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m Epoch 1: train loss 7.429812103509903e-05, accuracy 0.6851851851851852\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m [Client 33] fit, config: {'current_round': 70, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m Epoch 1: train loss 9.033104288391769e-05, accuracy 0.6481481481481481\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m [Client 31] fit, config: {'current_round': 70, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m [Client 47] fit, config: {'current_round': 70, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m Epoch 1: train loss 9.621071512810886e-05, accuracy 0.7222222222222222\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m [Client 5] fit, config: {'current_round': 70, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m Epoch 1: train loss 7.975281187100336e-05, accuracy 0.6851851851851852\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m Epoch 1: train loss 9.54194474616088e-05, accuracy 0.6481481481481481\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m [Client 38] fit, config: {'current_round': 70, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m Epoch 1: train loss 9.902713645715266e-05, accuracy 0.5740740740740741\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m [Client 95] fit, config: {'current_round': 70, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m Epoch 1: train loss 7.049975829431787e-05, accuracy 0.7222222222222222\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m [Client 78] fit, config: {'current_round': 70, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m Epoch 1: train loss 9.709627920528874e-05, accuracy 0.6481481481481481\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m [Client 88] fit, config: {'current_round': 70, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m Epoch 1: train loss 8.521896234015003e-05, accuracy 0.6666666666666666\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m [Client 55] fit, config: {'current_round': 70, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m [Client 46] fit, config: {'current_round': 70, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m Epoch 1: train loss 8.140248974086717e-05, accuracy 0.7037037037037037\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m Epoch 1: train loss 8.688394154887646e-05, accuracy 0.6851851851851852\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m [Client 52] fit, config: {'current_round': 70, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m Epoch 1: train loss 0.00010928807023447007, accuracy 0.5\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m [Client 21] fit, config: {'current_round': 70, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m Epoch 1: train loss 0.0001097705026040785, accuracy 0.6111111111111112\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m [Client 49] fit, config: {'current_round': 70, 'local_epochs': 3}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 12:59:23,906 | server.py:216 | fit_round received 30 results and 0 failures\n",
      "DEBUG flower 2023-02-01 12:59:23,980 | server.py:157 | evaluate_round: strategy sampled 30 clients (out of 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m [Client 63] fit, config: {'current_round': 70, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m [Client 3] fit, config: {'current_round': 70, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m [Client 81] fit, config: {'current_round': 70, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m [Client 65] fit, config: {'current_round': 70, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m Epoch 1: train loss 0.00010280180140398443, accuracy 0.5185185185185185\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m [Client 26] fit, config: {'current_round': 70, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m Epoch 1: train loss 0.000107377149106469, accuracy 0.6481481481481481\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m Epoch 1: train loss 0.00010342287714593112, accuracy 0.5740740740740741\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m [Client 57] fit, config: {'current_round': 70, 'local_epochs': 3}\n",
      "Saving round 70 aggregated_parameters...\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m Epoch 1: train loss 9.757165389601141e-05, accuracy 0.5740740740740741\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m Epoch 1: train loss 0.00010301319707650691, accuracy 0.5370370370370371\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m Epoch 1: train loss 0.00010318876593373716, accuracy 0.5740740740740741\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m Epoch 1: train loss 0.00010213780478807166, accuracy 0.6666666666666666\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98090)\u001b[0m [Client 62] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98088)\u001b[0m [Client 19] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98095)\u001b[0m [Client 69] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98093)\u001b[0m [Client 12] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98088)\u001b[0m [Client 59] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98093)\u001b[0m [Client 80] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98088)\u001b[0m [Client 32] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98093)\u001b[0m [Client 9] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98091)\u001b[0m [Client 58] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98090)\u001b[0m [Client 49] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98095)\u001b[0m [Client 25] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98093)\u001b[0m [Client 96] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98089)\u001b[0m [Client 92] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98094)\u001b[0m [Client 48] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98092)\u001b[0m [Client 17] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98091)\u001b[0m [Client 41] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98090)\u001b[0m [Client 60] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98088)\u001b[0m [Client 35] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98095)\u001b[0m [Client 53] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98093)\u001b[0m [Client 79] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98090)\u001b[0m [Client 26] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98095)\u001b[0m [Client 7] evaluate, config: {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 12:59:26,413 | server.py:170 | evaluate_round received 0 results and 30 failures\n",
      "DEBUG flower 2023-02-01 12:59:26,414 | server.py:203 | fit_round: strategy sampled 30 clients (out of 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98091)\u001b[0m [Client 18] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98090)\u001b[0m [Client 76] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98088)\u001b[0m [Client 38] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98095)\u001b[0m [Client 3] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98093)\u001b[0m [Client 71] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98089)\u001b[0m [Client 86] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98094)\u001b[0m [Client 13] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98092)\u001b[0m [Client 28] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m [Client 64] fit, config: {'current_round': 71, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m Epoch 1: train loss 8.155213436111808e-05, accuracy 0.6666666666666666\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m [Client 47] fit, config: {'current_round': 71, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m Epoch 1: train loss 8.158448326867074e-05, accuracy 0.7222222222222222\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m [Client 5] fit, config: {'current_round': 71, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m Epoch 1: train loss 9.095676796277985e-05, accuracy 0.5740740740740741\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m [Client 18] fit, config: {'current_round': 71, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m Epoch 1: train loss 0.00010453093273099512, accuracy 0.5555555555555556\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m [Client 58] fit, config: {'current_round': 71, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m Epoch 1: train loss 0.00010004789510276169, accuracy 0.5555555555555556\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m [Client 65] fit, config: {'current_round': 71, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m Epoch 1: train loss 8.878066728357226e-05, accuracy 0.5740740740740741\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m [Client 8] fit, config: {'current_round': 71, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m [Client 20] fit, config: {'current_round': 71, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m Epoch 1: train loss 0.00010893844591919333, accuracy 0.6296296296296297\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m Epoch 1: train loss 9.90585976978764e-05, accuracy 0.5740740740740741\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m [Client 77] fit, config: {'current_round': 71, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m Epoch 1: train loss 8.465753489872441e-05, accuracy 0.6851851851851852\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m [Client 57] fit, config: {'current_round': 71, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m Epoch 1: train loss 0.00010386235953774303, accuracy 0.6111111111111112\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m [Client 45] fit, config: {'current_round': 71, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m Epoch 1: train loss 8.551275823265314e-05, accuracy 0.7222222222222222\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m [Client 28] fit, config: {'current_round': 71, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m Epoch 1: train loss 9.638915798859671e-05, accuracy 0.6111111111111112\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m [Client 41] fit, config: {'current_round': 71, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m Epoch 1: train loss 9.675304318079725e-05, accuracy 0.5370370370370371\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m [Client 99] fit, config: {'current_round': 71, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m Epoch 1: train loss 8.922758570406586e-05, accuracy 0.6851851851851852\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m [Client 56] fit, config: {'current_round': 71, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m Epoch 1: train loss 0.00010134328476851806, accuracy 0.6296296296296297\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m [Client 96] fit, config: {'current_round': 71, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m Epoch 1: train loss 7.639711839146912e-05, accuracy 0.7222222222222222\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m [Client 78] fit, config: {'current_round': 71, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m Epoch 1: train loss 9.91002525552176e-05, accuracy 0.5740740740740741\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m [Client 98] fit, config: {'current_round': 71, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m [Client 76] fit, config: {'current_round': 71, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m Epoch 1: train loss 6.910401134518906e-05, accuracy 0.7222222222222222\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m Epoch 1: train loss 0.00010700072016334161, accuracy 0.5925925925925926\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m [Client 73] fit, config: {'current_round': 71, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m Epoch 1: train loss 8.788311970420182e-05, accuracy 0.7037037037037037\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 12:59:28,862 | server.py:216 | fit_round received 30 results and 0 failures\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m [Client 71] fit, config: {'current_round': 71, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m Epoch 1: train loss 8.796538168098778e-05, accuracy 0.6481481481481481\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m [Client 90] fit, config: {'current_round': 71, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m Epoch 1: train loss 8.035849168663844e-05, accuracy 0.8148148148148148\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m [Client 89] fit, config: {'current_round': 71, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m [Client 53] fit, config: {'current_round': 71, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m Epoch 1: train loss 8.68021888891235e-05, accuracy 0.7037037037037037\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m [Client 61] fit, config: {'current_round': 71, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m Epoch 1: train loss 9.892351954476908e-05, accuracy 0.6666666666666666\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m [Client 86] fit, config: {'current_round': 71, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m Epoch 1: train loss 7.84657895565033e-05, accuracy 0.7407407407407407\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m [Client 88] fit, config: {'current_round': 71, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m [Client 70] fit, config: {'current_round': 71, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m Epoch 1: train loss 0.00012023151793982834, accuracy 0.6111111111111112\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m Epoch 1: train loss 8.450276800431311e-05, accuracy 0.6851851851851852\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 12:59:28,918 | server.py:157 | evaluate_round: strategy sampled 30 clients (out of 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving round 71 aggregated_parameters...\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m [Client 79] fit, config: {'current_round': 71, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m Epoch 1: train loss 8.385173714486882e-05, accuracy 0.6296296296296297\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m Epoch 1: train loss 8.745792729314417e-05, accuracy 0.6481481481481481\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m [Client 84] fit, config: {'current_round': 71, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m Epoch 1: train loss 7.962967356434092e-05, accuracy 0.7037037037037037\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98092)\u001b[0m [Client 19] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98095)\u001b[0m [Client 48] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98093)\u001b[0m [Client 26] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98092)\u001b[0m [Client 40] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98095)\u001b[0m [Client 2] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98095)\u001b[0m [Client 51] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98095)\u001b[0m [Client 80] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98093)\u001b[0m [Client 54] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98092)\u001b[0m [Client 3] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98088)\u001b[0m [Client 13] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98088)\u001b[0m [Client 36] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98095)\u001b[0m [Client 65] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98092)\u001b[0m [Client 14] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98091)\u001b[0m [Client 68] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98089)\u001b[0m [Client 85] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98093)\u001b[0m [Client 0] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98093)\u001b[0m [Client 29] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98093)\u001b[0m [Client 20] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98093)\u001b[0m [Client 8] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98093)\u001b[0m [Client 9] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98095)\u001b[0m [Client 28] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98089)\u001b[0m [Client 33] evaluate, config: {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 12:59:31,408 | server.py:170 | evaluate_round received 0 results and 30 failures\n",
      "DEBUG flower 2023-02-01 12:59:31,409 | server.py:203 | fit_round: strategy sampled 30 clients (out of 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98091)\u001b[0m [Client 69] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98090)\u001b[0m [Client 4] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98088)\u001b[0m [Client 62] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98095)\u001b[0m [Client 32] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98093)\u001b[0m [Client 90] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98094)\u001b[0m [Client 59] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98092)\u001b[0m [Client 70] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98089)\u001b[0m [Client 79] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m [Client 17] fit, config: {'current_round': 72, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m [Client 81] fit, config: {'current_round': 72, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m Epoch 1: train loss 8.333518053404987e-05, accuracy 0.6851851851851852\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m Epoch 1: train loss 0.00010389714589109644, accuracy 0.6111111111111112\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m [Client 47] fit, config: {'current_round': 72, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m Epoch 1: train loss 9.574028081260622e-05, accuracy 0.7037037037037037\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m [Client 39] fit, config: {'current_round': 72, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m Epoch 1: train loss 9.208104165736586e-05, accuracy 0.6111111111111112\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m [Client 45] fit, config: {'current_round': 72, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m Epoch 1: train loss 0.00010404914792161435, accuracy 0.6296296296296297\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m [Client 76] fit, config: {'current_round': 72, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m Epoch 1: train loss 7.475386519217864e-05, accuracy 0.6296296296296297\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m [Client 79] fit, config: {'current_round': 72, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m Epoch 1: train loss 0.00010030083649326116, accuracy 0.6111111111111112\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m [Client 87] fit, config: {'current_round': 72, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m Epoch 1: train loss 8.437362703261897e-05, accuracy 0.6666666666666666\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m [Client 42] fit, config: {'current_round': 72, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m Epoch 1: train loss 9.922854223987088e-05, accuracy 0.5\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m [Client 27] fit, config: {'current_round': 72, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m Epoch 1: train loss 9.688548743724823e-05, accuracy 0.6481481481481481\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m [Client 99] fit, config: {'current_round': 72, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m Epoch 1: train loss 8.276820881292224e-05, accuracy 0.7592592592592593\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m [Client 18] fit, config: {'current_round': 72, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m Epoch 1: train loss 0.00011381129297660664, accuracy 0.6296296296296297\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m [Client 71] fit, config: {'current_round': 72, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m [Client 44] fit, config: {'current_round': 72, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m [Client 31] fit, config: {'current_round': 72, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m Epoch 1: train loss 9.358231181977317e-05, accuracy 0.6666666666666666\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m Epoch 1: train loss 8.282212365884334e-05, accuracy 0.7222222222222222\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m [Client 33] fit, config: {'current_round': 72, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m Epoch 1: train loss 0.000102836980659049, accuracy 0.6666666666666666\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m Epoch 1: train loss 8.812874148134142e-05, accuracy 0.6666666666666666\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m [Client 19] fit, config: {'current_round': 72, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m Epoch 1: train loss 7.589686720166355e-05, accuracy 0.7222222222222222\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m [Client 48] fit, config: {'current_round': 72, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m Epoch 1: train loss 9.500667511019856e-05, accuracy 0.6296296296296297\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m [Client 54] fit, config: {'current_round': 72, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m Epoch 1: train loss 0.00010506814578548074, accuracy 0.5370370370370371\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m [Client 74] fit, config: {'current_round': 72, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m Epoch 1: train loss 0.00010639170068316162, accuracy 0.6296296296296297\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m [Client 43] fit, config: {'current_round': 72, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m [Client 36] fit, config: {'current_round': 72, 'local_epochs': 3}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 12:59:34,370 | server.py:216 | fit_round received 30 results and 0 failures\n",
      "DEBUG flower 2023-02-01 12:59:34,436 | server.py:157 | evaluate_round: strategy sampled 30 clients (out of 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m [Client 0] fit, config: {'current_round': 72, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m [Client 14] fit, config: {'current_round': 72, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m [Client 53] fit, config: {'current_round': 72, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m [Client 70] fit, config: {'current_round': 72, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m Epoch 1: train loss 9.508937364444137e-05, accuracy 0.6481481481481481\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m Epoch 1: train loss 0.00010200482938671485, accuracy 0.6666666666666666\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m Epoch 1: train loss 9.150654659606516e-05, accuracy 0.6296296296296297\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m Epoch 1: train loss 0.00011795363388955593, accuracy 0.6111111111111112\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m Epoch 1: train loss 9.510825475445017e-05, accuracy 0.6296296296296297\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m [Client 90] fit, config: {'current_round': 72, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m Epoch 1: train loss 9.182551730191335e-05, accuracy 0.6111111111111112\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m Epoch 1: train loss 0.00011154381354572251, accuracy 0.6666666666666666\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m [Client 28] fit, config: {'current_round': 72, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m [Client 20] fit, config: {'current_round': 72, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m [Client 91] fit, config: {'current_round': 72, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m Epoch 1: train loss 8.68753922986798e-05, accuracy 0.7592592592592593\n",
      "Saving round 72 aggregated_parameters...\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m Epoch 1: train loss 8.359597268281505e-05, accuracy 0.7407407407407407\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m Epoch 1: train loss 0.00010880955233005807, accuracy 0.5555555555555556\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98094)\u001b[0m [Client 46] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98094)\u001b[0m [Client 55] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98094)\u001b[0m [Client 50] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98094)\u001b[0m [Client 59] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98094)\u001b[0m [Client 79] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98089)\u001b[0m [Client 62] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98094)\u001b[0m [Client 17] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98092)\u001b[0m [Client 6] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98089)\u001b[0m [Client 69] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98093)\u001b[0m [Client 78] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98092)\u001b[0m [Client 26] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98091)\u001b[0m [Client 42] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98090)\u001b[0m [Client 95] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98088)\u001b[0m [Client 98] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98093)\u001b[0m [Client 67] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98089)\u001b[0m [Client 77] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98094)\u001b[0m [Client 22] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98095)\u001b[0m [Client 85] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98092)\u001b[0m [Client 30] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98092)\u001b[0m [Client 91] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98088)\u001b[0m [Client 28] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98089)\u001b[0m [Client 56] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98092)\u001b[0m [Client 82] evaluate, config: {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 12:59:37,318 | server.py:170 | evaluate_round received 0 results and 30 failures\n",
      "DEBUG flower 2023-02-01 12:59:37,320 | server.py:203 | fit_round: strategy sampled 30 clients (out of 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98091)\u001b[0m [Client 61] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98093)\u001b[0m [Client 15] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98092)\u001b[0m [Client 72] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98090)\u001b[0m [Client 53] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98088)\u001b[0m [Client 32] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98095)\u001b[0m [Client 20] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98094)\u001b[0m [Client 63] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m [Client 80] fit, config: {'current_round': 73, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m Epoch 1: train loss 7.618270319653675e-05, accuracy 0.7407407407407407\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m [Client 4] fit, config: {'current_round': 73, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m [Client 94] fit, config: {'current_round': 73, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m Epoch 1: train loss 8.916995284380391e-05, accuracy 0.6481481481481481\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m Epoch 1: train loss 0.00010387886868556961, accuracy 0.6111111111111112\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m [Client 12] fit, config: {'current_round': 73, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m Epoch 1: train loss 9.655269968789071e-05, accuracy 0.6851851851851852\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m [Client 59] fit, config: {'current_round': 73, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m Epoch 1: train loss 9.247013076674193e-05, accuracy 0.7222222222222222\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m [Client 67] fit, config: {'current_round': 73, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m [Client 22] fit, config: {'current_round': 73, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m Epoch 1: train loss 0.00010988924623234197, accuracy 0.5740740740740741\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m [Client 32] fit, config: {'current_round': 73, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m Epoch 1: train loss 0.00011924293357878923, accuracy 0.6111111111111112\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m [Client 89] fit, config: {'current_round': 73, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m Epoch 1: train loss 8.895167411537841e-05, accuracy 0.6111111111111112\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m Epoch 1: train loss 9.089268860407174e-05, accuracy 0.6111111111111112\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m [Client 69] fit, config: {'current_round': 73, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m Epoch 1: train loss 7.815053686499596e-05, accuracy 0.6481481481481481\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m [Client 16] fit, config: {'current_round': 73, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m Epoch 1: train loss 0.0001019937262753956, accuracy 0.5185185185185185\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m [Client 7] fit, config: {'current_round': 73, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m Epoch 1: train loss 0.00010154164920095354, accuracy 0.6111111111111112\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m [Client 85] fit, config: {'current_round': 73, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m Epoch 1: train loss 0.00010495031892787665, accuracy 0.5740740740740741\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m [Client 44] fit, config: {'current_round': 73, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m Epoch 1: train loss 0.00010493672743905336, accuracy 0.5185185185185185\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m [Client 70] fit, config: {'current_round': 73, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m [Client 61] fit, config: {'current_round': 73, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m Epoch 1: train loss 0.00010224218567600474, accuracy 0.6481481481481481\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m [Client 42] fit, config: {'current_round': 73, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m Epoch 1: train loss 0.00011955728405155241, accuracy 0.6296296296296297\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m Epoch 1: train loss 9.996071457862854e-05, accuracy 0.6481481481481481\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m [Client 66] fit, config: {'current_round': 73, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m Epoch 1: train loss 8.247283403761685e-05, accuracy 0.6851851851851852\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m [Client 77] fit, config: {'current_round': 73, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m Epoch 1: train loss 8.447772415820509e-05, accuracy 0.7037037037037037\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m [Client 72] fit, config: {'current_round': 73, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m [Client 36] fit, config: {'current_round': 73, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m Epoch 1: train loss 0.00012137261364841834, accuracy 0.5\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m Epoch 1: train loss 7.672138599446043e-05, accuracy 0.7222222222222222\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m [Client 29] fit, config: {'current_round': 73, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m [Client 51] fit, config: {'current_round': 73, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m Epoch 1: train loss 9.417162800673395e-05, accuracy 0.6111111111111112\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m [Client 46] fit, config: {'current_round': 73, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m Epoch 1: train loss 6.900238076923415e-05, accuracy 0.6666666666666666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 12:59:40,014 | server.py:216 | fit_round received 30 results and 0 failures\n",
      "DEBUG flower 2023-02-01 12:59:40,108 | server.py:157 | evaluate_round: strategy sampled 30 clients (out of 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m Epoch 1: train loss 0.00010404239583294839, accuracy 0.5740740740740741\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m [Client 17] fit, config: {'current_round': 73, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m Epoch 1: train loss 8.014273043954745e-05, accuracy 0.6851851851851852\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m [Client 1] fit, config: {'current_round': 73, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m Epoch 1: train loss 9.620621131034568e-05, accuracy 0.6111111111111112\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m [Client 11] fit, config: {'current_round': 73, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m Epoch 1: train loss 9.358020179206505e-05, accuracy 0.6666666666666666\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m [Client 24] fit, config: {'current_round': 73, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m Epoch 1: train loss 7.521746010752395e-05, accuracy 0.6481481481481481\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m [Client 6] fit, config: {'current_round': 73, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m Epoch 1: train loss 8.959452679846436e-05, accuracy 0.6666666666666666\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m [Client 62] fit, config: {'current_round': 73, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m Epoch 1: train loss 8.344557863892987e-05, accuracy 0.6481481481481481\n",
      "Saving round 73 aggregated_parameters...\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98091)\u001b[0m [Client 83] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98094)\u001b[0m [Client 82] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98091)\u001b[0m [Client 55] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98090)\u001b[0m [Client 85] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98093)\u001b[0m [Client 98] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98094)\u001b[0m [Client 99] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98092)\u001b[0m [Client 2] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98090)\u001b[0m [Client 57] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98091)\u001b[0m [Client 53] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98090)\u001b[0m [Client 77] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98094)\u001b[0m [Client 58] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98091)\u001b[0m [Client 94] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98090)\u001b[0m [Client 59] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98088)\u001b[0m [Client 27] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98095)\u001b[0m [Client 38] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98093)\u001b[0m [Client 24] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98089)\u001b[0m [Client 15] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98092)\u001b[0m [Client 50] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98089)\u001b[0m [Client 34] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98094)\u001b[0m [Client 11] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98091)\u001b[0m [Client 16] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98090)\u001b[0m [Client 75] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98094)\u001b[0m [Client 42] evaluate, config: {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 12:59:42,406 | server.py:170 | evaluate_round received 0 results and 30 failures\n",
      "DEBUG flower 2023-02-01 12:59:42,408 | server.py:203 | fit_round: strategy sampled 30 clients (out of 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98091)\u001b[0m [Client 44] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98088)\u001b[0m [Client 30] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98095)\u001b[0m [Client 73] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98093)\u001b[0m [Client 25] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98089)\u001b[0m [Client 43] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98094)\u001b[0m [Client 66] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98092)\u001b[0m [Client 33] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m [Client 28] fit, config: {'current_round': 74, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m Epoch 1: train loss 8.336878818226978e-05, accuracy 0.7407407407407407\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m [Client 20] fit, config: {'current_round': 74, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m Epoch 1: train loss 0.000113403752038721, accuracy 0.6111111111111112\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m [Client 3] fit, config: {'current_round': 74, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m [Client 29] fit, config: {'current_round': 74, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m Epoch 1: train loss 9.736022184370086e-05, accuracy 0.6481481481481481\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m Epoch 1: train loss 9.796368976822123e-05, accuracy 0.6481481481481481\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m [Client 55] fit, config: {'current_round': 74, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m Epoch 1: train loss 8.873679325915873e-05, accuracy 0.6851851851851852\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m [Client 67] fit, config: {'current_round': 74, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m Epoch 1: train loss 0.00012301350943744183, accuracy 0.6111111111111112\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m [Client 90] fit, config: {'current_round': 74, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m Epoch 1: train loss 9.37785443966277e-05, accuracy 0.6666666666666666\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m [Client 51] fit, config: {'current_round': 74, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m Epoch 1: train loss 8.810932922642678e-05, accuracy 0.6851851851851852\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m [Client 38] fit, config: {'current_round': 74, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m [Client 63] fit, config: {'current_round': 74, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m [Client 6] fit, config: {'current_round': 74, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m Epoch 1: train loss 0.00010351399396313354, accuracy 0.5925925925925926\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m [Client 35] fit, config: {'current_round': 74, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m Epoch 1: train loss 9.906630293698981e-05, accuracy 0.5925925925925926\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m [Client 36] fit, config: {'current_round': 74, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m Epoch 1: train loss 9.965182835003361e-05, accuracy 0.6296296296296297\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m [Client 97] fit, config: {'current_round': 74, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m [Client 64] fit, config: {'current_round': 74, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m Epoch 1: train loss 7.776092388667166e-05, accuracy 0.6666666666666666\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m Epoch 1: train loss 0.00010099481005454436, accuracy 0.5925925925925926\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m Epoch 1: train loss 0.00010689443297451362, accuracy 0.5185185185185185\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m [Client 88] fit, config: {'current_round': 74, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m [Client 17] fit, config: {'current_round': 74, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m Epoch 1: train loss 8.289214019896463e-05, accuracy 0.7037037037037037\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m Epoch 1: train loss 0.00012622468057088554, accuracy 0.5185185185185185\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m [Client 12] fit, config: {'current_round': 74, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m Epoch 1: train loss 9.844210580922663e-05, accuracy 0.6296296296296297\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m Epoch 1: train loss 8.563460869481787e-05, accuracy 0.6666666666666666\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m [Client 61] fit, config: {'current_round': 74, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m [Client 16] fit, config: {'current_round': 74, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m Epoch 1: train loss 8.437567885266617e-05, accuracy 0.7222222222222222\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m Epoch 1: train loss 8.003613038454205e-05, accuracy 0.7222222222222222\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m [Client 30] fit, config: {'current_round': 74, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m Epoch 1: train loss 0.00010077503975480795, accuracy 0.5370370370370371\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m [Client 69] fit, config: {'current_round': 74, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m [Client 14] fit, config: {'current_round': 74, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m Epoch 1: train loss 9.511959797237068e-05, accuracy 0.6481481481481481\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m [Client 96] fit, config: {'current_round': 74, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m [Client 41] fit, config: {'current_round': 74, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m Epoch 1: train loss 8.605903713032603e-05, accuracy 0.6481481481481481\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m [Client 78] fit, config: {'current_round': 74, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m Epoch 1: train loss 0.00010366276546847075, accuracy 0.5740740740740741\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m Epoch 1: train loss 7.834691496100277e-05, accuracy 0.6666666666666666\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m Epoch 1: train loss 8.258740126620978e-05, accuracy 0.6851851851851852\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m [Client 87] fit, config: {'current_round': 74, 'local_epochs': 3}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 12:59:44,928 | server.py:216 | fit_round received 30 results and 0 failures\n",
      "DEBUG flower 2023-02-01 12:59:44,990 | server.py:157 | evaluate_round: strategy sampled 30 clients (out of 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m [Client 0] fit, config: {'current_round': 74, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m Epoch 1: train loss 0.00011681925388984382, accuracy 0.6111111111111112\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m Epoch 1: train loss 8.717612217878923e-05, accuracy 0.6666666666666666\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m [Client 8] fit, config: {'current_round': 74, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m Epoch 1: train loss 8.936053927754983e-05, accuracy 0.6111111111111112\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m [Client 49] fit, config: {'current_round': 74, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m Epoch 1: train loss 0.00010622815898386762, accuracy 0.5555555555555556\n",
      "Saving round 74 aggregated_parameters...\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98090)\u001b[0m [Client 25] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98090)\u001b[0m [Client 66] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98088)\u001b[0m [Client 3] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98095)\u001b[0m [Client 17] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98094)\u001b[0m [Client 7] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98088)\u001b[0m [Client 74] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98088)\u001b[0m [Client 87] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98090)\u001b[0m [Client 68] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98088)\u001b[0m [Client 94] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98095)\u001b[0m [Client 39] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98094)\u001b[0m [Client 82] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98091)\u001b[0m [Client 4] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98091)\u001b[0m [Client 24] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98091)\u001b[0m [Client 99] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98094)\u001b[0m [Client 54] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98094)\u001b[0m [Client 67] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98091)\u001b[0m [Client 84] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98095)\u001b[0m [Client 20] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98091)\u001b[0m [Client 79] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98091)\u001b[0m [Client 61] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98095)\u001b[0m [Client 2] evaluate, config: {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 12:59:47,351 | server.py:170 | evaluate_round received 0 results and 30 failures\n",
      "DEBUG flower 2023-02-01 12:59:47,353 | server.py:203 | fit_round: strategy sampled 30 clients (out of 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98095)\u001b[0m [Client 96] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98094)\u001b[0m [Client 1] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98091)\u001b[0m [Client 11] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98090)\u001b[0m [Client 9] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98088)\u001b[0m [Client 97] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98095)\u001b[0m [Client 63] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98094)\u001b[0m [Client 40] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98093)\u001b[0m [Client 23] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98092)\u001b[0m [Client 28] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m [Client 71] fit, config: {'current_round': 75, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m Epoch 1: train loss 8.395764598390087e-05, accuracy 0.6481481481481481\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m [Client 69] fit, config: {'current_round': 75, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m Epoch 1: train loss 7.627293234691024e-05, accuracy 0.7037037037037037\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m [Client 50] fit, config: {'current_round': 75, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m [Client 18] fit, config: {'current_round': 75, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m Epoch 1: train loss 0.00011099137918790802, accuracy 0.5370370370370371\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m Epoch 1: train loss 9.456868428969756e-05, accuracy 0.6296296296296297\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m [Client 97] fit, config: {'current_round': 75, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m Epoch 1: train loss 0.00013252449571155012, accuracy 0.5555555555555556\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m [Client 57] fit, config: {'current_round': 75, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m Epoch 1: train loss 9.697531640995294e-05, accuracy 0.6111111111111112\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m [Client 37] fit, config: {'current_round': 75, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m Epoch 1: train loss 7.10853491909802e-05, accuracy 0.6851851851851852\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m [Client 70] fit, config: {'current_round': 75, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m Epoch 1: train loss 0.00011852296302095056, accuracy 0.6296296296296297\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m [Client 58] fit, config: {'current_round': 75, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m Epoch 1: train loss 9.033388778334484e-05, accuracy 0.6296296296296297\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m [Client 16] fit, config: {'current_round': 75, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m Epoch 1: train loss 0.00010246329475194216, accuracy 0.6296296296296297\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m [Client 82] fit, config: {'current_round': 75, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m Epoch 1: train loss 7.880965858930722e-05, accuracy 0.6666666666666666\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m [Client 24] fit, config: {'current_round': 75, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m Epoch 1: train loss 7.890077540650964e-05, accuracy 0.6481481481481481\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m [Client 95] fit, config: {'current_round': 75, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m Epoch 1: train loss 6.840679998276755e-05, accuracy 0.6851851851851852\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m [Client 43] fit, config: {'current_round': 75, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m [Client 87] fit, config: {'current_round': 75, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m Epoch 1: train loss 8.456589421257377e-05, accuracy 0.7222222222222222\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m Epoch 1: train loss 8.640343730803579e-05, accuracy 0.6296296296296297\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m [Client 91] fit, config: {'current_round': 75, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m Epoch 1: train loss 9.693619358586147e-05, accuracy 0.5370370370370371\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m [Client 42] fit, config: {'current_round': 75, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m Epoch 1: train loss 9.636424510972574e-05, accuracy 0.6111111111111112\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m [Client 80] fit, config: {'current_round': 75, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m [Client 52] fit, config: {'current_round': 75, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m Epoch 1: train loss 9.092567779589444e-05, accuracy 0.6481481481481481\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m [Client 53] fit, config: {'current_round': 75, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m [Client 64] fit, config: {'current_round': 75, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m Epoch 1: train loss 7.735924737062305e-05, accuracy 0.7592592592592593\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m [Client 56] fit, config: {'current_round': 75, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m Epoch 1: train loss 0.00010644782742019743, accuracy 0.5\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m Epoch 1: train loss 7.138722867239267e-05, accuracy 0.7407407407407407\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m Epoch 1: train loss 9.40384779823944e-05, accuracy 0.5740740740740741\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 12:59:49,769 | server.py:216 | fit_round received 30 results and 0 failures\n",
      "DEBUG flower 2023-02-01 12:59:49,828 | server.py:157 | evaluate_round: strategy sampled 30 clients (out of 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m [Client 15] fit, config: {'current_round': 75, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m [Client 67] fit, config: {'current_round': 75, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m [Client 31] fit, config: {'current_round': 75, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m [Client 17] fit, config: {'current_round': 75, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m Epoch 1: train loss 8.07402393547818e-05, accuracy 0.6851851851851852\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m Epoch 1: train loss 0.00011812243610620499, accuracy 0.5370370370370371\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m [Client 36] fit, config: {'current_round': 75, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m Epoch 1: train loss 0.00011364390957169235, accuracy 0.5370370370370371\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m [Client 66] fit, config: {'current_round': 75, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m Epoch 1: train loss 7.841188926249743e-05, accuracy 0.6851851851851852\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m Epoch 1: train loss 0.0001152514960267581, accuracy 0.5925925925925926\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m Epoch 1: train loss 9.465040784562007e-05, accuracy 0.6296296296296297\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m [Client 88] fit, config: {'current_round': 75, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m Epoch 1: train loss 8.342644287040457e-05, accuracy 0.6851851851851852\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m [Client 62] fit, config: {'current_round': 75, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m Epoch 1: train loss 7.928225386422127e-05, accuracy 0.6481481481481481\n",
      "Saving round 75 aggregated_parameters...\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98089)\u001b[0m [Client 54] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98089)\u001b[0m [Client 73] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98088)\u001b[0m [Client 91] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98089)\u001b[0m [Client 51] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98094)\u001b[0m [Client 8] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98094)\u001b[0m [Client 52] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98088)\u001b[0m [Client 65] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98088)\u001b[0m [Client 95] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98089)\u001b[0m [Client 78] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98094)\u001b[0m [Client 15] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98089)\u001b[0m [Client 43] evaluate, config: {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 12:59:52,661 | server.py:170 | evaluate_round received 0 results and 30 failures\n",
      "DEBUG flower 2023-02-01 12:59:52,662 | server.py:203 | fit_round: strategy sampled 30 clients (out of 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98088)\u001b[0m [Client 1] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98095)\u001b[0m [Client 31] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98089)\u001b[0m [Client 21] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98094)\u001b[0m [Client 12] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98092)\u001b[0m [Client 44] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98091)\u001b[0m [Client 63] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98091)\u001b[0m [Client 13] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98091)\u001b[0m [Client 10] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98091)\u001b[0m [Client 56] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98091)\u001b[0m [Client 35] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98091)\u001b[0m [Client 83] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98090)\u001b[0m [Client 18] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98088)\u001b[0m [Client 82] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98095)\u001b[0m [Client 27] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98089)\u001b[0m [Client 48] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98094)\u001b[0m [Client 86] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98092)\u001b[0m [Client 92] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98091)\u001b[0m [Client 85] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98093)\u001b[0m [Client 34] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m [Client 90] fit, config: {'current_round': 76, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m Epoch 1: train loss 9.07767825992778e-05, accuracy 0.7222222222222222\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m [Client 14] fit, config: {'current_round': 76, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m Epoch 1: train loss 9.528841474093497e-05, accuracy 0.6111111111111112\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m [Client 81] fit, config: {'current_round': 76, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m Epoch 1: train loss 0.00010598279186524451, accuracy 0.5740740740740741\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m [Client 83] fit, config: {'current_round': 76, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m Epoch 1: train loss 9.10451853997074e-05, accuracy 0.6851851851851852\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m [Client 3] fit, config: {'current_round': 76, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m Epoch 1: train loss 9.965986828319728e-05, accuracy 0.5925925925925926\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m [Client 28] fit, config: {'current_round': 76, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m Epoch 1: train loss 8.210445230361074e-05, accuracy 0.7592592592592593\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m [Client 27] fit, config: {'current_round': 76, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m [Client 85] fit, config: {'current_round': 76, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m Epoch 1: train loss 0.00011731075937859714, accuracy 0.5185185185185185\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m Epoch 1: train loss 9.65065264608711e-05, accuracy 0.6111111111111112\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m [Client 46] fit, config: {'current_round': 76, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m Epoch 1: train loss 7.682231807848439e-05, accuracy 0.6851851851851852\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m [Client 17] fit, config: {'current_round': 76, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m Epoch 1: train loss 8.210373198380694e-05, accuracy 0.6851851851851852\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m [Client 91] fit, config: {'current_round': 76, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m Epoch 1: train loss 7.993867620825768e-05, accuracy 0.7037037037037037\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m [Client 7] fit, config: {'current_round': 76, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m Epoch 1: train loss 9.658453200245276e-05, accuracy 0.7592592592592593\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m [Client 9] fit, config: {'current_round': 76, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m Epoch 1: train loss 9.217269689543173e-05, accuracy 0.7407407407407407\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m [Client 99] fit, config: {'current_round': 76, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m Epoch 1: train loss 7.881654164521024e-05, accuracy 0.7407407407407407\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m [Client 60] fit, config: {'current_round': 76, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m Epoch 1: train loss 8.735932351555675e-05, accuracy 0.6851851851851852\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m [Client 79] fit, config: {'current_round': 76, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m Epoch 1: train loss 9.840731217991561e-05, accuracy 0.6296296296296297\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m [Client 56] fit, config: {'current_round': 76, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m Epoch 1: train loss 9.97157403617166e-05, accuracy 0.5925925925925926\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m [Client 32] fit, config: {'current_round': 76, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m Epoch 1: train loss 9.680903167463839e-05, accuracy 0.5925925925925926\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m [Client 70] fit, config: {'current_round': 76, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m Epoch 1: train loss 0.00011533982615219429, accuracy 0.6111111111111112\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m [Client 97] fit, config: {'current_round': 76, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m Epoch 1: train loss 0.00012499258446041495, accuracy 0.5185185185185185\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m [Client 64] fit, config: {'current_round': 76, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m [Client 19] fit, config: {'current_round': 76, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m Epoch 1: train loss 7.391750114038587e-05, accuracy 0.7407407407407407\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m Epoch 1: train loss 8.018982043722644e-05, accuracy 0.6481481481481481\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 12:59:55,296 | server.py:216 | fit_round received 30 results and 0 failures\n",
      "DEBUG flower 2023-02-01 12:59:55,350 | server.py:157 | evaluate_round: strategy sampled 30 clients (out of 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m [Client 8] fit, config: {'current_round': 76, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m Epoch 1: train loss 9.23000043258071e-05, accuracy 0.6111111111111112\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m [Client 78] fit, config: {'current_round': 76, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m [Client 71] fit, config: {'current_round': 76, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m Epoch 1: train loss 8.223029726650566e-05, accuracy 0.7407407407407407\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m [Client 12] fit, config: {'current_round': 76, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m Epoch 1: train loss 9.583061910234392e-05, accuracy 0.6111111111111112\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m [Client 34] fit, config: {'current_round': 76, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m Epoch 1: train loss 8.519030961906537e-05, accuracy 0.6666666666666666\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m Epoch 1: train loss 0.00010714621748775244, accuracy 0.5185185185185185\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m [Client 92] fit, config: {'current_round': 76, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m Epoch 1: train loss 0.00010643772839102894, accuracy 0.6111111111111112\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m [Client 0] fit, config: {'current_round': 76, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m Epoch 1: train loss 0.00011674135021166876, accuracy 0.5925925925925926\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m [Client 49] fit, config: {'current_round': 76, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m Epoch 1: train loss 0.0001030619750963524, accuracy 0.5555555555555556\n",
      "Saving round 76 aggregated_parameters...\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98090)\u001b[0m [Client 80] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98090)\u001b[0m [Client 12] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98094)\u001b[0m [Client 82] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98094)\u001b[0m [Client 6] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98091)\u001b[0m [Client 78] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98090)\u001b[0m [Client 51] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98094)\u001b[0m [Client 3] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98091)\u001b[0m [Client 59] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98091)\u001b[0m [Client 49] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98090)\u001b[0m [Client 81] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98090)\u001b[0m [Client 91] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98094)\u001b[0m [Client 63] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98094)\u001b[0m [Client 31] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98094)\u001b[0m [Client 18] evaluate, config: {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 12:59:57,571 | server.py:170 | evaluate_round received 0 results and 30 failures\n",
      "DEBUG flower 2023-02-01 12:59:57,573 | server.py:203 | fit_round: strategy sampled 30 clients (out of 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98091)\u001b[0m [Client 77] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98094)\u001b[0m [Client 62] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98091)\u001b[0m [Client 55] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98089)\u001b[0m [Client 98] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98094)\u001b[0m [Client 74] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98092)\u001b[0m [Client 22] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98090)\u001b[0m [Client 68] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98095)\u001b[0m [Client 11] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98093)\u001b[0m [Client 75] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98091)\u001b[0m [Client 45] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98095)\u001b[0m [Client 83] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98093)\u001b[0m [Client 35] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98093)\u001b[0m [Client 93] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98089)\u001b[0m [Client 60] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98094)\u001b[0m [Client 71] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98089)\u001b[0m [Client 34] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m [Client 23] fit, config: {'current_round': 77, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m Epoch 1: train loss 8.394409087486565e-05, accuracy 0.6851851851851852\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m [Client 40] fit, config: {'current_round': 77, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m [Client 61] fit, config: {'current_round': 77, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m Epoch 1: train loss 9.214301098836586e-05, accuracy 0.6481481481481481\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m Epoch 1: train loss 8.121714927256107e-05, accuracy 0.6851851851851852\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m [Client 88] fit, config: {'current_round': 77, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m [Client 9] fit, config: {'current_round': 77, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m Epoch 1: train loss 8.427543070865795e-05, accuracy 0.6296296296296297\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m [Client 75] fit, config: {'current_round': 77, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m [Client 26] fit, config: {'current_round': 77, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m [Client 79] fit, config: {'current_round': 77, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m Epoch 1: train loss 8.55215621413663e-05, accuracy 0.6296296296296297\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m Epoch 1: train loss 0.00010442087659612298, accuracy 0.5555555555555556\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m Epoch 1: train loss 0.0001094587059924379, accuracy 0.5370370370370371\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m [Client 71] fit, config: {'current_round': 77, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m Epoch 1: train loss 9.14799893507734e-05, accuracy 0.6296296296296297\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m Epoch 1: train loss 8.8112210505642e-05, accuracy 0.6296296296296297\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m [Client 38] fit, config: {'current_round': 77, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m [Client 48] fit, config: {'current_round': 77, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m [Client 39] fit, config: {'current_round': 77, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m Epoch 1: train loss 8.375124161830172e-05, accuracy 0.6851851851851852\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m Epoch 1: train loss 9.207554103340954e-05, accuracy 0.6666666666666666\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m Epoch 1: train loss 9.04924381757155e-05, accuracy 0.6851851851851852\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m [Client 87] fit, config: {'current_round': 77, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m Epoch 1: train loss 8.873474871506914e-05, accuracy 0.6296296296296297\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m [Client 66] fit, config: {'current_round': 77, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m Epoch 1: train loss 7.864204962970689e-05, accuracy 0.6851851851851852\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m [Client 33] fit, config: {'current_round': 77, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m Epoch 1: train loss 0.00010036263120127842, accuracy 0.5740740740740741\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m [Client 21] fit, config: {'current_round': 77, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m [Client 76] fit, config: {'current_round': 77, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m Epoch 1: train loss 6.47992710582912e-05, accuracy 0.7037037037037037\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m [Client 60] fit, config: {'current_round': 77, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m Epoch 1: train loss 9.058716386789456e-05, accuracy 0.6851851851851852\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m [Client 20] fit, config: {'current_round': 77, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m [Client 13] fit, config: {'current_round': 77, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m Epoch 1: train loss 9.75982693489641e-05, accuracy 0.5925925925925926\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m [Client 16] fit, config: {'current_round': 77, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m Epoch 1: train loss 0.0001257486001122743, accuracy 0.42592592592592593\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m [Client 10] fit, config: {'current_round': 77, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m Epoch 1: train loss 9.081738244276494e-05, accuracy 0.6111111111111112\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m Epoch 1: train loss 0.00010556356573943049, accuracy 0.6481481481481481\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m Epoch 1: train loss 0.00010292993829352781, accuracy 0.5555555555555556\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 13:00:00,073 | server.py:216 | fit_round received 30 results and 0 failures\n",
      "DEBUG flower 2023-02-01 13:00:00,134 | server.py:157 | evaluate_round: strategy sampled 30 clients (out of 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m [Client 4] fit, config: {'current_round': 77, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m Epoch 1: train loss 9.826591849559918e-05, accuracy 0.5925925925925926\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m [Client 80] fit, config: {'current_round': 77, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m Epoch 1: train loss 6.977328303037211e-05, accuracy 0.8148148148148148\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m [Client 30] fit, config: {'current_round': 77, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m Epoch 1: train loss 9.949171362677589e-05, accuracy 0.5925925925925926\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m [Client 41] fit, config: {'current_round': 77, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m Epoch 1: train loss 7.9874720540829e-05, accuracy 0.6296296296296297\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m [Client 55] fit, config: {'current_round': 77, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m Epoch 1: train loss 9.296595817431808e-05, accuracy 0.5925925925925926\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m [Client 12] fit, config: {'current_round': 77, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m Epoch 1: train loss 9.520941239316016e-05, accuracy 0.7037037037037037\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m [Client 94] fit, config: {'current_round': 77, 'local_epochs': 3}\n",
      "Saving round 77 aggregated_parameters...\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m Epoch 1: train loss 8.315005106851459e-05, accuracy 0.6666666666666666\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m [Client 45] fit, config: {'current_round': 77, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m Epoch 1: train loss 8.804999379208311e-05, accuracy 0.6851851851851852\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98092)\u001b[0m [Client 23] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98092)\u001b[0m [Client 30] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98092)\u001b[0m [Client 29] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98092)\u001b[0m [Client 31] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98092)\u001b[0m [Client 37] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98088)\u001b[0m [Client 53] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98092)\u001b[0m [Client 38] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98090)\u001b[0m [Client 96] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98088)\u001b[0m [Client 78] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98095)\u001b[0m [Client 4] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98093)\u001b[0m [Client 93] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98089)\u001b[0m [Client 51] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98094)\u001b[0m [Client 0] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98088)\u001b[0m [Client 17] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98093)\u001b[0m [Client 73] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98089)\u001b[0m [Client 5] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98093)\u001b[0m [Client 13] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98093)\u001b[0m [Client 77] evaluate, config: {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 13:00:02,794 | server.py:170 | evaluate_round received 0 results and 30 failures\n",
      "DEBUG flower 2023-02-01 13:00:02,802 | server.py:203 | fit_round: strategy sampled 30 clients (out of 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98089)\u001b[0m [Client 68] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98088)\u001b[0m [Client 40] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98094)\u001b[0m [Client 14] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98090)\u001b[0m [Client 52] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98095)\u001b[0m [Client 20] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98088)\u001b[0m [Client 19] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98089)\u001b[0m [Client 99] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98092)\u001b[0m [Client 12] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98090)\u001b[0m [Client 48] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98095)\u001b[0m [Client 43] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98093)\u001b[0m [Client 18] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98094)\u001b[0m [Client 21] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m [Client 69] fit, config: {'current_round': 78, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m Epoch 1: train loss 8.13955266494304e-05, accuracy 0.6851851851851852\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m [Client 78] fit, config: {'current_round': 78, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m [Client 37] fit, config: {'current_round': 78, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m Epoch 1: train loss 7.759327854728326e-05, accuracy 0.7407407407407407\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m Epoch 1: train loss 0.00010741879668785259, accuracy 0.5370370370370371\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m [Client 88] fit, config: {'current_round': 78, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m Epoch 1: train loss 8.035013888729736e-05, accuracy 0.6296296296296297\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m [Client 90] fit, config: {'current_round': 78, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m Epoch 1: train loss 8.472389890812337e-05, accuracy 0.7037037037037037\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m [Client 81] fit, config: {'current_round': 78, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m Epoch 1: train loss 0.00010455648589413613, accuracy 0.6111111111111112\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m [Client 87] fit, config: {'current_round': 78, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m [Client 9] fit, config: {'current_round': 78, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m Epoch 1: train loss 9.869449422694743e-05, accuracy 0.6851851851851852\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m Epoch 1: train loss 8.031137986108661e-05, accuracy 0.7037037037037037\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m [Client 52] fit, config: {'current_round': 78, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m Epoch 1: train loss 9.412577492184937e-05, accuracy 0.6296296296296297\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m [Client 71] fit, config: {'current_round': 78, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m [Client 56] fit, config: {'current_round': 78, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m Epoch 1: train loss 0.00010090955765917897, accuracy 0.6111111111111112\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m [Client 70] fit, config: {'current_round': 78, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m Epoch 1: train loss 0.00012186833919258788, accuracy 0.6666666666666666\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m Epoch 1: train loss 7.554634794360027e-05, accuracy 0.7962962962962963\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m [Client 18] fit, config: {'current_round': 78, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m [Client 63] fit, config: {'current_round': 78, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m Epoch 1: train loss 9.43363702390343e-05, accuracy 0.5555555555555556\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m [Client 75] fit, config: {'current_round': 78, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m Epoch 1: train loss 0.00011105368321295828, accuracy 0.6666666666666666\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m Epoch 1: train loss 9.805376612348482e-05, accuracy 0.6111111111111112\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m [Client 50] fit, config: {'current_round': 78, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m Epoch 1: train loss 8.693159907124937e-05, accuracy 0.6666666666666666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 13:00:05,285 | server.py:216 | fit_round received 30 results and 0 failures\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m [Client 21] fit, config: {'current_round': 78, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m Epoch 1: train loss 0.00010668135655578226, accuracy 0.6111111111111112\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m [Client 1] fit, config: {'current_round': 78, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m Epoch 1: train loss 9.717998909763992e-05, accuracy 0.5925925925925926\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m [Client 68] fit, config: {'current_round': 78, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m Epoch 1: train loss 8.229995728470385e-05, accuracy 0.6851851851851852\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m [Client 3] fit, config: {'current_round': 78, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m [Client 92] fit, config: {'current_round': 78, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m [Client 51] fit, config: {'current_round': 78, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m Epoch 1: train loss 8.95900375326164e-05, accuracy 0.6666666666666666\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m [Client 58] fit, config: {'current_round': 78, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m Epoch 1: train loss 8.983670704765245e-05, accuracy 0.6481481481481481\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m Epoch 1: train loss 0.00010243401629850268, accuracy 0.6481481481481481\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m Epoch 1: train loss 0.00010241857671644539, accuracy 0.6111111111111112\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m [Client 85] fit, config: {'current_round': 78, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m [Client 35] fit, config: {'current_round': 78, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m [Client 12] fit, config: {'current_round': 78, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m Epoch 1: train loss 9.461167064728215e-05, accuracy 0.6481481481481481\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m [Client 22] fit, config: {'current_round': 78, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m Epoch 1: train loss 0.00011522389831952751, accuracy 0.5185185185185185\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m [Client 89] fit, config: {'current_round': 78, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m Epoch 1: train loss 9.419190610060468e-05, accuracy 0.6481481481481481\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m Epoch 1: train loss 9.119575406657532e-05, accuracy 0.7037037037037037\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m Epoch 1: train loss 0.00011470804020063952, accuracy 0.4444444444444444\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m [Client 7] fit, config: {'current_round': 78, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m Epoch 1: train loss 0.000100155986729078, accuracy 0.7407407407407407\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m [Client 33] fit, config: {'current_round': 78, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m Epoch 1: train loss 8.567937038606033e-05, accuracy 0.7222222222222222\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 13:00:05,357 | server.py:157 | evaluate_round: strategy sampled 30 clients (out of 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving round 78 aggregated_parameters...\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98090)\u001b[0m [Client 76] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98095)\u001b[0m [Client 28] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98088)\u001b[0m [Client 17] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98093)\u001b[0m [Client 81] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98089)\u001b[0m [Client 87] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98094)\u001b[0m [Client 68] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98092)\u001b[0m [Client 2] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98094)\u001b[0m [Client 36] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98092)\u001b[0m [Client 67] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98093)\u001b[0m [Client 99] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98093)\u001b[0m [Client 66] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98094)\u001b[0m [Client 8] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98093)\u001b[0m [Client 40] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98093)\u001b[0m [Client 18] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98093)\u001b[0m [Client 71] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98094)\u001b[0m [Client 13] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98092)\u001b[0m [Client 9] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98092)\u001b[0m [Client 45] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98090)\u001b[0m [Client 11] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98088)\u001b[0m [Client 82] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98088)\u001b[0m [Client 70] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98093)\u001b[0m [Client 44] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98089)\u001b[0m [Client 24] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98094)\u001b[0m [Client 51] evaluate, config: {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 13:00:07,609 | server.py:170 | evaluate_round received 0 results and 30 failures\n",
      "DEBUG flower 2023-02-01 13:00:07,610 | server.py:203 | fit_round: strategy sampled 30 clients (out of 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98090)\u001b[0m [Client 38] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98088)\u001b[0m [Client 7] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98093)\u001b[0m [Client 35] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98089)\u001b[0m [Client 20] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98094)\u001b[0m [Client 57] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98092)\u001b[0m [Client 63] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m [Client 52] fit, config: {'current_round': 79, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m Epoch 1: train loss 8.899078966351226e-05, accuracy 0.6666666666666666\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m [Client 2] fit, config: {'current_round': 79, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m Epoch 1: train loss 6.78250944474712e-05, accuracy 0.7592592592592593\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m [Client 76] fit, config: {'current_round': 79, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m [Client 85] fit, config: {'current_round': 79, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m Epoch 1: train loss 6.407142791431397e-05, accuracy 0.7407407407407407\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m [Client 93] fit, config: {'current_round': 79, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m Epoch 1: train loss 0.00010331550583941862, accuracy 0.5370370370370371\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m [Client 36] fit, config: {'current_round': 79, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m Epoch 1: train loss 0.00010360416490584612, accuracy 0.5740740740740741\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m [Client 92] fit, config: {'current_round': 79, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m Epoch 1: train loss 9.028817294165492e-05, accuracy 0.7407407407407407\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m Epoch 1: train loss 7.831260154489428e-05, accuracy 0.7222222222222222\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m [Client 48] fit, config: {'current_round': 79, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m Epoch 1: train loss 9.436285472474992e-05, accuracy 0.7037037037037037\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m [Client 10] fit, config: {'current_round': 79, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m [Client 87] fit, config: {'current_round': 79, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m Epoch 1: train loss 8.813348540570587e-05, accuracy 0.6481481481481481\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m [Client 5] fit, config: {'current_round': 79, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m Epoch 1: train loss 9.069150110008195e-05, accuracy 0.5925925925925926\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m Epoch 1: train loss 8.703198545845225e-05, accuracy 0.6296296296296297\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m [Client 67] fit, config: {'current_round': 79, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m [Client 66] fit, config: {'current_round': 79, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m Epoch 1: train loss 7.608703890582547e-05, accuracy 0.6851851851851852\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m Epoch 1: train loss 0.00011506345617817715, accuracy 0.5925925925925926\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m [Client 79] fit, config: {'current_round': 79, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m Epoch 1: train loss 8.419992082053795e-05, accuracy 0.6111111111111112\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m [Client 23] fit, config: {'current_round': 79, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m Epoch 1: train loss 8.253390114987269e-05, accuracy 0.7222222222222222\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m [Client 7] fit, config: {'current_round': 79, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m Epoch 1: train loss 9.235970355803147e-05, accuracy 0.7037037037037037\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m [Client 49] fit, config: {'current_round': 79, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m [Client 61] fit, config: {'current_round': 79, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m Epoch 1: train loss 8.907852316042408e-05, accuracy 0.6296296296296297\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m Epoch 1: train loss 0.00010330119403079152, accuracy 0.5740740740740741\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m [Client 9] fit, config: {'current_round': 79, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m Epoch 1: train loss 0.00010634195496095344, accuracy 0.5370370370370371\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m [Client 80] fit, config: {'current_round': 79, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m [Client 38] fit, config: {'current_round': 79, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m Epoch 1: train loss 9.049232176039368e-05, accuracy 0.7037037037037037\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m Epoch 1: train loss 6.88086001900956e-05, accuracy 0.7962962962962963\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m [Client 1] fit, config: {'current_round': 79, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m Epoch 1: train loss 8.630027150502428e-05, accuracy 0.5925925925925926\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m [Client 37] fit, config: {'current_round': 79, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m [Client 25] fit, config: {'current_round': 79, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m [Client 98] fit, config: {'current_round': 79, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m Epoch 1: train loss 0.00010876245505642146, accuracy 0.5740740740740741\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m [Client 91] fit, config: {'current_round': 79, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m Epoch 1: train loss 9.117969602812082e-05, accuracy 0.5370370370370371\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m Epoch 1: train loss 6.865853356430307e-05, accuracy 0.6851851851851852\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m Epoch 1: train loss 7.932634616736323e-05, accuracy 0.6296296296296297\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m [Client 14] fit, config: {'current_round': 79, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m Epoch 1: train loss 9.21400060178712e-05, accuracy 0.5925925925925926\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m [Client 97] fit, config: {'current_round': 79, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m Epoch 1: train loss 0.00013215579383540899, accuracy 0.5555555555555556\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 13:00:09,900 | server.py:216 | fit_round received 30 results and 0 failures\n",
      "DEBUG flower 2023-02-01 13:00:09,957 | server.py:157 | evaluate_round: strategy sampled 30 clients (out of 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m [Client 26] fit, config: {'current_round': 79, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m Epoch 1: train loss 0.00010246539022773504, accuracy 0.5555555555555556\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m [Client 64] fit, config: {'current_round': 79, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m Epoch 1: train loss 7.391347025986761e-05, accuracy 0.7777777777777778\n",
      "Saving round 79 aggregated_parameters...\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98089)\u001b[0m [Client 89] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98092)\u001b[0m [Client 80] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98095)\u001b[0m [Client 8] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98093)\u001b[0m [Client 79] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98095)\u001b[0m [Client 27] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98095)\u001b[0m [Client 68] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98095)\u001b[0m [Client 60] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98095)\u001b[0m [Client 99] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98093)\u001b[0m [Client 24] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98093)\u001b[0m [Client 2] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98095)\u001b[0m [Client 67] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98092)\u001b[0m [Client 95] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98095)\u001b[0m [Client 82] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98093)\u001b[0m [Client 48] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98095)\u001b[0m [Client 44] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98089)\u001b[0m [Client 98] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98092)\u001b[0m [Client 88] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98089)\u001b[0m [Client 94] evaluate, config: {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 13:00:12,372 | server.py:170 | evaluate_round received 0 results and 30 failures\n",
      "DEBUG flower 2023-02-01 13:00:12,375 | server.py:203 | fit_round: strategy sampled 30 clients (out of 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98092)\u001b[0m [Client 51] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98090)\u001b[0m [Client 56] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98088)\u001b[0m [Client 9] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98095)\u001b[0m [Client 86] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98093)\u001b[0m [Client 75] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98090)\u001b[0m [Client 26] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98090)\u001b[0m [Client 28] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98088)\u001b[0m [Client 54] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98095)\u001b[0m [Client 7] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98093)\u001b[0m [Client 16] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98089)\u001b[0m [Client 81] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98092)\u001b[0m [Client 52] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m [Client 26] fit, config: {'current_round': 80, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m Epoch 1: train loss 9.625886013964191e-05, accuracy 0.6296296296296297\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m [Client 0] fit, config: {'current_round': 80, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m Epoch 1: train loss 0.00011467134027043357, accuracy 0.5925925925925926\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m [Client 82] fit, config: {'current_round': 80, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m Epoch 1: train loss 8.049733878578991e-05, accuracy 0.6666666666666666\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m [Client 51] fit, config: {'current_round': 80, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m Epoch 1: train loss 8.623649046057835e-05, accuracy 0.6666666666666666\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m [Client 68] fit, config: {'current_round': 80, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m [Client 91] fit, config: {'current_round': 80, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m [Client 90] fit, config: {'current_round': 80, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m [Client 89] fit, config: {'current_round': 80, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m Epoch 1: train loss 8.926603914005682e-05, accuracy 0.6666666666666666\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m [Client 41] fit, config: {'current_round': 80, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m Epoch 1: train loss 8.731090929359198e-05, accuracy 0.6666666666666666\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m [Client 97] fit, config: {'current_round': 80, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m Epoch 1: train loss 0.00012158617028035223, accuracy 0.5925925925925926\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m Epoch 1: train loss 7.895121962064877e-05, accuracy 0.6481481481481481\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m Epoch 1: train loss 7.542746607214212e-05, accuracy 0.7037037037037037\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m Epoch 1: train loss 8.305250958073884e-05, accuracy 0.7037037037037037\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m [Client 85] fit, config: {'current_round': 80, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m Epoch 1: train loss 0.00011193847603863105, accuracy 0.48148148148148145\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m [Client 86] fit, config: {'current_round': 80, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m Epoch 1: train loss 7.623646524734795e-05, accuracy 0.7777777777777778\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m [Client 11] fit, config: {'current_round': 80, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m Epoch 1: train loss 9.28710142034106e-05, accuracy 0.6666666666666666\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m [Client 28] fit, config: {'current_round': 80, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m Epoch 1: train loss 8.047818118939176e-05, accuracy 0.7222222222222222\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m [Client 59] fit, config: {'current_round': 80, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m Epoch 1: train loss 8.94376280484721e-05, accuracy 0.6851851851851852\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m [Client 77] fit, config: {'current_round': 80, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m Epoch 1: train loss 9.344661521026865e-05, accuracy 0.7037037037037037\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m [Client 62] fit, config: {'current_round': 80, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m Epoch 1: train loss 8.260453614639118e-05, accuracy 0.6851851851851852\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m [Client 14] fit, config: {'current_round': 80, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m Epoch 1: train loss 9.153489372693002e-05, accuracy 0.6481481481481481\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m [Client 76] fit, config: {'current_round': 80, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m [Client 78] fit, config: {'current_round': 80, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m Epoch 1: train loss 0.00010483412916073576, accuracy 0.5555555555555556\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m [Client 1] fit, config: {'current_round': 80, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m Epoch 1: train loss 9.153583232546225e-05, accuracy 0.5740740740740741\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m [Client 53] fit, config: {'current_round': 80, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m Epoch 1: train loss 8.339087798958644e-05, accuracy 0.7222222222222222\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m Epoch 1: train loss 7.261844439199194e-05, accuracy 0.6851851851851852\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m [Client 3] fit, config: {'current_round': 80, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m [Client 52] fit, config: {'current_round': 80, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m [Client 60] fit, config: {'current_round': 80, 'local_epochs': 3}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 13:00:14,925 | server.py:216 | fit_round received 30 results and 0 failures\n",
      "DEBUG flower 2023-02-01 13:00:14,983 | server.py:157 | evaluate_round: strategy sampled 30 clients (out of 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m [Client 55] fit, config: {'current_round': 80, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m [Client 84] fit, config: {'current_round': 80, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m Epoch 1: train loss 8.311375131597742e-05, accuracy 0.7037037037037037\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m [Client 21] fit, config: {'current_round': 80, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m Epoch 1: train loss 0.00010299822315573692, accuracy 0.6481481481481481\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m [Client 75] fit, config: {'current_round': 80, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m Epoch 1: train loss 9.83057398116216e-05, accuracy 0.6666666666666666\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m Epoch 1: train loss 8.890620665624738e-05, accuracy 0.6296296296296297\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m Epoch 1: train loss 8.376001642318442e-05, accuracy 0.7037037037037037\n",
      "Saving round 80 aggregated_parameters...\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m Epoch 1: train loss 7.892344001447782e-05, accuracy 0.7777777777777778\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m [Client 37] fit, config: {'current_round': 80, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m Epoch 1: train loss 7.408869714708999e-05, accuracy 0.7407407407407407\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m Epoch 1: train loss 0.0001092676175176166, accuracy 0.6481481481481481\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98088)\u001b[0m [Client 15] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98091)\u001b[0m [Client 64] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98088)\u001b[0m [Client 39] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98093)\u001b[0m [Client 2] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98091)\u001b[0m [Client 9] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98091)\u001b[0m [Client 83] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98091)\u001b[0m [Client 20] evaluate, config: {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 13:00:17,251 | server.py:170 | evaluate_round received 0 results and 30 failures\n",
      "DEBUG flower 2023-02-01 13:00:17,251 | server.py:203 | fit_round: strategy sampled 30 clients (out of 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98091)\u001b[0m [Client 42] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98095)\u001b[0m [Client 46] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98093)\u001b[0m [Client 11] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98092)\u001b[0m [Client 25] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98091)\u001b[0m [Client 29] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98090)\u001b[0m [Client 62] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98088)\u001b[0m [Client 53] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98095)\u001b[0m [Client 4] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98093)\u001b[0m [Client 6] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98089)\u001b[0m [Client 37] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98094)\u001b[0m [Client 61] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98094)\u001b[0m [Client 72] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98094)\u001b[0m [Client 92] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98091)\u001b[0m [Client 87] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98090)\u001b[0m [Client 65] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98088)\u001b[0m [Client 93] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98095)\u001b[0m [Client 23] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98093)\u001b[0m [Client 34] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98089)\u001b[0m [Client 18] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98094)\u001b[0m [Client 47] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98090)\u001b[0m [Client 77] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98094)\u001b[0m [Client 16] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98092)\u001b[0m [Client 19] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m [Client 43] fit, config: {'current_round': 81, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m [Client 95] fit, config: {'current_round': 81, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m Epoch 1: train loss 8.034316124394536e-05, accuracy 0.7592592592592593\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m [Client 38] fit, config: {'current_round': 81, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m Epoch 1: train loss 8.844878902891651e-05, accuracy 0.6851851851851852\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m [Client 25] fit, config: {'current_round': 81, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m Epoch 1: train loss 8.173877722583711e-05, accuracy 0.6111111111111112\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m Epoch 1: train loss 6.509097147500142e-05, accuracy 0.7037037037037037\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m [Client 96] fit, config: {'current_round': 81, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m Epoch 1: train loss 7.023350190138444e-05, accuracy 0.7037037037037037\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m [Client 37] fit, config: {'current_round': 81, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m Epoch 1: train loss 6.72692185617052e-05, accuracy 0.7592592592592593\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m [Client 99] fit, config: {'current_round': 81, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m Epoch 1: train loss 9.0102716058027e-05, accuracy 0.6481481481481481\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m [Client 78] fit, config: {'current_round': 81, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m [Client 71] fit, config: {'current_round': 81, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m [Client 32] fit, config: {'current_round': 81, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m Epoch 1: train loss 8.567165059503168e-05, accuracy 0.6296296296296297\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m [Client 41] fit, config: {'current_round': 81, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m [Client 87] fit, config: {'current_round': 81, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m Epoch 1: train loss 8.97684003575705e-05, accuracy 0.6296296296296297\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m Epoch 1: train loss 9.010688518173993e-05, accuracy 0.6111111111111112\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m Epoch 1: train loss 8.3041304606013e-05, accuracy 0.5555555555555556\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m [Client 36] fit, config: {'current_round': 81, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m Epoch 1: train loss 0.00010399385791970417, accuracy 0.5740740740740741\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m [Client 67] fit, config: {'current_round': 81, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m Epoch 1: train loss 0.00011658887524390593, accuracy 0.6296296296296297\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m [Client 65] fit, config: {'current_round': 81, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m Epoch 1: train loss 8.162017184076831e-05, accuracy 0.6111111111111112\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m Epoch 1: train loss 8.716826414456591e-05, accuracy 0.6296296296296297\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m [Client 48] fit, config: {'current_round': 81, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m Epoch 1: train loss 9.280862286686897e-05, accuracy 0.6666666666666666\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m [Client 15] fit, config: {'current_round': 81, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m Epoch 1: train loss 0.00011231694224989042, accuracy 0.5555555555555556\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m [Client 8] fit, config: {'current_round': 81, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m Epoch 1: train loss 9.19255762710236e-05, accuracy 0.5370370370370371\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m [Client 56] fit, config: {'current_round': 81, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m Epoch 1: train loss 0.00010314034443581477, accuracy 0.5370370370370371\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 13:00:19,766 | server.py:216 | fit_round received 30 results and 0 failures\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m [Client 6] fit, config: {'current_round': 81, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m Epoch 1: train loss 8.877335494617e-05, accuracy 0.6481481481481481\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m [Client 45] fit, config: {'current_round': 81, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m Epoch 1: train loss 8.630068623460829e-05, accuracy 0.6851851851851852\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m [Client 4] fit, config: {'current_round': 81, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m Epoch 1: train loss 9.971141844289377e-05, accuracy 0.6296296296296297\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m [Client 2] fit, config: {'current_round': 81, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m [Client 93] fit, config: {'current_round': 81, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m [Client 51] fit, config: {'current_round': 81, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m Epoch 1: train loss 8.797608461463824e-05, accuracy 0.6481481481481481\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m [Client 64] fit, config: {'current_round': 81, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m [Client 73] fit, config: {'current_round': 81, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m [Client 26] fit, config: {'current_round': 81, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m Epoch 1: train loss 0.00010433157876832411, accuracy 0.5370370370370371\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m Epoch 1: train loss 6.842294533271343e-05, accuracy 0.7592592592592593\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m Epoch 1: train loss 7.660160190425813e-05, accuracy 0.7222222222222222\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m [Client 57] fit, config: {'current_round': 81, 'local_epochs': 3}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 13:00:19,820 | server.py:157 | evaluate_round: strategy sampled 30 clients (out of 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving round 81 aggregated_parameters...\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m [Client 89] fit, config: {'current_round': 81, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m Epoch 1: train loss 8.590456855017692e-05, accuracy 0.5925925925925926\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m Epoch 1: train loss 7.25272111594677e-05, accuracy 0.7222222222222222\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m Epoch 1: train loss 9.57319643930532e-05, accuracy 0.5925925925925926\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m Epoch 1: train loss 8.786854596110061e-05, accuracy 0.6481481481481481\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98090)\u001b[0m [Client 89] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98090)\u001b[0m [Client 98] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98090)\u001b[0m [Client 5] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98090)\u001b[0m [Client 29] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98090)\u001b[0m [Client 19] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98090)\u001b[0m [Client 65] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98090)\u001b[0m [Client 84] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98095)\u001b[0m [Client 35] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98089)\u001b[0m [Client 57] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98091)\u001b[0m [Client 14] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98090)\u001b[0m [Client 0] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98093)\u001b[0m [Client 20] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98094)\u001b[0m [Client 80] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98092)\u001b[0m [Client 81] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98088)\u001b[0m [Client 74] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98088)\u001b[0m [Client 10] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98088)\u001b[0m [Client 62] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98088)\u001b[0m [Client 85] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98091)\u001b[0m [Client 49] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98090)\u001b[0m [Client 77] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98088)\u001b[0m [Client 1] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98095)\u001b[0m [Client 7] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98093)\u001b[0m [Client 96] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98092)\u001b[0m [Client 27] evaluate, config: {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 13:00:22,112 | server.py:170 | evaluate_round received 0 results and 30 failures\n",
      "DEBUG flower 2023-02-01 13:00:22,113 | server.py:203 | fit_round: strategy sampled 30 clients (out of 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98091)\u001b[0m [Client 93] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98090)\u001b[0m [Client 39] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98088)\u001b[0m [Client 73] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98093)\u001b[0m [Client 9] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98089)\u001b[0m [Client 13] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98094)\u001b[0m [Client 11] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m [Client 40] fit, config: {'current_round': 82, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m [Client 36] fit, config: {'current_round': 82, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m Epoch 1: train loss 0.00010341674351366237, accuracy 0.6296296296296297\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m Epoch 1: train loss 7.392794941551983e-05, accuracy 0.7407407407407407\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m [Client 61] fit, config: {'current_round': 82, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m Epoch 1: train loss 8.925014117266983e-05, accuracy 0.6851851851851852\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m [Client 19] fit, config: {'current_round': 82, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m Epoch 1: train loss 7.190320320660248e-05, accuracy 0.7592592592592593\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m [Client 90] fit, config: {'current_round': 82, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m Epoch 1: train loss 8.233725384343415e-05, accuracy 0.7222222222222222\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m [Client 56] fit, config: {'current_round': 82, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m Epoch 1: train loss 9.649228741182014e-05, accuracy 0.6481481481481481\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m [Client 84] fit, config: {'current_round': 82, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m Epoch 1: train loss 8.212648390326649e-05, accuracy 0.7407407407407407\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m [Client 51] fit, config: {'current_round': 82, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m [Client 76] fit, config: {'current_round': 82, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m Epoch 1: train loss 7.024974911473691e-05, accuracy 0.7222222222222222\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m [Client 1] fit, config: {'current_round': 82, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m [Client 17] fit, config: {'current_round': 82, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m Epoch 1: train loss 7.832900155335665e-05, accuracy 0.7777777777777778\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m Epoch 1: train loss 8.37432307889685e-05, accuracy 0.7407407407407407\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m [Client 91] fit, config: {'current_round': 82, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m [Client 44] fit, config: {'current_round': 82, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m Epoch 1: train loss 0.00010323430615244433, accuracy 0.6296296296296297\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m [Client 89] fit, config: {'current_round': 82, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m Epoch 1: train loss 8.908303425414488e-05, accuracy 0.6666666666666666\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m [Client 59] fit, config: {'current_round': 82, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m Epoch 1: train loss 8.817368507152423e-05, accuracy 0.6851851851851852\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m [Client 99] fit, config: {'current_round': 82, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m Epoch 1: train loss 7.506626570830122e-05, accuracy 0.7037037037037037\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m Epoch 1: train loss 9.021247387863696e-05, accuracy 0.5925925925925926\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m [Client 95] fit, config: {'current_round': 82, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m Epoch 1: train loss 6.773585482733324e-05, accuracy 0.7592592592592593\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m Epoch 1: train loss 7.659709808649495e-05, accuracy 0.7592592592592593\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m [Client 25] fit, config: {'current_round': 82, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m Epoch 1: train loss 8.420955418841913e-05, accuracy 0.7222222222222222\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m [Client 39] fit, config: {'current_round': 82, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m Epoch 1: train loss 8.268909732578322e-05, accuracy 0.6111111111111112\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m [Client 29] fit, config: {'current_round': 82, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m [Client 83] fit, config: {'current_round': 82, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m Epoch 1: train loss 9.142907219938934e-05, accuracy 0.5925925925925926\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m [Client 60] fit, config: {'current_round': 82, 'local_epochs': 3}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 13:00:24,456 | server.py:216 | fit_round received 30 results and 0 failures\n",
      "DEBUG flower 2023-02-01 13:00:24,510 | server.py:157 | evaluate_round: strategy sampled 30 clients (out of 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m [Client 74] fit, config: {'current_round': 82, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m Epoch 1: train loss 8.5671606939286e-05, accuracy 0.6851851851851852\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m [Client 14] fit, config: {'current_round': 82, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m [Client 34] fit, config: {'current_round': 82, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m Epoch 1: train loss 8.056934166233987e-05, accuracy 0.6481481481481481\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m [Client 52] fit, config: {'current_round': 82, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m Epoch 1: train loss 8.236875146394596e-05, accuracy 0.7037037037037037\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m [Client 98] fit, config: {'current_round': 82, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m Epoch 1: train loss 9.230987052433193e-05, accuracy 0.6296296296296297\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m Epoch 1: train loss 0.00010083356028189883, accuracy 0.6851851851851852\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m Epoch 1: train loss 9.124535426963121e-05, accuracy 0.7037037037037037\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m [Client 88] fit, config: {'current_round': 82, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m Epoch 1: train loss 7.38412854843773e-05, accuracy 0.7037037037037037\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m Epoch 1: train loss 8.901180990505964e-05, accuracy 0.6481481481481481\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m [Client 46] fit, config: {'current_round': 82, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m Epoch 1: train loss 7.000799814704806e-05, accuracy 0.7592592592592593\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m [Client 6] fit, config: {'current_round': 82, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m Epoch 1: train loss 9.52191257965751e-05, accuracy 0.6666666666666666\n",
      "Saving round 82 aggregated_parameters...\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98094)\u001b[0m [Client 77] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98095)\u001b[0m [Client 55] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98094)\u001b[0m [Client 4] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98092)\u001b[0m [Client 58] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98092)\u001b[0m [Client 18] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98092)\u001b[0m [Client 7] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98095)\u001b[0m [Client 91] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98095)\u001b[0m [Client 24] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98094)\u001b[0m [Client 74] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98092)\u001b[0m [Client 66] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98095)\u001b[0m [Client 38] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98094)\u001b[0m [Client 30] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98094)\u001b[0m [Client 2] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98092)\u001b[0m [Client 43] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98095)\u001b[0m [Client 27] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98093)\u001b[0m [Client 98] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98095)\u001b[0m [Client 73] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98095)\u001b[0m [Client 92] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98091)\u001b[0m [Client 46] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98090)\u001b[0m [Client 16] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98095)\u001b[0m [Client 64] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98089)\u001b[0m [Client 9] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98094)\u001b[0m [Client 35] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98092)\u001b[0m [Client 36] evaluate, config: {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 13:00:26,682 | server.py:170 | evaluate_round received 0 results and 30 failures\n",
      "DEBUG flower 2023-02-01 13:00:26,683 | server.py:203 | fit_round: strategy sampled 30 clients (out of 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98091)\u001b[0m [Client 5] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98090)\u001b[0m [Client 1] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98088)\u001b[0m [Client 65] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98093)\u001b[0m [Client 87] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98089)\u001b[0m [Client 76] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98095)\u001b[0m [Client 79] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m [Client 2] fit, config: {'current_round': 83, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m Epoch 1: train loss 7.023478246992454e-05, accuracy 0.6851851851851852\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m [Client 80] fit, config: {'current_round': 83, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m Epoch 1: train loss 7.23935809219256e-05, accuracy 0.7037037037037037\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m [Client 66] fit, config: {'current_round': 83, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m Epoch 1: train loss 7.77620225562714e-05, accuracy 0.6851851851851852\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m [Client 46] fit, config: {'current_round': 83, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m Epoch 1: train loss 6.510657112812623e-05, accuracy 0.7777777777777778\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m [Client 11] fit, config: {'current_round': 83, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m Epoch 1: train loss 8.802338561508805e-05, accuracy 0.6296296296296297\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m [Client 36] fit, config: {'current_round': 83, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m Epoch 1: train loss 0.00010397303412901238, accuracy 0.5740740740740741\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m [Client 6] fit, config: {'current_round': 83, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m Epoch 1: train loss 8.791092841420323e-05, accuracy 0.6851851851851852\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m [Client 97] fit, config: {'current_round': 83, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m Epoch 1: train loss 0.00013303259038366377, accuracy 0.5185185185185185\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m [Client 10] fit, config: {'current_round': 83, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m Epoch 1: train loss 8.948598406277597e-05, accuracy 0.6296296296296297\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m [Client 21] fit, config: {'current_round': 83, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m Epoch 1: train loss 0.00011476661165943369, accuracy 0.5370370370370371\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m [Client 5] fit, config: {'current_round': 83, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m [Client 98] fit, config: {'current_round': 83, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m Epoch 1: train loss 0.00010748545901151374, accuracy 0.6481481481481481\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m Epoch 1: train loss 8.941009582486004e-05, accuracy 0.6296296296296297\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m [Client 92] fit, config: {'current_round': 83, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m [Client 43] fit, config: {'current_round': 83, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m Epoch 1: train loss 8.040408283704892e-05, accuracy 0.7407407407407407\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m [Client 4] fit, config: {'current_round': 83, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m Epoch 1: train loss 0.00010094288882100955, accuracy 0.5740740740740741\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m [Client 91] fit, config: {'current_round': 83, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m Epoch 1: train loss 8.505061123287305e-05, accuracy 0.7407407407407407\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m Epoch 1: train loss 9.38463126658462e-05, accuracy 0.6666666666666666\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m [Client 74] fit, config: {'current_round': 83, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m [Client 90] fit, config: {'current_round': 83, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m Epoch 1: train loss 8.161528967320919e-05, accuracy 0.7037037037037037\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m [Client 88] fit, config: {'current_round': 83, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m Epoch 1: train loss 8.54252211865969e-05, accuracy 0.6481481481481481\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m [Client 55] fit, config: {'current_round': 83, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m [Client 89] fit, config: {'current_round': 83, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m Epoch 1: train loss 8.122785220621154e-05, accuracy 0.6296296296296297\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m [Client 26] fit, config: {'current_round': 83, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m Epoch 1: train loss 0.00010330474469810724, accuracy 0.6296296296296297\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m Epoch 1: train loss 0.00010217710951110348, accuracy 0.6851851851851852\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m Epoch 1: train loss 9.053020767169073e-05, accuracy 0.6481481481481481\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m [Client 73] fit, config: {'current_round': 83, 'local_epochs': 3}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 13:00:29,043 | server.py:216 | fit_round received 30 results and 0 failures\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m Epoch 1: train loss 8.414370677201077e-05, accuracy 0.6851851851851852\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m [Client 86] fit, config: {'current_round': 83, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m Epoch 1: train loss 7.782733155181631e-05, accuracy 0.7037037037037037\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m [Client 81] fit, config: {'current_round': 83, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m Epoch 1: train loss 9.735233470564708e-05, accuracy 0.5925925925925926\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m [Client 99] fit, config: {'current_round': 83, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m Epoch 1: train loss 8.995281677925959e-05, accuracy 0.6111111111111112\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m [Client 41] fit, config: {'current_round': 83, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m Epoch 1: train loss 8.979397534858435e-05, accuracy 0.5370370370370371\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m [Client 58] fit, config: {'current_round': 83, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m Epoch 1: train loss 0.00010074437886942178, accuracy 0.5740740740740741\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m [Client 13] fit, config: {'current_round': 83, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m Epoch 1: train loss 9.882039739750326e-05, accuracy 0.5740740740740741\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 13:00:29,094 | server.py:157 | evaluate_round: strategy sampled 30 clients (out of 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m [Client 96] fit, config: {'current_round': 83, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m Epoch 1: train loss 6.948663212824613e-05, accuracy 0.7222222222222222\n",
      "Saving round 83 aggregated_parameters...\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98094)\u001b[0m [Client 45] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98094)\u001b[0m [Client 8] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98094)\u001b[0m [Client 69] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98094)\u001b[0m [Client 98] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98094)\u001b[0m [Client 41] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98094)\u001b[0m [Client 97] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98094)\u001b[0m [Client 44] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98094)\u001b[0m [Client 59] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98091)\u001b[0m [Client 38] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98088)\u001b[0m [Client 10] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98094)\u001b[0m [Client 48] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98094)\u001b[0m [Client 67] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98091)\u001b[0m [Client 5] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98094)\u001b[0m [Client 51] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98094)\u001b[0m [Client 79] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98094)\u001b[0m [Client 52] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98091)\u001b[0m [Client 17] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98094)\u001b[0m [Client 60] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98091)\u001b[0m [Client 9] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98091)\u001b[0m [Client 86] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98091)\u001b[0m [Client 57] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98092)\u001b[0m [Client 80] evaluate, config: {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 13:00:31,548 | server.py:170 | evaluate_round received 0 results and 30 failures\n",
      "DEBUG flower 2023-02-01 13:00:31,549 | server.py:203 | fit_round: strategy sampled 30 clients (out of 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98091)\u001b[0m [Client 29] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98090)\u001b[0m [Client 96] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98088)\u001b[0m [Client 66] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98095)\u001b[0m [Client 32] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98093)\u001b[0m [Client 82] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98089)\u001b[0m [Client 95] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98094)\u001b[0m [Client 23] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98092)\u001b[0m [Client 65] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m [Client 19] fit, config: {'current_round': 84, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m Epoch 1: train loss 7.221635314635932e-05, accuracy 0.7222222222222222\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m [Client 98] fit, config: {'current_round': 84, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m Epoch 1: train loss 9.226577094523236e-05, accuracy 0.6481481481481481\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m [Client 91] fit, config: {'current_round': 84, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m [Client 77] fit, config: {'current_round': 84, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m Epoch 1: train loss 9.474693797528744e-05, accuracy 0.6481481481481481\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m [Client 66] fit, config: {'current_round': 84, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m Epoch 1: train loss 7.648859900655225e-05, accuracy 0.6851851851851852\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m [Client 8] fit, config: {'current_round': 84, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m Epoch 1: train loss 8.637207793071866e-05, accuracy 0.6111111111111112\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m Epoch 1: train loss 7.905045640654862e-05, accuracy 0.7037037037037037\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m [Client 83] fit, config: {'current_round': 84, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m Epoch 1: train loss 9.03991749510169e-05, accuracy 0.5925925925925926\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m [Client 18] fit, config: {'current_round': 84, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m Epoch 1: train loss 9.677313209977001e-05, accuracy 0.6111111111111112\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m [Client 22] fit, config: {'current_round': 84, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m Epoch 1: train loss 0.00011451113095972687, accuracy 0.5370370370370371\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m [Client 62] fit, config: {'current_round': 84, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m Epoch 1: train loss 7.778918370604515e-05, accuracy 0.6666666666666666\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m [Client 23] fit, config: {'current_round': 84, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m Epoch 1: train loss 9.860512363957241e-05, accuracy 0.6111111111111112\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m [Client 20] fit, config: {'current_round': 84, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m [Client 76] fit, config: {'current_round': 84, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m Epoch 1: train loss 0.00010005640069721267, accuracy 0.6111111111111112\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m Epoch 1: train loss 6.9613175583072e-05, accuracy 0.7037037037037037\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m [Client 84] fit, config: {'current_round': 84, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m Epoch 1: train loss 8.12221405794844e-05, accuracy 0.7592592592592593\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m [Client 21] fit, config: {'current_round': 84, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m Epoch 1: train loss 0.00010126824054168537, accuracy 0.5925925925925926\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m [Client 43] fit, config: {'current_round': 84, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m Epoch 1: train loss 9.203747322317213e-05, accuracy 0.7037037037037037\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m [Client 12] fit, config: {'current_round': 84, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m Epoch 1: train loss 9.216983016813174e-05, accuracy 0.6481481481481481\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m [Client 1] fit, config: {'current_round': 84, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m Epoch 1: train loss 9.29732050281018e-05, accuracy 0.5925925925925926\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m [Client 11] fit, config: {'current_round': 84, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m Epoch 1: train loss 8.95206758286804e-05, accuracy 0.6666666666666666\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m [Client 24] fit, config: {'current_round': 84, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m Epoch 1: train loss 7.876381278038025e-05, accuracy 0.7222222222222222\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m [Client 73] fit, config: {'current_round': 84, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m [Client 50] fit, config: {'current_round': 84, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m Epoch 1: train loss 8.193316898541525e-05, accuracy 0.7037037037037037\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m [Client 35] fit, config: {'current_round': 84, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m Epoch 1: train loss 9.677826164988801e-05, accuracy 0.6851851851851852\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m [Client 89] fit, config: {'current_round': 84, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m Epoch 1: train loss 8.946938760345802e-05, accuracy 0.6296296296296297\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m Epoch 1: train loss 9.271446469938383e-05, accuracy 0.6666666666666666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 13:00:34,033 | server.py:216 | fit_round received 30 results and 0 failures\n",
      "DEBUG flower 2023-02-01 13:00:34,085 | server.py:157 | evaluate_round: strategy sampled 30 clients (out of 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m [Client 65] fit, config: {'current_round': 84, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m Epoch 1: train loss 9.21502141864039e-05, accuracy 0.6296296296296297\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m [Client 40] fit, config: {'current_round': 84, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m Epoch 1: train loss 7.666667079320177e-05, accuracy 0.7222222222222222\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m [Client 55] fit, config: {'current_round': 84, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m [Client 87] fit, config: {'current_round': 84, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m Epoch 1: train loss 7.471830758731812e-05, accuracy 0.7407407407407407\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m [Client 47] fit, config: {'current_round': 84, 'local_epochs': 3}\n",
      "Saving round 84 aggregated_parameters...\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m Epoch 1: train loss 8.050687029026449e-05, accuracy 0.7592592592592593\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m [Client 51] fit, config: {'current_round': 84, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m Epoch 1: train loss 8.078476821538061e-05, accuracy 0.7592592592592593\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m Epoch 1: train loss 8.430946036241949e-05, accuracy 0.7592592592592593\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98089)\u001b[0m [Client 81] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98092)\u001b[0m [Client 38] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98092)\u001b[0m [Client 85] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98089)\u001b[0m [Client 4] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98092)\u001b[0m [Client 0] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98089)\u001b[0m [Client 48] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98089)\u001b[0m [Client 76] evaluate, config: {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 13:00:36,071 | server.py:170 | evaluate_round received 0 results and 30 failures\n",
      "DEBUG flower 2023-02-01 13:00:36,072 | server.py:203 | fit_round: strategy sampled 30 clients (out of 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98092)\u001b[0m [Client 20] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98088)\u001b[0m [Client 65] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98095)\u001b[0m [Client 39] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98093)\u001b[0m [Client 32] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98091)\u001b[0m [Client 89] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98090)\u001b[0m [Client 83] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98095)\u001b[0m [Client 64] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98093)\u001b[0m [Client 55] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98089)\u001b[0m [Client 99] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98094)\u001b[0m [Client 63] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98092)\u001b[0m [Client 27] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98091)\u001b[0m [Client 13] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98090)\u001b[0m [Client 60] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98088)\u001b[0m [Client 24] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98095)\u001b[0m [Client 61] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98093)\u001b[0m [Client 30] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98089)\u001b[0m [Client 40] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98089)\u001b[0m [Client 93] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98094)\u001b[0m [Client 35] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98092)\u001b[0m [Client 36] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98090)\u001b[0m [Client 51] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98088)\u001b[0m [Client 72] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98093)\u001b[0m [Client 47] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m [Client 31] fit, config: {'current_round': 85, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m Epoch 1: train loss 9.51376641751267e-05, accuracy 0.5740740740740741\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m [Client 54] fit, config: {'current_round': 85, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m Epoch 1: train loss 8.795032044872642e-05, accuracy 0.6666666666666666\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m [Client 83] fit, config: {'current_round': 85, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m [Client 64] fit, config: {'current_round': 85, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m Epoch 1: train loss 7.293986709555611e-05, accuracy 0.7037037037037037\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m [Client 50] fit, config: {'current_round': 85, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m Epoch 1: train loss 9.157593012787402e-05, accuracy 0.5740740740740741\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m [Client 68] fit, config: {'current_round': 85, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m Epoch 1: train loss 7.742776506347582e-05, accuracy 0.7592592592592593\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m Epoch 1: train loss 9.565861546434462e-05, accuracy 0.6481481481481481\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m [Client 12] fit, config: {'current_round': 85, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m Epoch 1: train loss 9.005863830680028e-05, accuracy 0.7222222222222222\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m [Client 65] fit, config: {'current_round': 85, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m Epoch 1: train loss 8.636520215077326e-05, accuracy 0.6481481481481481\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m [Client 16] fit, config: {'current_round': 85, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m Epoch 1: train loss 9.566146763972938e-05, accuracy 0.6296296296296297\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m [Client 57] fit, config: {'current_round': 85, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m Epoch 1: train loss 0.0001005835147225298, accuracy 0.6296296296296297\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m [Client 71] fit, config: {'current_round': 85, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m Epoch 1: train loss 8.744740625843406e-05, accuracy 0.6666666666666666\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m [Client 33] fit, config: {'current_round': 85, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m [Client 39] fit, config: {'current_round': 85, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m [Client 84] fit, config: {'current_round': 85, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m Epoch 1: train loss 9.267013956559822e-05, accuracy 0.6481481481481481\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m [Client 45] fit, config: {'current_round': 85, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m Epoch 1: train loss 8.324261580128223e-05, accuracy 0.7592592592592593\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m Epoch 1: train loss 7.715728133916855e-05, accuracy 0.6481481481481481\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m [Client 29] fit, config: {'current_round': 85, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m [Client 85] fit, config: {'current_round': 85, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m Epoch 1: train loss 9.906726336339489e-05, accuracy 0.5925925925925926\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m Epoch 1: train loss 7.696807733736932e-05, accuracy 0.7407407407407407\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m [Client 15] fit, config: {'current_round': 85, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m Epoch 1: train loss 0.00011178915156051517, accuracy 0.5\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m [Client 95] fit, config: {'current_round': 85, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m [Client 42] fit, config: {'current_round': 85, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m Epoch 1: train loss 9.541073814034462e-05, accuracy 0.6111111111111112\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m Epoch 1: train loss 0.0001028817641781643, accuracy 0.5185185185185185\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m [Client 94] fit, config: {'current_round': 85, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m Epoch 1: train loss 6.27571134828031e-05, accuracy 0.7407407407407407\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m [Client 46] fit, config: {'current_round': 85, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m [Client 73] fit, config: {'current_round': 85, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m Epoch 1: train loss 8.226219506468624e-05, accuracy 0.7222222222222222\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m Epoch 1: train loss 6.334800855256617e-05, accuracy 0.7222222222222222\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m Epoch 1: train loss 8.144829189404845e-05, accuracy 0.7037037037037037\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m [Client 9] fit, config: {'current_round': 85, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m Epoch 1: train loss 9.925494669005275e-05, accuracy 0.5925925925925926\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m [Client 60] fit, config: {'current_round': 85, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m Epoch 1: train loss 9.310982568422332e-05, accuracy 0.6481481481481481\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m [Client 66] fit, config: {'current_round': 85, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m Epoch 1: train loss 7.71173945395276e-05, accuracy 0.7222222222222222\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m [Client 48] fit, config: {'current_round': 85, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m Epoch 1: train loss 9.605824016034603e-05, accuracy 0.6481481481481481\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m [Client 67] fit, config: {'current_round': 85, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m Epoch 1: train loss 0.00011590890790103003, accuracy 0.6666666666666666\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m [Client 40] fit, config: {'current_round': 85, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m Epoch 1: train loss 7.387516234302893e-05, accuracy 0.6666666666666666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 13:00:38,152 | server.py:216 | fit_round received 30 results and 0 failures\n",
      "DEBUG flower 2023-02-01 13:00:38,204 | server.py:157 | evaluate_round: strategy sampled 30 clients (out of 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m [Client 75] fit, config: {'current_round': 85, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m Epoch 1: train loss 8.992531365947798e-05, accuracy 0.6666666666666666\n",
      "Saving round 85 aggregated_parameters...\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98091)\u001b[0m [Client 26] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98091)\u001b[0m [Client 22] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98089)\u001b[0m [Client 46] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98090)\u001b[0m [Client 59] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98088)\u001b[0m [Client 49] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98093)\u001b[0m [Client 80] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98092)\u001b[0m [Client 2] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98090)\u001b[0m [Client 82] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98090)\u001b[0m [Client 98] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98090)\u001b[0m [Client 96] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98090)\u001b[0m [Client 23] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98090)\u001b[0m [Client 92] evaluate, config: {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 13:00:40,405 | server.py:170 | evaluate_round received 0 results and 30 failures\n",
      "DEBUG flower 2023-02-01 13:00:40,406 | server.py:203 | fit_round: strategy sampled 30 clients (out of 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98090)\u001b[0m [Client 38] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98093)\u001b[0m [Client 34] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98092)\u001b[0m [Client 88] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98088)\u001b[0m [Client 21] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98088)\u001b[0m [Client 6] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98093)\u001b[0m [Client 95] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98090)\u001b[0m [Client 87] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98090)\u001b[0m [Client 69] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98088)\u001b[0m [Client 52] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98088)\u001b[0m [Client 65] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98091)\u001b[0m [Client 58] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98090)\u001b[0m [Client 64] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98088)\u001b[0m [Client 43] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98095)\u001b[0m [Client 18] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98093)\u001b[0m [Client 91] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98089)\u001b[0m [Client 44] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98094)\u001b[0m [Client 42] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98092)\u001b[0m [Client 27] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m [Client 75] fit, config: {'current_round': 86, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m Epoch 1: train loss 0.00010299067798769102, accuracy 0.6851851851851852\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m [Client 21] fit, config: {'current_round': 86, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m Epoch 1: train loss 0.00010108867718372494, accuracy 0.5740740740740741\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m [Client 87] fit, config: {'current_round': 86, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m [Client 79] fit, config: {'current_round': 86, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m Epoch 1: train loss 9.236680489266291e-05, accuracy 0.6111111111111112\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m Epoch 1: train loss 7.425861986121163e-05, accuracy 0.7222222222222222\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m [Client 8] fit, config: {'current_round': 86, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m Epoch 1: train loss 8.387806155951694e-05, accuracy 0.6296296296296297\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m [Client 53] fit, config: {'current_round': 86, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m Epoch 1: train loss 8.529957995051518e-05, accuracy 0.6666666666666666\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m [Client 7] fit, config: {'current_round': 86, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m [Client 95] fit, config: {'current_round': 86, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m Epoch 1: train loss 6.644520908594131e-05, accuracy 0.7222222222222222\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m [Client 25] fit, config: {'current_round': 86, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m [Client 34] fit, config: {'current_round': 86, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m Epoch 1: train loss 8.203372271964327e-05, accuracy 0.6481481481481481\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m [Client 69] fit, config: {'current_round': 86, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m Epoch 1: train loss 7.314642425626516e-05, accuracy 0.7222222222222222\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m Epoch 1: train loss 9.094439155887812e-05, accuracy 0.7592592592592593\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m Epoch 1: train loss 8.266179065685719e-05, accuracy 0.7222222222222222\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m [Client 30] fit, config: {'current_round': 86, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m Epoch 1: train loss 8.789344428805634e-05, accuracy 0.6296296296296297\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m [Client 43] fit, config: {'current_round': 86, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m Epoch 1: train loss 8.997275290312245e-05, accuracy 0.7037037037037037\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m [Client 85] fit, config: {'current_round': 86, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m Epoch 1: train loss 0.0001089890138246119, accuracy 0.5185185185185185\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m [Client 80] fit, config: {'current_round': 86, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m Epoch 1: train loss 6.73999820719473e-05, accuracy 0.7962962962962963\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m [Client 81] fit, config: {'current_round': 86, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m Epoch 1: train loss 9.855261305347085e-05, accuracy 0.6296296296296297\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m [Client 15] fit, config: {'current_round': 86, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m Epoch 1: train loss 0.0001234737574122846, accuracy 0.5370370370370371\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m [Client 14] fit, config: {'current_round': 86, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m Epoch 1: train loss 8.97102800081484e-05, accuracy 0.6296296296296297\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m [Client 32] fit, config: {'current_round': 86, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m Epoch 1: train loss 7.951061706990004e-05, accuracy 0.6851851851851852\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m [Client 29] fit, config: {'current_round': 86, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m Epoch 1: train loss 8.277563756564632e-05, accuracy 0.6111111111111112\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m [Client 92] fit, config: {'current_round': 86, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m Epoch 1: train loss 9.510479867458344e-05, accuracy 0.7407407407407407\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m [Client 68] fit, config: {'current_round': 86, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m Epoch 1: train loss 7.449438999174163e-05, accuracy 0.6851851851851852\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m [Client 24] fit, config: {'current_round': 86, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m Epoch 1: train loss 7.76994857005775e-05, accuracy 0.7037037037037037\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 13:00:42,588 | server.py:216 | fit_round received 30 results and 0 failures\n",
      "DEBUG flower 2023-02-01 13:00:42,644 | server.py:157 | evaluate_round: strategy sampled 30 clients (out of 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m [Client 23] fit, config: {'current_round': 86, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m Epoch 1: train loss 9.552642586641014e-05, accuracy 0.6666666666666666\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m [Client 91] fit, config: {'current_round': 86, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m Epoch 1: train loss 7.910363638075069e-05, accuracy 0.7407407407407407\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m [Client 66] fit, config: {'current_round': 86, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m Epoch 1: train loss 7.673480286030099e-05, accuracy 0.6851851851851852\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m [Client 2] fit, config: {'current_round': 86, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m Epoch 1: train loss 7.473434379789978e-05, accuracy 0.6111111111111112\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m [Client 4] fit, config: {'current_round': 86, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m [Client 33] fit, config: {'current_round': 86, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m Epoch 1: train loss 8.082054409896955e-05, accuracy 0.7037037037037037\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m [Client 37] fit, config: {'current_round': 86, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m Epoch 1: train loss 6.981765909586102e-05, accuracy 0.7592592592592593\n",
      "Saving round 86 aggregated_parameters...\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m Epoch 1: train loss 0.00010402001498732716, accuracy 0.5555555555555556\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98093)\u001b[0m [Client 42] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98092)\u001b[0m [Client 62] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98095)\u001b[0m [Client 21] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98093)\u001b[0m [Client 52] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98089)\u001b[0m [Client 17] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98092)\u001b[0m [Client 57] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98093)\u001b[0m [Client 4] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98095)\u001b[0m [Client 30] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98093)\u001b[0m [Client 81] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98094)\u001b[0m [Client 40] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98091)\u001b[0m [Client 64] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98090)\u001b[0m [Client 49] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98088)\u001b[0m [Client 34] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98095)\u001b[0m [Client 84] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98093)\u001b[0m [Client 99] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98089)\u001b[0m [Client 91] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98092)\u001b[0m [Client 98] evaluate, config: {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 13:00:44,851 | server.py:170 | evaluate_round received 0 results and 30 failures\n",
      "DEBUG flower 2023-02-01 13:00:44,852 | server.py:203 | fit_round: strategy sampled 30 clients (out of 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98095)\u001b[0m [Client 2] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98095)\u001b[0m [Client 13] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98095)\u001b[0m [Client 54] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98095)\u001b[0m [Client 24] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98093)\u001b[0m [Client 47] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98091)\u001b[0m [Client 68] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98088)\u001b[0m [Client 38] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98089)\u001b[0m [Client 18] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98090)\u001b[0m [Client 33] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98095)\u001b[0m [Client 71] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98093)\u001b[0m [Client 93] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98094)\u001b[0m [Client 69] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98092)\u001b[0m [Client 89] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m [Client 38] fit, config: {'current_round': 87, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m Epoch 1: train loss 9.151679114438593e-05, accuracy 0.6666666666666666\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m [Client 95] fit, config: {'current_round': 87, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m Epoch 1: train loss 6.399187259376049e-05, accuracy 0.7407407407407407\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m [Client 71] fit, config: {'current_round': 87, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m Epoch 1: train loss 8.740204066270962e-05, accuracy 0.6481481481481481\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m [Client 99] fit, config: {'current_round': 87, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m Epoch 1: train loss 9.043330646818504e-05, accuracy 0.6481481481481481\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m [Client 29] fit, config: {'current_round': 87, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m Epoch 1: train loss 0.00010053248115582392, accuracy 0.5740740740740741\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m [Client 18] fit, config: {'current_round': 87, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m [Client 69] fit, config: {'current_round': 87, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m [Client 3] fit, config: {'current_round': 87, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m Epoch 1: train loss 0.00010046230454463512, accuracy 0.6296296296296297\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m Epoch 1: train loss 0.0001101943853427656, accuracy 0.5555555555555556\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m [Client 9] fit, config: {'current_round': 87, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m Epoch 1: train loss 6.974894495215267e-05, accuracy 0.7407407407407407\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m [Client 47] fit, config: {'current_round': 87, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m Epoch 1: train loss 0.00010280869901180267, accuracy 0.5555555555555556\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m [Client 6] fit, config: {'current_round': 87, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m Epoch 1: train loss 8.400867227464914e-05, accuracy 0.7222222222222222\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m Epoch 1: train loss 8.058884122874588e-05, accuracy 0.6666666666666666\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m [Client 26] fit, config: {'current_round': 87, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m Epoch 1: train loss 0.00010343301255488768, accuracy 0.5740740740740741\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m [Client 4] fit, config: {'current_round': 87, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m Epoch 1: train loss 9.768319432623684e-05, accuracy 0.6296296296296297\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m [Client 92] fit, config: {'current_round': 87, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m [Client 79] fit, config: {'current_round': 87, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m Epoch 1: train loss 7.917323819128796e-05, accuracy 0.6666666666666666\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m [Client 7] fit, config: {'current_round': 87, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m [Client 85] fit, config: {'current_round': 87, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m Epoch 1: train loss 9.833322110353038e-05, accuracy 0.5740740740740741\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m Epoch 1: train loss 9.071134991245344e-05, accuracy 0.7407407407407407\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m Epoch 1: train loss 9.197116742143407e-05, accuracy 0.6296296296296297\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m [Client 37] fit, config: {'current_round': 87, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m Epoch 1: train loss 7.075554458424449e-05, accuracy 0.7222222222222222\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m [Client 89] fit, config: {'current_round': 87, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m Epoch 1: train loss 8.190001244656742e-05, accuracy 0.6666666666666666\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m [Client 15] fit, config: {'current_round': 87, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m Epoch 1: train loss 0.00011026834545191377, accuracy 0.5370370370370371\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m [Client 28] fit, config: {'current_round': 87, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m Epoch 1: train loss 9.700362716102973e-05, accuracy 0.6111111111111112\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m [Client 60] fit, config: {'current_round': 87, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m [Client 33] fit, config: {'current_round': 87, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m Epoch 1: train loss 9.428244084119797e-05, accuracy 0.6666666666666666\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m Epoch 1: train loss 9.250087168766186e-05, accuracy 0.6666666666666666\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m [Client 75] fit, config: {'current_round': 87, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m [Client 91] fit, config: {'current_round': 87, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m Epoch 1: train loss 8.454230555798858e-05, accuracy 0.7037037037037037\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m [Client 57] fit, config: {'current_round': 87, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m [Client 5] fit, config: {'current_round': 87, 'local_epochs': 3}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 13:00:47,041 | server.py:216 | fit_round received 30 results and 0 failures\n",
      "DEBUG flower 2023-02-01 13:00:47,096 | server.py:157 | evaluate_round: strategy sampled 30 clients (out of 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving round 87 aggregated_parameters...\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m [Client 66] fit, config: {'current_round': 87, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m Epoch 1: train loss 7.639270916115493e-05, accuracy 0.7037037037037037\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m Epoch 1: train loss 0.00010049994307337329, accuracy 0.6481481481481481\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m Epoch 1: train loss 8.928764873417094e-05, accuracy 0.6481481481481481\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m [Client 20] fit, config: {'current_round': 87, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m Epoch 1: train loss 0.00010608853335725144, accuracy 0.6111111111111112\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m [Client 49] fit, config: {'current_round': 87, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m Epoch 1: train loss 0.00010099424980580807, accuracy 0.5925925925925926\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m Epoch 1: train loss 8.80847655935213e-05, accuracy 0.7037037037037037\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98091)\u001b[0m [Client 12] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98089)\u001b[0m [Client 29] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98091)\u001b[0m [Client 79] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98089)\u001b[0m [Client 90] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98091)\u001b[0m [Client 96] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98093)\u001b[0m [Client 49] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98089)\u001b[0m [Client 53] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98091)\u001b[0m [Client 93] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98088)\u001b[0m [Client 0] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98088)\u001b[0m [Client 77] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98093)\u001b[0m [Client 75] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98089)\u001b[0m [Client 5] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98088)\u001b[0m [Client 58] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98088)\u001b[0m [Client 68] evaluate, config: {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 13:00:49,234 | server.py:170 | evaluate_round received 0 results and 30 failures\n",
      "DEBUG flower 2023-02-01 13:00:49,235 | server.py:203 | fit_round: strategy sampled 30 clients (out of 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98093)\u001b[0m [Client 27] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98093)\u001b[0m [Client 59] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98089)\u001b[0m [Client 17] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98089)\u001b[0m [Client 19] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98093)\u001b[0m [Client 4] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98089)\u001b[0m [Client 15] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98088)\u001b[0m [Client 54] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98093)\u001b[0m [Client 42] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98089)\u001b[0m [Client 47] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98091)\u001b[0m [Client 55] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98088)\u001b[0m [Client 97] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98095)\u001b[0m [Client 23] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98093)\u001b[0m [Client 39] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98089)\u001b[0m [Client 72] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98094)\u001b[0m [Client 57] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98092)\u001b[0m [Client 50] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m [Client 29] fit, config: {'current_round': 88, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m Epoch 1: train loss 8.649368828628212e-05, accuracy 0.6481481481481481\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m [Client 12] fit, config: {'current_round': 88, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m [Client 95] fit, config: {'current_round': 88, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m Epoch 1: train loss 6.685290281893685e-05, accuracy 0.7592592592592593\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m Epoch 1: train loss 9.199730993714184e-05, accuracy 0.6296296296296297\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m [Client 3] fit, config: {'current_round': 88, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m Epoch 1: train loss 9.112995030591264e-05, accuracy 0.5925925925925926\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m [Client 86] fit, config: {'current_round': 88, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m Epoch 1: train loss 7.343564357142895e-05, accuracy 0.7777777777777778\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m [Client 60] fit, config: {'current_round': 88, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m Epoch 1: train loss 8.224062185036018e-05, accuracy 0.6666666666666666\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m [Client 64] fit, config: {'current_round': 88, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m Epoch 1: train loss 7.291736983461305e-05, accuracy 0.7407407407407407\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m [Client 73] fit, config: {'current_round': 88, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m Epoch 1: train loss 9.353680070489645e-05, accuracy 0.6296296296296297\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m [Client 67] fit, config: {'current_round': 88, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m Epoch 1: train loss 0.00011331702262395993, accuracy 0.6296296296296297\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m [Client 68] fit, config: {'current_round': 88, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m Epoch 1: train loss 7.846095104468986e-05, accuracy 0.6666666666666666\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m [Client 65] fit, config: {'current_round': 88, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m Epoch 1: train loss 9.50975445448421e-05, accuracy 0.5370370370370371\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m [Client 10] fit, config: {'current_round': 88, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m [Client 85] fit, config: {'current_round': 88, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m Epoch 1: train loss 0.00011065808212151751, accuracy 0.5185185185185185\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m [Client 74] fit, config: {'current_round': 88, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m [Client 41] fit, config: {'current_round': 88, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m Epoch 1: train loss 8.341582724824548e-05, accuracy 0.6481481481481481\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m [Client 36] fit, config: {'current_round': 88, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m [Client 38] fit, config: {'current_round': 88, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m [Client 53] fit, config: {'current_round': 88, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m Epoch 1: train loss 9.200865315506235e-05, accuracy 0.6296296296296297\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m Epoch 1: train loss 0.00010118065983988345, accuracy 0.6111111111111112\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m [Client 93] fit, config: {'current_round': 88, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m Epoch 1: train loss 8.39114873087965e-05, accuracy 0.6851851851851852\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m Epoch 1: train loss 9.619107004255056e-05, accuracy 0.6296296296296297\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m Epoch 1: train loss 9.340605174656957e-05, accuracy 0.6666666666666666\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m Epoch 1: train loss 7.884403748903424e-05, accuracy 0.6851851851851852\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m [Client 79] fit, config: {'current_round': 88, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m [Client 87] fit, config: {'current_round': 88, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m Epoch 1: train loss 7.751071825623512e-05, accuracy 0.6851851851851852\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m Epoch 1: train loss 9.523227345198393e-05, accuracy 0.6296296296296297\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m [Client 99] fit, config: {'current_round': 88, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m [Client 9] fit, config: {'current_round': 88, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m Epoch 1: train loss 8.912720659282058e-05, accuracy 0.7222222222222222\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m [Client 98] fit, config: {'current_round': 88, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m Epoch 1: train loss 8.678318408783525e-05, accuracy 0.6666666666666666\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m [Client 26] fit, config: {'current_round': 88, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m [Client 66] fit, config: {'current_round': 88, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m [Client 72] fit, config: {'current_round': 88, 'local_epochs': 3}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 13:00:51,505 | server.py:216 | fit_round received 30 results and 0 failures\n",
      "DEBUG flower 2023-02-01 13:00:51,555 | server.py:157 | evaluate_round: strategy sampled 30 clients (out of 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m [Client 76] fit, config: {'current_round': 88, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m Epoch 1: train loss 6.9178051489871e-05, accuracy 0.7037037037037037\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m Epoch 1: train loss 7.167855073930696e-05, accuracy 0.7407407407407407\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m [Client 90] fit, config: {'current_round': 88, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m Epoch 1: train loss 8.222157339332625e-05, accuracy 0.7407407407407407\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m [Client 45] fit, config: {'current_round': 88, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m Epoch 1: train loss 9.286955901188776e-05, accuracy 0.6666666666666666\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m Epoch 1: train loss 7.660027767997235e-05, accuracy 0.6851851851851852\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m Epoch 1: train loss 7.46530422475189e-05, accuracy 0.8148148148148148\n",
      "Saving round 88 aggregated_parameters...\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m Epoch 1: train loss 9.327285806648433e-05, accuracy 0.6296296296296297\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98091)\u001b[0m [Client 15] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98088)\u001b[0m [Client 76] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98091)\u001b[0m [Client 41] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98095)\u001b[0m [Client 82] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98089)\u001b[0m [Client 5] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98089)\u001b[0m [Client 20] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98095)\u001b[0m [Client 12] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98091)\u001b[0m [Client 62] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98092)\u001b[0m [Client 71] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98090)\u001b[0m [Client 28] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98088)\u001b[0m [Client 67] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98095)\u001b[0m [Client 74] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98093)\u001b[0m [Client 65] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98089)\u001b[0m [Client 70] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98094)\u001b[0m [Client 6] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98092)\u001b[0m [Client 75] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98092)\u001b[0m [Client 7] evaluate, config: {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 13:00:53,845 | server.py:170 | evaluate_round received 0 results and 30 failures\n",
      "DEBUG flower 2023-02-01 13:00:53,846 | server.py:203 | fit_round: strategy sampled 30 clients (out of 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98092)\u001b[0m [Client 1] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98090)\u001b[0m [Client 80] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98088)\u001b[0m [Client 66] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98089)\u001b[0m [Client 55] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98092)\u001b[0m [Client 25] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98090)\u001b[0m [Client 16] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98088)\u001b[0m [Client 44] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98093)\u001b[0m [Client 38] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98089)\u001b[0m [Client 72] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98091)\u001b[0m [Client 8] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98095)\u001b[0m [Client 56] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98094)\u001b[0m [Client 24] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98092)\u001b[0m [Client 85] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m [Client 54] fit, config: {'current_round': 89, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m Epoch 1: train loss 9.08247529878281e-05, accuracy 0.6296296296296297\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m [Client 40] fit, config: {'current_round': 89, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m Epoch 1: train loss 7.602122786920518e-05, accuracy 0.6666666666666666\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m [Client 14] fit, config: {'current_round': 89, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m Epoch 1: train loss 9.185684757540002e-05, accuracy 0.6296296296296297\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m [Client 92] fit, config: {'current_round': 89, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m [Client 53] fit, config: {'current_round': 89, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m Epoch 1: train loss 8.645606430945918e-05, accuracy 0.6481481481481481\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m Epoch 1: train loss 8.760023774811998e-05, accuracy 0.6851851851851852\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m [Client 72] fit, config: {'current_round': 89, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m Epoch 1: train loss 7.399842434097081e-05, accuracy 0.7037037037037037\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m [Client 74] fit, config: {'current_round': 89, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m Epoch 1: train loss 9.560846956446767e-05, accuracy 0.6481481481481481\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m [Client 84] fit, config: {'current_round': 89, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m Epoch 1: train loss 7.327245839405805e-05, accuracy 0.7407407407407407\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m [Client 69] fit, config: {'current_round': 89, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m Epoch 1: train loss 7.072597509250045e-05, accuracy 0.7037037037037037\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m [Client 55] fit, config: {'current_round': 89, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m Epoch 1: train loss 8.813182648736984e-05, accuracy 0.6111111111111112\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m [Client 80] fit, config: {'current_round': 89, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m Epoch 1: train loss 6.938388833077624e-05, accuracy 0.7777777777777778\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m [Client 24] fit, config: {'current_round': 89, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m Epoch 1: train loss 7.567936700070277e-05, accuracy 0.6481481481481481\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m [Client 7] fit, config: {'current_round': 89, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m Epoch 1: train loss 9.558349120197818e-05, accuracy 0.6296296296296297\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m [Client 70] fit, config: {'current_round': 89, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m [Client 58] fit, config: {'current_round': 89, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m [Client 68] fit, config: {'current_round': 89, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m Epoch 1: train loss 7.256961544044316e-05, accuracy 0.6851851851851852\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 13:00:55,954 | server.py:216 | fit_round received 30 results and 0 failures\n",
      "DEBUG flower 2023-02-01 13:00:56,016 | server.py:157 | evaluate_round: strategy sampled 30 clients (out of 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m Epoch 1: train loss 0.00012062230234732851, accuracy 0.6111111111111112\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m Epoch 1: train loss 9.07966896193102e-05, accuracy 0.5925925925925926\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m [Client 28] fit, config: {'current_round': 89, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m [Client 13] fit, config: {'current_round': 89, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m Epoch 1: train loss 9.475465049035847e-05, accuracy 0.5925925925925926\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m [Client 56] fit, config: {'current_round': 89, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m [Client 12] fit, config: {'current_round': 89, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m Epoch 1: train loss 9.216942271450534e-05, accuracy 0.7037037037037037\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m Epoch 1: train loss 9.980846516555175e-05, accuracy 0.5185185185185185\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m [Client 83] fit, config: {'current_round': 89, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m Epoch 1: train loss 9.534264972899109e-05, accuracy 0.5740740740740741\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m [Client 27] fit, config: {'current_round': 89, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m Epoch 1: train loss 9.550162212690338e-05, accuracy 0.5925925925925926\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m Epoch 1: train loss 9.811772179091349e-05, accuracy 0.6111111111111112\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m [Client 35] fit, config: {'current_round': 89, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m Epoch 1: train loss 8.798880298854783e-05, accuracy 0.6666666666666666\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m [Client 66] fit, config: {'current_round': 89, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m Epoch 1: train loss 7.377814472420141e-05, accuracy 0.6851851851851852\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m [Client 19] fit, config: {'current_round': 89, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m Epoch 1: train loss 8.129383786581457e-05, accuracy 0.6296296296296297\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m [Client 5] fit, config: {'current_round': 89, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m Epoch 1: train loss 9.12461182451807e-05, accuracy 0.5925925925925926\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m [Client 45] fit, config: {'current_round': 89, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m Epoch 1: train loss 8.179891301551834e-05, accuracy 0.6851851851851852\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m [Client 20] fit, config: {'current_round': 89, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m Epoch 1: train loss 0.00010284700692864135, accuracy 0.6481481481481481\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m [Client 33] fit, config: {'current_round': 89, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m Epoch 1: train loss 9.919842705130577e-05, accuracy 0.6851851851851852\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m [Client 10] fit, config: {'current_round': 89, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m Epoch 1: train loss 8.862496906658635e-05, accuracy 0.6111111111111112\n",
      "Saving round 89 aggregated_parameters...\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98095)\u001b[0m [Client 16] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98094)\u001b[0m [Client 18] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98090)\u001b[0m [Client 3] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98091)\u001b[0m [Client 11] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98090)\u001b[0m [Client 86] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98095)\u001b[0m [Client 19] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98094)\u001b[0m [Client 25] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98091)\u001b[0m [Client 70] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98095)\u001b[0m [Client 9] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98095)\u001b[0m [Client 95] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98095)\u001b[0m [Client 79] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98095)\u001b[0m [Client 26] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98095)\u001b[0m [Client 81] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98091)\u001b[0m [Client 22] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98095)\u001b[0m [Client 85] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98095)\u001b[0m [Client 96] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98094)\u001b[0m [Client 30] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98091)\u001b[0m [Client 57] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98090)\u001b[0m [Client 29] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98095)\u001b[0m [Client 42] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98091)\u001b[0m [Client 52] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98094)\u001b[0m [Client 31] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98095)\u001b[0m [Client 84] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98094)\u001b[0m [Client 24] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98093)\u001b[0m [Client 88] evaluate, config: {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(raylet)\u001b[0m Spilled 263744 MiB, 8682 objects, write throughput 1068 MiB/s.\n",
      "DEBUG flower 2023-02-01 13:00:58,289 | server.py:170 | evaluate_round received 0 results and 30 failures\n",
      "DEBUG flower 2023-02-01 13:00:58,290 | server.py:203 | fit_round: strategy sampled 30 clients (out of 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98088)\u001b[0m [Client 63] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98095)\u001b[0m [Client 74] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98089)\u001b[0m [Client 6] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98091)\u001b[0m [Client 33] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98090)\u001b[0m [Client 10] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m [Client 17] fit, config: {'current_round': 90, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m Epoch 1: train loss 7.787093636579812e-05, accuracy 0.7407407407407407\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m [Client 69] fit, config: {'current_round': 90, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m Epoch 1: train loss 7.691860082559288e-05, accuracy 0.7222222222222222\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m [Client 28] fit, config: {'current_round': 90, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m Epoch 1: train loss 7.91012862464413e-05, accuracy 0.7037037037037037\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m [Client 3] fit, config: {'current_round': 90, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m Epoch 1: train loss 9.199982741847634e-05, accuracy 0.5925925925925926\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m [Client 61] fit, config: {'current_round': 90, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m Epoch 1: train loss 8.920893014874309e-05, accuracy 0.7037037037037037\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m [Client 92] fit, config: {'current_round': 90, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m Epoch 1: train loss 0.0001019966002786532, accuracy 0.6296296296296297\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m [Client 66] fit, config: {'current_round': 90, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m Epoch 1: train loss 7.991410529939458e-05, accuracy 0.6296296296296297\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m [Client 52] fit, config: {'current_round': 90, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m [Client 41] fit, config: {'current_round': 90, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m Epoch 1: train loss 9.038954885909334e-05, accuracy 0.6296296296296297\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 13:01:00,478 | server.py:216 | fit_round received 30 results and 0 failures\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m [Client 79] fit, config: {'current_round': 90, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m Epoch 1: train loss 9.621600474929437e-05, accuracy 0.6111111111111112\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m [Client 45] fit, config: {'current_round': 90, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m [Client 77] fit, config: {'current_round': 90, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m Epoch 1: train loss 9.189890988636762e-05, accuracy 0.6481481481481481\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m Epoch 1: train loss 9.723795665195212e-05, accuracy 0.5925925925925926\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m [Client 82] fit, config: {'current_round': 90, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m Epoch 1: train loss 7.960372749948874e-05, accuracy 0.6851851851851852\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m [Client 19] fit, config: {'current_round': 90, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m [Client 88] fit, config: {'current_round': 90, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m Epoch 1: train loss 8.229076047427952e-05, accuracy 0.6666666666666666\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m [Client 68] fit, config: {'current_round': 90, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m Epoch 1: train loss 9.589516412233934e-05, accuracy 0.6296296296296297\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m [Client 93] fit, config: {'current_round': 90, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m Epoch 1: train loss 8.831325976643711e-05, accuracy 0.6851851851851852\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m Epoch 1: train loss 7.150126475607976e-05, accuracy 0.7222222222222222\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m [Client 0] fit, config: {'current_round': 90, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m Epoch 1: train loss 8.564034942537546e-05, accuracy 0.6481481481481481\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m Epoch 1: train loss 0.00011210899538127705, accuracy 0.5740740740740741\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m [Client 85] fit, config: {'current_round': 90, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m Epoch 1: train loss 0.0001117224819608964, accuracy 0.5370370370370371\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m [Client 25] fit, config: {'current_round': 90, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m [Client 49] fit, config: {'current_round': 90, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m Epoch 1: train loss 0.00010183775157202035, accuracy 0.5555555555555556\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m Epoch 1: train loss 8.834221080178395e-05, accuracy 0.6296296296296297\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m [Client 24] fit, config: {'current_round': 90, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m [Client 10] fit, config: {'current_round': 90, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m Epoch 1: train loss 9.920117008732632e-05, accuracy 0.6296296296296297\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m [Client 96] fit, config: {'current_round': 90, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m Epoch 1: train loss 7.541252125520259e-05, accuracy 0.6481481481481481\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m [Client 43] fit, config: {'current_round': 90, 'local_epochs': 3}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 13:01:00,527 | server.py:157 | evaluate_round: strategy sampled 30 clients (out of 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m [Client 21] fit, config: {'current_round': 90, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m Epoch 1: train loss 9.409821359440684e-05, accuracy 0.6481481481481481\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m [Client 36] fit, config: {'current_round': 90, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m Epoch 1: train loss 0.0001008172839647159, accuracy 0.6111111111111112\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m [Client 71] fit, config: {'current_round': 90, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m Epoch 1: train loss 7.671461935387924e-05, accuracy 0.7222222222222222\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m Epoch 1: train loss 9.073078399524093e-05, accuracy 0.6851851851851852\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m Epoch 1: train loss 8.015744970180094e-05, accuracy 0.7037037037037037\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m [Client 9] fit, config: {'current_round': 90, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m Epoch 1: train loss 8.773242007009685e-05, accuracy 0.6851851851851852\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m [Client 34] fit, config: {'current_round': 90, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m Epoch 1: train loss 8.575221727369353e-05, accuracy 0.6666666666666666\n",
      "Saving round 90 aggregated_parameters...\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98090)\u001b[0m [Client 33] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98089)\u001b[0m [Client 13] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98090)\u001b[0m [Client 89] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98090)\u001b[0m [Client 38] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98090)\u001b[0m [Client 56] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98089)\u001b[0m [Client 62] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98090)\u001b[0m [Client 32] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98089)\u001b[0m [Client 67] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98090)\u001b[0m [Client 86] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98095)\u001b[0m [Client 83] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98094)\u001b[0m [Client 47] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98092)\u001b[0m [Client 64] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98091)\u001b[0m [Client 91] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98095)\u001b[0m [Client 21] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98093)\u001b[0m [Client 12] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98094)\u001b[0m [Client 65] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98092)\u001b[0m [Client 51] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98090)\u001b[0m [Client 82] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98088)\u001b[0m [Client 57] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98089)\u001b[0m [Client 48] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98089)\u001b[0m [Client 97] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98089)\u001b[0m [Client 18] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98092)\u001b[0m [Client 85] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98090)\u001b[0m [Client 4] evaluate, config: {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 13:01:02,947 | server.py:170 | evaluate_round received 0 results and 30 failures\n",
      "DEBUG flower 2023-02-01 13:01:02,948 | server.py:203 | fit_round: strategy sampled 30 clients (out of 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98088)\u001b[0m [Client 76] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98095)\u001b[0m [Client 2] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98093)\u001b[0m [Client 29] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98094)\u001b[0m [Client 17] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98091)\u001b[0m [Client 95] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98089)\u001b[0m [Client 34] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m [Client 28] fit, config: {'current_round': 91, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m Epoch 1: train loss 9.118911839323118e-05, accuracy 0.6111111111111112\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m [Client 45] fit, config: {'current_round': 91, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m Epoch 1: train loss 8.45455433591269e-05, accuracy 0.6851851851851852\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m [Client 65] fit, config: {'current_round': 91, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m Epoch 1: train loss 8.572440856369212e-05, accuracy 0.6481481481481481\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m [Client 56] fit, config: {'current_round': 91, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m Epoch 1: train loss 9.84178768703714e-05, accuracy 0.6481481481481481\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m [Client 94] fit, config: {'current_round': 91, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m Epoch 1: train loss 7.744511094642803e-05, accuracy 0.7407407407407407\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m [Client 22] fit, config: {'current_round': 91, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m Epoch 1: train loss 0.00010848867532331496, accuracy 0.5370370370370371\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m [Client 77] fit, config: {'current_round': 91, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m Epoch 1: train loss 8.342761429958045e-05, accuracy 0.7037037037037037\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m [Client 18] fit, config: {'current_round': 91, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m Epoch 1: train loss 0.00011235890269745141, accuracy 0.5\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m [Client 26] fit, config: {'current_round': 91, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m Epoch 1: train loss 9.596317249815911e-05, accuracy 0.6296296296296297\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m [Client 60] fit, config: {'current_round': 91, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m Epoch 1: train loss 8.58821949805133e-05, accuracy 0.6851851851851852\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m [Client 71] fit, config: {'current_round': 91, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m [Client 68] fit, config: {'current_round': 91, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m [Client 84] fit, config: {'current_round': 91, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m Epoch 1: train loss 7.352291140705347e-05, accuracy 0.6851851851851852\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m [Client 87] fit, config: {'current_round': 91, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m Epoch 1: train loss 8.32955411169678e-05, accuracy 0.6851851851851852\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m [Client 13] fit, config: {'current_round': 91, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m Epoch 1: train loss 9.276106720790267e-05, accuracy 0.6296296296296297\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m [Client 16] fit, config: {'current_round': 91, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m Epoch 1: train loss 9.743747068569064e-05, accuracy 0.6111111111111112\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m [Client 40] fit, config: {'current_round': 91, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m Epoch 1: train loss 7.733717211522162e-05, accuracy 0.7037037037037037\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m Epoch 1: train loss 8.23826267151162e-05, accuracy 0.7037037037037037\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m [Client 72] fit, config: {'current_round': 91, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m Epoch 1: train loss 7.572856702608988e-05, accuracy 0.7222222222222222\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m [Client 58] fit, config: {'current_round': 91, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m Epoch 1: train loss 8.26451214379631e-05, accuracy 0.7222222222222222\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m [Client 90] fit, config: {'current_round': 91, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m Epoch 1: train loss 8.219819574151188e-05, accuracy 0.6296296296296297\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m [Client 66] fit, config: {'current_round': 91, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m Epoch 1: train loss 7.234114309540018e-05, accuracy 0.6666666666666666\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m [Client 69] fit, config: {'current_round': 91, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m Epoch 1: train loss 7.14178167982027e-05, accuracy 0.7407407407407407\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m Epoch 1: train loss 7.175832433858886e-05, accuracy 0.6851851851851852\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m [Client 99] fit, config: {'current_round': 91, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m Epoch 1: train loss 8.635115227662027e-05, accuracy 0.6666666666666666\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m [Client 12] fit, config: {'current_round': 91, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m [Client 30] fit, config: {'current_round': 91, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m [Client 5] fit, config: {'current_round': 91, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m Epoch 1: train loss 8.926892041927204e-05, accuracy 0.6666666666666666\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m [Client 43] fit, config: {'current_round': 91, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m Epoch 1: train loss 8.176672417903319e-05, accuracy 0.7037037037037037\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m [Client 44] fit, config: {'current_round': 91, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m Epoch 1: train loss 0.00010107129492098466, accuracy 0.5925925925925926\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 13:01:05,150 | server.py:216 | fit_round received 30 results and 0 failures\n",
      "DEBUG flower 2023-02-01 13:01:05,196 | server.py:157 | evaluate_round: strategy sampled 30 clients (out of 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m [Client 80] fit, config: {'current_round': 91, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m Epoch 1: train loss 6.504131306428462e-05, accuracy 0.8333333333333334\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m Epoch 1: train loss 9.012271766550839e-05, accuracy 0.7037037037037037\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m Epoch 1: train loss 9.248607238987461e-05, accuracy 0.6111111111111112\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m [Client 64] fit, config: {'current_round': 91, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m Epoch 1: train loss 6.680809747194871e-05, accuracy 0.8148148148148148\n",
      "Saving round 91 aggregated_parameters...\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98093)\u001b[0m [Client 60] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98090)\u001b[0m [Client 48] evaluate, config: {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 13:01:07,241 | server.py:170 | evaluate_round received 0 results and 30 failures\n",
      "DEBUG flower 2023-02-01 13:01:07,244 | server.py:203 | fit_round: strategy sampled 30 clients (out of 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98090)\u001b[0m [Client 44] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98093)\u001b[0m [Client 45] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98090)\u001b[0m [Client 82] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98093)\u001b[0m [Client 96] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98093)\u001b[0m [Client 92] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98090)\u001b[0m [Client 16] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98090)\u001b[0m [Client 84] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98093)\u001b[0m [Client 58] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98090)\u001b[0m [Client 12] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98093)\u001b[0m [Client 8] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98090)\u001b[0m [Client 39] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98093)\u001b[0m [Client 50] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98090)\u001b[0m [Client 54] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98093)\u001b[0m [Client 15] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98095)\u001b[0m [Client 14] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98090)\u001b[0m [Client 57] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98095)\u001b[0m [Client 97] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98093)\u001b[0m [Client 59] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98090)\u001b[0m [Client 17] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98090)\u001b[0m [Client 78] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98088)\u001b[0m [Client 52] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98095)\u001b[0m [Client 3] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98093)\u001b[0m [Client 18] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98094)\u001b[0m [Client 22] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98092)\u001b[0m [Client 89] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98091)\u001b[0m [Client 94] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98093)\u001b[0m [Client 77] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98089)\u001b[0m [Client 29] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m [Client 6] fit, config: {'current_round': 92, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m [Client 33] fit, config: {'current_round': 92, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m Epoch 1: train loss 7.897477189544588e-05, accuracy 0.7592592592592593\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m Epoch 1: train loss 9.274647891288623e-05, accuracy 0.5925925925925926\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m [Client 71] fit, config: {'current_round': 92, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m Epoch 1: train loss 7.097955676726997e-05, accuracy 0.7592592592592593\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m [Client 51] fit, config: {'current_round': 92, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m Epoch 1: train loss 8.612415695097297e-05, accuracy 0.7037037037037037\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m [Client 75] fit, config: {'current_round': 92, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m Epoch 1: train loss 0.0001031916108331643, accuracy 0.6296296296296297\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m [Client 94] fit, config: {'current_round': 92, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m Epoch 1: train loss 9.537703590467572e-05, accuracy 0.6111111111111112\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m [Client 54] fit, config: {'current_round': 92, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m Epoch 1: train loss 9.135353320743889e-05, accuracy 0.6481481481481481\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m [Client 32] fit, config: {'current_round': 92, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m Epoch 1: train loss 9.20511010917835e-05, accuracy 0.6296296296296297\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m [Client 39] fit, config: {'current_round': 92, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m Epoch 1: train loss 7.585711864521727e-05, accuracy 0.6666666666666666\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m [Client 15] fit, config: {'current_round': 92, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m [Client 35] fit, config: {'current_round': 92, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m Epoch 1: train loss 8.084838191280141e-05, accuracy 0.7222222222222222\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m [Client 43] fit, config: {'current_round': 92, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m Epoch 1: train loss 8.865600102581084e-05, accuracy 0.6481481481481481\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m [Client 21] fit, config: {'current_round': 92, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m Epoch 1: train loss 9.91055931081064e-05, accuracy 0.6111111111111112\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m Epoch 1: train loss 0.00012672632874455303, accuracy 0.5555555555555556\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m [Client 64] fit, config: {'current_round': 92, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m Epoch 1: train loss 7.20437674317509e-05, accuracy 0.7222222222222222\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m [Client 29] fit, config: {'current_round': 92, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m Epoch 1: train loss 8.999432611744851e-05, accuracy 0.6296296296296297\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 13:01:09,303 | server.py:216 | fit_round received 30 results and 0 failures\n",
      "DEBUG flower 2023-02-01 13:01:09,361 | server.py:157 | evaluate_round: strategy sampled 30 clients (out of 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m [Client 52] fit, config: {'current_round': 92, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m Epoch 1: train loss 9.1275927843526e-05, accuracy 0.5925925925925926\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m [Client 78] fit, config: {'current_round': 92, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m Epoch 1: train loss 0.00010609525634208694, accuracy 0.5555555555555556\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m [Client 81] fit, config: {'current_round': 92, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m Epoch 1: train loss 0.00010404752538306639, accuracy 0.5925925925925926\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m [Client 1] fit, config: {'current_round': 92, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m [Client 48] fit, config: {'current_round': 92, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m Epoch 1: train loss 8.396697376156226e-05, accuracy 0.6296296296296297\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m [Client 23] fit, config: {'current_round': 92, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m Epoch 1: train loss 9.87387029454112e-05, accuracy 0.6296296296296297\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m [Client 50] fit, config: {'current_round': 92, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m [Client 25] fit, config: {'current_round': 92, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m Epoch 1: train loss 8.563651499571279e-05, accuracy 0.6481481481481481\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m [Client 38] fit, config: {'current_round': 92, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m Epoch 1: train loss 8.974673983175308e-05, accuracy 0.6666666666666666\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m Epoch 1: train loss 9.534320270176977e-05, accuracy 0.6111111111111112\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m [Client 85] fit, config: {'current_round': 92, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m Epoch 1: train loss 0.0001082790840882808, accuracy 0.5370370370370371\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m Epoch 1: train loss 8.249339589383453e-05, accuracy 0.6666666666666666\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m [Client 20] fit, config: {'current_round': 92, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m [Client 91] fit, config: {'current_round': 92, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m [Client 68] fit, config: {'current_round': 92, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m Epoch 1: train loss 8.280322072096169e-05, accuracy 0.6481481481481481\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m [Client 62] fit, config: {'current_round': 92, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m Epoch 1: train loss 7.913395529612899e-05, accuracy 0.7037037037037037\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m [Client 5] fit, config: {'current_round': 92, 'local_epochs': 3}\n",
      "Saving round 92 aggregated_parameters...\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m Epoch 1: train loss 0.0001051687722792849, accuracy 0.5740740740740741\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m Epoch 1: train loss 7.566613203380257e-05, accuracy 0.6851851851851852\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m Epoch 1: train loss 7.633299537701532e-05, accuracy 0.7407407407407407\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98090)\u001b[0m [Client 15] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98090)\u001b[0m [Client 29] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98094)\u001b[0m [Client 37] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98094)\u001b[0m [Client 11] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98094)\u001b[0m [Client 59] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98094)\u001b[0m [Client 54] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98094)\u001b[0m [Client 58] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98090)\u001b[0m [Client 99] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98094)\u001b[0m [Client 5] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98090)\u001b[0m [Client 97] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98094)\u001b[0m [Client 23] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98090)\u001b[0m [Client 74] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98094)\u001b[0m [Client 98] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98094)\u001b[0m [Client 80] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98090)\u001b[0m [Client 83] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98094)\u001b[0m [Client 55] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98091)\u001b[0m [Client 71] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98091)\u001b[0m [Client 39] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98091)\u001b[0m [Client 26] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98091)\u001b[0m [Client 13] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98090)\u001b[0m [Client 60] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98094)\u001b[0m [Client 46] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98092)\u001b[0m [Client 84] evaluate, config: {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 13:01:11,507 | server.py:170 | evaluate_round received 0 results and 30 failures\n",
      "DEBUG flower 2023-02-01 13:01:11,508 | server.py:203 | fit_round: strategy sampled 30 clients (out of 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98090)\u001b[0m [Client 0] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98088)\u001b[0m [Client 53] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98095)\u001b[0m [Client 34] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98093)\u001b[0m [Client 76] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98089)\u001b[0m [Client 66] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98094)\u001b[0m [Client 32] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98092)\u001b[0m [Client 45] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m [Client 44] fit, config: {'current_round': 93, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m Epoch 1: train loss 9.802229760680348e-05, accuracy 0.6481481481481481\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m [Client 41] fit, config: {'current_round': 93, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m Epoch 1: train loss 7.0312584284693e-05, accuracy 0.6481481481481481\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m [Client 65] fit, config: {'current_round': 93, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m Epoch 1: train loss 8.353583689313382e-05, accuracy 0.6666666666666666\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m [Client 79] fit, config: {'current_round': 93, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m Epoch 1: train loss 8.127813634928316e-05, accuracy 0.6666666666666666\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m [Client 75] fit, config: {'current_round': 93, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m Epoch 1: train loss 8.714962314115837e-05, accuracy 0.6851851851851852\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m [Client 29] fit, config: {'current_round': 93, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m Epoch 1: train loss 9.132015111390501e-05, accuracy 0.6296296296296297\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m [Client 8] fit, config: {'current_round': 93, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m Epoch 1: train loss 8.55069374665618e-05, accuracy 0.6481481481481481\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m [Client 98] fit, config: {'current_round': 93, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m [Client 68] fit, config: {'current_round': 93, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m Epoch 1: train loss 6.994109571678564e-05, accuracy 0.7407407407407407\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m [Client 38] fit, config: {'current_round': 93, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m Epoch 1: train loss 8.409133442910388e-05, accuracy 0.7037037037037037\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m Epoch 1: train loss 0.00010523201490286738, accuracy 0.6111111111111112\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m [Client 49] fit, config: {'current_round': 93, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m [Client 1] fit, config: {'current_round': 93, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m Epoch 1: train loss 8.361732761841267e-05, accuracy 0.6111111111111112\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m [Client 34] fit, config: {'current_round': 93, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m Epoch 1: train loss 9.097575821215287e-05, accuracy 0.6111111111111112\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m Epoch 1: train loss 9.557964949635789e-05, accuracy 0.6296296296296297\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m [Client 32] fit, config: {'current_round': 93, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m Epoch 1: train loss 7.122246461221948e-05, accuracy 0.6481481481481481\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m [Client 13] fit, config: {'current_round': 93, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m Epoch 1: train loss 9.255063196178526e-05, accuracy 0.6481481481481481\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m [Client 62] fit, config: {'current_round': 93, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m [Client 58] fit, config: {'current_round': 93, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m Epoch 1: train loss 8.044722926570103e-05, accuracy 0.7037037037037037\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m [Client 30] fit, config: {'current_round': 93, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m Epoch 1: train loss 8.66343907546252e-05, accuracy 0.6481481481481481\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m Epoch 1: train loss 7.41219992050901e-05, accuracy 0.7222222222222222\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m [Client 93] fit, config: {'current_round': 93, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m [Client 28] fit, config: {'current_round': 93, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m Epoch 1: train loss 8.453879854641855e-05, accuracy 0.6111111111111112\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m [Client 92] fit, config: {'current_round': 93, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m Epoch 1: train loss 8.709394023753703e-05, accuracy 0.7037037037037037\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m Epoch 1: train loss 7.285770698217675e-05, accuracy 0.7962962962962963\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m [Client 31] fit, config: {'current_round': 93, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m [Client 37] fit, config: {'current_round': 93, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m [Client 73] fit, config: {'current_round': 93, 'local_epochs': 3}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 13:01:13,628 | server.py:216 | fit_round received 30 results and 0 failures\n",
      "DEBUG flower 2023-02-01 13:01:13,678 | server.py:157 | evaluate_round: strategy sampled 30 clients (out of 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m [Client 22] fit, config: {'current_round': 93, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m Epoch 1: train loss 8.863687980920076e-05, accuracy 0.6666666666666666\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m [Client 94] fit, config: {'current_round': 93, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m [Client 84] fit, config: {'current_round': 93, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m Epoch 1: train loss 6.17994592175819e-05, accuracy 0.7222222222222222\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m [Client 90] fit, config: {'current_round': 93, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m [Client 80] fit, config: {'current_round': 93, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m Epoch 1: train loss 6.330310134217143e-05, accuracy 0.7777777777777778\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m Epoch 1: train loss 8.614696707809344e-05, accuracy 0.6666666666666666\n",
      "Saving round 93 aggregated_parameters...\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m Epoch 1: train loss 0.00010779662261484191, accuracy 0.5740740740740741\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m [Client 16] fit, config: {'current_round': 93, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m Epoch 1: train loss 9.162248898064718e-05, accuracy 0.6666666666666666\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m Epoch 1: train loss 7.575911149615422e-05, accuracy 0.7037037037037037\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m Epoch 1: train loss 7.050792191876099e-05, accuracy 0.7407407407407407\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m Epoch 1: train loss 8.10504425317049e-05, accuracy 0.7222222222222222\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98090)\u001b[0m [Client 17] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98090)\u001b[0m [Client 71] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98089)\u001b[0m [Client 73] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98089)\u001b[0m [Client 12] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98089)\u001b[0m [Client 26] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98091)\u001b[0m [Client 9] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98089)\u001b[0m [Client 44] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98090)\u001b[0m [Client 65] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98090)\u001b[0m [Client 52] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98090)\u001b[0m [Client 1] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98091)\u001b[0m [Client 3] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98090)\u001b[0m [Client 8] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98089)\u001b[0m [Client 79] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98091)\u001b[0m [Client 23] evaluate, config: {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 13:01:15,908 | server.py:170 | evaluate_round received 0 results and 30 failures\n",
      "DEBUG flower 2023-02-01 13:01:15,909 | server.py:203 | fit_round: strategy sampled 30 clients (out of 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98090)\u001b[0m [Client 16] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98088)\u001b[0m [Client 28] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98095)\u001b[0m [Client 67] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98089)\u001b[0m [Client 72] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98094)\u001b[0m [Client 69] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98091)\u001b[0m [Client 97] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98090)\u001b[0m [Client 63] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98093)\u001b[0m [Client 75] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98089)\u001b[0m [Client 82] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98094)\u001b[0m [Client 91] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98092)\u001b[0m [Client 57] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98091)\u001b[0m [Client 96] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98093)\u001b[0m [Client 51] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98089)\u001b[0m [Client 39] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98094)\u001b[0m [Client 76] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98092)\u001b[0m [Client 64] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m [Client 40] fit, config: {'current_round': 94, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m Epoch 1: train loss 7.018906762823462e-05, accuracy 0.7222222222222222\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m [Client 59] fit, config: {'current_round': 94, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m Epoch 1: train loss 8.055316720856354e-05, accuracy 0.7037037037037037\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m [Client 89] fit, config: {'current_round': 94, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m [Client 21] fit, config: {'current_round': 94, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m [Client 17] fit, config: {'current_round': 94, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m Epoch 1: train loss 7.385104981949553e-05, accuracy 0.7962962962962963\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m Epoch 1: train loss 8.196615817723796e-05, accuracy 0.7037037037037037\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m [Client 58] fit, config: {'current_round': 94, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m Epoch 1: train loss 8.429664740106091e-05, accuracy 0.6481481481481481\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m Epoch 1: train loss 9.402614523423836e-05, accuracy 0.6481481481481481\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m [Client 31] fit, config: {'current_round': 94, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m Epoch 1: train loss 7.586875290144235e-05, accuracy 0.7037037037037037\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m [Client 30] fit, config: {'current_round': 94, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m Epoch 1: train loss 8.614852413302287e-05, accuracy 0.6666666666666666\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m [Client 90] fit, config: {'current_round': 94, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m [Client 75] fit, config: {'current_round': 94, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m Epoch 1: train loss 9.816695092013106e-05, accuracy 0.6666666666666666\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m [Client 72] fit, config: {'current_round': 94, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m Epoch 1: train loss 6.925754860276356e-05, accuracy 0.8333333333333334\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m Epoch 1: train loss 7.557295612059534e-05, accuracy 0.7407407407407407\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m [Client 76] fit, config: {'current_round': 94, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m Epoch 1: train loss 6.583192589459941e-05, accuracy 0.7037037037037037\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m [Client 69] fit, config: {'current_round': 94, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m [Client 57] fit, config: {'current_round': 94, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m Epoch 1: train loss 0.00010174216004088521, accuracy 0.5740740740740741\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m [Client 49] fit, config: {'current_round': 94, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m Epoch 1: train loss 9.177275205729529e-05, accuracy 0.6481481481481481\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m [Client 1] fit, config: {'current_round': 94, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m Epoch 1: train loss 8.839488873491064e-05, accuracy 0.6111111111111112\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m [Client 47] fit, config: {'current_round': 94, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m Epoch 1: train loss 7.901704520918429e-05, accuracy 0.7037037037037037\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m Epoch 1: train loss 7.082737283781171e-05, accuracy 0.6851851851851852\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m [Client 22] fit, config: {'current_round': 94, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m [Client 63] fit, config: {'current_round': 94, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m Epoch 1: train loss 8.814131433609873e-05, accuracy 0.5740740740740741\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m Epoch 1: train loss 0.00010596017818897963, accuracy 0.5185185185185185\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m [Client 64] fit, config: {'current_round': 94, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m Epoch 1: train loss 6.85037302901037e-05, accuracy 0.7962962962962963\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 13:01:18,163 | server.py:216 | fit_round received 30 results and 0 failures\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m [Client 25] fit, config: {'current_round': 94, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m Epoch 1: train loss 7.877734606154263e-05, accuracy 0.7222222222222222\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m [Client 86] fit, config: {'current_round': 94, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m [Client 99] fit, config: {'current_round': 94, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m [Client 26] fit, config: {'current_round': 94, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m Epoch 1: train loss 9.067913197213784e-05, accuracy 0.5740740740740741\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m [Client 81] fit, config: {'current_round': 94, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m Epoch 1: train loss 9.857663826551288e-05, accuracy 0.6111111111111112\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m [Client 52] fit, config: {'current_round': 94, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m [Client 28] fit, config: {'current_round': 94, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m Epoch 1: train loss 6.922893226146698e-05, accuracy 0.7777777777777778\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m Epoch 1: train loss 6.878397107357159e-05, accuracy 0.7592592592592593\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m [Client 3] fit, config: {'current_round': 94, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m Epoch 1: train loss 8.862466347636655e-05, accuracy 0.7592592592592593\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m [Client 73] fit, config: {'current_round': 94, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m Epoch 1: train loss 8.895801147446036e-05, accuracy 0.6666666666666666\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m Epoch 1: train loss 8.357325714314356e-05, accuracy 0.6296296296296297\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m Epoch 1: train loss 7.559169171145186e-05, accuracy 0.7037037037037037\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 13:01:18,215 | server.py:157 | evaluate_round: strategy sampled 30 clients (out of 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m [Client 56] fit, config: {'current_round': 94, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m Epoch 1: train loss 9.492552635492757e-05, accuracy 0.6481481481481481\n",
      "Saving round 94 aggregated_parameters...\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98091)\u001b[0m [Client 34] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98089)\u001b[0m [Client 61] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98089)\u001b[0m [Client 49] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98091)\u001b[0m [Client 19] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98089)\u001b[0m [Client 90] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98089)\u001b[0m [Client 88] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98089)\u001b[0m [Client 30] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98089)\u001b[0m [Client 89] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98091)\u001b[0m [Client 96] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98091)\u001b[0m [Client 71] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98091)\u001b[0m [Client 28] evaluate, config: {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 13:01:20,268 | server.py:170 | evaluate_round received 0 results and 30 failures\n",
      "DEBUG flower 2023-02-01 13:01:20,269 | server.py:203 | fit_round: strategy sampled 30 clients (out of 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98095)\u001b[0m [Client 29] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98089)\u001b[0m [Client 75] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98089)\u001b[0m [Client 52] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98089)\u001b[0m [Client 87] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98089)\u001b[0m [Client 86] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98089)\u001b[0m [Client 83] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98090)\u001b[0m [Client 27] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98088)\u001b[0m [Client 70] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98095)\u001b[0m [Client 44] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98089)\u001b[0m [Client 85] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98092)\u001b[0m [Client 41] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98091)\u001b[0m [Client 53] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98095)\u001b[0m [Client 55] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98094)\u001b[0m [Client 9] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98090)\u001b[0m [Client 4] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98088)\u001b[0m [Client 67] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98089)\u001b[0m [Client 43] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98094)\u001b[0m [Client 82] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98092)\u001b[0m [Client 56] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m [Client 80] fit, config: {'current_round': 95, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m Epoch 1: train loss 6.799810216762125e-05, accuracy 0.7407407407407407\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m [Client 35] fit, config: {'current_round': 95, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m Epoch 1: train loss 9.090977982850745e-05, accuracy 0.6296296296296297\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m [Client 90] fit, config: {'current_round': 95, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m Epoch 1: train loss 8.016111678443849e-05, accuracy 0.6666666666666666\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m [Client 74] fit, config: {'current_round': 95, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m Epoch 1: train loss 9.416582906851545e-05, accuracy 0.6296296296296297\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m [Client 56] fit, config: {'current_round': 95, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m Epoch 1: train loss 9.082740871235728e-05, accuracy 0.7037037037037037\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m [Client 94] fit, config: {'current_round': 95, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m Epoch 1: train loss 7.491381256841123e-05, accuracy 0.7592592592592593\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m [Client 45] fit, config: {'current_round': 95, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m Epoch 1: train loss 8.342300134245306e-05, accuracy 0.6666666666666666\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m [Client 85] fit, config: {'current_round': 95, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m Epoch 1: train loss 0.00010219682735623792, accuracy 0.5555555555555556\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m [Client 16] fit, config: {'current_round': 95, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m Epoch 1: train loss 9.152324491878971e-05, accuracy 0.5925925925925926\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m [Client 69] fit, config: {'current_round': 95, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m Epoch 1: train loss 7.102224481059238e-05, accuracy 0.6481481481481481\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m [Client 79] fit, config: {'current_round': 95, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m Epoch 1: train loss 7.80231857788749e-05, accuracy 0.6666666666666666\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m [Client 17] fit, config: {'current_round': 95, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m Epoch 1: train loss 7.462505163857713e-05, accuracy 0.7592592592592593\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m [Client 31] fit, config: {'current_round': 95, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m Epoch 1: train loss 8.66543487063609e-05, accuracy 0.7037037037037037\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m [Client 42] fit, config: {'current_round': 95, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m Epoch 1: train loss 9.077976574189961e-05, accuracy 0.5925925925925926\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m [Client 26] fit, config: {'current_round': 95, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m Epoch 1: train loss 9.071696695173159e-05, accuracy 0.7222222222222222\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m [Client 24] fit, config: {'current_round': 95, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m Epoch 1: train loss 7.601972174597904e-05, accuracy 0.6851851851851852\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m [Client 38] fit, config: {'current_round': 95, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m Epoch 1: train loss 8.507468010066077e-05, accuracy 0.6296296296296297\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m [Client 65] fit, config: {'current_round': 95, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m Epoch 1: train loss 8.581300062360242e-05, accuracy 0.6481481481481481\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m [Client 25] fit, config: {'current_round': 95, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m [Client 33] fit, config: {'current_round': 95, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m Epoch 1: train loss 9.016265539685264e-05, accuracy 0.5925925925925926\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m Epoch 1: train loss 7.302121230168268e-05, accuracy 0.6666666666666666\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m [Client 84] fit, config: {'current_round': 95, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m Epoch 1: train loss 7.312365050893277e-05, accuracy 0.6851851851851852\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m [Client 36] fit, config: {'current_round': 95, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m [Client 21] fit, config: {'current_round': 95, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m Epoch 1: train loss 0.000112583686131984, accuracy 0.48148148148148145\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m [Client 8] fit, config: {'current_round': 95, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m [Client 97] fit, config: {'current_round': 95, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m Epoch 1: train loss 0.00012364743452053517, accuracy 0.46296296296296297\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 13:01:22,529 | server.py:216 | fit_round received 30 results and 0 failures\n",
      "DEBUG flower 2023-02-01 13:01:22,582 | server.py:157 | evaluate_round: strategy sampled 30 clients (out of 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m [Client 62] fit, config: {'current_round': 95, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m Epoch 1: train loss 9.369986219098791e-05, accuracy 0.6111111111111112\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m [Client 19] fit, config: {'current_round': 95, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m Epoch 1: train loss 7.468522380804643e-05, accuracy 0.6296296296296297\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m Epoch 1: train loss 8.359256025869399e-05, accuracy 0.6481481481481481\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m [Client 72] fit, config: {'current_round': 95, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m Epoch 1: train loss 7.359615847235546e-05, accuracy 0.6666666666666666\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m [Client 77] fit, config: {'current_round': 95, 'local_epochs': 3}\n",
      "Saving round 95 aggregated_parameters...\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m Epoch 1: train loss 7.35705834813416e-05, accuracy 0.6851851851851852\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m [Client 89] fit, config: {'current_round': 95, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m Epoch 1: train loss 7.652542262803763e-05, accuracy 0.6111111111111112\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m Epoch 1: train loss 8.015509229153395e-05, accuracy 0.7222222222222222\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98094)\u001b[0m [Client 80] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98094)\u001b[0m [Client 62] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98092)\u001b[0m [Client 72] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98092)\u001b[0m [Client 4] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98092)\u001b[0m [Client 40] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98092)\u001b[0m [Client 22] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98091)\u001b[0m [Client 7] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98094)\u001b[0m [Client 19] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98092)\u001b[0m [Client 58] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98090)\u001b[0m [Client 75] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98095)\u001b[0m [Client 6] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98089)\u001b[0m [Client 66] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98089)\u001b[0m [Client 57] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98089)\u001b[0m [Client 68] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98089)\u001b[0m [Client 89] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98090)\u001b[0m [Client 88] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98095)\u001b[0m [Client 35] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98089)\u001b[0m [Client 14] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98095)\u001b[0m [Client 33] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98089)\u001b[0m [Client 76] evaluate, config: {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 13:01:24,702 | server.py:170 | evaluate_round received 0 results and 30 failures\n",
      "DEBUG flower 2023-02-01 13:01:24,705 | server.py:203 | fit_round: strategy sampled 30 clients (out of 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98091)\u001b[0m [Client 24] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98090)\u001b[0m [Client 61] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98095)\u001b[0m [Client 17] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98089)\u001b[0m [Client 74] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98094)\u001b[0m [Client 81] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98091)\u001b[0m [Client 16] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98090)\u001b[0m [Client 48] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98095)\u001b[0m [Client 50] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98089)\u001b[0m [Client 82] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98094)\u001b[0m [Client 12] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m [Client 57] fit, config: {'current_round': 96, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m [Client 0] fit, config: {'current_round': 96, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m Epoch 1: train loss 0.00010906220995821059, accuracy 0.6111111111111112\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m [Client 42] fit, config: {'current_round': 96, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m Epoch 1: train loss 9.454173414269462e-05, accuracy 0.5555555555555556\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m Epoch 1: train loss 0.00011453179467935115, accuracy 0.5740740740740741\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m [Client 18] fit, config: {'current_round': 96, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m Epoch 1: train loss 9.678316564531997e-05, accuracy 0.6296296296296297\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m [Client 44] fit, config: {'current_round': 96, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m Epoch 1: train loss 9.848221088759601e-05, accuracy 0.6481481481481481\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m [Client 51] fit, config: {'current_round': 96, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m Epoch 1: train loss 8.503153367200866e-05, accuracy 0.7037037037037037\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m [Client 64] fit, config: {'current_round': 96, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m Epoch 1: train loss 6.838016270194203e-05, accuracy 0.7962962962962963\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m [Client 27] fit, config: {'current_round': 96, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m Epoch 1: train loss 9.807579044718295e-05, accuracy 0.5925925925925926\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m [Client 66] fit, config: {'current_round': 96, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m Epoch 1: train loss 7.842628110665828e-05, accuracy 0.6851851851851852\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m [Client 87] fit, config: {'current_round': 96, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m Epoch 1: train loss 8.043183333938941e-05, accuracy 0.7222222222222222\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m [Client 8] fit, config: {'current_round': 96, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m Epoch 1: train loss 9.22639956115745e-05, accuracy 0.6666666666666666\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m [Client 43] fit, config: {'current_round': 96, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m [Client 28] fit, config: {'current_round': 96, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m [Client 12] fit, config: {'current_round': 96, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m Epoch 1: train loss 8.716792217455804e-05, accuracy 0.6481481481481481\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m [Client 45] fit, config: {'current_round': 96, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m Epoch 1: train loss 8.631667151348665e-05, accuracy 0.6481481481481481\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m [Client 94] fit, config: {'current_round': 96, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m Epoch 1: train loss 8.603664173278958e-05, accuracy 0.6851851851851852\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m Epoch 1: train loss 7.695002568652853e-05, accuracy 0.7037037037037037\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m Epoch 1: train loss 9.295561903854832e-05, accuracy 0.5925925925925926\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m [Client 35] fit, config: {'current_round': 96, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m Epoch 1: train loss 7.886531238909811e-05, accuracy 0.7222222222222222\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m [Client 49] fit, config: {'current_round': 96, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m [Client 58] fit, config: {'current_round': 96, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m Epoch 1: train loss 9.46293948800303e-05, accuracy 0.5925925925925926\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m [Client 79] fit, config: {'current_round': 96, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m Epoch 1: train loss 9.542891348246485e-05, accuracy 0.6111111111111112\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m [Client 97] fit, config: {'current_round': 96, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m [Client 99] fit, config: {'current_round': 96, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m [Client 93] fit, config: {'current_round': 96, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m Epoch 1: train loss 8.887119474820793e-05, accuracy 0.6481481481481481\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 13:01:27,090 | server.py:216 | fit_round received 30 results and 0 failures\n",
      "DEBUG flower 2023-02-01 13:01:27,141 | server.py:157 | evaluate_round: strategy sampled 30 clients (out of 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m [Client 24] fit, config: {'current_round': 96, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m Epoch 1: train loss 0.00012015790707664564, accuracy 0.5555555555555556\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m Epoch 1: train loss 7.060703501338139e-05, accuracy 0.8148148148148148\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m [Client 92] fit, config: {'current_round': 96, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m [Client 23] fit, config: {'current_round': 96, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m Epoch 1: train loss 9.518999286228791e-05, accuracy 0.6666666666666666\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m [Client 20] fit, config: {'current_round': 96, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m [Client 60] fit, config: {'current_round': 96, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m Epoch 1: train loss 7.995849591679871e-05, accuracy 0.6851851851851852\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m Epoch 1: train loss 7.017081952653825e-05, accuracy 0.6851851851851852\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m [Client 39] fit, config: {'current_round': 96, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m [Client 25] fit, config: {'current_round': 96, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m Epoch 1: train loss 9.593443246558309e-05, accuracy 0.6481481481481481\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m Epoch 1: train loss 0.00010136832133866847, accuracy 0.5740740740740741\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m Epoch 1: train loss 8.148628694470972e-05, accuracy 0.7037037037037037\n",
      "Saving round 96 aggregated_parameters...\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m Epoch 1: train loss 7.176348299253732e-05, accuracy 0.6851851851851852\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m Epoch 1: train loss 8.403891115449369e-05, accuracy 0.6666666666666666\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98088)\u001b[0m [Client 41] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98090)\u001b[0m [Client 25] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98088)\u001b[0m [Client 47] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98090)\u001b[0m [Client 87] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98088)\u001b[0m [Client 11] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98088)\u001b[0m [Client 73] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98091)\u001b[0m [Client 80] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98088)\u001b[0m [Client 42] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98093)\u001b[0m [Client 20] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98090)\u001b[0m [Client 75] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98088)\u001b[0m [Client 21] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98095)\u001b[0m [Client 55] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98093)\u001b[0m [Client 91] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98089)\u001b[0m [Client 62] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98094)\u001b[0m [Client 61] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98092)\u001b[0m [Client 71] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98091)\u001b[0m [Client 51] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98091)\u001b[0m [Client 22] evaluate, config: {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 13:01:29,415 | server.py:170 | evaluate_round received 0 results and 30 failures\n",
      "DEBUG flower 2023-02-01 13:01:29,416 | server.py:203 | fit_round: strategy sampled 30 clients (out of 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98088)\u001b[0m [Client 82] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98093)\u001b[0m [Client 85] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98094)\u001b[0m [Client 37] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98091)\u001b[0m [Client 10] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98088)\u001b[0m [Client 48] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98089)\u001b[0m [Client 65] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98094)\u001b[0m [Client 63] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98092)\u001b[0m [Client 30] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98091)\u001b[0m [Client 89] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98090)\u001b[0m [Client 59] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98095)\u001b[0m [Client 14] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98093)\u001b[0m [Client 38] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m [Client 46] fit, config: {'current_round': 97, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m Epoch 1: train loss 6.02420732320752e-05, accuracy 0.8148148148148148\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m [Client 56] fit, config: {'current_round': 97, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m Epoch 1: train loss 9.562548802932724e-05, accuracy 0.6481481481481481\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m [Client 86] fit, config: {'current_round': 97, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m Epoch 1: train loss 7.699059642618522e-05, accuracy 0.6851851851851852\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m [Client 62] fit, config: {'current_round': 97, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m [Client 83] fit, config: {'current_round': 97, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m Epoch 1: train loss 7.326892955461517e-05, accuracy 0.7037037037037037\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m [Client 8] fit, config: {'current_round': 97, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m Epoch 1: train loss 8.533927757525817e-05, accuracy 0.6481481481481481\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m Epoch 1: train loss 9.252060408471152e-05, accuracy 0.6296296296296297\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m [Client 79] fit, config: {'current_round': 97, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m Epoch 1: train loss 7.86673990660347e-05, accuracy 0.6666666666666666\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m [Client 95] fit, config: {'current_round': 97, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m Epoch 1: train loss 5.9993475588271394e-05, accuracy 0.7222222222222222\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m [Client 30] fit, config: {'current_round': 97, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m Epoch 1: train loss 8.589176286477596e-05, accuracy 0.6481481481481481\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m [Client 33] fit, config: {'current_round': 97, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m Epoch 1: train loss 8.715527656022459e-05, accuracy 0.6666666666666666\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m [Client 49] fit, config: {'current_round': 97, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m [Client 53] fit, config: {'current_round': 97, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m Epoch 1: train loss 8.774692105362192e-05, accuracy 0.6481481481481481\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m [Client 76] fit, config: {'current_round': 97, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m Epoch 1: train loss 6.1325408751145e-05, accuracy 0.7407407407407407\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m Epoch 1: train loss 9.349834726890549e-05, accuracy 0.6296296296296297\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m [Client 88] fit, config: {'current_round': 97, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m Epoch 1: train loss 7.301703590201214e-05, accuracy 0.7407407407407407\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m [Client 38] fit, config: {'current_round': 97, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m [Client 43] fit, config: {'current_round': 97, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m Epoch 1: train loss 8.091289782896638e-05, accuracy 0.7407407407407407\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m [Client 63] fit, config: {'current_round': 97, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m Epoch 1: train loss 8.080278348643333e-05, accuracy 0.6851851851851852\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m Epoch 1: train loss 8.351944416062906e-05, accuracy 0.7037037037037037\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m [Client 36] fit, config: {'current_round': 97, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m Epoch 1: train loss 9.6876137831714e-05, accuracy 0.5740740740740741\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m [Client 72] fit, config: {'current_round': 97, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m [Client 5] fit, config: {'current_round': 97, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m Epoch 1: train loss 8.544697629986331e-05, accuracy 0.7037037037037037\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m Epoch 1: train loss 7.518168422393501e-05, accuracy 0.7222222222222222\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m [Client 51] fit, config: {'current_round': 97, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m Epoch 1: train loss 8.211270323954523e-05, accuracy 0.6481481481481481\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m [Client 70] fit, config: {'current_round': 97, 'local_epochs': 3}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 13:01:31,813 | server.py:216 | fit_round received 30 results and 0 failures\n",
      "DEBUG flower 2023-02-01 13:01:31,864 | server.py:157 | evaluate_round: strategy sampled 30 clients (out of 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m [Client 11] fit, config: {'current_round': 97, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m Epoch 1: train loss 8.048175368458033e-05, accuracy 0.7037037037037037\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m Epoch 1: train loss 0.00011191812518518418, accuracy 0.6111111111111112\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m [Client 31] fit, config: {'current_round': 97, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m [Client 87] fit, config: {'current_round': 97, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m [Client 0] fit, config: {'current_round': 97, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m [Client 10] fit, config: {'current_round': 97, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m [Client 58] fit, config: {'current_round': 97, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m Epoch 1: train loss 8.007763972273096e-05, accuracy 0.7037037037037037\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m Epoch 1: train loss 8.653777331346646e-05, accuracy 0.6666666666666666\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m [Client 91] fit, config: {'current_round': 97, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m Epoch 1: train loss 9.038001007866114e-05, accuracy 0.5370370370370371\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m [Client 67] fit, config: {'current_round': 97, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m Epoch 1: train loss 0.0001103384856833145, accuracy 0.5925925925925926\n",
      "Saving round 97 aggregated_parameters...\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m Epoch 1: train loss 8.009380690054968e-05, accuracy 0.6481481481481481\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m Epoch 1: train loss 0.00010084702080348507, accuracy 0.6296296296296297\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m Epoch 1: train loss 8.492331835441291e-05, accuracy 0.6666666666666666\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98088)\u001b[0m [Client 95] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98095)\u001b[0m [Client 7] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98094)\u001b[0m [Client 58] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98092)\u001b[0m [Client 28] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98091)\u001b[0m [Client 45] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98088)\u001b[0m [Client 55] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98093)\u001b[0m [Client 18] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98093)\u001b[0m [Client 5] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98088)\u001b[0m [Client 60] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98095)\u001b[0m [Client 86] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98094)\u001b[0m [Client 65] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98092)\u001b[0m [Client 72] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98091)\u001b[0m [Client 9] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98090)\u001b[0m [Client 85] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98088)\u001b[0m [Client 63] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98093)\u001b[0m [Client 23] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98089)\u001b[0m [Client 73] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98092)\u001b[0m [Client 13] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98095)\u001b[0m [Client 88] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98094)\u001b[0m [Client 57] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98090)\u001b[0m [Client 39] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98095)\u001b[0m [Client 98] evaluate, config: {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 13:01:34,622 | server.py:170 | evaluate_round received 0 results and 30 failures\n",
      "DEBUG flower 2023-02-01 13:01:34,623 | server.py:203 | fit_round: strategy sampled 30 clients (out of 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98090)\u001b[0m [Client 91] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98095)\u001b[0m [Client 27] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98089)\u001b[0m [Client 44] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98094)\u001b[0m [Client 40] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98092)\u001b[0m [Client 21] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98091)\u001b[0m [Client 19] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98088)\u001b[0m [Client 49] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98093)\u001b[0m [Client 79] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m [Client 60] fit, config: {'current_round': 98, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m Epoch 1: train loss 8.228541992139071e-05, accuracy 0.6851851851851852\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m [Client 95] fit, config: {'current_round': 98, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m Epoch 1: train loss 6.503315671579912e-05, accuracy 0.7777777777777778\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m [Client 79] fit, config: {'current_round': 98, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m Epoch 1: train loss 8.899637032300234e-05, accuracy 0.6666666666666666\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m [Client 14] fit, config: {'current_round': 98, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m Epoch 1: train loss 8.816639456199482e-05, accuracy 0.5925925925925926\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m [Client 58] fit, config: {'current_round': 98, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m Epoch 1: train loss 8.600605360697955e-05, accuracy 0.6481481481481481\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m [Client 10] fit, config: {'current_round': 98, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m [Client 70] fit, config: {'current_round': 98, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m Epoch 1: train loss 0.0001117586944019422, accuracy 0.6666666666666666\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m [Client 39] fit, config: {'current_round': 98, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m [Client 81] fit, config: {'current_round': 98, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m Epoch 1: train loss 0.0001034540546243079, accuracy 0.5740740740740741\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m Epoch 1: train loss 9.085239435080439e-05, accuracy 0.6481481481481481\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m [Client 77] fit, config: {'current_round': 98, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m Epoch 1: train loss 7.400460162898526e-05, accuracy 0.6851851851851852\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m [Client 78] fit, config: {'current_round': 98, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m Epoch 1: train loss 9.779907122720033e-05, accuracy 0.5740740740740741\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m Epoch 1: train loss 8.739529585000128e-05, accuracy 0.6666666666666666\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m [Client 6] fit, config: {'current_round': 98, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m Epoch 1: train loss 9.016067633638158e-05, accuracy 0.6296296296296297\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 13:01:37,051 | server.py:216 | fit_round received 30 results and 0 failures\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m [Client 17] fit, config: {'current_round': 98, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m Epoch 1: train loss 7.52902269596234e-05, accuracy 0.7592592592592593\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m [Client 34] fit, config: {'current_round': 98, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m Epoch 1: train loss 7.909452688181773e-05, accuracy 0.6666666666666666\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m [Client 16] fit, config: {'current_round': 98, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m Epoch 1: train loss 7.222701970022172e-05, accuracy 0.7592592592592593\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m [Client 56] fit, config: {'current_round': 98, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m Epoch 1: train loss 9.221286745741963e-05, accuracy 0.6111111111111112\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m [Client 0] fit, config: {'current_round': 98, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m Epoch 1: train loss 0.0001027786493068561, accuracy 0.5925925925925926\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m [Client 47] fit, config: {'current_round': 98, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m [Client 4] fit, config: {'current_round': 98, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m Epoch 1: train loss 0.00010682420543162152, accuracy 0.48148148148148145\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m [Client 49] fit, config: {'current_round': 98, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m Epoch 1: train loss 8.094657823676243e-05, accuracy 0.6851851851851852\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m [Client 75] fit, config: {'current_round': 98, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m Epoch 1: train loss 9.69792963587679e-05, accuracy 0.6481481481481481\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m [Client 90] fit, config: {'current_round': 98, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m Epoch 1: train loss 9.226441761711612e-05, accuracy 0.6296296296296297\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m [Client 76] fit, config: {'current_round': 98, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m Epoch 1: train loss 7.93304352555424e-05, accuracy 0.7407407407407407\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m Epoch 1: train loss 6.680743535980582e-05, accuracy 0.6481481481481481\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m [Client 29] fit, config: {'current_round': 98, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m [Client 7] fit, config: {'current_round': 98, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m [Client 53] fit, config: {'current_round': 98, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m Epoch 1: train loss 7.349400402745232e-05, accuracy 0.7222222222222222\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m [Client 65] fit, config: {'current_round': 98, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m Epoch 1: train loss 9.308526205131784e-05, accuracy 0.5370370370370371\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m [Client 9] fit, config: {'current_round': 98, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m Epoch 1: train loss 8.557787805330008e-05, accuracy 0.7407407407407407\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m [Client 54] fit, config: {'current_round': 98, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m Epoch 1: train loss 8.701557817403227e-05, accuracy 0.6666666666666666\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m Epoch 1: train loss 8.702823106432334e-05, accuracy 0.6296296296296297\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m [Client 83] fit, config: {'current_round': 98, 'local_epochs': 3}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 13:01:37,107 | server.py:157 | evaluate_round: strategy sampled 30 clients (out of 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving round 98 aggregated_parameters...\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m Epoch 1: train loss 8.944718138081953e-05, accuracy 0.7222222222222222\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m Epoch 1: train loss 8.52018129080534e-05, accuracy 0.6666666666666666\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98091)\u001b[0m [Client 90] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98091)\u001b[0m [Client 97] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98091)\u001b[0m [Client 4] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98091)\u001b[0m [Client 25] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98091)\u001b[0m [Client 84] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98092)\u001b[0m [Client 52] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98091)\u001b[0m [Client 2] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98093)\u001b[0m [Client 1] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98092)\u001b[0m [Client 11] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98093)\u001b[0m [Client 62] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98092)\u001b[0m [Client 98] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98091)\u001b[0m [Client 56] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98088)\u001b[0m [Client 72] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98093)\u001b[0m [Client 33] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98092)\u001b[0m [Client 61] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98092)\u001b[0m [Client 50] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98091)\u001b[0m [Client 53] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98091)\u001b[0m [Client 31] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98091)\u001b[0m [Client 36] evaluate, config: {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 13:01:39,442 | server.py:170 | evaluate_round received 0 results and 30 failures\n",
      "DEBUG flower 2023-02-01 13:01:39,443 | server.py:203 | fit_round: strategy sampled 30 clients (out of 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98091)\u001b[0m [Client 19] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98090)\u001b[0m [Client 42] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98088)\u001b[0m [Client 29] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98095)\u001b[0m [Client 69] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98093)\u001b[0m [Client 68] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98089)\u001b[0m [Client 46] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98094)\u001b[0m [Client 66] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98092)\u001b[0m [Client 78] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98093)\u001b[0m [Client 43] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98089)\u001b[0m [Client 73] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98092)\u001b[0m [Client 41] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m [Client 99] fit, config: {'current_round': 99, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m [Client 1] fit, config: {'current_round': 99, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m Epoch 1: train loss 7.984176045283675e-05, accuracy 0.6481481481481481\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m [Client 45] fit, config: {'current_round': 99, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m Epoch 1: train loss 7.958392961882055e-05, accuracy 0.7037037037037037\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m Epoch 1: train loss 8.110327325994149e-05, accuracy 0.6851851851851852\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m [Client 37] fit, config: {'current_round': 99, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m Epoch 1: train loss 6.202345684869215e-05, accuracy 0.7777777777777778\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m [Client 11] fit, config: {'current_round': 99, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m Epoch 1: train loss 7.923732482595369e-05, accuracy 0.7222222222222222\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m [Client 15] fit, config: {'current_round': 99, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m Epoch 1: train loss 0.00010807924263644964, accuracy 0.5740740740740741\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m [Client 52] fit, config: {'current_round': 99, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m Epoch 1: train loss 8.258331217803061e-05, accuracy 0.6851851851851852\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m [Client 85] fit, config: {'current_round': 99, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m Epoch 1: train loss 9.660488285589963e-05, accuracy 0.5925925925925926\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m [Client 0] fit, config: {'current_round': 99, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m Epoch 1: train loss 9.659004717832431e-05, accuracy 0.6851851851851852\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m [Client 48] fit, config: {'current_round': 99, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m Epoch 1: train loss 8.14634986454621e-05, accuracy 0.6851851851851852\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m [Client 66] fit, config: {'current_round': 99, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m Epoch 1: train loss 7.14795824023895e-05, accuracy 0.6851851851851852\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m [Client 83] fit, config: {'current_round': 99, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m Epoch 1: train loss 8.828045247355476e-05, accuracy 0.5925925925925926\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m [Client 5] fit, config: {'current_round': 99, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m [Client 87] fit, config: {'current_round': 99, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m Epoch 1: train loss 8.162931771948934e-05, accuracy 0.6296296296296297\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m [Client 90] fit, config: {'current_round': 99, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m Epoch 1: train loss 8.197333954740316e-05, accuracy 0.6851851851851852\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m Epoch 1: train loss 7.711072248639539e-05, accuracy 0.7592592592592593\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m [Client 74] fit, config: {'current_round': 99, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m Epoch 1: train loss 9.008080087369308e-05, accuracy 0.6851851851851852\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m [Client 64] fit, config: {'current_round': 99, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m Epoch 1: train loss 6.04382403253112e-05, accuracy 0.8148148148148148\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m [Client 36] fit, config: {'current_round': 99, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m [Client 96] fit, config: {'current_round': 99, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m Epoch 1: train loss 6.106545333750546e-05, accuracy 0.7037037037037037\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m [Client 95] fit, config: {'current_round': 99, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m [Client 33] fit, config: {'current_round': 99, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m Epoch 1: train loss 9.455437248107046e-05, accuracy 0.5555555555555556\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m [Client 6] fit, config: {'current_round': 99, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m Epoch 1: train loss 8.088723552646115e-05, accuracy 0.7037037037037037\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m [Client 57] fit, config: {'current_round': 99, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m Epoch 1: train loss 9.029610373545438e-05, accuracy 0.6111111111111112\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m Epoch 1: train loss 5.7532888604328036e-05, accuracy 0.7222222222222222\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 13:01:41,860 | server.py:216 | fit_round received 30 results and 0 failures\n",
      "DEBUG flower 2023-02-01 13:01:41,914 | server.py:157 | evaluate_round: strategy sampled 30 clients (out of 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m Epoch 1: train loss 8.627485658507794e-05, accuracy 0.6666666666666666\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m [Client 98] fit, config: {'current_round': 99, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m [Client 88] fit, config: {'current_round': 99, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m [Client 91] fit, config: {'current_round': 99, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m Epoch 1: train loss 8.562581206206232e-05, accuracy 0.5740740740740741\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m [Client 16] fit, config: {'current_round': 99, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98090)\u001b[0m Epoch 1: train loss 8.796045585768297e-05, accuracy 0.6481481481481481\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m [Client 7] fit, config: {'current_round': 99, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m Epoch 1: train loss 8.65957626956515e-05, accuracy 0.6666666666666666\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m Epoch 1: train loss 0.00010215862857876346, accuracy 0.6111111111111112\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m [Client 61] fit, config: {'current_round': 99, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98089)\u001b[0m Epoch 1: train loss 8.145141327986494e-05, accuracy 0.7222222222222222\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m Epoch 1: train loss 7.350264786509797e-05, accuracy 0.7407407407407407\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m [Client 32] fit, config: {'current_round': 99, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m Epoch 1: train loss 7.28707091184333e-05, accuracy 0.6481481481481481\n",
      "Saving round 99 aggregated_parameters...\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98088)\u001b[0m [Client 23] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98091)\u001b[0m [Client 37] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98088)\u001b[0m [Client 29] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98091)\u001b[0m [Client 63] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98091)\u001b[0m [Client 91] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98091)\u001b[0m [Client 40] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98088)\u001b[0m [Client 13] evaluate, config: {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 13:01:44,251 | server.py:170 | evaluate_round received 0 results and 30 failures\n",
      "DEBUG flower 2023-02-01 13:01:44,252 | server.py:203 | fit_round: strategy sampled 30 clients (out of 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98088)\u001b[0m [Client 4] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98091)\u001b[0m [Client 75] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98088)\u001b[0m [Client 43] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98091)\u001b[0m [Client 97] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98088)\u001b[0m [Client 80] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98089)\u001b[0m [Client 17] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98088)\u001b[0m [Client 78] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98089)\u001b[0m [Client 89] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98091)\u001b[0m [Client 3] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98088)\u001b[0m [Client 55] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98089)\u001b[0m [Client 22] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98092)\u001b[0m [Client 39] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98092)\u001b[0m [Client 21] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98091)\u001b[0m [Client 32] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98091)\u001b[0m [Client 74] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98090)\u001b[0m [Client 24] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98088)\u001b[0m [Client 58] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98095)\u001b[0m [Client 33] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98093)\u001b[0m [Client 93] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98089)\u001b[0m [Client 42] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98094)\u001b[0m [Client 34] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98088)\u001b[0m [Client 85] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98092)\u001b[0m [Client 18] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m [Client 19] fit, config: {'current_round': 100, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m Epoch 1: train loss 6.82334866723977e-05, accuracy 0.7222222222222222\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m [Client 76] fit, config: {'current_round': 100, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m [Client 0] fit, config: {'current_round': 100, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m Epoch 1: train loss 0.00010298675624653697, accuracy 0.5925925925925926\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m Epoch 1: train loss 6.593769649043679e-05, accuracy 0.6666666666666666\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m [Client 87] fit, config: {'current_round': 100, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m Epoch 1: train loss 7.56740482756868e-05, accuracy 0.7222222222222222\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m [Client 35] fit, config: {'current_round': 100, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m Epoch 1: train loss 8.184144826373085e-05, accuracy 0.7037037037037037\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m [Client 8] fit, config: {'current_round': 100, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m Epoch 1: train loss 8.308675023727119e-05, accuracy 0.6666666666666666\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m [Client 68] fit, config: {'current_round': 100, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m Epoch 1: train loss 7.581977115478367e-05, accuracy 0.6666666666666666\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m [Client 97] fit, config: {'current_round': 100, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m [Client 54] fit, config: {'current_round': 100, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m Epoch 1: train loss 8.642130705993623e-05, accuracy 0.6666666666666666\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m [Client 84] fit, config: {'current_round': 100, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m Epoch 1: train loss 7.906318933237344e-05, accuracy 0.7037037037037037\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m Epoch 1: train loss 0.00011395024921512231, accuracy 0.6111111111111112\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m [Client 73] fit, config: {'current_round': 100, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m Epoch 1: train loss 9.125012729782611e-05, accuracy 0.6666666666666666\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m [Client 80] fit, config: {'current_round': 100, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m Epoch 1: train loss 6.585464143427089e-05, accuracy 0.8148148148148148\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m [Client 45] fit, config: {'current_round': 100, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m Epoch 1: train loss 8.713957504369318e-05, accuracy 0.6296296296296297\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m [Client 39] fit, config: {'current_round': 100, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m [Client 43] fit, config: {'current_round': 100, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m Epoch 1: train loss 8.46186449052766e-05, accuracy 0.6851851851851852\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m Epoch 1: train loss 7.364664634224027e-05, accuracy 0.6666666666666666\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m [Client 40] fit, config: {'current_round': 100, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98088)\u001b[0m Epoch 1: train loss 7.109621947165579e-05, accuracy 0.6851851851851852\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m [Client 58] fit, config: {'current_round': 100, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m Epoch 1: train loss 8.410996088059619e-05, accuracy 0.6666666666666666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 13:01:46,605 | server.py:216 | fit_round received 30 results and 0 failures\n",
      "DEBUG flower 2023-02-01 13:01:46,662 | server.py:157 | evaluate_round: strategy sampled 30 clients (out of 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m [Client 36] fit, config: {'current_round': 100, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m Epoch 1: train loss 9.301487443735823e-05, accuracy 0.6296296296296297\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m [Client 95] fit, config: {'current_round': 100, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m Epoch 1: train loss 6.379406113410369e-05, accuracy 0.7962962962962963\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m [Client 65] fit, config: {'current_round': 100, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m Epoch 1: train loss 8.90104565769434e-05, accuracy 0.5925925925925926\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m [Client 46] fit, config: {'current_round': 100, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m [Client 60] fit, config: {'current_round': 100, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m Epoch 1: train loss 8.061915286816657e-05, accuracy 0.6851851851851852\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m [Client 63] fit, config: {'current_round': 100, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m Epoch 1: train loss 6.14103046245873e-05, accuracy 0.7777777777777778\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m Epoch 1: train loss 8.917355444282293e-05, accuracy 0.5740740740740741\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m [Client 24] fit, config: {'current_round': 100, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m Epoch 1: train loss 7.355849083978683e-05, accuracy 0.6851851851851852\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m [Client 23] fit, config: {'current_round': 100, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98095)\u001b[0m Epoch 1: train loss 9.378817776450887e-05, accuracy 0.6481481481481481\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m [Client 48] fit, config: {'current_round': 100, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m Epoch 1: train loss 7.970992737682536e-05, accuracy 0.6481481481481481\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m [Client 71] fit, config: {'current_round': 100, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98091)\u001b[0m Epoch 1: train loss 6.991934060351923e-05, accuracy 0.7592592592592593\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m [Client 72] fit, config: {'current_round': 100, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98093)\u001b[0m Epoch 1: train loss 6.954040145501494e-05, accuracy 0.8148148148148148\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m [Client 78] fit, config: {'current_round': 100, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m [Client 44] fit, config: {'current_round': 100, 'local_epochs': 3}\n",
      "Saving round 100 aggregated_parameters...\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98094)\u001b[0m Epoch 1: train loss 9.575542935635895e-05, accuracy 0.5555555555555556\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=98092)\u001b[0m Epoch 1: train loss 9.420239075552672e-05, accuracy 0.7037037037037037\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98092)\u001b[0m [Client 87] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98094)\u001b[0m [Client 98] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98094)\u001b[0m [Client 43] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98092)\u001b[0m [Client 86] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98092)\u001b[0m [Client 80] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98092)\u001b[0m [Client 83] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98091)\u001b[0m [Client 35] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98093)\u001b[0m [Client 30] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98094)\u001b[0m [Client 95] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98092)\u001b[0m [Client 18] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98092)\u001b[0m [Client 79] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98092)\u001b[0m [Client 38] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98091)\u001b[0m [Client 47] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98093)\u001b[0m [Client 10] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98092)\u001b[0m [Client 77] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98093)\u001b[0m [Client 53] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98093)\u001b[0m [Client 59] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98093)\u001b[0m [Client 74] evaluate, config: {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-02-01 13:01:48,944 | server.py:170 | evaluate_round received 0 results and 30 failures\n",
      "INFO flower 2023-02-01 13:01:48,945 | server.py:138 | FL finished in 448.250414866\n",
      "INFO flower 2023-02-01 13:01:48,949 | app.py:178 | app_fit: losses_distributed []\n",
      "INFO flower 2023-02-01 13:01:48,949 | app.py:179 | app_fit: metrics_distributed {}\n",
      "INFO flower 2023-02-01 13:01:48,950 | app.py:180 | app_fit: losses_centralized []\n",
      "INFO flower 2023-02-01 13:01:48,950 | app.py:181 | app_fit: metrics_centralized {}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98093)\u001b[0m [Client 34] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98092)\u001b[0m [Client 33] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98091)\u001b[0m [Client 28] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98091)\u001b[0m [Client 90] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98090)\u001b[0m [Client 76] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98088)\u001b[0m [Client 36] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98095)\u001b[0m [Client 9] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98095)\u001b[0m [Client 15] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98093)\u001b[0m [Client 29] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98089)\u001b[0m [Client 91] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98094)\u001b[0m [Client 51] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=98092)\u001b[0m [Client 44] evaluate, config: {}\n"
     ]
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def fit_config(rnd: int):\n",
    "    config = {\n",
    "        \"current_round\": rnd,\n",
    "        \"local_epochs\": LOCAL_EPOCH,\n",
    "    }\n",
    "    return config\n",
    "\n",
    "##################################################################################\n",
    "\n",
    "class SaveModelStrategy(fl.server.strategy.FedAvg):\n",
    "    def aggregate_fit(\n",
    "        self,\n",
    "        rnd: int,\n",
    "        results: List[Tuple[fl.server.client_proxy.ClientProxy, fl.common.FitRes]],\n",
    "        failures: List[BaseException],\n",
    "    ) -> Optional[fl.common.Weights]:\n",
    "        \n",
    "        # Aggregate model weights using weighted average and store checkpoint\n",
    "        aggregated_parameters_tuple = super().aggregate_fit(rnd, results, failures)\n",
    "        aggregated_parameters, _ = aggregated_parameters_tuple\n",
    "        # log_dict['aggregated_parameters']=aggregated_parameters\n",
    "        \n",
    "        if aggregated_parameters is not None:\n",
    "            print(f\"Saving round {rnd} aggregated_parameters...\")\n",
    "            # Convert `Parameters` to `List[np.ndarray]`\n",
    "            aggregated_weights: List[np.ndarray] = fl.common.parameters_to_weights(aggregated_parameters)\n",
    "            \n",
    "            # Convert `List[np.ndarray]` to PyTorch`state_dict`\n",
    "            params_dict = zip(Net().state_dict().keys(), aggregated_weights)\n",
    "            state_dict = OrderedDict({k: torch.tensor(v) for k, v in params_dict})\n",
    "            \n",
    "            net = Net().to(DEVICE)\n",
    "            net.load_state_dict(state_dict, strict=True)\n",
    "            \n",
    "            # torch.save(Net().state_dict(), PATH_TO_EXPERIMENT + f\"model_round_{rnd}.pth\")\n",
    "            torch.save(net.state_dict(), os.getcwd() + '/' + str(rnd) + '.pth')\n",
    "            \n",
    "        return aggregated_parameters_tuple \n",
    "\n",
    "\n",
    "##################################################################################\n",
    "    \n",
    "# Create strategy and run server\n",
    "strategy = SaveModelStrategy(\n",
    "    \n",
    "    # fl.server.strategy.FedAvg(  # .FedAdagrad(    (As an alternative).\n",
    "    fraction_fit=0.3,  # Train on 30% of clients (each round)\n",
    "    fraction_eval=0.3,  # Evaluate on 30% of clients (each round)\n",
    "    min_fit_clients=3,\n",
    "    min_eval_clients=3,\n",
    "    min_available_clients=NUM_DEVICES,\n",
    "    \n",
    "    initial_parameters=fl.common.weights_to_parameters(get_parameters(Net())),\n",
    "    \n",
    "    on_fit_config_fn=fit_config,\n",
    "    # To evaluate aggregated model parameters on the server-side, open evaluate function above and run below:\n",
    "    # eval_fn=evaluate,  # Pass the evaluation function\n",
    "    # (same arguments as FedAvg here)\n",
    ")\n",
    "    \n",
    "\"\"\"    \n",
    "strategy = fl.server.strategy.FedAvg(  # .FedAdagrad(    (As an alternative).\n",
    "    fraction_fit=0.3,  # Train on 30% of clients (each round)\n",
    "    fraction_eval=0.3,  # Evaluate on 30% of clients (each round)\n",
    "    min_fit_clients=3,\n",
    "    min_eval_clients=3,\n",
    "    min_available_clients=NUM_DEVICES,\n",
    "    \n",
    "    initial_parameters=fl.common.weights_to_parameters(get_parameters(Net())),\n",
    "    \n",
    "    on_fit_config_fn=fit_config,\n",
    "    # To evaluate aggregated model parameters on the server-side, open evaluate function above and run below:\n",
    "    # eval_fn=evaluate,  # Pass the evaluation function\n",
    ")\n",
    "\"\"\"\n",
    "\n",
    "fl.simulation.start_simulation(\n",
    "    client_fn=client_fn,\n",
    "    num_clients=NUM_DEVICES,\n",
    "    num_rounds=NUM_ROUNDS,\n",
    "    strategy=strategy,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec28e947-d5d0-4105-beef-afccffee134c",
   "metadata": {},
   "source": [
    "***\n",
    "# Result Analysis:\n",
    "***\n",
    "## Helper Function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "078e9167-7429-4899-a21f-4b42a2251d38",
   "metadata": {},
   "outputs": [],
   "source": [
    "def take_global_model():\n",
    "    \n",
    "    GM = Net().to(device=DEVICE)\n",
    "    \n",
    "    PATH = os.getcwd() + '/' + str(NUM_ROUNDS) + '.pth'\n",
    "    state_dict = torch.load(PATH)\n",
    "    \n",
    "    GM.load_state_dict(state_dict)\n",
    "    \n",
    "    return GM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1f255a23-04b3-4863-923b-ffd66f5d3048",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GM loss and acc: 0.013445634967088699 0.6622\n"
     ]
    }
   ],
   "source": [
    "GM = take_global_model()\n",
    "GM_loss, GM_acc = test_model(GM, testloader)\n",
    "print('GM loss and acc:', GM_loss, GM_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a021e87-a9b1-45f9-b382-9e1287d7c1c0",
   "metadata": {},
   "source": [
    "***\n",
    "## Pruning Functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "37632487-3fbc-46aa-ac90-7361e2d4fd4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def take_sparsity(model):\n",
    "    \n",
    "    \n",
    "    conv1 = 100. * float(torch.sum(model.conv1.weight == 0)) / float(model.conv1.weight.nelement())\n",
    "    conv2 = 100. * float(torch.sum(model.conv2.weight == 0)) / float(model.conv2.weight.nelement())\n",
    "    \n",
    "    fc1 = 100. * float(torch.sum(model.fc1.weight == 0)) / float(model.fc1.weight.nelement())\n",
    "    fc2 = 100. * float(torch.sum(model.fc2.weight == 0)) / float(model.fc2.weight.nelement())\n",
    "    fc3 = 100. * float(torch.sum(model.fc3.weight == 0)) / float(model.fc3.weight.nelement())\n",
    "\n",
    "    global_sparsity = float(conv1 + conv2 + fc1 + fc2 + fc3) / 5.0\n",
    "    \n",
    "    print(\"Sparsity in conv1.weight: {:.2f}%\".format(conv1))\n",
    "    print(\"Sparsity in conv2.weight: {:.2f}%\".format(conv2))\n",
    "    \n",
    "    print(\"Sparsity in fc1.weight: {:.2f}%\".format(fc1))\n",
    "    print(\"Sparsity in fc2.weight: {:.2f}%\".format(fc2))\n",
    "    print(\"Sparsity in fc3.weight: {:.2f}%\".format(fc3))\n",
    "\n",
    "    print(\"Global sparsity: {:.2f}%\".format(global_sparsity))\n",
    "    \n",
    "    \n",
    "    return [conv1, conv2, fc1, fc2, fc3, global_sparsity]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3d1005d5-e255-4a86-8325-c504d1cd981b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def prune_model(model, threshold=0.5):\n",
    "    \n",
    "    # Search about prune.remove(layername, \"weight\")\n",
    "    \n",
    "    model = model.eval()\n",
    "\n",
    "    parameters_to_prune = (\n",
    "        (model.conv1, 'weight'),\n",
    "        (model.conv2, 'weight'),\n",
    "        (model.fc1, 'weight'),\n",
    "        (model.fc2, 'weight'),\n",
    "        (model.fc3, 'weight'),\n",
    "    )\n",
    "    \n",
    "    \n",
    "    prune.global_unstructured(parameters_to_prune,\n",
    "                              pruning_method=prune.L1Unstructured,\n",
    "                              amount=threshold,)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "301a29dd-3cba-4885-8f1b-9f9b5a9b3ae8",
   "metadata": {},
   "source": [
    "***\n",
    "## Results after Pruning:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9048b92a-66ca-468b-87fa-6e08e6db2c65",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " *******************************************************\n",
      "\n",
      " Threshold is: 0.1 \n",
      "\n",
      "Sparsity in conv1.weight: 3.33%\n",
      "Sparsity in conv2.weight: 6.33%\n",
      "Sparsity in fc1.weight: 11.22%\n",
      "Sparsity in fc2.weight: 5.68%\n",
      "Sparsity in fc3.weight: 3.93%\n",
      "Global sparsity: 6.10%\n",
      "\n",
      " Pruned GM1 loss and acc: [0.013407625448703766, 0.6619]\n",
      "\n",
      " *******************************************************\n",
      "\n",
      " Threshold is: 0.2 \n",
      "\n",
      "Sparsity in conv1.weight: 5.33%\n",
      "Sparsity in conv2.weight: 12.71%\n",
      "Sparsity in fc1.weight: 22.36%\n",
      "Sparsity in fc2.weight: 11.73%\n",
      "Sparsity in fc3.weight: 7.74%\n",
      "Global sparsity: 11.97%\n",
      "\n",
      " Pruned GM1 loss and acc: [0.013453949058055878, 0.6607]\n",
      "\n",
      " *******************************************************\n",
      "\n",
      " Threshold is: 0.3 \n",
      "\n",
      "Sparsity in conv1.weight: 7.33%\n",
      "Sparsity in conv2.weight: 19.50%\n",
      "Sparsity in fc1.weight: 33.51%\n",
      "Sparsity in fc2.weight: 17.56%\n",
      "Sparsity in fc3.weight: 12.50%\n",
      "Global sparsity: 18.08%\n",
      "\n",
      " Pruned GM1 loss and acc: [0.013822464418411255, 0.6518]\n",
      "\n",
      " *******************************************************\n",
      "\n",
      " Threshold is: 0.4 \n",
      "\n",
      "Sparsity in conv1.weight: 10.67%\n",
      "Sparsity in conv2.weight: 25.83%\n",
      "Sparsity in fc1.weight: 44.64%\n",
      "Sparsity in fc2.weight: 23.58%\n",
      "Sparsity in fc3.weight: 17.50%\n",
      "Global sparsity: 24.44%\n",
      "\n",
      " Pruned GM1 loss and acc: [0.014454128569364547, 0.633]\n",
      "\n",
      " *******************************************************\n",
      "\n",
      " Threshold is: 0.5 \n",
      "\n",
      "Sparsity in conv1.weight: 13.33%\n",
      "Sparsity in conv2.weight: 31.71%\n",
      "Sparsity in fc1.weight: 55.73%\n",
      "Sparsity in fc2.weight: 29.89%\n",
      "Sparsity in fc3.weight: 22.86%\n",
      "Global sparsity: 30.70%\n",
      "\n",
      " Pruned GM1 loss and acc: [0.014778010451793671, 0.6262]\n",
      "\n",
      " *******************************************************\n",
      "\n",
      " Threshold is: 0.6 \n",
      "\n",
      "Sparsity in conv1.weight: 17.33%\n",
      "Sparsity in conv2.weight: 38.12%\n",
      "Sparsity in fc1.weight: 66.85%\n",
      "Sparsity in fc2.weight: 35.97%\n",
      "Sparsity in fc3.weight: 26.90%\n",
      "Global sparsity: 37.04%\n",
      "\n",
      " Pruned GM1 loss and acc: [0.014424456441402436, 0.6463]\n",
      "\n",
      " *******************************************************\n",
      "\n",
      " Threshold is: 0.7 \n",
      "\n",
      "Sparsity in conv1.weight: 18.67%\n",
      "Sparsity in conv2.weight: 45.54%\n",
      "Sparsity in fc1.weight: 77.74%\n",
      "Sparsity in fc2.weight: 42.95%\n",
      "Sparsity in fc3.weight: 31.19%\n",
      "Global sparsity: 43.22%\n",
      "\n",
      " Pruned GM1 loss and acc: [0.015265482145547868, 0.6034]\n",
      "\n",
      " *******************************************************\n",
      "\n",
      " Threshold is: 0.8 \n",
      "\n",
      "Sparsity in conv1.weight: 20.67%\n",
      "Sparsity in conv2.weight: 54.04%\n",
      "Sparsity in fc1.weight: 88.41%\n",
      "Sparsity in fc2.weight: 50.62%\n",
      "Sparsity in fc3.weight: 36.55%\n",
      "Global sparsity: 50.06%\n",
      "\n",
      " Pruned GM1 loss and acc: [0.017763696455955505, 0.5513]\n",
      "\n",
      " *******************************************************\n",
      "\n",
      " Threshold is: 0.9 \n",
      "\n",
      "Sparsity in conv1.weight: 24.67%\n",
      "Sparsity in conv2.weight: 67.21%\n",
      "Sparsity in fc1.weight: 97.54%\n",
      "Sparsity in fc2.weight: 64.03%\n",
      "Sparsity in fc3.weight: 47.38%\n",
      "Global sparsity: 60.17%\n",
      "\n",
      " Pruned GM1 loss and acc: [0.02923840562105179, 0.4112]\n",
      "\n",
      " *******************************************************\n",
      "\n",
      " Threshold is: 1.0 \n",
      "\n",
      "Sparsity in conv1.weight: 100.00%\n",
      "Sparsity in conv2.weight: 100.00%\n",
      "Sparsity in fc1.weight: 100.00%\n",
      "Sparsity in fc2.weight: 100.00%\n",
      "Sparsity in fc3.weight: 100.00%\n",
      "Global sparsity: 100.00%\n",
      "\n",
      " Pruned GM1 loss and acc: [0.03618916342258453, 0.1]\n"
     ]
    }
   ],
   "source": [
    "threshold_arr = []\n",
    "sparsity_arr = []\n",
    "loss_and_acc_arr = []\n",
    "\n",
    "for t in range(1, 11):\n",
    "    \n",
    "    T = t/10\n",
    "    threshold_arr.append(T)\n",
    "    \n",
    "    print('\\n *******************************************************')\n",
    "    print('\\n Threshold is:', T, '\\n')\n",
    "    \n",
    "    GM1 = take_global_model()\n",
    "\n",
    "    temp_pruned_GM = prune_model(GM1, threshold=T) \n",
    "    sparsity_arr.append(take_sparsity(temp_pruned_GM))\n",
    "    \n",
    "    performance = test_model(temp_pruned_GM, testloader)\n",
    "    loss_and_acc_arr.append(performance)\n",
    "\n",
    "    print('\\n Pruned GM1 loss and acc:', performance)\n",
    "    \n",
    "sparsity_arr = np.array(sparsity_arr)\n",
    "\n",
    "loss_and_acc_arr = np.array(loss_and_acc_arr)\n",
    "loss_arr = loss_and_acc_arr[:,0]\n",
    "acc_arr = loss_and_acc_arr[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "507b0eb2-ab2d-43f2-a354-ed5e1c37bd5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Threshold</th>\n",
       "      <th>SFL Accuracy</th>\n",
       "      <th>GPFL Accuracy</th>\n",
       "      <th>SFL Loss</th>\n",
       "      <th>GPFL Loss</th>\n",
       "      <th>Participation</th>\n",
       "      <th>Global Sparsity</th>\n",
       "      <th>Conv1</th>\n",
       "      <th>Conv2</th>\n",
       "      <th>FC1</th>\n",
       "      <th>FC2</th>\n",
       "      <th>FC3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>GM</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1478</td>\n",
       "      <td>0.1478</td>\n",
       "      <td>0.036188</td>\n",
       "      <td>0.036188</td>\n",
       "      <td>100</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SM1</th>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1085</td>\n",
       "      <td>0.6619</td>\n",
       "      <td>0.036194</td>\n",
       "      <td>0.013408</td>\n",
       "      <td>200</td>\n",
       "      <td>6.099286</td>\n",
       "      <td>3.333333</td>\n",
       "      <td>6.333333</td>\n",
       "      <td>11.216667</td>\n",
       "      <td>5.684524</td>\n",
       "      <td>3.928571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SM2</th>\n",
       "      <td>0.2</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>0.6607</td>\n",
       "      <td>0.036187</td>\n",
       "      <td>0.013454</td>\n",
       "      <td>300</td>\n",
       "      <td>11.973690</td>\n",
       "      <td>5.333333</td>\n",
       "      <td>12.708333</td>\n",
       "      <td>22.362500</td>\n",
       "      <td>11.726190</td>\n",
       "      <td>7.738095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SM3</th>\n",
       "      <td>0.3</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>0.6518</td>\n",
       "      <td>0.036216</td>\n",
       "      <td>0.013822</td>\n",
       "      <td>400</td>\n",
       "      <td>18.081488</td>\n",
       "      <td>7.333333</td>\n",
       "      <td>19.500000</td>\n",
       "      <td>33.514583</td>\n",
       "      <td>17.559524</td>\n",
       "      <td>12.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SM4</th>\n",
       "      <td>0.4</td>\n",
       "      <td>0.1190</td>\n",
       "      <td>0.6330</td>\n",
       "      <td>0.036207</td>\n",
       "      <td>0.014454</td>\n",
       "      <td>500</td>\n",
       "      <td>24.444603</td>\n",
       "      <td>10.666667</td>\n",
       "      <td>25.833333</td>\n",
       "      <td>44.641667</td>\n",
       "      <td>23.581349</td>\n",
       "      <td>17.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SM5</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0853</td>\n",
       "      <td>0.6262</td>\n",
       "      <td>0.036201</td>\n",
       "      <td>0.014778</td>\n",
       "      <td>600</td>\n",
       "      <td>30.703353</td>\n",
       "      <td>13.333333</td>\n",
       "      <td>31.708333</td>\n",
       "      <td>55.727083</td>\n",
       "      <td>29.890873</td>\n",
       "      <td>22.857143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SM6</th>\n",
       "      <td>0.6</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>0.6463</td>\n",
       "      <td>0.036191</td>\n",
       "      <td>0.014424</td>\n",
       "      <td>700</td>\n",
       "      <td>37.037480</td>\n",
       "      <td>17.333333</td>\n",
       "      <td>38.125000</td>\n",
       "      <td>66.852083</td>\n",
       "      <td>35.972222</td>\n",
       "      <td>26.904762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SM7</th>\n",
       "      <td>0.7</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>0.6034</td>\n",
       "      <td>0.036172</td>\n",
       "      <td>0.015265</td>\n",
       "      <td>800</td>\n",
       "      <td>43.217798</td>\n",
       "      <td>18.666667</td>\n",
       "      <td>45.541667</td>\n",
       "      <td>77.743750</td>\n",
       "      <td>42.946429</td>\n",
       "      <td>31.190476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SM8</th>\n",
       "      <td>0.8</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>0.5513</td>\n",
       "      <td>0.036205</td>\n",
       "      <td>0.017764</td>\n",
       "      <td>900</td>\n",
       "      <td>50.057123</td>\n",
       "      <td>20.666667</td>\n",
       "      <td>54.041667</td>\n",
       "      <td>88.414583</td>\n",
       "      <td>50.615079</td>\n",
       "      <td>36.547619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SM9</th>\n",
       "      <td>0.9</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>0.4112</td>\n",
       "      <td>0.036168</td>\n",
       "      <td>0.029238</td>\n",
       "      <td>1000</td>\n",
       "      <td>60.165496</td>\n",
       "      <td>24.666667</td>\n",
       "      <td>67.208333</td>\n",
       "      <td>97.543750</td>\n",
       "      <td>64.027778</td>\n",
       "      <td>47.380952</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Threshold  SFL Accuracy  GPFL Accuracy  SFL Loss  GPFL Loss  \\\n",
       "GM         0.0        0.1478         0.1478  0.036188   0.036188   \n",
       "SM1        0.1        0.1085         0.6619  0.036194   0.013408   \n",
       "SM2        0.2        0.1000         0.6607  0.036187   0.013454   \n",
       "SM3        0.3        0.1000         0.6518  0.036216   0.013822   \n",
       "SM4        0.4        0.1190         0.6330  0.036207   0.014454   \n",
       "SM5        0.5        0.0853         0.6262  0.036201   0.014778   \n",
       "SM6        0.6        0.1000         0.6463  0.036191   0.014424   \n",
       "SM7        0.7        0.1000         0.6034  0.036172   0.015265   \n",
       "SM8        0.8        0.1000         0.5513  0.036205   0.017764   \n",
       "SM9        0.9        0.1000         0.4112  0.036168   0.029238   \n",
       "\n",
       "     Participation  Global Sparsity      Conv1      Conv2        FC1  \\\n",
       "GM             100         0.000000   0.000000   0.000000   0.000000   \n",
       "SM1            200         6.099286   3.333333   6.333333  11.216667   \n",
       "SM2            300        11.973690   5.333333  12.708333  22.362500   \n",
       "SM3            400        18.081488   7.333333  19.500000  33.514583   \n",
       "SM4            500        24.444603  10.666667  25.833333  44.641667   \n",
       "SM5            600        30.703353  13.333333  31.708333  55.727083   \n",
       "SM6            700        37.037480  17.333333  38.125000  66.852083   \n",
       "SM7            800        43.217798  18.666667  45.541667  77.743750   \n",
       "SM8            900        50.057123  20.666667  54.041667  88.414583   \n",
       "SM9           1000        60.165496  24.666667  67.208333  97.543750   \n",
       "\n",
       "           FC2        FC3  \n",
       "GM    0.000000   0.000000  \n",
       "SM1   5.684524   3.928571  \n",
       "SM2  11.726190   7.738095  \n",
       "SM3  17.559524  12.500000  \n",
       "SM4  23.581349  17.500000  \n",
       "SM5  29.890873  22.857143  \n",
       "SM6  35.972222  26.904762  \n",
       "SM7  42.946429  31.190476  \n",
       "SM8  50.615079  36.547619  \n",
       "SM9  64.027778  47.380952  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(data=sparsity_arr, columns=['Conv1', 'Conv2', 'FC1', 'FC2', 'FC3', 'Global Sparsity'])\n",
    "df[\"GPFL Accuracy\"] = acc_arr\n",
    "df[\"GPFL Loss\"] = loss_arr\n",
    "df[\"Threshold\"] = threshold_arr\n",
    "df = df[['Threshold', 'GPFL Accuracy', 'GPFL Loss', 'Global Sparsity', \n",
    "         'Conv1', 'Conv2', 'FC1', 'FC2', 'FC3']]\n",
    "df.loc[-1] = [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0] \n",
    "df.index = df.index + 1  \n",
    "df.sort_index(inplace=True) \n",
    "df['Participation'] = [x*100 for x in range(1, 11)] + [1000]\n",
    "df = df[:-1]\n",
    "# Add SFL Results:\n",
    "arr = [[], []]\n",
    "for t in range(0, 10):\n",
    "\n",
    "    T = t/10\n",
    "    \n",
    "    S_FL_GM = Net().to(device=DEVICE)\n",
    "    SM = prune_model(S_FL_GM, threshold=T)\n",
    "    l, a = test_model(SM, testloader)\n",
    "    \n",
    "    arr[0].append(l)\n",
    "    arr[1].append(a)\n",
    "\n",
    "df['SFL Loss'] = arr[0]\n",
    "df['SFL Accuracy'] = arr[1]\n",
    "\n",
    "\n",
    "df.loc[0, 'GPFL Accuracy'] = df.loc[0, 'SFL Accuracy']\n",
    "df.loc[0, 'GPFL Loss'] = df.loc[0, 'SFL Loss']\n",
    "\n",
    "df = df[['Threshold', 'SFL Accuracy', 'GPFL Accuracy', 'SFL Loss', 'GPFL Loss', 'Participation', \n",
    "         'Global Sparsity', 'Conv1', 'Conv2', 'FC1', 'FC2','FC3']]\n",
    "\n",
    "df = df.rename(index={0: 'GM', 1: 'SM1', 2: 'SM2', 3: 'SM3', 4: 'SM4', 5: 'SM5', 6: 'SM6', 7: 'SM7',\n",
    "                      8: 'SM8', 9: 'SM9'})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3d51ba3d-fc15-41fd-860e-c1c3294305a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Threshold</th>\n",
       "      <th>SFL Accuracy</th>\n",
       "      <th>GPFL Accuracy</th>\n",
       "      <th>SFL Loss</th>\n",
       "      <th>GPFL Loss</th>\n",
       "      <th>Participation</th>\n",
       "      <th>Global Sparsity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>GM</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1478</td>\n",
       "      <td>0.1478</td>\n",
       "      <td>0.036188</td>\n",
       "      <td>0.036188</td>\n",
       "      <td>100</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SM1</th>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1085</td>\n",
       "      <td>0.6619</td>\n",
       "      <td>0.036194</td>\n",
       "      <td>0.013408</td>\n",
       "      <td>200</td>\n",
       "      <td>6.099286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SM2</th>\n",
       "      <td>0.2</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>0.6607</td>\n",
       "      <td>0.036187</td>\n",
       "      <td>0.013454</td>\n",
       "      <td>300</td>\n",
       "      <td>11.973690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SM3</th>\n",
       "      <td>0.3</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>0.6518</td>\n",
       "      <td>0.036216</td>\n",
       "      <td>0.013822</td>\n",
       "      <td>400</td>\n",
       "      <td>18.081488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SM4</th>\n",
       "      <td>0.4</td>\n",
       "      <td>0.1190</td>\n",
       "      <td>0.6330</td>\n",
       "      <td>0.036207</td>\n",
       "      <td>0.014454</td>\n",
       "      <td>500</td>\n",
       "      <td>24.444603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SM5</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0853</td>\n",
       "      <td>0.6262</td>\n",
       "      <td>0.036201</td>\n",
       "      <td>0.014778</td>\n",
       "      <td>600</td>\n",
       "      <td>30.703353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SM6</th>\n",
       "      <td>0.6</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>0.6463</td>\n",
       "      <td>0.036191</td>\n",
       "      <td>0.014424</td>\n",
       "      <td>700</td>\n",
       "      <td>37.037480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SM7</th>\n",
       "      <td>0.7</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>0.6034</td>\n",
       "      <td>0.036172</td>\n",
       "      <td>0.015265</td>\n",
       "      <td>800</td>\n",
       "      <td>43.217798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SM8</th>\n",
       "      <td>0.8</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>0.5513</td>\n",
       "      <td>0.036205</td>\n",
       "      <td>0.017764</td>\n",
       "      <td>900</td>\n",
       "      <td>50.057123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SM9</th>\n",
       "      <td>0.9</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>0.4112</td>\n",
       "      <td>0.036168</td>\n",
       "      <td>0.029238</td>\n",
       "      <td>1000</td>\n",
       "      <td>60.165496</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Threshold  SFL Accuracy  GPFL Accuracy  SFL Loss  GPFL Loss  \\\n",
       "GM         0.0        0.1478         0.1478  0.036188   0.036188   \n",
       "SM1        0.1        0.1085         0.6619  0.036194   0.013408   \n",
       "SM2        0.2        0.1000         0.6607  0.036187   0.013454   \n",
       "SM3        0.3        0.1000         0.6518  0.036216   0.013822   \n",
       "SM4        0.4        0.1190         0.6330  0.036207   0.014454   \n",
       "SM5        0.5        0.0853         0.6262  0.036201   0.014778   \n",
       "SM6        0.6        0.1000         0.6463  0.036191   0.014424   \n",
       "SM7        0.7        0.1000         0.6034  0.036172   0.015265   \n",
       "SM8        0.8        0.1000         0.5513  0.036205   0.017764   \n",
       "SM9        0.9        0.1000         0.4112  0.036168   0.029238   \n",
       "\n",
       "     Participation  Global Sparsity  \n",
       "GM             100         0.000000  \n",
       "SM1            200         6.099286  \n",
       "SM2            300        11.973690  \n",
       "SM3            400        18.081488  \n",
       "SM4            500        24.444603  \n",
       "SM5            600        30.703353  \n",
       "SM6            700        37.037480  \n",
       "SM7            800        43.217798  \n",
       "SM8            900        50.057123  \n",
       "SM9           1000        60.165496  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final = df[['Threshold', 'SFL Accuracy', 'GPFL Accuracy', 'SFL Loss', 'GPFL Loss', \n",
    "               'Participation', 'Global Sparsity']]\n",
    "df_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "49b8af25-ea5f-4970-baf6-eed81e11e36b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lrrrrrrr}\n",
      " & Threshold & SFL Accuracy & GPFL Accuracy & SFL Loss & GPFL Loss & Participation & Global Sparsity \\\\\n",
      "GM & 0.000000 & 0.147800 & 0.147800 & 0.036188 & 0.036188 & 100 & 0.000000 \\\\\n",
      "SM1 & 0.100000 & 0.108500 & 0.661900 & 0.036194 & 0.013408 & 200 & 6.099286 \\\\\n",
      "SM2 & 0.200000 & 0.100000 & 0.660700 & 0.036187 & 0.013454 & 300 & 11.973690 \\\\\n",
      "SM3 & 0.300000 & 0.100000 & 0.651800 & 0.036216 & 0.013822 & 400 & 18.081488 \\\\\n",
      "SM4 & 0.400000 & 0.119000 & 0.633000 & 0.036207 & 0.014454 & 500 & 24.444603 \\\\\n",
      "SM5 & 0.500000 & 0.085300 & 0.626200 & 0.036201 & 0.014778 & 600 & 30.703353 \\\\\n",
      "SM6 & 0.600000 & 0.100000 & 0.646300 & 0.036191 & 0.014424 & 700 & 37.037480 \\\\\n",
      "SM7 & 0.700000 & 0.100000 & 0.603400 & 0.036172 & 0.015265 & 800 & 43.217798 \\\\\n",
      "SM8 & 0.800000 & 0.100000 & 0.551300 & 0.036205 & 0.017764 & 900 & 50.057123 \\\\\n",
      "SM9 & 0.900000 & 0.100000 & 0.411200 & 0.036168 & 0.029238 & \\cellcolor{red} \\bfseries 1000 & 60.165496 \\\\\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "s = df_final.style.highlight_max(axis=None, props='cellcolor:{red}; bfseries: ;')\n",
    "\n",
    "print(s.to_latex()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "06794b74-2bf0-4ad0-a61a-7d585e4d9c91",
   "metadata": {},
   "outputs": [],
   "source": [
    "table_latex_version = {'table_latex_version': s.to_latex()}\n",
    "\n",
    "with open('table_latex_version.txt', 'w') as f:\n",
    "    f.write(json.dumps(table_latex_version))\n",
    "\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8341bd9-4c62-405c-af96-ce2fb62203dc",
   "metadata": {
    "tags": []
   },
   "source": [
    "***\n",
    "# Pruning Result with S-FL Visualisation:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71822bb8-1f47-465d-a1b4-7f0d108dd90e",
   "metadata": {},
   "source": [
    "***\n",
    "### Initial Accuracy & Participation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e3c45fd5-4fbb-4f01-9d5e-a8d05c737bcd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# create figure and axis objects with subplots()\n",
    "fig, ax = plt.subplots()\n",
    "plt.grid()\n",
    "\n",
    "# Our Algo. Acc.\n",
    "ax.plot(df['Threshold'].values, \n",
    "        df['GPFL Accuracy'].values, \n",
    "        color=\"green\", \n",
    "        label='Accuracy of GPFL', \n",
    "        marker=\"o\")\n",
    "\n",
    "# S-FL Acc.\n",
    "ax.plot(df['Threshold'].values, \n",
    "        df['SFL Accuracy'].values, \n",
    "        color=\"red\", \n",
    "        label='S-FL Accuracy',\n",
    "        marker=\"o\")\n",
    "\n",
    "plt.legend(framealpha=1, frameon=True, bbox_to_anchor=(0.38, 1.2));\n",
    "\n",
    "# set x-axis label\n",
    "ax.set_xlabel(\"Threshold Values\", fontweight='bold', fontsize=14)\n",
    "# set y-axis label\n",
    "ax.set_ylabel(\"Accuracy of Models\", color=\"black\", fontweight='bold', fontsize=14)\n",
    "\n",
    "# twin object for two different y-axis on the sample plot\n",
    "ax2=ax.twinx()\n",
    "# make a plot with different y-axis using second axis object\n",
    "ax2.plot(df['Threshold'].values, \n",
    "         df['Participation'].values, \n",
    "         color=\"blue\", \n",
    "         label='Participation', \n",
    "         marker=\"x\")\n",
    "ax2.set_ylabel(\"Number of Participated Devices\", color=\"black\", fontweight='bold', fontsize=14)\n",
    "# ax2.legend(loc='upper left', frameon=False)\n",
    "\n",
    "#plt.legend(lines[:2], ['first', 'second']);\n",
    "# plt.title(\"Initial Accuracy values of Standard Federated Learning\", fontweight=\"bold\")\n",
    "plt.legend(framealpha=1, frameon=True, bbox_to_anchor=(1.015, 1.15));\n",
    "plt.show()\n",
    "\n",
    "# save the plot as a file\n",
    "fig.savefig('Accuracy&Participation vs Threshold with S-FL.jpg', \n",
    "            format='jpeg', dpi=100, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8413aee5-465a-4f20-9212-dd1c9ed34e96",
   "metadata": {},
   "source": [
    "### Initial Accuracy & Model Sparsity:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "75eed462-ba81-4d8b-b6d3-b7066d77bc87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# create figure and axis objects with subplots()\n",
    "fig, ax = plt.subplots()\n",
    "plt.grid()\n",
    "# make a plot\n",
    "ax.plot(df['Threshold'].values, \n",
    "        df['GPFL Accuracy'].values, \n",
    "        label='Accuracy of GPFL', \n",
    "        color=\"green\", \n",
    "        marker=\"o\")\n",
    "\n",
    "ax.plot(df['Threshold'].values, \n",
    "        df['SFL Accuracy'].values, \n",
    "        label='S-FL Accuracy', \n",
    "        color=\"red\", \n",
    "        marker=\"o\")\n",
    "\n",
    "plt.legend(framealpha=1, frameon=True, bbox_to_anchor=(0.38, 1.2));\n",
    "\n",
    "# set x-axis label\n",
    "ax.set_xlabel(\"Threshold Values\", fontweight='bold', fontsize = 14)\n",
    "# set y-axis label\n",
    "ax.set_ylabel(\"Accuracy of Models\", color=\"black\", fontweight='bold', fontsize=14)\n",
    "\n",
    "# twin object for two different y-axis on the sample plot\n",
    "ax2=ax.twinx()\n",
    "# make a plot with different y-axis using second axis object\n",
    "ax2.plot(df['Threshold'].values, \n",
    "         df['Global Sparsity'].values, \n",
    "         label='Global Sparsity', \n",
    "         color=\"orange\", \n",
    "         marker=\"x\")\n",
    "ax2.set_ylabel(\"Global Sparsity\", color=\"black\", fontweight='bold', fontsize=14)\n",
    "\n",
    "plt.legend(framealpha=1, frameon=True, bbox_to_anchor=(1.015, 1.15));\n",
    "plt.show()\n",
    "# save the plot as a file\n",
    "fig.savefig('Accuracy&Global_Sparsity vs Threshold with S-FL.jpg', \n",
    "            format='jpeg', dpi=100, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b3b4a06-04ff-4eb6-86f3-7c64a96a94c0",
   "metadata": {},
   "source": [
    "***\n",
    "### Initial Loss & Partcipation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5af61e8c-93f3-4365-bf25-cd926113242a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# create figure and axis objects with subplots()\n",
    "fig, ax = plt.subplots()\n",
    "plt.grid()\n",
    "# make a plot\n",
    "ax.plot(df['Threshold'].values, \n",
    "        df['GPFL Loss'].values, \n",
    "        color=\"green\", \n",
    "        label='Loss of GPFL', \n",
    "        marker=\"o\")\n",
    "\n",
    "ax.plot(df['Threshold'].values, \n",
    "        df['SFL Loss'].values, \n",
    "        color=\"red\", \n",
    "        label='S-FL Loss', \n",
    "        marker=\"o\")\n",
    "\n",
    "plt.legend(framealpha=1, frameon=True, bbox_to_anchor=(0.31, 1.2));\n",
    "\n",
    "# set x-axis label\n",
    "ax.set_xlabel(\"Threshold Values\", fontweight='bold', fontsize = 14)\n",
    "# set y-axis label\n",
    "ax.set_ylabel(\"Loss\", color=\"black\", fontweight='bold', fontsize=14)\n",
    "\n",
    "# twin object for two different y-axis on the sample plot\n",
    "ax2=ax.twinx()\n",
    "# make a plot with different y-axis using second axis object\n",
    "ax2.plot(df['Threshold'].values, \n",
    "         df['Participation'].values, \n",
    "         label='Participation', \n",
    "         color=\"blue\", \n",
    "         marker=\"x\")\n",
    "ax2.set_ylabel(\"Number of Participated Devices\", fontweight='bold', color=\"black\", fontsize=14)\n",
    "\n",
    "plt.legend(framealpha=1, frameon=True, bbox_to_anchor=(1.015, 1.15));\n",
    "plt.show()\n",
    "# save the plot as a file\n",
    "fig.savefig('Loss&Participation vs Threshold with S-FL.jpg', \n",
    "            format='jpeg', dpi=100, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b71c0b48-2915-42cc-a6d4-b853e12937cc",
   "metadata": {},
   "source": [
    "### Loss & Model Sparsity:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d83de388-7347-4a8e-80d7-50ccacaa5144",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# create figure and axis objects with subplots()\n",
    "fig, ax = plt.subplots()\n",
    "plt.grid()\n",
    "# make a plot\n",
    "ax.plot(df['Threshold'].values, \n",
    "        df['GPFL Loss'].values, \n",
    "        color=\"green\", \n",
    "        label='Loss of GPFL', \n",
    "        marker=\"o\")\n",
    "\n",
    "ax.plot(df['Threshold'].values, \n",
    "        df['SFL Loss'], \n",
    "        color=\"red\", \n",
    "        label='S-FL Loss',\n",
    "        marker=\"o\")\n",
    "\n",
    "plt.legend(framealpha=1, frameon=True, bbox_to_anchor=(0.31, 1.2));\n",
    "\n",
    "# set x-axis label\n",
    "ax.set_xlabel(\"Threshold Values\", fontweight='bold', fontsize = 14)\n",
    "# set y-axis label\n",
    "ax.set_ylabel(\"Loss\", color=\"black\", fontweight='bold', fontsize=14)\n",
    "\n",
    "# twin object for two different y-axis on the sample plot\n",
    "ax2=ax.twinx()\n",
    "# make a plot with different y-axis using second axis object\n",
    "ax2.plot(df['Threshold'].values, \n",
    "         df['Global Sparsity'].values, \n",
    "         label='Global Sparsity', \n",
    "         color=\"orange\", \n",
    "         marker=\"x\")\n",
    "ax2.set_ylabel(\"Global Sparsity\",color=\"black\", fontweight='bold', fontsize=14)\n",
    "\n",
    "plt.legend(framealpha=1, frameon=True, bbox_to_anchor=(1.015, 1.15));\n",
    "plt.show()\n",
    "# save the plot as a file\n",
    "fig.savefig('Loss&Global_Sparsity vs Threshold with S-FL.jpg', \n",
    "            format='jpeg', dpi=100, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80f572ef-7973-4e3b-abb2-87225ad378c2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
